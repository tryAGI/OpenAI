openapi: 3.0.1
info:
  title: OpenAI API
  description: The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
  termsOfService: https://openai.com/policies/terms-of-use
  contact:
    name: OpenAI Support
    url: https://help.openai.com/
  license:
    name: MIT
    url: https://github.com/openai/openai-openapi/blob/master/LICENSE
  version: '2.3.0'
servers:
  - url: https://api.openai.com/v1
paths:
  /assistants:
    get:
      tags:
        - Assistants
      summary: Returns a list of assistants.
      operationId: listAssistants
      parameters:
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: before
          in: query
          description: "A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListAssistantsResponse'
      x-oaiMeta:
        name: List assistants
        group: assistants
        beta: true
        returns: 'A list of [assistant](/docs/api-reference/assistants/object) objects.'
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/assistants?order=desc&limit=20\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nmy_assistants = client.beta.assistants.list(\n    order=\"desc\",\n    limit=\"20\",\n)\nprint(my_assistants.data)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const myAssistants = await openai.beta.assistants.list({\n    order: \"desc\",\n    limit: \"20\",\n  });\n\n  console.log(myAssistants.data);\n}\n\nmain();"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"asst_abc123\",\n      \"object\": \"assistant\",\n      \"created_at\": 1698982736,\n      \"name\": \"Coding Tutor\",\n      \"description\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": \"You are a helpful assistant designed to make me better at coding!\",\n      \"tools\": [],\n      \"tool_resources\": {},\n      \"metadata\": {},\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\": \"auto\"\n    },\n    {\n      \"id\": \"asst_abc456\",\n      \"object\": \"assistant\",\n      \"created_at\": 1698982718,\n      \"name\": \"My Assistant\",\n      \"description\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": \"You are a helpful assistant designed to make me better at coding!\",\n      \"tools\": [],\n      \"tool_resources\": {},\n      \"metadata\": {},\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\": \"auto\"\n    },\n    {\n      \"id\": \"asst_abc789\",\n      \"object\": \"assistant\",\n      \"created_at\": 1698982643,\n      \"name\": null,\n      \"description\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": null,\n      \"tools\": [],\n      \"tool_resources\": {},\n      \"metadata\": {},\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\": \"auto\"\n    }\n  ],\n  \"first_id\": \"asst_abc123\",\n  \"last_id\": \"asst_abc789\",\n  \"has_more\": false\n}\n"
    post:
      tags:
        - Assistants
      summary: Create an assistant with a model and instructions.
      operationId: createAssistant
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateAssistantRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantObject'
      x-oaiMeta:
        name: Create assistant
        group: assistants
        beta: true
        returns: 'An [assistant](/docs/api-reference/assistants/object) object.'
        examples:
          - title: Code Interpreter
            request:
              curl: "curl \"https://api.openai.com/v1/assistants\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"instructions\": \"You are a personal math tutor. When asked a question, write and run Python code to answer the question.\",\n    \"name\": \"Math Tutor\",\n    \"tools\": [{\"type\": \"code_interpreter\"}],\n    \"model\": \"gpt-4o\"\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\nmy_assistant = client.beta.assistants.create(\n    instructions=\"You are a personal math tutor. When asked a question, write and run Python code to answer the question.\",\n    name=\"Math Tutor\",\n    tools=[{\"type\": \"code_interpreter\"}],\n    model=\"gpt-4o\",\n)\nprint(my_assistant)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const myAssistant = await openai.beta.assistants.create({\n    instructions:\n      \"You are a personal math tutor. When asked a question, write and run Python code to answer the question.\",\n    name: \"Math Tutor\",\n    tools: [{ type: \"code_interpreter\" }],\n    model: \"gpt-4o\",\n  });\n\n  console.log(myAssistant);\n}\n\nmain();"
            response: "{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n  \"created_at\": 1698984975,\n  \"name\": \"Math Tutor\",\n  \"description\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You are a personal math tutor. When asked a question, write and run Python code to answer the question.\",\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n  \"top_p\": 1.0,\n  \"temperature\": 1.0,\n  \"response_format\": \"auto\"\n}\n"
          - title: Files
            request:
              curl: "curl https://api.openai.com/v1/assistants \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"instructions\": \"You are an HR bot, and you have access to files to answer employee questions about company policies.\",\n    \"tools\": [{\"type\": \"file_search\"}],\n    \"tool_resources\": {\"file_search\": {\"vector_store_ids\": [\"vs_123\"]}},\n    \"model\": \"gpt-4o\"\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\nmy_assistant = client.beta.assistants.create(\n    instructions=\"You are an HR bot, and you have access to files to answer employee questions about company policies.\",\n    name=\"HR Helper\",\n    tools=[{\"type\": \"file_search\"}],\n    tool_resources={\"file_search\": {\"vector_store_ids\": [\"vs_123\"]}},\n    model=\"gpt-4o\"\n)\nprint(my_assistant)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const myAssistant = await openai.beta.assistants.create({\n    instructions:\n      \"You are an HR bot, and you have access to files to answer employee questions about company policies.\",\n    name: \"HR Helper\",\n    tools: [{ type: \"file_search\" }],\n    tool_resources: {\n      file_search: {\n        vector_store_ids: [\"vs_123\"]\n      }\n    },\n    model: \"gpt-4o\"\n  });\n\n  console.log(myAssistant);\n}\n\nmain();"
            response: "{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n  \"created_at\": 1699009403,\n  \"name\": \"HR Helper\",\n  \"description\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You are an HR bot, and you have access to files to answer employee questions about company policies.\",\n  \"tools\": [\n    {\n      \"type\": \"file_search\"\n    }\n  ],\n  \"tool_resources\": {\n    \"file_search\": {\n      \"vector_store_ids\": [\"vs_123\"]\n    }\n  },\n  \"metadata\": {},\n  \"top_p\": 1.0,\n  \"temperature\": 1.0,\n  \"response_format\": \"auto\"\n}\n"
  '/assistants/{assistant_id}':
    get:
      tags:
        - Assistants
      summary: Retrieves an assistant.
      operationId: getAssistant
      parameters:
        - name: assistant_id
          in: path
          description: The ID of the assistant to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantObject'
      x-oaiMeta:
        name: Retrieve assistant
        group: assistants
        beta: true
        returns: 'The [assistant](/docs/api-reference/assistants/object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/assistants/asst_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nmy_assistant = client.beta.assistants.retrieve(\"asst_abc123\")\nprint(my_assistant)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const myAssistant = await openai.beta.assistants.retrieve(\n    \"asst_abc123\"\n  );\n\n  console.log(myAssistant);\n}\n\nmain();"
          response: "{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n  \"created_at\": 1699009709,\n  \"name\": \"HR Helper\",\n  \"description\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You are an HR bot, and you have access to files to answer employee questions about company policies.\",\n  \"tools\": [\n    {\n      \"type\": \"file_search\"\n    }\n  ],\n  \"metadata\": {},\n  \"top_p\": 1.0,\n  \"temperature\": 1.0,\n  \"response_format\": \"auto\"\n}\n"
    post:
      tags:
        - Assistants
      summary: Modifies an assistant.
      operationId: modifyAssistant
      parameters:
        - name: assistant_id
          in: path
          description: The ID of the assistant to modify.
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyAssistantRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantObject'
      x-oaiMeta:
        name: Modify assistant
        group: assistants
        beta: true
        returns: 'The modified [assistant](/docs/api-reference/assistants/object) object.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/assistants/asst_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n      \"instructions\": \"You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.\",\n      \"tools\": [{\"type\": \"file_search\"}],\n      \"model\": \"gpt-4o\"\n    }'\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nmy_updated_assistant = client.beta.assistants.update(\n  \"asst_abc123\",\n  instructions=\"You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.\",\n  name=\"HR Helper\",\n  tools=[{\"type\": \"file_search\"}],\n  model=\"gpt-4o\"\n)\n\nprint(my_updated_assistant)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const myUpdatedAssistant = await openai.beta.assistants.update(\n    \"asst_abc123\",\n    {\n      instructions:\n        \"You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.\",\n      name: \"HR Helper\",\n      tools: [{ type: \"file_search\" }],\n      model: \"gpt-4o\"\n    }\n  );\n\n  console.log(myUpdatedAssistant);\n}\n\nmain();"
          response: "{\n  \"id\": \"asst_123\",\n  \"object\": \"assistant\",\n  \"created_at\": 1699009709,\n  \"name\": \"HR Helper\",\n  \"description\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.\",\n  \"tools\": [\n    {\n      \"type\": \"file_search\"\n    }\n  ],\n  \"tool_resources\": {\n    \"file_search\": {\n      \"vector_store_ids\": []\n    }\n  },\n  \"metadata\": {},\n  \"top_p\": 1.0,\n  \"temperature\": 1.0,\n  \"response_format\": \"auto\"\n}\n"
    delete:
      tags:
        - Assistants
      summary: Delete an assistant.
      operationId: deleteAssistant
      parameters:
        - name: assistant_id
          in: path
          description: The ID of the assistant to delete.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteAssistantResponse'
      x-oaiMeta:
        name: Delete assistant
        group: assistants
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: "curl https://api.openai.com/v1/assistants/asst_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -X DELETE\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nresponse = client.beta.assistants.delete(\"asst_abc123\")\nprint(response)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const response = await openai.beta.assistants.del(\"asst_abc123\");\n\n  console.log(response);\n}\nmain();"
          response: "{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant.deleted\",\n  \"deleted\": true\n}\n"
  /audio/speech:
    post:
      tags:
        - Audio
      summary: Generates audio from the input text.
      operationId: createSpeech
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateSpeechRequest'
        required: true
      responses:
        '200':
          description: OK
          headers:
            Transfer-Encoding:
              description: chunked
              schema:
                type: string
          content:
            application/octet-stream:
              schema:
                type: string
                format: binary
      x-oaiMeta:
        name: Create speech
        group: audio
        returns: The audio file content.
        examples:
          request:
            curl: "curl https://api.openai.com/v1/audio/speech \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"tts-1\",\n    \"input\": \"The quick brown fox jumped over the lazy dog.\",\n    \"voice\": \"alloy\"\n  }' \\\n  --output speech.mp3\n"
            python: "from pathlib import Path\nimport openai\n\nspeech_file_path = Path(__file__).parent / \"speech.mp3\"\nresponse = openai.audio.speech.create(\n  model=\"tts-1\",\n  voice=\"alloy\",\n  input=\"The quick brown fox jumped over the lazy dog.\"\n)\nresponse.stream_to_file(speech_file_path)\n"
            node: "import fs from \"fs\";\nimport path from \"path\";\nimport OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nconst speechFile = path.resolve(\"./speech.mp3\");\n\nasync function main() {\n  const mp3 = await openai.audio.speech.create({\n    model: \"tts-1\",\n    voice: \"alloy\",\n    input: \"Today is a wonderful day to build something people love!\",\n  });\n  console.log(speechFile);\n  const buffer = Buffer.from(await mp3.arrayBuffer());\n  await fs.promises.writeFile(speechFile, buffer);\n}\nmain();\n"
  /audio/transcriptions:
    post:
      tags:
        - Audio
      summary: Transcribes audio into the input language.
      operationId: createTranscription
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateTranscriptionRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                oneOf:
                  - $ref: '#/components/schemas/CreateTranscriptionResponseJson'
                  - $ref: '#/components/schemas/CreateTranscriptionResponseVerboseJson'
      x-oaiMeta:
        name: Create transcription
        group: audio
        returns: 'The [transcription object](/docs/api-reference/audio/json-object) or a [verbose transcription object](/docs/api-reference/audio/verbose-json-object).'
        examples:
          - title: Default
            request:
              curl: "curl https://api.openai.com/v1/audio/transcriptions \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F file=\"@/path/to/file/audio.mp3\" \\\n  -F model=\"whisper-1\"\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\naudio_file = open(\"speech.mp3\", \"rb\")\ntranscript = client.audio.transcriptions.create(\n  model=\"whisper-1\",\n  file=audio_file\n)\n"
              node: "import fs from \"fs\";\nimport OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const transcription = await openai.audio.transcriptions.create({\n    file: fs.createReadStream(\"audio.mp3\"),\n    model: \"whisper-1\",\n  });\n\n  console.log(transcription.text);\n}\nmain();\n"
            response: "{\n  \"text\": \"Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that.\"\n}\n"
          - title: Word timestamps
            request:
              curl: "curl https://api.openai.com/v1/audio/transcriptions \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F file=\"@/path/to/file/audio.mp3\" \\\n  -F \"timestamp_granularities[]=word\" \\\n  -F model=\"whisper-1\" \\\n  -F response_format=\"verbose_json\"\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\naudio_file = open(\"speech.mp3\", \"rb\")\ntranscript = client.audio.transcriptions.create(\n  file=audio_file,\n  model=\"whisper-1\",\n  response_format=\"verbose_json\",\n  timestamp_granularities=[\"word\"]\n)\n\nprint(transcript.words)\n"
              node: "import fs from \"fs\";\nimport OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const transcription = await openai.audio.transcriptions.create({\n    file: fs.createReadStream(\"audio.mp3\"),\n    model: \"whisper-1\",\n    response_format: \"verbose_json\",\n    timestamp_granularities: [\"word\"]\n  });\n\n  console.log(transcription.text);\n}\nmain();\n"
            response: "{\n  \"task\": \"transcribe\",\n  \"language\": \"english\",\n  \"duration\": 8.470000267028809,\n  \"text\": \"The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.\",\n  \"words\": [\n    {\n      \"word\": \"The\",\n      \"start\": 0.0,\n      \"end\": 0.23999999463558197\n    },\n    ...\n    {\n      \"word\": \"volleyball\",\n      \"start\": 7.400000095367432,\n      \"end\": 7.900000095367432\n    }\n  ]\n}\n"
          - title: Segment timestamps
            request:
              curl: "curl https://api.openai.com/v1/audio/transcriptions \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F file=\"@/path/to/file/audio.mp3\" \\\n  -F \"timestamp_granularities[]=segment\" \\\n  -F model=\"whisper-1\" \\\n  -F response_format=\"verbose_json\"\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\naudio_file = open(\"speech.mp3\", \"rb\")\ntranscript = client.audio.transcriptions.create(\n  file=audio_file,\n  model=\"whisper-1\",\n  response_format=\"verbose_json\",\n  timestamp_granularities=[\"segment\"]\n)\n\nprint(transcript.words)\n"
              node: "import fs from \"fs\";\nimport OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const transcription = await openai.audio.transcriptions.create({\n    file: fs.createReadStream(\"audio.mp3\"),\n    model: \"whisper-1\",\n    response_format: \"verbose_json\",\n    timestamp_granularities: [\"segment\"]\n  });\n\n  console.log(transcription.text);\n}\nmain();\n"
            response: "{\n  \"task\": \"transcribe\",\n  \"language\": \"english\",\n  \"duration\": 8.470000267028809,\n  \"text\": \"The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.\",\n  \"segments\": [\n    {\n      \"id\": 0,\n      \"seek\": 0,\n      \"start\": 0.0,\n      \"end\": 3.319999933242798,\n      \"text\": \" The beach was a popular spot on a hot summer day.\",\n      \"tokens\": [\n        50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530\n      ],\n      \"temperature\": 0.0,\n      \"avg_logprob\": -0.2860786020755768,\n      \"compression_ratio\": 1.2363636493682861,\n      \"no_speech_prob\": 0.00985979475080967\n    },\n    ...\n  ]\n}\n"
  /audio/translations:
    post:
      tags:
        - Audio
      summary: Translates audio into English.
      operationId: createTranslation
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateTranslationRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                oneOf:
                  - $ref: '#/components/schemas/CreateTranslationResponseJson'
                  - $ref: '#/components/schemas/CreateTranslationResponseVerboseJson'
      x-oaiMeta:
        name: Create translation
        group: audio
        returns: The translated text.
        examples:
          request:
            curl: "curl https://api.openai.com/v1/audio/translations \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F file=\"@/path/to/file/german.m4a\" \\\n  -F model=\"whisper-1\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\naudio_file = open(\"speech.mp3\", \"rb\")\ntranscript = client.audio.translations.create(\n  model=\"whisper-1\",\n  file=audio_file\n)\n"
            node: "import fs from \"fs\";\nimport OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n    const translation = await openai.audio.translations.create({\n        file: fs.createReadStream(\"speech.mp3\"),\n        model: \"whisper-1\",\n    });\n\n    console.log(translation.text);\n}\nmain();\n"
          response: "{\n  \"text\": \"Hello, my name is Wolfgang and I come from Germany. Where are you heading today?\"\n}\n"
  /batches:
    post:
      tags:
        - Batch
      summary: Creates and executes a batch from an uploaded file of requests
      operationId: createBatch
      requestBody:
        content:
          application/json:
            schema:
              required:
                - input_file_id
                - endpoint
                - completion_window
              type: object
              properties:
                input_file_id:
                  type: string
                  description: "The ID of an uploaded file that contains requests for the new batch.\n\nSee [upload file](/docs/api-reference/files/create) for how to upload a file.\n\nYour input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 200 MB in size.\n"
                endpoint:
                  enum:
                    - /v1/chat/completions
                    - /v1/embeddings
                    - /v1/completions
                  type: string
                  description: 'The endpoint to be used for all requests in the batch. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.'
                completion_window:
                  enum:
                    - 24h
                  type: string
                  description: The time frame within which the batch should be processed. Currently only `24h` is supported.
                metadata:
                  type: object
                  additionalProperties:
                    type: string
                  description: Optional custom metadata for the batch.
                  nullable: true
        required: true
      responses:
        '200':
          description: Batch created successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
      x-oaiMeta:
        name: Create batch
        group: batch
        returns: 'The created [Batch](/docs/api-reference/batch/object) object.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/batches \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"input_file_id\": \"file-abc123\",\n    \"endpoint\": \"/v1/chat/completions\",\n    \"completion_window\": \"24h\"\n  }'\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.batches.create(\n  input_file_id=\"file-abc123\",\n  endpoint=\"/v1/chat/completions\",\n  completion_window=\"24h\"\n)\n"
            node: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const batch = await openai.batches.create({\n    input_file_id: \"file-abc123\",\n    endpoint: \"/v1/chat/completions\",\n    completion_window: \"24h\"\n  });\n\n  console.log(batch);\n}\n\nmain();\n"
          response: "{\n  \"id\": \"batch_abc123\",\n  \"object\": \"batch\",\n  \"endpoint\": \"/v1/chat/completions\",\n  \"errors\": null,\n  \"input_file_id\": \"file-abc123\",\n  \"completion_window\": \"24h\",\n  \"status\": \"validating\",\n  \"output_file_id\": null,\n  \"error_file_id\": null,\n  \"created_at\": 1711471533,\n  \"in_progress_at\": null,\n  \"expires_at\": null,\n  \"finalizing_at\": null,\n  \"completed_at\": null,\n  \"failed_at\": null,\n  \"expired_at\": null,\n  \"cancelling_at\": null,\n  \"cancelled_at\": null,\n  \"request_counts\": {\n    \"total\": 0,\n    \"completed\": 0,\n    \"failed\": 0\n  },\n  \"metadata\": {\n    \"customer_id\": \"user_123456789\",\n    \"batch_description\": \"Nightly eval job\",\n  }\n}\n"
    get:
      tags:
        - Batch
      summary: List your organization's batches.
      operationId: listBatches
      parameters:
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
      responses:
        '200':
          description: Batch listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListBatchesResponse'
      x-oaiMeta:
        name: List batch
        group: batch
        returns: 'A list of paginated [Batch](/docs/api-reference/batch/object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/batches?limit=2 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.batches.list()\n"
            node: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const list = await openai.batches.list();\n\n  for await (const batch of list) {\n    console.log(batch);\n  }\n}\n\nmain();\n"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"batch_abc123\",\n      \"object\": \"batch\",\n      \"endpoint\": \"/v1/chat/completions\",\n      \"errors\": null,\n      \"input_file_id\": \"file-abc123\",\n      \"completion_window\": \"24h\",\n      \"status\": \"completed\",\n      \"output_file_id\": \"file-cvaTdG\",\n      \"error_file_id\": \"file-HOWS94\",\n      \"created_at\": 1711471533,\n      \"in_progress_at\": 1711471538,\n      \"expires_at\": 1711557933,\n      \"finalizing_at\": 1711493133,\n      \"completed_at\": 1711493163,\n      \"failed_at\": null,\n      \"expired_at\": null,\n      \"cancelling_at\": null,\n      \"cancelled_at\": null,\n      \"request_counts\": {\n        \"total\": 100,\n        \"completed\": 95,\n        \"failed\": 5\n      },\n      \"metadata\": {\n        \"customer_id\": \"user_123456789\",\n        \"batch_description\": \"Nightly job\",\n      }\n    },\n    { ... },\n  ],\n  \"first_id\": \"batch_abc123\",\n  \"last_id\": \"batch_abc456\",\n  \"has_more\": true\n}\n"
  '/batches/{batch_id}':
    get:
      tags:
        - Batch
      summary: Retrieves a batch.
      operationId: retrieveBatch
      parameters:
        - name: batch_id
          in: path
          description: The ID of the batch to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Batch retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
      x-oaiMeta:
        name: Retrieve batch
        group: batch
        returns: 'The [Batch](/docs/api-reference/batch/object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/batches/batch_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.batches.retrieve(\"batch_abc123\")\n"
            node: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const batch = await openai.batches.retrieve(\"batch_abc123\");\n\n  console.log(batch);\n}\n\nmain();\n"
          response: "{\n  \"id\": \"batch_abc123\",\n  \"object\": \"batch\",\n  \"endpoint\": \"/v1/completions\",\n  \"errors\": null,\n  \"input_file_id\": \"file-abc123\",\n  \"completion_window\": \"24h\",\n  \"status\": \"completed\",\n  \"output_file_id\": \"file-cvaTdG\",\n  \"error_file_id\": \"file-HOWS94\",\n  \"created_at\": 1711471533,\n  \"in_progress_at\": 1711471538,\n  \"expires_at\": 1711557933,\n  \"finalizing_at\": 1711493133,\n  \"completed_at\": 1711493163,\n  \"failed_at\": null,\n  \"expired_at\": null,\n  \"cancelling_at\": null,\n  \"cancelled_at\": null,\n  \"request_counts\": {\n    \"total\": 100,\n    \"completed\": 95,\n    \"failed\": 5\n  },\n  \"metadata\": {\n    \"customer_id\": \"user_123456789\",\n    \"batch_description\": \"Nightly eval job\",\n  }\n}\n"
  '/batches/{batch_id}/cancel':
    post:
      tags:
        - Batch
      summary: 'Cancels an in-progress batch. The batch will be in status `cancelling` for up to 10 minutes, before changing to `cancelled`, where it will have partial results (if any) available in the output file.'
      operationId: cancelBatch
      parameters:
        - name: batch_id
          in: path
          description: The ID of the batch to cancel.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Batch is cancelling. Returns the cancelling batch's details.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
      x-oaiMeta:
        name: Cancel batch
        group: batch
        returns: 'The [Batch](/docs/api-reference/batch/object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/batches/batch_abc123/cancel \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -X POST\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.batches.cancel(\"batch_abc123\")\n"
            node: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const batch = await openai.batches.cancel(\"batch_abc123\");\n\n  console.log(batch);\n}\n\nmain();\n"
          response: "{\n  \"id\": \"batch_abc123\",\n  \"object\": \"batch\",\n  \"endpoint\": \"/v1/chat/completions\",\n  \"errors\": null,\n  \"input_file_id\": \"file-abc123\",\n  \"completion_window\": \"24h\",\n  \"status\": \"cancelling\",\n  \"output_file_id\": null,\n  \"error_file_id\": null,\n  \"created_at\": 1711471533,\n  \"in_progress_at\": 1711471538,\n  \"expires_at\": 1711557933,\n  \"finalizing_at\": null,\n  \"completed_at\": null,\n  \"failed_at\": null,\n  \"expired_at\": null,\n  \"cancelling_at\": 1711475133,\n  \"cancelled_at\": null,\n  \"request_counts\": {\n    \"total\": 100,\n    \"completed\": 23,\n    \"failed\": 1\n  },\n  \"metadata\": {\n    \"customer_id\": \"user_123456789\",\n    \"batch_description\": \"Nightly eval job\",\n  }\n}\n"
  /chat/completions:
    post:
      tags:
        - Chat
      summary: "Creates a model response for the given chat conversation. Learn more in the\n[text generation](/docs/guides/text-generation), [vision](/docs/guides/vision),\nand [audio](/docs/guides/audio) guides.\n"
      operationId: createChatCompletion
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateChatCompletionRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionResponse'
      x-oaiMeta:
        name: Create chat completion
        group: chat
        returns: "Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.\n"
        path: create
        examples:
          - title: Default
            request:
              curl: "curl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"VAR_chat_model_id\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are a helpful assistant.\"\n      },\n      {\n        \"role\": \"user\",\n        \"content\": \"Hello!\"\n      }\n    ]\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\ncompletion = client.chat.completions.create(\n  model=\"VAR_chat_model_id\",\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Hello!\"}\n  ]\n)\n\nprint(completion.choices[0].message)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const completion = await openai.chat.completions.create({\n    messages: [{ role: \"system\", content: \"You are a helpful assistant.\" }],\n    model: \"VAR_chat_model_id\",\n  });\n\n  console.log(completion.choices[0]);\n}\n\nmain();"
            response: "{\n  \"id\": \"chatcmpl-123\",\n  \"object\": \"chat.completion\",\n  \"created\": 1677652288,\n  \"model\": \"gpt-4o-mini\",\n  \"system_fingerprint\": \"fp_44709d6fcb\",\n  \"choices\": [{\n    \"index\": 0,\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"\\n\\nHello there, how may I assist you today?\",\n    },\n    \"logprobs\": null,\n    \"finish_reason\": \"stop\"\n  }],\n  \"usage\": {\n    \"prompt_tokens\": 9,\n    \"completion_tokens\": 12,\n    \"total_tokens\": 21,\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\": 0,\n      \"accepted_prediction_tokens\": 0,\n      \"rejected_prediction_tokens\": 0\n    }\n  }\n}\n"
          - title: Image input
            request:
              curl: "curl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-4o\",\n    \"messages\": [\n      {\n        \"role\": \"user\",\n        \"content\": [\n          {\n            \"type\": \"text\",\n            \"text\": \"What'\\''s in this image?\"\n          },\n          {\n            \"type\": \"image_url\",\n            \"image_url\": {\n              \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n            }\n          }\n        ]\n      }\n    ],\n    \"max_tokens\": 300\n  }'\n"
              python: "from openai import OpenAI\n\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"text\", \"text\": \"What's in this image?\"},\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\n                        \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n                    }\n                },\n            ],\n        }\n    ],\n    max_tokens=300,\n)\n\nprint(response.choices[0])\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const response = await openai.chat.completions.create({\n    model: \"gpt-4o\",\n    messages: [\n      {\n        role: \"user\",\n        content: [\n          { type: \"text\", text: \"What's in this image?\" },\n          {\n            type: \"image_url\",\n            image_url: {\n              \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n            },\n          }\n        ],\n      },\n    ],\n  });\n  console.log(response.choices[0]);\n}\nmain();"
            response: "{\n  \"id\": \"chatcmpl-123\",\n  \"object\": \"chat.completion\",\n  \"created\": 1677652288,\n  \"model\": \"gpt-4o-mini\",\n  \"system_fingerprint\": \"fp_44709d6fcb\",\n  \"choices\": [{\n    \"index\": 0,\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"\\n\\nThis image shows a wooden boardwalk extending through a lush green marshland.\",\n    },\n    \"logprobs\": null,\n    \"finish_reason\": \"stop\"\n  }],\n  \"usage\": {\n    \"prompt_tokens\": 9,\n    \"completion_tokens\": 12,\n    \"total_tokens\": 21,\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\": 0,\n      \"accepted_prediction_tokens\": 0,\n      \"rejected_prediction_tokens\": 0\n    }\n  }\n}\n"
          - title: Streaming
            request:
              curl: "curl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"VAR_chat_model_id\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are a helpful assistant.\"\n      },\n      {\n        \"role\": \"user\",\n        \"content\": \"Hello!\"\n      }\n    ],\n    \"stream\": true\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\ncompletion = client.chat.completions.create(\n  model=\"VAR_chat_model_id\",\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Hello!\"}\n  ],\n  stream=True\n)\n\nfor chunk in completion:\n  print(chunk.choices[0].delta)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const completion = await openai.chat.completions.create({\n    model: \"VAR_chat_model_id\",\n    messages: [\n      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n      {\"role\": \"user\", \"content\": \"Hello!\"}\n    ],\n    stream: true,\n  });\n\n  for await (const chunk of completion) {\n    console.log(chunk.choices[0].delta.content);\n  }\n}\n\nmain();"
            response: "{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-4o-mini\", \"system_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\"},\"logprobs\":null,\"finish_reason\":null}]}\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-4o-mini\", \"system_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{\"content\":\"Hello\"},\"logprobs\":null,\"finish_reason\":null}]}\n\n....\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-4o-mini\", \"system_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{},\"logprobs\":null,\"finish_reason\":\"stop\"}]}\n"
          - title: Functions
            request:
              curl: "curl https://api.openai.com/v1/chat/completions \\\n-H \"Content-Type: application/json\" \\\n-H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n-d '{\n  \"model\": \"gpt-4o\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"What'\\''s the weather like in Boston today?\"\n    }\n  ],\n  \"tools\": [\n    {\n      \"type\": \"function\",\n      \"function\": {\n        \"name\": \"get_current_weather\",\n        \"description\": \"Get the current weather in a given location\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"location\": {\n              \"type\": \"string\",\n              \"description\": \"The city and state, e.g. San Francisco, CA\"\n            },\n            \"unit\": {\n              \"type\": \"string\",\n              \"enum\": [\"celsius\", \"fahrenheit\"]\n            }\n          },\n          \"required\": [\"location\"]\n        }\n      }\n    }\n  ],\n  \"tool_choice\": \"auto\"\n}'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\ntools = [\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"get_current_weather\",\n      \"description\": \"Get the current weather in a given location\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"location\": {\n            \"type\": \"string\",\n            \"description\": \"The city and state, e.g. San Francisco, CA\",\n          },\n          \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n        },\n        \"required\": [\"location\"],\n      },\n    }\n  }\n]\nmessages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston today?\"}]\ncompletion = client.chat.completions.create(\n  model=\"VAR_chat_model_id\",\n  messages=messages,\n  tools=tools,\n  tool_choice=\"auto\"\n)\n\nprint(completion)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston today?\"}];\n  const tools = [\n      {\n        \"type\": \"function\",\n        \"function\": {\n          \"name\": \"get_current_weather\",\n          \"description\": \"Get the current weather in a given location\",\n          \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n              \"location\": {\n                \"type\": \"string\",\n                \"description\": \"The city and state, e.g. San Francisco, CA\",\n              },\n              \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n            },\n            \"required\": [\"location\"],\n          },\n        }\n      }\n  ];\n\n  const response = await openai.chat.completions.create({\n    model: \"gpt-4o\",\n    messages: messages,\n    tools: tools,\n    tool_choice: \"auto\",\n  });\n\n  console.log(response);\n}\n\nmain();"
            response: "{\n  \"id\": \"chatcmpl-abc123\",\n  \"object\": \"chat.completion\",\n  \"created\": 1699896916,\n  \"model\": \"gpt-4o-mini\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": null,\n        \"tool_calls\": [\n          {\n            \"id\": \"call_abc123\",\n            \"type\": \"function\",\n            \"function\": {\n              \"name\": \"get_current_weather\",\n              \"arguments\": \"{\\n\\\"location\\\": \\\"Boston, MA\\\"\\n}\"\n            }\n          }\n        ]\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"tool_calls\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 82,\n    \"completion_tokens\": 17,\n    \"total_tokens\": 99,\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\": 0,\n      \"accepted_prediction_tokens\": 0,\n      \"rejected_prediction_tokens\": 0\n    }\n  }\n}\n"
          - title: Logprobs
            request:
              curl: "curl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"VAR_chat_model_id\",\n    \"messages\": [\n      {\n        \"role\": \"user\",\n        \"content\": \"Hello!\"\n      }\n    ],\n    \"logprobs\": true,\n    \"top_logprobs\": 2\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\ncompletion = client.chat.completions.create(\n  model=\"VAR_chat_model_id\",\n  messages=[\n    {\"role\": \"user\", \"content\": \"Hello!\"}\n  ],\n  logprobs=True,\n  top_logprobs=2\n)\n\nprint(completion.choices[0].message)\nprint(completion.choices[0].logprobs)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const completion = await openai.chat.completions.create({\n    messages: [{ role: \"user\", content: \"Hello!\" }],\n    model: \"VAR_chat_model_id\",\n    logprobs: true,\n    top_logprobs: 2,\n  });\n\n  console.log(completion.choices[0]);\n}\n\nmain();"
            response: "{\n  \"id\": \"chatcmpl-123\",\n  \"object\": \"chat.completion\",\n  \"created\": 1702685778,\n  \"model\": \"gpt-4o-mini\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"Hello! How can I assist you today?\"\n      },\n      \"logprobs\": {\n        \"content\": [\n          {\n            \"token\": \"Hello\",\n            \"logprob\": -0.31725305,\n            \"bytes\": [72, 101, 108, 108, 111],\n            \"top_logprobs\": [\n              {\n                \"token\": \"Hello\",\n                \"logprob\": -0.31725305,\n                \"bytes\": [72, 101, 108, 108, 111]\n              },\n              {\n                \"token\": \"Hi\",\n                \"logprob\": -1.3190403,\n                \"bytes\": [72, 105]\n              }\n            ]\n          },\n          {\n            \"token\": \"!\",\n            \"logprob\": -0.02380986,\n            \"bytes\": [\n              33\n            ],\n            \"top_logprobs\": [\n              {\n                \"token\": \"!\",\n                \"logprob\": -0.02380986,\n                \"bytes\": [33]\n              },\n              {\n                \"token\": \" there\",\n                \"logprob\": -3.787621,\n                \"bytes\": [32, 116, 104, 101, 114, 101]\n              }\n            ]\n          },\n          {\n            \"token\": \" How\",\n            \"logprob\": -0.000054669687,\n            \"bytes\": [32, 72, 111, 119],\n            \"top_logprobs\": [\n              {\n                \"token\": \" How\",\n                \"logprob\": -0.000054669687,\n                \"bytes\": [32, 72, 111, 119]\n              },\n              {\n                \"token\": \"<|end|>\",\n                \"logprob\": -10.953937,\n                \"bytes\": null\n              }\n            ]\n          },\n          {\n            \"token\": \" can\",\n            \"logprob\": -0.015801601,\n            \"bytes\": [32, 99, 97, 110],\n            \"top_logprobs\": [\n              {\n                \"token\": \" can\",\n                \"logprob\": -0.015801601,\n                \"bytes\": [32, 99, 97, 110]\n              },\n              {\n                \"token\": \" may\",\n                \"logprob\": -4.161023,\n                \"bytes\": [32, 109, 97, 121]\n              }\n            ]\n          },\n          {\n            \"token\": \" I\",\n            \"logprob\": -3.7697225e-6,\n            \"bytes\": [\n              32,\n              73\n            ],\n            \"top_logprobs\": [\n              {\n                \"token\": \" I\",\n                \"logprob\": -3.7697225e-6,\n                \"bytes\": [32, 73]\n              },\n              {\n                \"token\": \" assist\",\n                \"logprob\": -13.596657,\n                \"bytes\": [32, 97, 115, 115, 105, 115, 116]\n              }\n            ]\n          },\n          {\n            \"token\": \" assist\",\n            \"logprob\": -0.04571125,\n            \"bytes\": [32, 97, 115, 115, 105, 115, 116],\n            \"top_logprobs\": [\n              {\n                \"token\": \" assist\",\n                \"logprob\": -0.04571125,\n                \"bytes\": [32, 97, 115, 115, 105, 115, 116]\n              },\n              {\n                \"token\": \" help\",\n                \"logprob\": -3.1089056,\n                \"bytes\": [32, 104, 101, 108, 112]\n              }\n            ]\n          },\n          {\n            \"token\": \" you\",\n            \"logprob\": -5.4385737e-6,\n            \"bytes\": [32, 121, 111, 117],\n            \"top_logprobs\": [\n              {\n                \"token\": \" you\",\n                \"logprob\": -5.4385737e-6,\n                \"bytes\": [32, 121, 111, 117]\n              },\n              {\n                \"token\": \" today\",\n                \"logprob\": -12.807695,\n                \"bytes\": [32, 116, 111, 100, 97, 121]\n              }\n            ]\n          },\n          {\n            \"token\": \" today\",\n            \"logprob\": -0.0040071653,\n            \"bytes\": [32, 116, 111, 100, 97, 121],\n            \"top_logprobs\": [\n              {\n                \"token\": \" today\",\n                \"logprob\": -0.0040071653,\n                \"bytes\": [32, 116, 111, 100, 97, 121]\n              },\n              {\n                \"token\": \"?\",\n                \"logprob\": -5.5247097,\n                \"bytes\": [63]\n              }\n            ]\n          },\n          {\n            \"token\": \"?\",\n            \"logprob\": -0.0008108172,\n            \"bytes\": [63],\n            \"top_logprobs\": [\n              {\n                \"token\": \"?\",\n                \"logprob\": -0.0008108172,\n                \"bytes\": [63]\n              },\n              {\n                \"token\": \"?\\n\",\n                \"logprob\": -7.184561,\n                \"bytes\": [63, 10]\n              }\n            ]\n          }\n        ]\n      },\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 9,\n    \"completion_tokens\": 9,\n    \"total_tokens\": 18,\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\": 0,\n      \"accepted_prediction_tokens\": 0,\n      \"rejected_prediction_tokens\": 0\n    }\n  },\n  \"system_fingerprint\": null\n}\n"
  /completions:
    post:
      tags:
        - Completions
      summary: Creates a completion for the provided prompt and parameters.
      operationId: createCompletion
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateCompletionRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateCompletionResponse'
      x-oaiMeta:
        name: Create completion
        group: completions
        returns: "Returns a [completion](/docs/api-reference/completions/object) object, or a sequence of completion objects if the request is streamed.\n"
        legacy: true
        examples:
          - title: No streaming
            request:
              curl: "curl https://api.openai.com/v1/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"VAR_completion_model_id\",\n    \"prompt\": \"Say this is a test\",\n    \"max_tokens\": 7,\n    \"temperature\": 0\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.completions.create(\n  model=\"VAR_completion_model_id\",\n  prompt=\"Say this is a test\",\n  max_tokens=7,\n  temperature=0\n)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const completion = await openai.completions.create({\n    model: \"VAR_completion_model_id\",\n    prompt: \"Say this is a test.\",\n    max_tokens: 7,\n    temperature: 0,\n  });\n\n  console.log(completion);\n}\nmain();"
            response: "{\n  \"id\": \"cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7\",\n  \"object\": \"text_completion\",\n  \"created\": 1589478378,\n  \"model\": \"VAR_completion_model_id\",\n  \"system_fingerprint\": \"fp_44709d6fcb\",\n  \"choices\": [\n    {\n      \"text\": \"\\n\\nThis is indeed a test\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"finish_reason\": \"length\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 5,\n    \"completion_tokens\": 7,\n    \"total_tokens\": 12\n  }\n}\n"
          - title: Streaming
            request:
              curl: "curl https://api.openai.com/v1/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"VAR_completion_model_id\",\n    \"prompt\": \"Say this is a test\",\n    \"max_tokens\": 7,\n    \"temperature\": 0,\n    \"stream\": true\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\nfor chunk in client.completions.create(\n  model=\"VAR_completion_model_id\",\n  prompt=\"Say this is a test\",\n  max_tokens=7,\n  temperature=0,\n  stream=True\n):\n  print(chunk.choices[0].text)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const stream = await openai.completions.create({\n    model: \"VAR_completion_model_id\",\n    prompt: \"Say this is a test.\",\n    stream: true,\n  });\n\n  for await (const chunk of stream) {\n    console.log(chunk.choices[0].text)\n  }\n}\nmain();"
            response: "{\n  \"id\": \"cmpl-7iA7iJjj8V2zOkCGvWF2hAkDWBQZe\",\n  \"object\": \"text_completion\",\n  \"created\": 1690759702,\n  \"choices\": [\n    {\n      \"text\": \"This\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"finish_reason\": null\n    }\n  ],\n  \"model\": \"gpt-3.5-turbo-instruct\"\n  \"system_fingerprint\": \"fp_44709d6fcb\",\n}\n"
  /embeddings:
    post:
      tags:
        - Embeddings
      summary: Creates an embedding vector representing the input text.
      operationId: createEmbedding
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEmbeddingRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateEmbeddingResponse'
      x-oaiMeta:
        name: Create embeddings
        group: embeddings
        returns: 'A list of [embedding](/docs/api-reference/embeddings/object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/embeddings \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"input\": \"The food was delicious and the waiter...\",\n    \"model\": \"text-embedding-ada-002\",\n    \"encoding_format\": \"float\"\n  }'\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.embeddings.create(\n  model=\"text-embedding-ada-002\",\n  input=\"The food was delicious and the waiter...\",\n  encoding_format=\"float\"\n)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const embedding = await openai.embeddings.create({\n    model: \"text-embedding-ada-002\",\n    input: \"The quick brown fox jumped over the lazy dog\",\n    encoding_format: \"float\",\n  });\n\n  console.log(embedding);\n}\n\nmain();"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"embedding\",\n      \"embedding\": [\n        0.0023064255,\n        -0.009327292,\n        .... (1536 floats total for ada-002)\n        -0.0028842222,\n      ],\n      \"index\": 0\n    }\n  ],\n  \"model\": \"text-embedding-ada-002\",\n  \"usage\": {\n    \"prompt_tokens\": 8,\n    \"total_tokens\": 8\n  }\n}\n"
  /files:
    get:
      tags:
        - Files
      summary: Returns a list of files.
      operationId: listFiles
      parameters:
        - name: purpose
          in: query
          description: Only return files with the given purpose.
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 10,000, and the default is 10,000.\n"
          schema:
            type: integer
            default: 10000
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFilesResponse'
      x-oaiMeta:
        name: List files
        group: files
        returns: 'A list of [File](/docs/api-reference/files/object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.files.list()\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const list = await openai.files.list();\n\n  for await (const file of list) {\n    console.log(file);\n  }\n}\n\nmain();"
          response: "{\n  \"data\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"file\",\n      \"bytes\": 175,\n      \"created_at\": 1613677385,\n      \"filename\": \"salesOverview.pdf\",\n      \"purpose\": \"assistants\",\n    },\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"file\",\n      \"bytes\": 140,\n      \"created_at\": 1613779121,\n      \"filename\": \"puppy.jsonl\",\n      \"purpose\": \"fine-tune\",\n    }\n  ],\n  \"object\": \"list\"\n}\n"
    post:
      tags:
        - Files
      summary: "Upload a file that can be used across various endpoints. Individual files can be up to 512 MB, and the size of all files uploaded by one organization can be up to 100 GB.\n\nThe Assistants API supports files up to 2 million tokens and of specific file types. See the [Assistants Tools guide](/docs/assistants/tools) for details.\n\nThe Fine-tuning API only supports `.jsonl` files. The input also has certain required formats for fine-tuning [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) models.\n\nThe Batch API only supports `.jsonl` files up to 200 MB in size. The input also has a specific required [format](/docs/api-reference/batch/request-input).\n\nPlease [contact us](https://help.openai.com/) if you need to increase these storage limits.\n"
      operationId: createFile
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateFileRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OpenAIFile'
      x-oaiMeta:
        name: Upload file
        group: files
        returns: 'The uploaded [File](/docs/api-reference/files/object) object.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -F purpose=\"fine-tune\" \\\n  -F file=\"@mydata.jsonl\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.files.create(\n  file=open(\"mydata.jsonl\", \"rb\"),\n  purpose=\"fine-tune\"\n)\n"
            node.js: "import fs from \"fs\";\nimport OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const file = await openai.files.create({\n    file: fs.createReadStream(\"mydata.jsonl\"),\n    purpose: \"fine-tune\",\n  });\n\n  console.log(file);\n}\n\nmain();"
          response: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"bytes\": 120000,\n  \"created_at\": 1677610602,\n  \"filename\": \"mydata.jsonl\",\n  \"purpose\": \"fine-tune\",\n}\n"
  '/files/{file_id}':
    delete:
      tags:
        - Files
      summary: Delete a file.
      operationId: deleteFile
      parameters:
        - name: file_id
          in: path
          description: The ID of the file to use for this request.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteFileResponse'
      x-oaiMeta:
        name: Delete file
        group: files
        returns: Deletion status.
        examples:
          request:
            curl: "curl https://api.openai.com/v1/files/file-abc123 \\\n  -X DELETE \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.files.delete(\"file-abc123\")\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const file = await openai.files.del(\"file-abc123\");\n\n  console.log(file);\n}\n\nmain();"
          response: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"deleted\": true\n}\n"
    get:
      tags:
        - Files
      summary: Returns information about a specific file.
      operationId: retrieveFile
      parameters:
        - name: file_id
          in: path
          description: The ID of the file to use for this request.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OpenAIFile'
      x-oaiMeta:
        name: Retrieve file
        group: files
        returns: 'The [File](/docs/api-reference/files/object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/files/file-abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.files.retrieve(\"file-abc123\")\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const file = await openai.files.retrieve(\"file-abc123\");\n\n  console.log(file);\n}\n\nmain();"
          response: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"bytes\": 120000,\n  \"created_at\": 1677610602,\n  \"filename\": \"mydata.jsonl\",\n  \"purpose\": \"fine-tune\",\n}\n"
  '/files/{file_id}/content':
    get:
      tags:
        - Files
      summary: Returns the contents of the specified file.
      operationId: downloadFile
      parameters:
        - name: file_id
          in: path
          description: The ID of the file to use for this request.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/octet-stream:
              schema:
                type: string
                format: binary
      x-oaiMeta:
        name: Retrieve file content
        group: files
        returns: The file content.
        examples:
          request:
            curl: "curl https://api.openai.com/v1/files/file-abc123/content \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" > file.jsonl\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\ncontent = client.files.content(\"file-abc123\")\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const file = await openai.files.content(\"file-abc123\");\n\n  console.log(file);\n}\n\nmain();\n"
  /fine_tuning/jobs:
    post:
      tags:
        - Fine-tuning
      summary: "Creates a fine-tuning job which begins the process of creating a new model from a given dataset.\n\nResponse includes details of the enqueued job including job status and the name of the fine-tuned models once complete.\n\n[Learn more about fine-tuning](/docs/guides/fine-tuning)\n"
      operationId: createFineTuningJob
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateFineTuningJobRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
      x-oaiMeta:
        name: Create fine-tuning job
        group: fine-tuning
        returns: 'A [fine-tuning.job](/docs/api-reference/fine-tuning/object) object.'
        examples:
          - title: Default
            request:
              curl: "curl https://api.openai.com/v1/fine_tuning/jobs \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"training_file\": \"file-BK7bzQj3FfZFXr7DbL6xJwfo\",\n    \"model\": \"gpt-4o-mini\"\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.fine_tuning.jobs.create(\n  training_file=\"file-abc123\",\n  model=\"gpt-4o-mini\"\n)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const fineTune = await openai.fineTuning.jobs.create({\n    training_file: \"file-abc123\"\n  });\n\n  console.log(fineTune);\n}\n\nmain();\n"
            response: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"gpt-4o-mini-2024-07-18\",\n  \"created_at\": 1721764800,\n  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n  \"result_files\": [],\n  \"status\": \"queued\",\n  \"validation_file\": null,\n  \"training_file\": \"file-abc123\",\n}\n"
          - title: Epochs
            request:
              curl: "curl https://api.openai.com/v1/fine_tuning/jobs \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"training_file\": \"file-abc123\",\n    \"model\": \"gpt-4o-mini\",\n    \"hyperparameters\": {\n      \"n_epochs\": 2\n    }\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.fine_tuning.jobs.create(\n  training_file=\"file-abc123\",\n  model=\"gpt-4o-mini\",\n  hyperparameters={\n    \"n_epochs\":2\n  }\n)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const fineTune = await openai.fineTuning.jobs.create({\n    training_file: \"file-abc123\",\n    model: \"gpt-4o-mini\",\n    hyperparameters: { n_epochs: 2 }\n  });\n\n  console.log(fineTune);\n}\n\nmain();\n"
            response: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"gpt-4o-mini-2024-07-18\",\n  \"created_at\": 1721764800,\n  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n  \"result_files\": [],\n  \"status\": \"queued\",\n  \"validation_file\": null,\n  \"training_file\": \"file-abc123\",\n  \"hyperparameters\": {\"n_epochs\": 2},\n}\n"
          - title: Validation file
            request:
              curl: "curl https://api.openai.com/v1/fine_tuning/jobs \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"training_file\": \"file-abc123\",\n    \"validation_file\": \"file-abc123\",\n    \"model\": \"gpt-4o-mini\"\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.fine_tuning.jobs.create(\n  training_file=\"file-abc123\",\n  validation_file=\"file-def456\",\n  model=\"gpt-4o-mini\"\n)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const fineTune = await openai.fineTuning.jobs.create({\n    training_file: \"file-abc123\",\n    validation_file: \"file-abc123\"\n  });\n\n  console.log(fineTune);\n}\n\nmain();\n"
            response: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"gpt-4o-mini-2024-07-18\",\n  \"created_at\": 1721764800,\n  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n  \"result_files\": [],\n  \"status\": \"queued\",\n  \"validation_file\": \"file-abc123\",\n  \"training_file\": \"file-abc123\",\n}\n"
          - title: W&B Integration
            request:
              curl: "curl https://api.openai.com/v1/fine_tuning/jobs \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"training_file\": \"file-abc123\",\n    \"validation_file\": \"file-abc123\",\n    \"model\": \"gpt-4o-mini\",\n    \"integrations\": [\n      {\n        \"type\": \"wandb\",\n        \"wandb\": {\n          \"project\": \"my-wandb-project\",\n          \"name\": \"ft-run-display-name\"\n          \"tags\": [\n            \"first-experiment\", \"v2\"\n          ]\n        }\n      }\n    ]\n  }'\n"
            response: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"gpt-4o-mini-2024-07-18\",\n  \"created_at\": 1721764800,\n  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n  \"result_files\": [],\n  \"status\": \"queued\",\n  \"validation_file\": \"file-abc123\",\n  \"training_file\": \"file-abc123\",\n  \"integrations\": [\n    {\n      \"type\": \"wandb\",\n      \"wandb\": {\n        \"project\": \"my-wandb-project\",\n        \"entity\": None,\n        \"run_id\": \"ftjob-abc123\"\n      }\n    }\n  ]\n}\n"
    get:
      tags:
        - Fine-tuning
      summary: "List your organization's fine-tuning jobs\n"
      operationId: listPaginatedFineTuningJobs
      parameters:
        - name: after
          in: query
          description: Identifier for the last job from the previous pagination request.
          schema:
            type: string
        - name: limit
          in: query
          description: Number of fine-tuning jobs to retrieve.
          schema:
            type: integer
            default: 20
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListPaginatedFineTuningJobsResponse'
      x-oaiMeta:
        name: List fine-tuning jobs
        group: fine-tuning
        returns: 'A list of paginated [fine-tuning job](/docs/api-reference/fine-tuning/object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/fine_tuning/jobs?limit=2 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.fine_tuning.jobs.list()\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const list = await openai.fineTuning.jobs.list();\n\n  for await (const fineTune of list) {\n    console.log(fineTune);\n  }\n}\n\nmain();"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"fine_tuning.job.event\",\n      \"id\": \"ft-event-TjX0lMfOniCZX64t9PUQT5hn\",\n      \"created_at\": 1689813489,\n      \"level\": \"warn\",\n      \"message\": \"Fine tuning process stopping due to job cancellation\",\n      \"data\": null,\n      \"type\": \"message\"\n    },\n    { ... },\n    { ... }\n  ], \"has_more\": true\n}\n"
  '/fine_tuning/jobs/{fine_tuning_job_id}':
    get:
      tags:
        - Fine-tuning
      summary: "Get info about a fine-tuning job.\n\n[Learn more about fine-tuning](/docs/guides/fine-tuning)\n"
      operationId: retrieveFineTuningJob
      parameters:
        - name: fine_tuning_job_id
          in: path
          description: "The ID of the fine-tuning job.\n"
          required: true
          schema:
            type: string
            example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
      x-oaiMeta:
        name: Retrieve fine-tuning job
        group: fine-tuning
        returns: 'The [fine-tuning](/docs/api-reference/fine-tuning/object) object with the given ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.fine_tuning.jobs.retrieve(\"ftjob-abc123\")\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const fineTune = await openai.fineTuning.jobs.retrieve(\"ftjob-abc123\");\n\n  console.log(fineTune);\n}\n\nmain();\n"
          response: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"davinci-002\",\n  \"created_at\": 1692661014,\n  \"finished_at\": 1692661190,\n  \"fine_tuned_model\": \"ft:davinci-002:my-org:custom_suffix:7q8mpxmy\",\n  \"organization_id\": \"org-123\",\n  \"result_files\": [\n      \"file-abc123\"\n  ],\n  \"status\": \"succeeded\",\n  \"validation_file\": null,\n  \"training_file\": \"file-abc123\",\n  \"hyperparameters\": {\n      \"n_epochs\": 4,\n      \"batch_size\": 1,\n      \"learning_rate_multiplier\": 1.0\n  },\n  \"trained_tokens\": 5768,\n  \"integrations\": [],\n  \"seed\": 0,\n  \"estimated_finish\": 0\n}\n"
  '/fine_tuning/jobs/{fine_tuning_job_id}/cancel':
    post:
      tags:
        - Fine-tuning
      summary: "Immediately cancel a fine-tune job.\n"
      operationId: cancelFineTuningJob
      parameters:
        - name: fine_tuning_job_id
          in: path
          description: "The ID of the fine-tuning job to cancel.\n"
          required: true
          schema:
            type: string
            example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
      x-oaiMeta:
        name: Cancel fine-tuning
        group: fine-tuning
        returns: 'The cancelled [fine-tuning](/docs/api-reference/fine-tuning/object) object.'
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.fine_tuning.jobs.cancel(\"ftjob-abc123\")\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const fineTune = await openai.fineTuning.jobs.cancel(\"ftjob-abc123\");\n\n  console.log(fineTune);\n}\nmain();"
          response: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"gpt-4o-mini-2024-07-18\",\n  \"created_at\": 1721764800,\n  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n  \"result_files\": [],\n  \"hyperparameters\": {\n    \"n_epochs\":  \"auto\"\n  },\n  \"status\": \"cancelled\",\n  \"validation_file\": \"file-abc123\",\n  \"training_file\": \"file-abc123\"\n}\n"
  '/fine_tuning/jobs/{fine_tuning_job_id}/checkpoints':
    get:
      tags:
        - Fine-tuning
      summary: "List checkpoints for a fine-tuning job.\n"
      operationId: listFineTuningJobCheckpoints
      parameters:
        - name: fine_tuning_job_id
          in: path
          description: "The ID of the fine-tuning job to get checkpoints for.\n"
          required: true
          schema:
            type: string
            example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
        - name: after
          in: query
          description: Identifier for the last checkpoint ID from the previous pagination request.
          schema:
            type: string
        - name: limit
          in: query
          description: Number of checkpoints to retrieve.
          schema:
            type: integer
            default: 10
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuningJobCheckpointsResponse'
      x-oaiMeta:
        name: List fine-tuning checkpoints
        group: fine-tuning
        returns: 'A list of fine-tuning [checkpoint objects](/docs/api-reference/fine-tuning/checkpoint-object) for a fine-tuning job.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
          response: "{\n  \"object\": \"list\"\n  \"data\": [\n    {\n      \"object\": \"fine_tuning.job.checkpoint\",\n      \"id\": \"ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB\",\n      \"created_at\": 1721764867,\n      \"fine_tuned_model_checkpoint\": \"ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:96olL566:ckpt-step-2000\",\n      \"metrics\": {\n        \"full_valid_loss\": 0.134,\n        \"full_valid_mean_token_accuracy\": 0.874\n      },\n      \"fine_tuning_job_id\": \"ftjob-abc123\",\n      \"step_number\": 2000,\n    },\n    {\n      \"object\": \"fine_tuning.job.checkpoint\",\n      \"id\": \"ftckpt_enQCFmOTGj3syEpYVhBRLTSy\",\n      \"created_at\": 1721764800,\n      \"fine_tuned_model_checkpoint\": \"ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000\",\n      \"metrics\": {\n        \"full_valid_loss\": 0.167,\n        \"full_valid_mean_token_accuracy\": 0.781\n      },\n      \"fine_tuning_job_id\": \"ftjob-abc123\",\n      \"step_number\": 1000,\n    },\n  ],\n  \"first_id\": \"ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB\",\n  \"last_id\": \"ftckpt_enQCFmOTGj3syEpYVhBRLTSy\",\n  \"has_more\": true\n}\n"
  '/fine_tuning/jobs/{fine_tuning_job_id}/events':
    get:
      tags:
        - Fine-tuning
      summary: "Get status updates for a fine-tuning job.\n"
      operationId: listFineTuningEvents
      parameters:
        - name: fine_tuning_job_id
          in: path
          description: "The ID of the fine-tuning job to get events for.\n"
          required: true
          schema:
            type: string
            example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
        - name: after
          in: query
          description: Identifier for the last event from the previous pagination request.
          schema:
            type: string
        - name: limit
          in: query
          description: Number of events to retrieve.
          schema:
            type: integer
            default: 20
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuningJobEventsResponse'
      x-oaiMeta:
        name: List fine-tuning events
        group: fine-tuning
        returns: A list of fine-tuning event objects.
        examples:
          request:
            curl: "curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.fine_tuning.jobs.list_events(\n  fine_tuning_job_id=\"ftjob-abc123\",\n  limit=2\n)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const list = await openai.fineTuning.list_events(id=\"ftjob-abc123\", limit=2);\n\n  for await (const fineTune of list) {\n    console.log(fineTune);\n  }\n}\n\nmain();"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"fine_tuning.job.event\",\n      \"id\": \"ft-event-ddTJfwuMVpfLXseO0Am0Gqjm\",\n      \"created_at\": 1721764800,\n      \"level\": \"info\",\n      \"message\": \"Fine tuning job successfully completed\",\n      \"data\": null,\n      \"type\": \"message\"\n    },\n    {\n      \"object\": \"fine_tuning.job.event\",\n      \"id\": \"ft-event-tyiGuB72evQncpH87xe505Sv\",\n      \"created_at\": 1721764800,\n      \"level\": \"info\",\n      \"message\": \"New fine-tuned model created: ft:gpt-4o-mini:openai::7p4lURel\",\n      \"data\": null,\n      \"type\": \"message\"\n    }\n  ],\n  \"has_more\": true\n}\n"
  /images/edits:
    post:
      tags:
        - Images
      summary: Creates an edited or extended image given an original image and a prompt.
      operationId: createImageEdit
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateImageEditRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
      x-oaiMeta:
        name: Create image edit
        group: images
        returns: 'Returns a list of [image](/docs/api-reference/images/object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/images/edits \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -F image=\"@otter.png\" \\\n  -F mask=\"@mask.png\" \\\n  -F prompt=\"A cute baby sea otter wearing a beret\" \\\n  -F n=2 \\\n  -F size=\"1024x1024\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.images.edit(\n  image=open(\"otter.png\", \"rb\"),\n  mask=open(\"mask.png\", \"rb\"),\n  prompt=\"A cute baby sea otter wearing a beret\",\n  n=2,\n  size=\"1024x1024\"\n)\n"
            node.js: "import fs from \"fs\";\nimport OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const image = await openai.images.edit({\n    image: fs.createReadStream(\"otter.png\"),\n    mask: fs.createReadStream(\"mask.png\"),\n    prompt: \"A cute baby sea otter wearing a beret\",\n  });\n\n  console.log(image.data);\n}\nmain();"
          response: "{\n  \"created\": 1589478378,\n  \"data\": [\n    {\n      \"url\": \"https://...\"\n    },\n    {\n      \"url\": \"https://...\"\n    }\n  ]\n}\n"
  /images/generations:
    post:
      tags:
        - Images
      summary: Creates an image given a prompt.
      operationId: createImage
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateImageRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
      x-oaiMeta:
        name: Create image
        group: images
        returns: 'Returns a list of [image](/docs/api-reference/images/object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/images/generations \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"dall-e-3\",\n    \"prompt\": \"A cute baby sea otter\",\n    \"n\": 1,\n    \"size\": \"1024x1024\"\n  }'\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.images.generate(\n  model=\"dall-e-3\",\n  prompt=\"A cute baby sea otter\",\n  n=1,\n  size=\"1024x1024\"\n)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const image = await openai.images.generate({ model: \"dall-e-3\", prompt: \"A cute baby sea otter\" });\n\n  console.log(image.data);\n}\nmain();"
          response: "{\n  \"created\": 1589478378,\n  \"data\": [\n    {\n      \"url\": \"https://...\"\n    },\n    {\n      \"url\": \"https://...\"\n    }\n  ]\n}\n"
  /images/variations:
    post:
      tags:
        - Images
      summary: Creates a variation of a given image.
      operationId: createImageVariation
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateImageVariationRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
      x-oaiMeta:
        name: Create image variation
        group: images
        returns: 'Returns a list of [image](/docs/api-reference/images/object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/images/variations \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -F image=\"@otter.png\" \\\n  -F n=2 \\\n  -F size=\"1024x1024\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nresponse = client.images.create_variation(\n  image=open(\"image_edit_original.png\", \"rb\"),\n  n=2,\n  size=\"1024x1024\"\n)\n"
            node.js: "import fs from \"fs\";\nimport OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const image = await openai.images.createVariation({\n    image: fs.createReadStream(\"otter.png\"),\n  });\n\n  console.log(image.data);\n}\nmain();"
          response: "{\n  \"created\": 1589478378,\n  \"data\": [\n    {\n      \"url\": \"https://...\"\n    },\n    {\n      \"url\": \"https://...\"\n    }\n  ]\n}\n"
  /models:
    get:
      tags:
        - Models
      summary: 'Lists the currently available models, and provides basic information about each one such as the owner and availability.'
      operationId: listModels
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListModelsResponse'
      x-oaiMeta:
        name: List models
        group: models
        returns: 'A list of [model](/docs/api-reference/models/object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/models \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.models.list()\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const list = await openai.models.list();\n\n  for await (const model of list) {\n    console.log(model);\n  }\n}\nmain();"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"model-id-0\",\n      \"object\": \"model\",\n      \"created\": 1686935002,\n      \"owned_by\": \"organization-owner\"\n    },\n    {\n      \"id\": \"model-id-1\",\n      \"object\": \"model\",\n      \"created\": 1686935002,\n      \"owned_by\": \"organization-owner\",\n    },\n    {\n      \"id\": \"model-id-2\",\n      \"object\": \"model\",\n      \"created\": 1686935002,\n      \"owned_by\": \"openai\"\n    },\n  ],\n  \"object\": \"list\"\n}\n"
  '/models/{model}':
    get:
      tags:
        - Models
      summary: 'Retrieves a model instance, providing basic information about the model such as the owner and permissioning.'
      operationId: retrieveModel
      parameters:
        - name: model
          in: path
          description: The ID of the model to use for this request
          required: true
          schema:
            type: string
            example: gpt-4o-mini
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Model'
      x-oaiMeta:
        name: Retrieve model
        group: models
        returns: 'The [model](/docs/api-reference/models/object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/models/VAR_chat_model_id \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.models.retrieve(\"VAR_chat_model_id\")\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const model = await openai.models.retrieve(\"VAR_chat_model_id\");\n\n  console.log(model);\n}\n\nmain();"
          response: "{\n  \"id\": \"VAR_chat_model_id\",\n  \"object\": \"model\",\n  \"created\": 1686935002,\n  \"owned_by\": \"openai\"\n}\n"
    delete:
      tags:
        - Models
      summary: Delete a fine-tuned model. You must have the Owner role in your organization to delete a model.
      operationId: deleteModel
      parameters:
        - name: model
          in: path
          description: The model to delete
          required: true
          schema:
            type: string
            example: ft:gpt-4o-mini:acemeco:suffix:abc123
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteModelResponse'
      x-oaiMeta:
        name: Delete a fine-tuned model
        group: models
        returns: Deletion status.
        examples:
          request:
            curl: "curl https://api.openai.com/v1/models/ft:gpt-4o-mini:acemeco:suffix:abc123 \\\n  -X DELETE \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.models.delete(\"ft:gpt-4o-mini:acemeco:suffix:abc123\")\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const model = await openai.models.del(\"ft:gpt-4o-mini:acemeco:suffix:abc123\");\n\n  console.log(model);\n}\nmain();"
          response: "{\n  \"id\": \"ft:gpt-4o-mini:acemeco:suffix:abc123\",\n  \"object\": \"model\",\n  \"deleted\": true\n}\n"
  /moderations:
    post:
      tags:
        - Moderations
      summary: "Classifies if text and/or image inputs are potentially harmful. Learn\nmore in the [moderation guide](/docs/guides/moderation).\n"
      operationId: createModeration
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateModerationRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateModerationResponse'
      x-oaiMeta:
        name: Create moderation
        group: moderations
        returns: 'A [moderation](/docs/api-reference/moderations/object) object.'
        examples:
          - title: Single string
            request:
              curl: "curl https://api.openai.com/v1/moderations \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"input\": \"I want to kill them.\"\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\nmoderation = client.moderations.create(input=\"I want to kill them.\")\nprint(moderation)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const moderation = await openai.moderations.create({ input: \"I want to kill them.\" });\n\n  console.log(moderation);\n}\nmain();\n"
            response: "{\n  \"id\": \"modr-AB8CjOTu2jiq12hp1AQPfeqFWaORR\",\n  \"model\": \"text-moderation-007\",\n  \"results\": [\n    {\n      \"flagged\": true,\n      \"categories\": {\n        \"sexual\": false,\n        \"hate\": false,\n        \"harassment\": true,\n        \"self-harm\": false,\n        \"sexual/minors\": false,\n        \"hate/threatening\": false,\n        \"violence/graphic\": false,\n        \"self-harm/intent\": false,\n        \"self-harm/instructions\": false,\n        \"harassment/threatening\": true,\n        \"violence\": true\n      },\n      \"category_scores\": {\n        \"sexual\": 0.000011726012417057063,\n        \"hate\": 0.22706663608551025,\n        \"harassment\": 0.5215635299682617,\n        \"self-harm\": 2.227119921371923e-6,\n        \"sexual/minors\": 7.107352217872176e-8,\n        \"hate/threatening\": 0.023547329008579254,\n        \"violence/graphic\": 0.00003391829886822961,\n        \"self-harm/intent\": 1.646940972932498e-6,\n        \"self-harm/instructions\": 1.1198755256458526e-9,\n        \"harassment/threatening\": 0.5694745779037476,\n        \"violence\": 0.9971134662628174\n      }\n    }\n  ]\n}\n"
          - title: Image and text
            request:
              curl: "curl https://api.openai.com/v1/moderations \\\n  -X POST \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"omni-moderation-latest\",\n    \"input\": [\n      { \"type\": \"text\", \"text\": \"...text to classify goes here...\" },\n      {\n        \"type\": \"image_url\",\n        \"image_url\": {\n          \"url\": \"https://example.com/image.png\"\n        }\n      }\n    ]\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\nresponse = client.moderations.create(\n    model=\"omni-moderation-latest\",\n    input=[\n        {\"type\": \"text\", \"text\": \"...text to classify goes here...\"},\n        {\n            \"type\": \"image_url\",\n            \"image_url\": {\n                \"url\": \"https://example.com/image.png\",\n                # can also use base64 encoded image URLs\n                # \"url\": \"data:image/jpeg;base64,abcdefg...\"\n            }\n        },\n    ],\n)\n\nprint(response)\n"
              node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\nconst moderation = await openai.moderations.create({\n    model: \"omni-moderation-latest\",\n    input: [\n        { type: \"text\", text: \"...text to classify goes here...\" },\n        {\n            type: \"image_url\",\n            image_url: {\n                url: \"https://example.com/image.png\"\n                // can also use base64 encoded image URLs\n                // url: \"data:image/jpeg;base64,abcdefg...\"\n            }\n        }\n    ],\n});\n\nconsole.log(moderation);\n"
            response: "{\n  \"id\": \"modr-0d9740456c391e43c445bf0f010940c7\",\n  \"model\": \"omni-moderation-latest\",\n  \"results\": [\n    {\n      \"flagged\": true,\n      \"categories\": {\n        \"harassment\": true,\n        \"harassment/threatening\": true,\n        \"sexual\": false,\n        \"hate\": false,\n        \"hate/threatening\": false,\n        \"illicit\": false,\n        \"illicit/violent\": false,\n        \"self-harm/intent\": false,\n        \"self-harm/instructions\": false,\n        \"self-harm\": false,\n        \"sexual/minors\": false,\n        \"violence\": true,\n        \"violence/graphic\": true\n      },\n      \"category_scores\": {\n        \"harassment\": 0.8189693396524255,\n        \"harassment/threatening\": 0.804985420696006,\n        \"sexual\": 1.573112165348997e-6,\n        \"hate\": 0.007562942636942845,\n        \"hate/threatening\": 0.004208854591835476,\n        \"illicit\": 0.030535955153511665,\n        \"illicit/violent\": 0.008925306722380033,\n        \"self-harm/intent\": 0.00023023930975076432,\n        \"self-harm/instructions\": 0.0002293869201073356,\n        \"self-harm\": 0.012598046106750154,\n        \"sexual/minors\": 2.212566909570261e-8,\n        \"violence\": 0.9999992735124786,\n        \"violence/graphic\": 0.843064871157054\n      },\n      \"category_applied_input_types\": {\n        \"harassment\": [\n          \"text\"\n        ],\n        \"harassment/threatening\": [\n          \"text\"\n        ],\n        \"sexual\": [\n          \"text\",\n          \"image\"\n        ],\n        \"hate\": [\n          \"text\"\n        ],\n        \"hate/threatening\": [\n          \"text\"\n        ],\n        \"illicit\": [\n          \"text\"\n        ],\n        \"illicit/violent\": [\n          \"text\"\n        ],\n        \"self-harm/intent\": [\n          \"text\",\n          \"image\"\n        ],\n        \"self-harm/instructions\": [\n          \"text\",\n          \"image\"\n        ],\n        \"self-harm\": [\n          \"text\",\n          \"image\"\n        ],\n        \"sexual/minors\": [\n          \"text\"\n        ],\n        \"violence\": [\n          \"text\",\n          \"image\"\n        ],\n        \"violence/graphic\": [\n          \"text\",\n          \"image\"\n        ]\n      }\n    }\n  ]\n}\n"
  /organization/audit_logs:
    get:
      tags:
        - Audit Logs
      summary: List user actions and configuration changes within this organization.
      operationId: list-audit-logs
      parameters:
        - name: effective_at
          in: query
          description: Return only events whose `effective_at` (Unix seconds) is in this range.
          schema:
            type: object
            properties:
              gt:
                type: integer
                description: Return only events whose `effective_at` (Unix seconds) is greater than this value.
              gte:
                type: integer
                description: Return only events whose `effective_at` (Unix seconds) is greater than or equal to this value.
              lt:
                type: integer
                description: Return only events whose `effective_at` (Unix seconds) is less than this value.
              lte:
                type: integer
                description: Return only events whose `effective_at` (Unix seconds) is less than or equal to this value.
        - name: 'project_ids[]'
          in: query
          description: Return only events for these projects.
          schema:
            type: array
            items:
              type: string
        - name: 'event_types[]'
          in: query
          description: 'Return only events with a `type` in one of these values. For example, `project.created`. For all options, see the documentation for the [audit log object](/docs/api-reference/audit-logs/object).'
          schema:
            type: array
            items:
              $ref: '#/components/schemas/AuditLogEventType'
        - name: 'actor_ids[]'
          in: query
          description: 'Return only events performed by these actors. Can be a user ID, a service account ID, or an api key tracking ID.'
          schema:
            type: array
            items:
              type: string
        - name: 'actor_emails[]'
          in: query
          description: Return only events performed by users with these emails.
          schema:
            type: array
            items:
              type: string
        - name: 'resource_ids[]'
          in: query
          description: 'Return only events performed on these targets. For example, a project ID updated.'
          schema:
            type: array
            items:
              type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: before
          in: query
          description: "A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: Audit logs listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListAuditLogsResponse'
      x-oaiMeta:
        name: List audit logs
        group: audit-logs
        returns: 'A list of paginated [Audit Log](/docs/api-reference/audit-logs/object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/audit_logs \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"id\": \"audit_log-xxx_yyyymmdd\",\n            \"type\": \"project.archived\",\n            \"effective_at\": 1722461446,\n            \"actor\": {\n                \"type\": \"api_key\",\n                \"api_key\": {\n                    \"type\": \"user\",\n                    \"user\": {\n                        \"id\": \"user-xxx\",\n                        \"email\": \"user@example.com\"\n                    }\n                }\n            },\n            \"project.archived\": {\n                \"id\": \"proj_abc\"\n            },\n        },\n        {\n            \"id\": \"audit_log-yyy__20240101\",\n            \"type\": \"api_key.updated\",\n            \"effective_at\": 1720804190,\n            \"actor\": {\n                \"type\": \"session\",\n                \"session\": {\n                    \"user\": {\n                        \"id\": \"user-xxx\",\n                        \"email\": \"user@example.com\"\n                    },\n                    \"ip_address\": \"127.0.0.1\",\n                    \"user_agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n                }\n            },\n            \"api_key.updated\": {\n                \"id\": \"key_xxxx\",\n                \"data\": {\n                    \"scopes\": [\"resource_2.operation_2\"]\n                }\n            },\n        }\n    ],\n    \"first_id\": \"audit_log-xxx__20240101\",\n    \"last_id\": \"audit_log_yyy__20240101\",\n    \"has_more\": true\n}\n"
  /organization/costs:
    get:
      tags:
        - Usage
      summary: Get costs details for the organization.
      operationId: usage-costs
      parameters:
        - name: start_time
          in: query
          description: 'Start time (Unix seconds) of the query time range, inclusive.'
          required: true
          schema:
            type: integer
        - name: end_time
          in: query
          description: 'End time (Unix seconds) of the query time range, exclusive.'
          schema:
            type: integer
        - name: bucket_width
          in: query
          description: 'Width of each time bucket in response. Currently only `1d` is supported, default to `1d`.'
          schema:
            enum:
              - 1d
            type: string
            default: 1d
        - name: project_ids
          in: query
          description: Return only costs for these projects.
          schema:
            type: array
            items:
              type: string
        - name: group_by
          in: query
          description: 'Group the costs by the specified fields. Support fields include `project_id`, `line_item` and any combination of them.'
          schema:
            type: array
            items:
              enum:
                - project_id
                - line_item
              type: string
        - name: limit
          in: query
          description: "A limit on the number of buckets to be returned. Limit can range between 1 and 180, and the default is 7.\n"
          schema:
            type: integer
            default: 7
        - name: page
          in: query
          description: A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.
          schema:
            type: string
      responses:
        '200':
          description: Costs data retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        name: Costs
        group: usage-costs
        returns: 'A list of paginated, time bucketed [Costs](/docs/api-reference/usage/costs_object) objects.'
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/costs?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"orgainzation.costs.result\",\n                    \"amount\": {\n                        \"value\": 0.06,\n                        \"currency\": \"usd\"\n                    },\n                    \"line_item\": null,\n                    \"project_id\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\n"
  /organization/invites:
    get:
      tags:
        - Invites
      summary: Returns a list of invites in the organization.
      operationId: list-invites
      parameters:
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: Invites listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/InviteListResponse'
      x-oaiMeta:
        name: List invites
        group: administration
        returns: 'A list of [Invite](/docs/api-reference/invite/object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/invites?after=invite-abc&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response:
            content: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"organization.invite\",\n      \"id\": \"invite-abc\",\n      \"email\": \"user@example.com\",\n      \"role\": \"owner\",\n      \"status\": \"accepted\",\n      \"invited_at\": 1711471533,\n      \"expires_at\": 1711471533,\n      \"accepted_at\": 1711471533\n    }\n  ],\n  \"first_id\": \"invite-abc\",\n  \"last_id\": \"invite-abc\",\n  \"has_more\": false\n}\n"
    post:
      tags:
        - Invites
      summary: Create an invite for a user to the organization. The invite must be accepted by the user before they have access to the organization.
      operationId: inviteUser
      requestBody:
        description: The invite request payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/InviteRequest'
        required: true
      responses:
        '200':
          description: User invited successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Invite'
      x-oaiMeta:
        name: Create invite
        group: administration
        returns: 'The created [Invite](/docs/api-reference/invite/object) object.'
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/invites \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"email\": \"user@example.com\",\n      \"role\": \"owner\"\n  }'\n"
          response:
            content: "{\n    \"object\": \"organization.invite\",\n    \"id\": \"invite-abc\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"invited_at\": 1711471533,\n    \"expires_at\": 1711471533,\n    \"accepted_at\": null\n}\n"
  '/organization/invites/{invite_id}':
    get:
      tags:
        - Invites
      summary: Retrieves an invite.
      operationId: retrieve-invite
      parameters:
        - name: invite_id
          in: path
          description: The ID of the invite to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Invite retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Invite'
      x-oaiMeta:
        name: Retrieve invite
        group: administration
        returns: 'The [Invite](/docs/api-reference/invite/object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/invites/invite-abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response:
            content: "{\n    \"object\": \"organization.invite\",\n    \"id\": \"invite-abc\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"status\": \"accepted\",\n    \"invited_at\": 1711471533,\n    \"expires_at\": 1711471533,\n    \"accepted_at\": 1711471533\n}\n"
    delete:
      tags:
        - Invites
      summary: 'Delete an invite. If the invite has already been accepted, it cannot be deleted.'
      operationId: delete-invite
      parameters:
        - name: invite_id
          in: path
          description: The ID of the invite to delete.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Invite deleted successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/InviteDeleteResponse'
      x-oaiMeta:
        name: Delete invite
        group: administration
        returns: Confirmation that the invite has been deleted
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/organization/invites/invite-abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response:
            content: "{\n    \"object\": \"organization.invite.deleted\",\n    \"id\": \"invite-abc\",\n    \"deleted\": true\n}\n"
  /organization/projects:
    get:
      tags:
        - Projects
      summary: Returns a list of projects.
      operationId: list-projects
      parameters:
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: include_archived
          in: query
          description: If `true` returns all projects including those that have been `archived`. Archived projects are not included by default.
          schema:
            type: boolean
            default: false
      responses:
        '200':
          description: Projects listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectListResponse'
      x-oaiMeta:
        name: List projects
        group: administration
        returns: 'A list of [Project](/docs/api-reference/projects/object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects?after=proj_abc&limit=20&include_archived=false \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response:
            content: "{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"id\": \"proj_abc\",\n            \"object\": \"organization.project\",\n            \"name\": \"Project example\",\n            \"created_at\": 1711471533,\n            \"archived_at\": null,\n            \"status\": \"active\"\n        }\n    ],\n    \"first_id\": \"proj-abc\",\n    \"last_id\": \"proj-xyz\",\n    \"has_more\": false\n}\n"
    post:
      tags:
        - Projects
      summary: 'Create a new project in the organization. Projects can be created and archived, but cannot be deleted.'
      operationId: create-project
      requestBody:
        description: The project create request payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectCreateRequest'
        required: true
      responses:
        '200':
          description: Project created successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'
      x-oaiMeta:
        name: Create project
        group: administration
        returns: 'The created [Project](/docs/api-reference/projects/object) object.'
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/projects \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"name\": \"Project ABC\"\n  }'\n"
          response:
            content: "{\n    \"id\": \"proj_abc\",\n    \"object\": \"organization.project\",\n    \"name\": \"Project ABC\",\n    \"created_at\": 1711471533,\n    \"archived_at\": null,\n    \"status\": \"active\"\n}\n"
  '/organization/projects/{project_id}':
    get:
      tags:
        - Projects
      summary: Retrieves a project.
      operationId: retrieve-project
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Project retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'
      x-oaiMeta:
        name: Retrieve project
        group: administration
        description: Retrieve a project.
        returns: 'The [Project](/docs/api-reference/projects/object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response:
            content: "{\n    \"id\": \"proj_abc\",\n    \"object\": \"organization.project\",\n    \"name\": \"Project example\",\n    \"created_at\": 1711471533,\n    \"archived_at\": null,\n    \"status\": \"active\"\n}\n"
    post:
      tags:
        - Projects
      summary: Modifies a project in the organization.
      operationId: modify-project
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
      requestBody:
        description: The project update request payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectUpdateRequest'
        required: true
      responses:
        '200':
          description: Project updated successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'
        '400':
          description: Error response when updating the default project.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        name: Modify project
        group: administration
        returns: 'The updated [Project](/docs/api-reference/projects/object) object.'
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/projects/proj_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"name\": \"Project DEF\"\n  }'\n"
  '/organization/projects/{project_id}/api_keys':
    get:
      tags:
        - Projects
      summary: Returns a list of API keys in the project.
      operationId: list-project-api-keys
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: Project API keys listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectApiKeyListResponse'
      x-oaiMeta:
        name: List project API keys
        group: administration
        returns: 'A list of [ProjectApiKey](/docs/api-reference/project-api-keys/object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys?after=key_abc&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response:
            content: "{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"object\": \"organization.project.api_key\",\n            \"redacted_value\": \"sk-abc...def\",\n            \"name\": \"My API Key\",\n            \"created_at\": 1711471533,\n            \"id\": \"key_abc\",\n            \"owner\": {\n                \"type\": \"user\",\n                \"user\": {\n                    \"object\": \"organization.project.user\",\n                    \"id\": \"user_abc\",\n                    \"name\": \"First Last\",\n                    \"email\": \"user@example.com\",\n                    \"role\": \"owner\",\n                    \"added_at\": 1711471533\n                }\n            }\n        }\n    ],\n    \"first_id\": \"key_abc\",\n    \"last_id\": \"key_xyz\",\n    \"has_more\": false\n}\n"
          error_response:
            content: "{\n    \"code\": 400,\n    \"message\": \"Project {name} is archived\"\n}\n"
  '/organization/projects/{project_id}/api_keys/{key_id}':
    get:
      tags:
        - Projects
      summary: Retrieves an API key in the project.
      operationId: retrieve-project-api-key
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: key_id
          in: path
          description: The ID of the API key.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Project API key retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectApiKey'
      x-oaiMeta:
        name: Retrieve project API key
        group: administration
        returns: 'The [ProjectApiKey](/docs/api-reference/project-api-keys/object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response:
            content: "{\n    \"object\": \"organization.project.api_key\",\n    \"redacted_value\": \"sk-abc...def\",\n    \"name\": \"My API Key\",\n    \"created_at\": 1711471533,\n    \"id\": \"key_abc\",\n    \"owner\": {\n        \"type\": \"user\",\n        \"user\": {\n            \"object\": \"organization.project.user\",\n            \"id\": \"user_abc\",\n            \"name\": \"First Last\",\n            \"email\": \"user@example.com\",\n            \"role\": \"owner\",\n            \"added_at\": 1711471533\n        }\n    }\n}\n"
    delete:
      tags:
        - Projects
      summary: Deletes an API key from the project.
      operationId: delete-project-api-key
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: key_id
          in: path
          description: The ID of the API key.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Project API key deleted successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectApiKeyDeleteResponse'
        '400':
          description: Error response for various conditions.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        name: Delete project API key
        group: administration
        returns: Confirmation of the key's deletion or an error if the key belonged to a service account
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response:
            content: "{\n    \"object\": \"organization.project.api_key.deleted\",\n    \"id\": \"key_abc\",\n    \"deleted\": true\n}\n"
          error_response:
            content: "{\n    \"code\": 400,\n    \"message\": \"API keys cannot be deleted for service accounts, please delete the service account\"\n}\n"
  '/organization/projects/{project_id}/archive':
    post:
      tags:
        - Projects
      summary: Archives a project in the organization. Archived projects cannot be used or updated.
      operationId: archive-project
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Project archived successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'
      x-oaiMeta:
        name: Archive project
        group: administration
        returns: 'The archived [Project](/docs/api-reference/projects/object) object.'
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/archive \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response:
            content: "{\n    \"id\": \"proj_abc\",\n    \"object\": \"organization.project\",\n    \"name\": \"Project DEF\",\n    \"created_at\": 1711471533,\n    \"archived_at\": 1711471533,\n    \"status\": \"archived\"\n}\n"
  '/organization/projects/{project_id}/rate_limits':
    get:
      tags:
        - Projects
      summary: Returns the rate limits per model for a project.
      operationId: list-project-rate-limits
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. The default is 100.\n"
          schema:
            type: integer
            default: 100
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: before
          in: query
          description: "A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, beginning with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: Project rate limits listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectRateLimitListResponse'
      x-oaiMeta:
        name: List project rate limits
        group: administration
        returns: 'A list of [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc/rate_limits?after=rl_xxx&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"list\",\n    \"data\": [\n        {\n          \"object\": \"project.rate_limit\",\n          \"id\": \"rl-ada\",\n          \"model\": \"ada\",\n          \"max_requests_per_1_minute\": 600,\n          \"max_tokens_per_1_minute\": 150000,\n          \"max_images_per_1_minute\": 10\n        }\n    ],\n    \"first_id\": \"rl-ada\",\n    \"last_id\": \"rl-ada\",\n    \"has_more\": false\n}\n"
          error_response: "{\n    \"code\": 404,\n    \"message\": \"The project {project_id} was not found\"\n}\n"
  '/organization/projects/{project_id}/rate_limits/{rate_limit_id}':
    post:
      tags:
        - Projects
      summary: Updates a project rate limit.
      operationId: update-project-rate-limits
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: rate_limit_id
          in: path
          description: The ID of the rate limit.
          required: true
          schema:
            type: string
      requestBody:
        description: The project rate limit update request payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectRateLimitUpdateRequest'
        required: true
      responses:
        '200':
          description: Project rate limit updated successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectRateLimit'
        '400':
          description: Error response for various conditions.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        name: Modify project rate limit
        group: administration
        returns: 'The updated [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) object.'
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/rate_limits/rl_xxx \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"max_requests_per_1_minute\": 500\n  }'\n"
          response: "{\n    \"object\": \"project.rate_limit\",\n    \"id\": \"rl-ada\",\n    \"model\": \"ada\",\n    \"max_requests_per_1_minute\": 600,\n    \"max_tokens_per_1_minute\": 150000,\n    \"max_images_per_1_minute\": 10\n  }\n"
          error_response: "{\n    \"code\": 404,\n    \"message\": \"The project {project_id} was not found\"\n}\n"
  '/organization/projects/{project_id}/service_accounts':
    get:
      tags:
        - Projects
      summary: Returns a list of service accounts in the project.
      operationId: list-project-service-accounts
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: Project service accounts listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectServiceAccountListResponse'
        '400':
          description: Error response when project is archived.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        name: List project service accounts
        group: administration
        returns: 'A list of [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts?after=custom_id&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response:
            content: "{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"object\": \"organization.project.service_account\",\n            \"id\": \"svc_acct_abc\",\n            \"name\": \"Service Account\",\n            \"role\": \"owner\",\n            \"created_at\": 1711471533\n        }\n    ],\n    \"first_id\": \"svc_acct_abc\",\n    \"last_id\": \"svc_acct_xyz\",\n    \"has_more\": false\n}\n"
    post:
      tags:
        - Projects
      summary: Creates a new service account in the project. This also returns an unredacted API key for the service account.
      operationId: create-project-service-account
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
      requestBody:
        description: The project service account create request payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectServiceAccountCreateRequest'
        required: true
      responses:
        '200':
          description: Project service account created successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectServiceAccountCreateResponse'
        '400':
          description: Error response when project is archived.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        name: Create project service account
        group: administration
        returns: 'The created [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object.'
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/service_accounts \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"name\": \"Production App\"\n  }'\n"
          response:
            content: "{\n    \"object\": \"organization.project.service_account\",\n    \"id\": \"svc_acct_abc\",\n    \"name\": \"Production App\",\n    \"role\": \"member\",\n    \"created_at\": 1711471533,\n    \"api_key\": {\n        \"object\": \"organization.project.service_account.api_key\",\n        \"value\": \"sk-abcdefghijklmnop123\",\n        \"name\": \"Secret Key\",\n        \"created_at\": 1711471533,\n        \"id\": \"key_abc\"\n    }\n}\n"
  '/organization/projects/{project_id}/service_accounts/{service_account_id}':
    get:
      tags:
        - Projects
      summary: Retrieves a service account in the project.
      operationId: retrieve-project-service-account
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: service_account_id
          in: path
          description: The ID of the service account.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Project service account retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectServiceAccount'
      x-oaiMeta:
        name: Retrieve project service account
        group: administration
        returns: 'The [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response:
            content: "{\n    \"object\": \"organization.project.service_account\",\n    \"id\": \"svc_acct_abc\",\n    \"name\": \"Service Account\",\n    \"role\": \"owner\",\n    \"created_at\": 1711471533\n}\n"
    delete:
      tags:
        - Projects
      summary: Deletes a service account from the project.
      operationId: delete-project-service-account
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: service_account_id
          in: path
          description: The ID of the service account.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Project service account deleted successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectServiceAccountDeleteResponse'
      x-oaiMeta:
        name: Delete project service account
        group: administration
        returns: 'Confirmation of service account being deleted, or an error in case of an archived project, which has no service accounts'
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response:
            content: "{\n    \"object\": \"organization.project.service_account.deleted\",\n    \"id\": \"svc_acct_abc\",\n    \"deleted\": true\n}\n"
  '/organization/projects/{project_id}/users':
    get:
      tags:
        - Projects
      summary: Returns a list of users in the project.
      operationId: list-project-users
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: Project users listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUserListResponse'
        '400':
          description: Error response when project is archived.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        name: List project users
        group: administration
        returns: 'A list of [ProjectUser](/docs/api-reference/project-users/object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc/users?after=user_abc&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response:
            content: "{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"object\": \"organization.project.user\",\n            \"id\": \"user_abc\",\n            \"name\": \"First Last\",\n            \"email\": \"user@example.com\",\n            \"role\": \"owner\",\n            \"added_at\": 1711471533\n        }\n    ],\n    \"first_id\": \"user-abc\",\n    \"last_id\": \"user-xyz\",\n    \"has_more\": false\n}\n"
          error_response:
            content: "{\n    \"code\": 400,\n    \"message\": \"Project {name} is archived\"\n}\n"
    post:
      tags:
        - Projects
      summary: Adds a user to the project. Users must already be members of the organization to be added to a project.
      operationId: create-project-user
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
      requestBody:
        description: The project user create request payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectUserCreateRequest'
        required: true
      responses:
        '200':
          description: User added to project successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUser'
        '400':
          description: Error response for various conditions.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        name: Create project user
        group: administration
        returns: 'The created [ProjectUser](/docs/api-reference/project-users/object) object.'
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"user_id\": \"user_abc\",\n      \"role\": \"member\"\n  }'\n"
          response:
            content: "{\n    \"object\": \"organization.project.user\",\n    \"id\": \"user_abc\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\n"
          error_response:
            content: "{\n    \"code\": 400,\n    \"message\": \"Project {name} is archived\"\n}\n"
  '/organization/projects/{project_id}/users/{user_id}':
    get:
      tags:
        - Projects
      summary: Retrieves a user in the project.
      operationId: retrieve-project-user
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: user_id
          in: path
          description: The ID of the user.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Project user retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUser'
      x-oaiMeta:
        name: Retrieve project user
        group: administration
        returns: 'The [ProjectUser](/docs/api-reference/project-users/object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response:
            content: "{\n    \"object\": \"organization.project.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\n"
    post:
      tags:
        - Projects
      summary: Modifies a user's role in the project.
      operationId: modify-project-user
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: user_id
          in: path
          description: The ID of the user.
          required: true
          schema:
            type: string
      requestBody:
        description: The project user update request payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectUserUpdateRequest'
        required: true
      responses:
        '200':
          description: Project user's role updated successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUser'
        '400':
          description: Error response for various conditions.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        name: Modify project user
        group: administration
        returns: 'The updated [ProjectUser](/docs/api-reference/project-users/object) object.'
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"role\": \"owner\"\n  }'\n"
          response:
            content: "{\n    \"object\": \"organization.project.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\n"
    delete:
      tags:
        - Projects
      summary: Deletes a user from the project.
      operationId: delete-project-user
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: user_id
          in: path
          description: The ID of the user.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Project user deleted successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUserDeleteResponse'
        '400':
          description: Error response for various conditions.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        name: Delete project user
        group: administration
        returns: 'Confirmation that project has been deleted or an error in case of an archived project, which has no users'
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response:
            content: "{\n    \"object\": \"organization.project.user.deleted\",\n    \"id\": \"user_abc\",\n    \"deleted\": true\n}\n"
  /organization/usage/audio_speeches:
    get:
      tags:
        - Usage
      summary: Get audio speeches usage details for the organization.
      operationId: usage-audio-speeches
      parameters:
        - name: start_time
          in: query
          description: 'Start time (Unix seconds) of the query time range, inclusive.'
          required: true
          schema:
            type: integer
        - name: end_time
          in: query
          description: 'End time (Unix seconds) of the query time range, exclusive.'
          schema:
            type: integer
        - name: bucket_width
          in: query
          description: 'Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.'
          schema:
            enum:
              - 1m
              - 1h
              - 1d
            type: string
            default: 1d
        - name: project_ids
          in: query
          description: Return only usage for these projects.
          schema:
            type: array
            items:
              type: string
        - name: user_ids
          in: query
          description: Return only usage for these users.
          schema:
            type: array
            items:
              type: string
        - name: api_key_ids
          in: query
          description: Return only usage for these API keys.
          schema:
            type: array
            items:
              type: string
        - name: models
          in: query
          description: Return only usage for these models.
          schema:
            type: array
            items:
              type: string
        - name: group_by
          in: query
          description: 'Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.'
          schema:
            type: array
            items:
              enum:
                - project_id
                - user_id
                - api_key_id
                - model
              type: string
        - name: limit
          in: query
          description: "Specifies the number of buckets to return.\n- `bucket_width=1d`: default: 7, max: 31\n- `bucket_width=1h`: default: 24, max: 168\n- `bucket_width=1m`: default: 60, max: 1440\n"
          schema:
            type: integer
        - name: page
          in: query
          description: A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.
          schema:
            type: string
      responses:
        '200':
          description: Usage data retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        name: Audio speeches
        group: usage-audio-speeches
        returns: 'A list of paginated, time bucketed [Audio speeches usage](/docs/api-reference/usage/audio_speeches_object) objects.'
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/usage/audio_speeches?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"orgainzation.usage.audio_speeches.result\",\n                    \"characters\": 45,\n                    \"num_model_requests\": 1,\n                    \"project_id\": null,\n                    \"user_id\": null,\n                    \"api_key_id\": null,\n                    \"model\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\n"
  /organization/usage/audio_transcriptions:
    get:
      tags:
        - Usage
      summary: Get audio transcriptions usage details for the organization.
      operationId: usage-audio-transcriptions
      parameters:
        - name: start_time
          in: query
          description: 'Start time (Unix seconds) of the query time range, inclusive.'
          required: true
          schema:
            type: integer
        - name: end_time
          in: query
          description: 'End time (Unix seconds) of the query time range, exclusive.'
          schema:
            type: integer
        - name: bucket_width
          in: query
          description: 'Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.'
          schema:
            enum:
              - 1m
              - 1h
              - 1d
            type: string
            default: 1d
        - name: project_ids
          in: query
          description: Return only usage for these projects.
          schema:
            type: array
            items:
              type: string
        - name: user_ids
          in: query
          description: Return only usage for these users.
          schema:
            type: array
            items:
              type: string
        - name: api_key_ids
          in: query
          description: Return only usage for these API keys.
          schema:
            type: array
            items:
              type: string
        - name: models
          in: query
          description: Return only usage for these models.
          schema:
            type: array
            items:
              type: string
        - name: group_by
          in: query
          description: 'Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.'
          schema:
            type: array
            items:
              enum:
                - project_id
                - user_id
                - api_key_id
                - model
              type: string
        - name: limit
          in: query
          description: "Specifies the number of buckets to return.\n- `bucket_width=1d`: default: 7, max: 31\n- `bucket_width=1h`: default: 24, max: 168\n- `bucket_width=1m`: default: 60, max: 1440\n"
          schema:
            type: integer
        - name: page
          in: query
          description: A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.
          schema:
            type: string
      responses:
        '200':
          description: Usage data retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        name: Audio transcriptions
        group: usage-audio-transcriptions
        returns: 'A list of paginated, time bucketed [Audio transcriptions usage](/docs/api-reference/usage/audio_transcriptions_object) objects.'
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/usage/audio_transcriptions?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"orgainzation.usage.audio_transcriptions.result\",\n                    \"seconds\": 20,\n                    \"num_model_requests\": 1,\n                    \"project_id\": null,\n                    \"user_id\": null,\n                    \"api_key_id\": null,\n                    \"model\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\n"
  /organization/usage/code_interpreter_sessions:
    get:
      tags:
        - Usage
      summary: Get code interpreter sessions usage details for the organization.
      operationId: usage-code-interpreter-sessions
      parameters:
        - name: start_time
          in: query
          description: 'Start time (Unix seconds) of the query time range, inclusive.'
          required: true
          schema:
            type: integer
        - name: end_time
          in: query
          description: 'End time (Unix seconds) of the query time range, exclusive.'
          schema:
            type: integer
        - name: bucket_width
          in: query
          description: 'Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.'
          schema:
            enum:
              - 1m
              - 1h
              - 1d
            type: string
            default: 1d
        - name: project_ids
          in: query
          description: Return only usage for these projects.
          schema:
            type: array
            items:
              type: string
        - name: group_by
          in: query
          description: Group the usage data by the specified fields. Support fields include `project_id`.
          schema:
            type: array
            items:
              enum:
                - project_id
              type: string
        - name: limit
          in: query
          description: "Specifies the number of buckets to return.\n- `bucket_width=1d`: default: 7, max: 31\n- `bucket_width=1h`: default: 24, max: 168\n- `bucket_width=1m`: default: 60, max: 1440\n"
          schema:
            type: integer
        - name: page
          in: query
          description: A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.
          schema:
            type: string
      responses:
        '200':
          description: Usage data retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        name: Code interpreter sessions
        group: usage-code-interpreter-sessions
        returns: 'A list of paginated, time bucketed [Code interpreter sessions usage](/docs/api-reference/usage/code_interpreter_sessions_object) objects.'
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/usage/code_interpreter_sessions?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"orgainzation.usage.code_interpreter_sessions.result\",\n                    \"sessions\": 1,\n                    \"project_id\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\n"
  /organization/usage/completions:
    get:
      tags:
        - Usage
      summary: Get completions usage details for the organization.
      operationId: usage-completions
      parameters:
        - name: start_time
          in: query
          description: 'Start time (Unix seconds) of the query time range, inclusive.'
          required: true
          schema:
            type: integer
        - name: end_time
          in: query
          description: 'End time (Unix seconds) of the query time range, exclusive.'
          schema:
            type: integer
        - name: bucket_width
          in: query
          description: 'Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.'
          schema:
            enum:
              - 1m
              - 1h
              - 1d
            type: string
            default: 1d
        - name: project_ids
          in: query
          description: Return only usage for these projects.
          schema:
            type: array
            items:
              type: string
        - name: user_ids
          in: query
          description: Return only usage for these users.
          schema:
            type: array
            items:
              type: string
        - name: api_key_ids
          in: query
          description: Return only usage for these API keys.
          schema:
            type: array
            items:
              type: string
        - name: models
          in: query
          description: Return only usage for these models.
          schema:
            type: array
            items:
              type: string
        - name: batch
          in: query
          description: "If `true`, return batch jobs only. If `false`, return non-batch jobs only. By default, return both.\n"
          schema:
            type: boolean
        - name: group_by
          in: query
          description: 'Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `batch` or any combination of them.'
          schema:
            type: array
            items:
              enum:
                - project_id
                - user_id
                - api_key_id
                - model
                - batch
              type: string
        - name: limit
          in: query
          description: "Specifies the number of buckets to return.\n- `bucket_width=1d`: default: 7, max: 31\n- `bucket_width=1h`: default: 24, max: 168\n- `bucket_width=1m`: default: 60, max: 1440\n"
          schema:
            type: integer
        - name: page
          in: query
          description: A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.
          schema:
            type: string
      responses:
        '200':
          description: Usage data retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        name: Completions
        group: usage-completions
        returns: 'A list of paginated, time bucketed [Completions usage](/docs/api-reference/usage/completions_object) objects.'
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/usage/completions?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"orgainzation.usage.completions.result\",\n                    \"input_tokens\": 1000,\n                    \"output_tokens\": 500,\n                    \"input_cached_tokens\": 800,\n                    \"num_model_requests\": 5,\n                    \"project_id\": null,\n                    \"user_id\": null,\n                    \"api_key_id\": null,\n                    \"model\": null,\n                    \"batch\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": true,\n    \"next_page\": \"AAAAAGdGxdEiJdKOAAAAAGcqsYA=\"\n}\n"
  /organization/usage/embeddings:
    get:
      tags:
        - Usage
      summary: Get embeddings usage details for the organization.
      operationId: usage-embeddings
      parameters:
        - name: start_time
          in: query
          description: 'Start time (Unix seconds) of the query time range, inclusive.'
          required: true
          schema:
            type: integer
        - name: end_time
          in: query
          description: 'End time (Unix seconds) of the query time range, exclusive.'
          schema:
            type: integer
        - name: bucket_width
          in: query
          description: 'Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.'
          schema:
            enum:
              - 1m
              - 1h
              - 1d
            type: string
            default: 1d
        - name: project_ids
          in: query
          description: Return only usage for these projects.
          schema:
            type: array
            items:
              type: string
        - name: user_ids
          in: query
          description: Return only usage for these users.
          schema:
            type: array
            items:
              type: string
        - name: api_key_ids
          in: query
          description: Return only usage for these API keys.
          schema:
            type: array
            items:
              type: string
        - name: models
          in: query
          description: Return only usage for these models.
          schema:
            type: array
            items:
              type: string
        - name: group_by
          in: query
          description: 'Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.'
          schema:
            type: array
            items:
              enum:
                - project_id
                - user_id
                - api_key_id
                - model
              type: string
        - name: limit
          in: query
          description: "Specifies the number of buckets to return.\n- `bucket_width=1d`: default: 7, max: 31\n- `bucket_width=1h`: default: 24, max: 168\n- `bucket_width=1m`: default: 60, max: 1440\n"
          schema:
            type: integer
        - name: page
          in: query
          description: A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.
          schema:
            type: string
      responses:
        '200':
          description: Usage data retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        name: Embeddings
        group: usage-embeddings
        returns: 'A list of paginated, time bucketed [Embeddings usage](/docs/api-reference/usage/embeddings_object) objects.'
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/usage/embeddings?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"orgainzation.usage.embeddings.result\",\n                    \"input_tokens\": 16,\n                    \"num_model_requests\": 2,\n                    \"project_id\": null,\n                    \"user_id\": null,\n                    \"api_key_id\": null,\n                    \"model\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\n"
  /organization/usage/images:
    get:
      tags:
        - Usage
      summary: Get images usage details for the organization.
      operationId: usage-images
      parameters:
        - name: start_time
          in: query
          description: 'Start time (Unix seconds) of the query time range, inclusive.'
          required: true
          schema:
            type: integer
        - name: end_time
          in: query
          description: 'End time (Unix seconds) of the query time range, exclusive.'
          schema:
            type: integer
        - name: bucket_width
          in: query
          description: 'Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.'
          schema:
            enum:
              - 1m
              - 1h
              - 1d
            type: string
            default: 1d
        - name: sources
          in: query
          description: 'Return only usages for these sources. Possible values are `image.generation`, `image.edit`, `image.variation` or any combination of them.'
          schema:
            type: array
            items:
              enum:
                - image.generation
                - image.edit
                - image.variation
              type: string
        - name: sizes
          in: query
          description: 'Return only usages for these image sizes. Possible values are `256x256`, `512x512`, `1024x1024`, `1792x1792`, `1024x1792` or any combination of them.'
          schema:
            type: array
            items:
              enum:
                - 256x256
                - 512x512
                - 1024x1024
                - 1792x1792
                - 1024x1792
              type: string
        - name: project_ids
          in: query
          description: Return only usage for these projects.
          schema:
            type: array
            items:
              type: string
        - name: user_ids
          in: query
          description: Return only usage for these users.
          schema:
            type: array
            items:
              type: string
        - name: api_key_ids
          in: query
          description: Return only usage for these API keys.
          schema:
            type: array
            items:
              type: string
        - name: models
          in: query
          description: Return only usage for these models.
          schema:
            type: array
            items:
              type: string
        - name: group_by
          in: query
          description: 'Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `size`, `source` or any combination of them.'
          schema:
            type: array
            items:
              enum:
                - project_id
                - user_id
                - api_key_id
                - model
                - size
                - source
              type: string
        - name: limit
          in: query
          description: "Specifies the number of buckets to return.\n- `bucket_width=1d`: default: 7, max: 31\n- `bucket_width=1h`: default: 24, max: 168\n- `bucket_width=1m`: default: 60, max: 1440\n"
          schema:
            type: integer
        - name: page
          in: query
          description: A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.
          schema:
            type: string
      responses:
        '200':
          description: Usage data retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        name: Images
        group: usage-images
        returns: 'A list of paginated, time bucketed [Images usage](/docs/api-reference/usage/images_object) objects.'
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/usage/images?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"orgainzation.usage.images.result\",\n                    \"images\": 2,\n                    \"num_model_requests\": 2,\n                    \"size\": null,\n                    \"source\": null,\n                    \"project_id\": null,\n                    \"user_id\": null,\n                    \"api_key_id\": null,\n                    \"model\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\n"
  /organization/usage/moderations:
    get:
      tags:
        - Usage
      summary: Get moderations usage details for the organization.
      operationId: usage-moderations
      parameters:
        - name: start_time
          in: query
          description: 'Start time (Unix seconds) of the query time range, inclusive.'
          required: true
          schema:
            type: integer
        - name: end_time
          in: query
          description: 'End time (Unix seconds) of the query time range, exclusive.'
          schema:
            type: integer
        - name: bucket_width
          in: query
          description: 'Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.'
          schema:
            enum:
              - 1m
              - 1h
              - 1d
            type: string
            default: 1d
        - name: project_ids
          in: query
          description: Return only usage for these projects.
          schema:
            type: array
            items:
              type: string
        - name: user_ids
          in: query
          description: Return only usage for these users.
          schema:
            type: array
            items:
              type: string
        - name: api_key_ids
          in: query
          description: Return only usage for these API keys.
          schema:
            type: array
            items:
              type: string
        - name: models
          in: query
          description: Return only usage for these models.
          schema:
            type: array
            items:
              type: string
        - name: group_by
          in: query
          description: 'Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.'
          schema:
            type: array
            items:
              enum:
                - project_id
                - user_id
                - api_key_id
                - model
              type: string
        - name: limit
          in: query
          description: "Specifies the number of buckets to return.\n- `bucket_width=1d`: default: 7, max: 31\n- `bucket_width=1h`: default: 24, max: 168\n- `bucket_width=1m`: default: 60, max: 1440\n"
          schema:
            type: integer
        - name: page
          in: query
          description: A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.
          schema:
            type: string
      responses:
        '200':
          description: Usage data retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        name: Moderations
        group: usage-moderations
        returns: 'A list of paginated, time bucketed [Moderations usage](/docs/api-reference/usage/moderations_object) objects.'
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/usage/moderations?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"orgainzation.usage.moderations.result\",\n                    \"input_tokens\": 16,\n                    \"num_model_requests\": 2,\n                    \"project_id\": null,\n                    \"user_id\": null,\n                    \"api_key_id\": null,\n                    \"model\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\n"
  /organization/usage/vector_stores:
    get:
      tags:
        - Usage
      summary: Get vector stores usage details for the organization.
      operationId: usage-vector-stores
      parameters:
        - name: start_time
          in: query
          description: 'Start time (Unix seconds) of the query time range, inclusive.'
          required: true
          schema:
            type: integer
        - name: end_time
          in: query
          description: 'End time (Unix seconds) of the query time range, exclusive.'
          schema:
            type: integer
        - name: bucket_width
          in: query
          description: 'Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.'
          schema:
            enum:
              - 1m
              - 1h
              - 1d
            type: string
            default: 1d
        - name: project_ids
          in: query
          description: Return only usage for these projects.
          schema:
            type: array
            items:
              type: string
        - name: group_by
          in: query
          description: Group the usage data by the specified fields. Support fields include `project_id`.
          schema:
            type: array
            items:
              enum:
                - project_id
              type: string
        - name: limit
          in: query
          description: "Specifies the number of buckets to return.\n- `bucket_width=1d`: default: 7, max: 31\n- `bucket_width=1h`: default: 24, max: 168\n- `bucket_width=1m`: default: 60, max: 1440\n"
          schema:
            type: integer
        - name: page
          in: query
          description: A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.
          schema:
            type: string
      responses:
        '200':
          description: Usage data retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        name: Vector stores
        group: usage-vector-stores
        returns: 'A list of paginated, time bucketed [Vector stores usage](/docs/api-reference/usage/vector_stores_object) objects.'
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/usage/vector_stores?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"orgainzation.usage.vector_stores.result\",\n                    \"usage_bytes\": 1024,\n                    \"project_id\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\n"
  /organization/users:
    get:
      tags:
        - Users
      summary: Lists all of the users in the organization.
      operationId: list-users
      parameters:
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: Users listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UserListResponse'
      x-oaiMeta:
        name: List users
        group: administration
        returns: 'A list of [User](/docs/api-reference/users/object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/users?after=user_abc&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response:
            content: "{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"object\": \"organization.user\",\n            \"id\": \"user_abc\",\n            \"name\": \"First Last\",\n            \"email\": \"user@example.com\",\n            \"role\": \"owner\",\n            \"added_at\": 1711471533\n        }\n    ],\n    \"first_id\": \"user-abc\",\n    \"last_id\": \"user-xyz\",\n    \"has_more\": false\n}\n"
  '/organization/users/{user_id}':
    get:
      tags:
        - Users
      summary: Retrieves a user by their identifier.
      operationId: retrieve-user
      parameters:
        - name: user_id
          in: path
          description: The ID of the user.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: User retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'
      x-oaiMeta:
        name: Retrieve user
        group: administration
        returns: 'The [User](/docs/api-reference/users/object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/users/user_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response:
            content: "{\n    \"object\": \"organization.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\n"
    post:
      tags:
        - Users
      summary: Modifies a user's role in the organization.
      operationId: modify-user
      parameters:
        - name: user_id
          in: path
          description: The ID of the user.
          required: true
          schema:
            type: string
      requestBody:
        description: The new user role to modify. This must be one of `owner` or `member`.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UserRoleUpdateRequest'
        required: true
      responses:
        '200':
          description: User role updated successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'
      x-oaiMeta:
        name: Modify user
        group: administration
        returns: 'The updated [User](/docs/api-reference/users/object) object.'
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/users/user_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"role\": \"owner\"\n  }'\n"
          response:
            content: "{\n    \"object\": \"organization.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\n"
    delete:
      tags:
        - Users
      summary: Deletes a user from the organization.
      operationId: delete-user
      parameters:
        - name: user_id
          in: path
          description: The ID of the user.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: User deleted successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UserDeleteResponse'
      x-oaiMeta:
        name: Delete user
        group: administration
        returns: Confirmation of the deleted user
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/organization/users/user_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response:
            content: "{\n    \"object\": \"organization.user.deleted\",\n    \"id\": \"user_abc\",\n    \"deleted\": true\n}\n"
  /threads:
    post:
      tags:
        - Assistants
      summary: Create a thread.
      operationId: createThread
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateThreadRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
      x-oaiMeta:
        name: Create thread
        group: threads
        beta: true
        returns: 'A [thread](/docs/api-reference/threads) object.'
        examples:
          - title: Empty
            request:
              curl: "curl https://api.openai.com/v1/threads \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d ''\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\nempty_thread = client.beta.threads.create()\nprint(empty_thread)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const emptyThread = await openai.beta.threads.create();\n\n  console.log(emptyThread);\n}\n\nmain();"
            response: "{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n  \"created_at\": 1699012949,\n  \"metadata\": {},\n  \"tool_resources\": {}\n}\n"
          - title: Messages
            request:
              curl: "curl https://api.openai.com/v1/threads \\\n-H \"Content-Type: application/json\" \\\n-H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n-H \"OpenAI-Beta: assistants=v2\" \\\n-d '{\n    \"messages\": [{\n      \"role\": \"user\",\n      \"content\": \"Hello, what is AI?\"\n    }, {\n      \"role\": \"user\",\n      \"content\": \"How does AI work? Explain it in simple terms.\"\n    }]\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\nmessage_thread = client.beta.threads.create(\n  messages=[\n    {\n      \"role\": \"user\",\n      \"content\": \"Hello, what is AI?\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"How does AI work? Explain it in simple terms.\"\n    },\n  ]\n)\n\nprint(message_thread)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const messageThread = await openai.beta.threads.create({\n    messages: [\n      {\n        role: \"user\",\n        content: \"Hello, what is AI?\"\n      },\n      {\n        role: \"user\",\n        content: \"How does AI work? Explain it in simple terms.\",\n      },\n    ],\n  });\n\n  console.log(messageThread);\n}\n\nmain();"
            response: "{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n  \"created_at\": 1699014083,\n  \"metadata\": {},\n  \"tool_resources\": {}\n}\n"
  /threads/runs:
    post:
      tags:
        - Assistants
      summary: Create a thread and run it in one request.
      operationId: createThreadAndRun
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateThreadAndRunRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Create thread and run
        group: threads
        beta: true
        returns: 'A [run](/docs/api-reference/runs/object) object.'
        examples:
          - title: Default
            request:
              curl: "curl https://api.openai.com/v1/threads/runs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n      \"assistant_id\": \"asst_abc123\",\n      \"thread\": {\n        \"messages\": [\n          {\"role\": \"user\", \"content\": \"Explain deep learning to a 5 year old.\"}\n        ]\n      }\n    }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\nrun = client.beta.threads.create_and_run(\n  assistant_id=\"asst_abc123\",\n  thread={\n    \"messages\": [\n      {\"role\": \"user\", \"content\": \"Explain deep learning to a 5 year old.\"}\n    ]\n  }\n)\n\nprint(run)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const run = await openai.beta.threads.createAndRun({\n    assistant_id: \"asst_abc123\",\n    thread: {\n      messages: [\n        { role: \"user\", content: \"Explain deep learning to a 5 year old.\" },\n      ],\n    },\n  });\n\n  console.log(run);\n}\n\nmain();\n"
            response: "{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699076792,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"queued\",\n  \"started_at\": null,\n  \"expires_at\": 1699077392,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": null,\n  \"required_action\": null,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You are a helpful assistant.\",\n  \"tools\": [],\n  \"tool_resources\": {},\n  \"metadata\": {},\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_completion_tokens\": null,\n  \"max_prompt_tokens\": null,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"incomplete_details\": null,\n  \"usage\": null,\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\n"
          - title: Streaming
            request:
              curl: "curl https://api.openai.com/v1/threads/runs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"assistant_id\": \"asst_123\",\n    \"thread\": {\n      \"messages\": [\n        {\"role\": \"user\", \"content\": \"Hello\"}\n      ]\n    },\n    \"stream\": true\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\nstream = client.beta.threads.create_and_run(\n  assistant_id=\"asst_123\",\n  thread={\n    \"messages\": [\n      {\"role\": \"user\", \"content\": \"Hello\"}\n    ]\n  },\n  stream=True\n)\n\nfor event in stream:\n  print(event)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const stream = await openai.beta.threads.createAndRun({\n      assistant_id: \"asst_123\",\n      thread: {\n        messages: [\n          { role: \"user\", content: \"Hello\" },\n        ],\n      },\n      stream: true\n  });\n\n  for await (const event of stream) {\n    console.log(event);\n  }\n}\n\nmain();\n"
            response: "event: thread.created\ndata: {\"id\":\"thread_123\",\"object\":\"thread\",\"created_at\":1710348075,\"metadata\":{}}\n\nevent: thread.run.created\ndata: {\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710348075,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"queued\",\"started_at\":null,\"expires_at\":1710348675,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":null,\"required_action\":null,\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[],\"tool_resources\":{},\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":null,\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}\n\nevent: thread.run.queued\ndata: {\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710348075,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"queued\",\"started_at\":null,\"expires_at\":1710348675,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":null,\"required_action\":null,\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[],\"tool_resources\":{},\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":null,\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}\n\nevent: thread.run.in_progress\ndata: {\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710348075,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"in_progress\",\"started_at\":null,\"expires_at\":1710348675,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":null,\"required_action\":null,\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[],\"tool_resources\":{},\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":null,\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}\n\nevent: thread.run.step.created\ndata: {\"id\":\"step_001\",\"object\":\"thread.run.step\",\"created_at\":1710348076,\"run_id\":\"run_123\",\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"type\":\"message_creation\",\"status\":\"in_progress\",\"cancelled_at\":null,\"completed_at\":null,\"expires_at\":1710348675,\"failed_at\":null,\"last_error\":null,\"step_details\":{\"type\":\"message_creation\",\"message_creation\":{\"message_id\":\"msg_001\"}},\"usage\":null}\n\nevent: thread.run.step.in_progress\ndata: {\"id\":\"step_001\",\"object\":\"thread.run.step\",\"created_at\":1710348076,\"run_id\":\"run_123\",\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"type\":\"message_creation\",\"status\":\"in_progress\",\"cancelled_at\":null,\"completed_at\":null,\"expires_at\":1710348675,\"failed_at\":null,\"last_error\":null,\"step_details\":{\"type\":\"message_creation\",\"message_creation\":{\"message_id\":\"msg_001\"}},\"usage\":null}\n\nevent: thread.message.created\ndata: {\"id\":\"msg_001\",\"object\":\"thread.message\",\"created_at\":1710348076,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"run_id\":\"run_123\",\"status\":\"in_progress\",\"incomplete_details\":null,\"incomplete_at\":null,\"completed_at\":null,\"role\":\"assistant\",\"content\":[], \"metadata\":{}}\n\nevent: thread.message.in_progress\ndata: {\"id\":\"msg_001\",\"object\":\"thread.message\",\"created_at\":1710348076,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"run_id\":\"run_123\",\"status\":\"in_progress\",\"incomplete_details\":null,\"incomplete_at\":null,\"completed_at\":null,\"role\":\"assistant\",\"content\":[], \"metadata\":{}}\n\nevent: thread.message.delta\ndata: {\"id\":\"msg_001\",\"object\":\"thread.message.delta\",\"delta\":{\"content\":[{\"index\":0,\"type\":\"text\",\"text\":{\"value\":\"Hello\",\"annotations\":[]}}]}}\n\n...\n\nevent: thread.message.delta\ndata: {\"id\":\"msg_001\",\"object\":\"thread.message.delta\",\"delta\":{\"content\":[{\"index\":0,\"type\":\"text\",\"text\":{\"value\":\" today\"}}]}}\n\nevent: thread.message.delta\ndata: {\"id\":\"msg_001\",\"object\":\"thread.message.delta\",\"delta\":{\"content\":[{\"index\":0,\"type\":\"text\",\"text\":{\"value\":\"?\"}}]}}\n\nevent: thread.message.completed\ndata: {\"id\":\"msg_001\",\"object\":\"thread.message\",\"created_at\":1710348076,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"run_id\":\"run_123\",\"status\":\"completed\",\"incomplete_details\":null,\"incomplete_at\":null,\"completed_at\":1710348077,\"role\":\"assistant\",\"content\":[{\"type\":\"text\",\"text\":{\"value\":\"Hello! How can I assist you today?\",\"annotations\":[]}}], \"metadata\":{}}\n\nevent: thread.run.step.completed\ndata: {\"id\":\"step_001\",\"object\":\"thread.run.step\",\"created_at\":1710348076,\"run_id\":\"run_123\",\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"type\":\"message_creation\",\"status\":\"completed\",\"cancelled_at\":null,\"completed_at\":1710348077,\"expires_at\":1710348675,\"failed_at\":null,\"last_error\":null,\"step_details\":{\"type\":\"message_creation\",\"message_creation\":{\"message_id\":\"msg_001\"}},\"usage\":{\"prompt_tokens\":20,\"completion_tokens\":11,\"total_tokens\":31}}\n\nevent: thread.run.completed\n{\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710348076,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"completed\",\"started_at\":1713226836,\"expires_at\":null,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":1713226837,\"required_action\":null,\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[],\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":{\"prompt_tokens\":345,\"completion_tokens\":11,\"total_tokens\":356},\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}\n\nevent: done\ndata: [DONE]\n"
          - title: Streaming with Functions
            request:
              curl: "curl https://api.openai.com/v1/threads/runs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"assistant_id\": \"asst_abc123\",\n    \"thread\": {\n      \"messages\": [\n        {\"role\": \"user\", \"content\": \"What is the weather like in San Francisco?\"}\n      ]\n    },\n    \"tools\": [\n      {\n        \"type\": \"function\",\n        \"function\": {\n          \"name\": \"get_current_weather\",\n          \"description\": \"Get the current weather in a given location\",\n          \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n              \"location\": {\n                \"type\": \"string\",\n                \"description\": \"The city and state, e.g. San Francisco, CA\"\n              },\n              \"unit\": {\n                \"type\": \"string\",\n                \"enum\": [\"celsius\", \"fahrenheit\"]\n              }\n            },\n            \"required\": [\"location\"]\n          }\n        }\n      }\n    ],\n    \"stream\": true\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\ntools = [\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"get_current_weather\",\n      \"description\": \"Get the current weather in a given location\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"location\": {\n            \"type\": \"string\",\n            \"description\": \"The city and state, e.g. San Francisco, CA\",\n          },\n          \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n        },\n        \"required\": [\"location\"],\n      },\n    }\n  }\n]\n\nstream = client.beta.threads.create_and_run(\n  thread={\n      \"messages\": [\n        {\"role\": \"user\", \"content\": \"What is the weather like in San Francisco?\"}\n      ]\n  },\n  assistant_id=\"asst_abc123\",\n  tools=tools,\n  stream=True\n)\n\nfor event in stream:\n  print(event)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nconst tools = [\n    {\n      \"type\": \"function\",\n      \"function\": {\n        \"name\": \"get_current_weather\",\n        \"description\": \"Get the current weather in a given location\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"location\": {\n              \"type\": \"string\",\n              \"description\": \"The city and state, e.g. San Francisco, CA\",\n            },\n            \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n          },\n          \"required\": [\"location\"],\n        },\n      }\n    }\n];\n\nasync function main() {\n  const stream = await openai.beta.threads.createAndRun({\n    assistant_id: \"asst_123\",\n    thread: {\n      messages: [\n        { role: \"user\", content: \"What is the weather like in San Francisco?\" },\n      ],\n    },\n    tools: tools,\n    stream: true\n  });\n\n  for await (const event of stream) {\n    console.log(event);\n  }\n}\n\nmain();\n"
            response: "event: thread.created\ndata: {\"id\":\"thread_123\",\"object\":\"thread\",\"created_at\":1710351818,\"metadata\":{}}\n\nevent: thread.run.created\ndata: {\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710351818,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"queued\",\"started_at\":null,\"expires_at\":1710352418,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":null,\"required_action\":null,\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"get_current_weather\",\"description\":\"Get the current weather in a given location\",\"parameters\":{\"type\":\"object\",\"properties\":{\"location\":{\"type\":\"string\",\"description\":\"The city and state, e.g. San Francisco, CA\"},\"unit\":{\"type\":\"string\",\"enum\":[\"celsius\",\"fahrenheit\"]}},\"required\":[\"location\"]}}}],\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":null,\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}}\n\nevent: thread.run.queued\ndata: {\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710351818,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"queued\",\"started_at\":null,\"expires_at\":1710352418,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":null,\"required_action\":null,\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"get_current_weather\",\"description\":\"Get the current weather in a given location\",\"parameters\":{\"type\":\"object\",\"properties\":{\"location\":{\"type\":\"string\",\"description\":\"The city and state, e.g. San Francisco, CA\"},\"unit\":{\"type\":\"string\",\"enum\":[\"celsius\",\"fahrenheit\"]}},\"required\":[\"location\"]}}}],\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":null,\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}}\n\nevent: thread.run.in_progress\ndata: {\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710351818,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"in_progress\",\"started_at\":1710351818,\"expires_at\":1710352418,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":null,\"required_action\":null,\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"get_current_weather\",\"description\":\"Get the current weather in a given location\",\"parameters\":{\"type\":\"object\",\"properties\":{\"location\":{\"type\":\"string\",\"description\":\"The city and state, e.g. San Francisco, CA\"},\"unit\":{\"type\":\"string\",\"enum\":[\"celsius\",\"fahrenheit\"]}},\"required\":[\"location\"]}}}],\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":null,\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}}\n\nevent: thread.run.step.created\ndata: {\"id\":\"step_001\",\"object\":\"thread.run.step\",\"created_at\":1710351819,\"run_id\":\"run_123\",\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"type\":\"tool_calls\",\"status\":\"in_progress\",\"cancelled_at\":null,\"completed_at\":null,\"expires_at\":1710352418,\"failed_at\":null,\"last_error\":null,\"step_details\":{\"type\":\"tool_calls\",\"tool_calls\":[]},\"usage\":null}\n\nevent: thread.run.step.in_progress\ndata: {\"id\":\"step_001\",\"object\":\"thread.run.step\",\"created_at\":1710351819,\"run_id\":\"run_123\",\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"type\":\"tool_calls\",\"status\":\"in_progress\",\"cancelled_at\":null,\"completed_at\":null,\"expires_at\":1710352418,\"failed_at\":null,\"last_error\":null,\"step_details\":{\"type\":\"tool_calls\",\"tool_calls\":[]},\"usage\":null}\n\nevent: thread.run.step.delta\ndata: {\"id\":\"step_001\",\"object\":\"thread.run.step.delta\",\"delta\":{\"step_details\":{\"type\":\"tool_calls\",\"tool_calls\":[{\"index\":0,\"id\":\"call_XXNp8YGaFrjrSjgqxtC8JJ1B\",\"type\":\"function\",\"function\":{\"name\":\"get_current_weather\",\"arguments\":\"\",\"output\":null}}]}}}\n\nevent: thread.run.step.delta\ndata: {\"id\":\"step_001\",\"object\":\"thread.run.step.delta\",\"delta\":{\"step_details\":{\"type\":\"tool_calls\",\"tool_calls\":[{\"index\":0,\"type\":\"function\",\"function\":{\"arguments\":\"{\\\"\"}}]}}}\n\nevent: thread.run.step.delta\ndata: {\"id\":\"step_001\",\"object\":\"thread.run.step.delta\",\"delta\":{\"step_details\":{\"type\":\"tool_calls\",\"tool_calls\":[{\"index\":0,\"type\":\"function\",\"function\":{\"arguments\":\"location\"}}]}}}\n\n...\n\nevent: thread.run.step.delta\ndata: {\"id\":\"step_001\",\"object\":\"thread.run.step.delta\",\"delta\":{\"step_details\":{\"type\":\"tool_calls\",\"tool_calls\":[{\"index\":0,\"type\":\"function\",\"function\":{\"arguments\":\"ahrenheit\"}}]}}}\n\nevent: thread.run.step.delta\ndata: {\"id\":\"step_001\",\"object\":\"thread.run.step.delta\",\"delta\":{\"step_details\":{\"type\":\"tool_calls\",\"tool_calls\":[{\"index\":0,\"type\":\"function\",\"function\":{\"arguments\":\"\\\"}\"}}]}}}\n\nevent: thread.run.requires_action\ndata: {\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710351818,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"requires_action\",\"started_at\":1710351818,\"expires_at\":1710352418,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":null,\"required_action\":{\"type\":\"submit_tool_outputs\",\"submit_tool_outputs\":{\"tool_calls\":[{\"id\":\"call_XXNp8YGaFrjrSjgqxtC8JJ1B\",\"type\":\"function\",\"function\":{\"name\":\"get_current_weather\",\"arguments\":\"{\\\"location\\\":\\\"San Francisco, CA\\\",\\\"unit\\\":\\\"fahrenheit\\\"}\"}}]}},\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"get_current_weather\",\"description\":\"Get the current weather in a given location\",\"parameters\":{\"type\":\"object\",\"properties\":{\"location\":{\"type\":\"string\",\"description\":\"The city and state, e.g. San Francisco, CA\"},\"unit\":{\"type\":\"string\",\"enum\":[\"celsius\",\"fahrenheit\"]}},\"required\":[\"location\"]}}}],\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":{\"prompt_tokens\":345,\"completion_tokens\":11,\"total_tokens\":356},\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}}\n\nevent: done\ndata: [DONE]\n"
  '/threads/{thread_id}':
    get:
      tags:
        - Assistants
      summary: Retrieves a thread.
      operationId: getThread
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
      x-oaiMeta:
        name: Retrieve thread
        group: threads
        beta: true
        returns: 'The [thread](/docs/api-reference/threads/object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nmy_thread = client.beta.threads.retrieve(\"thread_abc123\")\nprint(my_thread)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const myThread = await openai.beta.threads.retrieve(\n    \"thread_abc123\"\n  );\n\n  console.log(myThread);\n}\n\nmain();"
          response: "{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n  \"created_at\": 1699014083,\n  \"metadata\": {},\n  \"tool_resources\": {\n    \"code_interpreter\": {\n      \"file_ids\": []\n    }\n  }\n}\n"
    post:
      tags:
        - Assistants
      summary: Modifies a thread.
      operationId: modifyThread
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread to modify. Only the `metadata` can be modified.
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyThreadRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
      x-oaiMeta:
        name: Modify thread
        group: threads
        beta: true
        returns: 'The modified [thread](/docs/api-reference/threads/object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n      \"metadata\": {\n        \"modified\": \"true\",\n        \"user\": \"abc123\"\n      }\n    }'\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nmy_updated_thread = client.beta.threads.update(\n  \"thread_abc123\",\n  metadata={\n    \"modified\": \"true\",\n    \"user\": \"abc123\"\n  }\n)\nprint(my_updated_thread)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const updatedThread = await openai.beta.threads.update(\n    \"thread_abc123\",\n    {\n      metadata: { modified: \"true\", user: \"abc123\" },\n    }\n  );\n\n  console.log(updatedThread);\n}\n\nmain();"
          response: "{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n  \"created_at\": 1699014083,\n  \"metadata\": {\n    \"modified\": \"true\",\n    \"user\": \"abc123\"\n  },\n  \"tool_resources\": {}\n}\n"
    delete:
      tags:
        - Assistants
      summary: Delete a thread.
      operationId: deleteThread
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread to delete.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteThreadResponse'
      x-oaiMeta:
        name: Delete thread
        group: threads
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -X DELETE\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nresponse = client.beta.threads.delete(\"thread_abc123\")\nprint(response)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const response = await openai.beta.threads.del(\"thread_abc123\");\n\n  console.log(response);\n}\nmain();"
          response: "{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread.deleted\",\n  \"deleted\": true\n}\n"
  '/threads/{thread_id}/messages':
    get:
      tags:
        - Assistants
      summary: Returns a list of messages for a given thread.
      operationId: listMessages
      parameters:
        - name: thread_id
          in: path
          description: 'The ID of the [thread](/docs/api-reference/threads) the messages belong to.'
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: before
          in: query
          description: "A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n"
          schema:
            type: string
        - name: run_id
          in: query
          description: "Filter messages by the run ID that generated them.\n"
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListMessagesResponse'
      x-oaiMeta:
        name: List messages
        group: threads
        beta: true
        returns: 'A list of [message](/docs/api-reference/messages) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/messages \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nthread_messages = client.beta.threads.messages.list(\"thread_abc123\")\nprint(thread_messages.data)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const threadMessages = await openai.beta.threads.messages.list(\n    \"thread_abc123\"\n  );\n\n  console.log(threadMessages.data);\n}\n\nmain();"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"msg_abc123\",\n      \"object\": \"thread.message\",\n      \"created_at\": 1699016383,\n      \"assistant_id\": null,\n      \"thread_id\": \"thread_abc123\",\n      \"run_id\": null,\n      \"role\": \"user\",\n      \"content\": [\n        {\n          \"type\": \"text\",\n          \"text\": {\n            \"value\": \"How does AI work? Explain it in simple terms.\",\n            \"annotations\": []\n          }\n        }\n      ],\n      \"attachments\": [],\n      \"metadata\": {}\n    },\n    {\n      \"id\": \"msg_abc456\",\n      \"object\": \"thread.message\",\n      \"created_at\": 1699016383,\n      \"assistant_id\": null,\n      \"thread_id\": \"thread_abc123\",\n      \"run_id\": null,\n      \"role\": \"user\",\n      \"content\": [\n        {\n          \"type\": \"text\",\n          \"text\": {\n            \"value\": \"Hello, what is AI?\",\n            \"annotations\": []\n          }\n        }\n      ],\n      \"attachments\": [],\n      \"metadata\": {}\n    }\n  ],\n  \"first_id\": \"msg_abc123\",\n  \"last_id\": \"msg_abc456\",\n  \"has_more\": false\n}\n"
    post:
      tags:
        - Assistants
      summary: Create a message.
      operationId: createMessage
      parameters:
        - name: thread_id
          in: path
          description: 'The ID of the [thread](/docs/api-reference/threads) to create a message for.'
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateMessageRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
      x-oaiMeta:
        name: Create message
        group: threads
        beta: true
        returns: 'A [message](/docs/api-reference/messages/object) object.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/messages \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n      \"role\": \"user\",\n      \"content\": \"How does AI work? Explain it in simple terms.\"\n    }'\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nthread_message = client.beta.threads.messages.create(\n  \"thread_abc123\",\n  role=\"user\",\n  content=\"How does AI work? Explain it in simple terms.\",\n)\nprint(thread_message)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const threadMessages = await openai.beta.threads.messages.create(\n    \"thread_abc123\",\n    { role: \"user\", content: \"How does AI work? Explain it in simple terms.\" }\n  );\n\n  console.log(threadMessages);\n}\n\nmain();"
          response: "{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\",\n  \"created_at\": 1713226573,\n  \"assistant_id\": null,\n  \"thread_id\": \"thread_abc123\",\n  \"run_id\": null,\n  \"role\": \"user\",\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"value\": \"How does AI work? Explain it in simple terms.\",\n        \"annotations\": []\n      }\n    }\n  ],\n  \"attachments\": [],\n  \"metadata\": {}\n}\n"
  '/threads/{thread_id}/messages/{message_id}':
    get:
      tags:
        - Assistants
      summary: Retrieve a message.
      operationId: getMessage
      parameters:
        - name: thread_id
          in: path
          description: 'The ID of the [thread](/docs/api-reference/threads) to which this message belongs.'
          required: true
          schema:
            type: string
        - name: message_id
          in: path
          description: The ID of the message to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
      x-oaiMeta:
        name: Retrieve message
        group: threads
        beta: true
        returns: 'The [message](/docs/api-reference/messages/object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nmessage = client.beta.threads.messages.retrieve(\n  message_id=\"msg_abc123\",\n  thread_id=\"thread_abc123\",\n)\nprint(message)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const message = await openai.beta.threads.messages.retrieve(\n    \"thread_abc123\",\n    \"msg_abc123\"\n  );\n\n  console.log(message);\n}\n\nmain();"
          response: "{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\",\n  \"created_at\": 1699017614,\n  \"assistant_id\": null,\n  \"thread_id\": \"thread_abc123\",\n  \"run_id\": null,\n  \"role\": \"user\",\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"value\": \"How does AI work? Explain it in simple terms.\",\n        \"annotations\": []\n      }\n    }\n  ],\n  \"attachments\": [],\n  \"metadata\": {}\n}\n"
    post:
      tags:
        - Assistants
      summary: Modifies a message.
      operationId: modifyMessage
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread to which this message belongs.
          required: true
          schema:
            type: string
        - name: message_id
          in: path
          description: The ID of the message to modify.
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyMessageRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
      x-oaiMeta:
        name: Modify message
        group: threads
        beta: true
        returns: 'The modified [message](/docs/api-reference/messages/object) object.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n      \"metadata\": {\n        \"modified\": \"true\",\n        \"user\": \"abc123\"\n      }\n    }'\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nmessage = client.beta.threads.messages.update(\n  message_id=\"msg_abc12\",\n  thread_id=\"thread_abc123\",\n  metadata={\n    \"modified\": \"true\",\n    \"user\": \"abc123\",\n  },\n)\nprint(message)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const message = await openai.beta.threads.messages.update(\n    \"thread_abc123\",\n    \"msg_abc123\",\n    {\n      metadata: {\n        modified: \"true\",\n        user: \"abc123\",\n      },\n    }\n  }'"
          response: "{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\",\n  \"created_at\": 1699017614,\n  \"assistant_id\": null,\n  \"thread_id\": \"thread_abc123\",\n  \"run_id\": null,\n  \"role\": \"user\",\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"value\": \"How does AI work? Explain it in simple terms.\",\n        \"annotations\": []\n      }\n    }\n  ],\n  \"file_ids\": [],\n  \"metadata\": {\n    \"modified\": \"true\",\n    \"user\": \"abc123\"\n  }\n}\n"
    delete:
      tags:
        - Assistants
      summary: Deletes a message.
      operationId: deleteMessage
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread to which this message belongs.
          required: true
          schema:
            type: string
        - name: message_id
          in: path
          description: The ID of the message to delete.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteMessageResponse'
      x-oaiMeta:
        name: Delete message
        group: threads
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\ndeleted_message = client.beta.threads.messages.delete(\n  message_id=\"msg_abc12\",\n  thread_id=\"thread_abc123\",\n)\nprint(deleted_message)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const deletedMessage = await openai.beta.threads.messages.del(\n    \"thread_abc123\",\n    \"msg_abc123\"\n  );\n\n  console.log(deletedMessage);\n}"
          response: "{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message.deleted\",\n  \"deleted\": true\n}\n"
  '/threads/{thread_id}/runs':
    get:
      tags:
        - Assistants
      summary: Returns a list of runs belonging to a thread.
      operationId: listRuns
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread the run belongs to.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: before
          in: query
          description: "A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListRunsResponse'
      x-oaiMeta:
        name: List runs
        group: threads
        beta: true
        returns: 'A list of [run](/docs/api-reference/runs/object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nruns = client.beta.threads.runs.list(\n  \"thread_abc123\"\n)\n\nprint(runs)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const runs = await openai.beta.threads.runs.list(\n    \"thread_abc123\"\n  );\n\n  console.log(runs);\n}\n\nmain();\n"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"run_abc123\",\n      \"object\": \"thread.run\",\n      \"created_at\": 1699075072,\n      \"assistant_id\": \"asst_abc123\",\n      \"thread_id\": \"thread_abc123\",\n      \"status\": \"completed\",\n      \"started_at\": 1699075072,\n      \"expires_at\": null,\n      \"cancelled_at\": null,\n      \"failed_at\": null,\n      \"completed_at\": 1699075073,\n      \"last_error\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": null,\n      \"incomplete_details\": null,\n      \"tools\": [\n        {\n          \"type\": \"code_interpreter\"\n        }\n      ],\n      \"tool_resources\": {\n        \"code_interpreter\": {\n          \"file_ids\": [\n            \"file-abc123\",\n            \"file-abc456\"\n          ]\n        }\n      },\n      \"metadata\": {},\n      \"usage\": {\n        \"prompt_tokens\": 123,\n        \"completion_tokens\": 456,\n        \"total_tokens\": 579\n      },\n      \"temperature\": 1.0,\n      \"top_p\": 1.0,\n      \"max_prompt_tokens\": 1000,\n      \"max_completion_tokens\": 1000,\n      \"truncation_strategy\": {\n        \"type\": \"auto\",\n        \"last_messages\": null\n      },\n      \"response_format\": \"auto\",\n      \"tool_choice\": \"auto\",\n      \"parallel_tool_calls\": true\n    },\n    {\n      \"id\": \"run_abc456\",\n      \"object\": \"thread.run\",\n      \"created_at\": 1699063290,\n      \"assistant_id\": \"asst_abc123\",\n      \"thread_id\": \"thread_abc123\",\n      \"status\": \"completed\",\n      \"started_at\": 1699063290,\n      \"expires_at\": null,\n      \"cancelled_at\": null,\n      \"failed_at\": null,\n      \"completed_at\": 1699063291,\n      \"last_error\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": null,\n      \"incomplete_details\": null,\n      \"tools\": [\n        {\n          \"type\": \"code_interpreter\"\n        }\n      ],\n      \"tool_resources\": {\n        \"code_interpreter\": {\n          \"file_ids\": [\n            \"file-abc123\",\n            \"file-abc456\"\n          ]\n        }\n      },\n      \"metadata\": {},\n      \"usage\": {\n        \"prompt_tokens\": 123,\n        \"completion_tokens\": 456,\n        \"total_tokens\": 579\n      },\n      \"temperature\": 1.0,\n      \"top_p\": 1.0,\n      \"max_prompt_tokens\": 1000,\n      \"max_completion_tokens\": 1000,\n      \"truncation_strategy\": {\n        \"type\": \"auto\",\n        \"last_messages\": null\n      },\n      \"response_format\": \"auto\",\n      \"tool_choice\": \"auto\",\n      \"parallel_tool_calls\": true\n    }\n  ],\n  \"first_id\": \"run_abc123\",\n  \"last_id\": \"run_abc456\",\n  \"has_more\": false\n}\n"
    post:
      tags:
        - Assistants
      summary: Create a run.
      operationId: createRun
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread to run.
          required: true
          schema:
            type: string
        - name: 'include[]'
          in: query
          description: "A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.\n\nSee the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n"
          schema:
            type: array
            items:
              enum:
                - 'step_details.tool_calls[*].file_search.results[*].content'
              type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateRunRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Create run
        group: threads
        beta: true
        returns: 'A [run](/docs/api-reference/runs/object) object.'
        examples:
          - title: Default
            request:
              curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"assistant_id\": \"asst_abc123\"\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\nrun = client.beta.threads.runs.create(\n  thread_id=\"thread_abc123\",\n  assistant_id=\"asst_abc123\"\n)\n\nprint(run)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const run = await openai.beta.threads.runs.create(\n    \"thread_abc123\",\n    { assistant_id: \"asst_abc123\" }\n  );\n\n  console.log(run);\n}\n\nmain();\n"
            response: "{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699063290,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"queued\",\n  \"started_at\": 1699063290,\n  \"expires_at\": null,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": 1699063291,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": null,\n  \"incomplete_details\": null,\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n  \"usage\": null,\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\": 1000,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\n"
          - title: Streaming
            request:
              curl: "curl https://api.openai.com/v1/threads/thread_123/runs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"assistant_id\": \"asst_123\",\n    \"stream\": true\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\nstream = client.beta.threads.runs.create(\n  thread_id=\"thread_123\",\n  assistant_id=\"asst_123\",\n  stream=True\n)\n\nfor event in stream:\n  print(event)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const stream = await openai.beta.threads.runs.create(\n    \"thread_123\",\n    { assistant_id: \"asst_123\", stream: true }\n  );\n\n  for await (const event of stream) {\n    console.log(event);\n  }\n}\n\nmain();\n"
            response: "event: thread.run.created\ndata: {\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710330640,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"queued\",\"started_at\":null,\"expires_at\":1710331240,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":null,\"required_action\":null,\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[],\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":null,\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}}\n\nevent: thread.run.queued\ndata: {\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710330640,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"queued\",\"started_at\":null,\"expires_at\":1710331240,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":null,\"required_action\":null,\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[],\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":null,\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}}\n\nevent: thread.run.in_progress\ndata: {\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710330640,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"in_progress\",\"started_at\":1710330641,\"expires_at\":1710331240,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":null,\"required_action\":null,\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[],\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":null,\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}}\n\nevent: thread.run.step.created\ndata: {\"id\":\"step_001\",\"object\":\"thread.run.step\",\"created_at\":1710330641,\"run_id\":\"run_123\",\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"type\":\"message_creation\",\"status\":\"in_progress\",\"cancelled_at\":null,\"completed_at\":null,\"expires_at\":1710331240,\"failed_at\":null,\"last_error\":null,\"step_details\":{\"type\":\"message_creation\",\"message_creation\":{\"message_id\":\"msg_001\"}},\"usage\":null}\n\nevent: thread.run.step.in_progress\ndata: {\"id\":\"step_001\",\"object\":\"thread.run.step\",\"created_at\":1710330641,\"run_id\":\"run_123\",\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"type\":\"message_creation\",\"status\":\"in_progress\",\"cancelled_at\":null,\"completed_at\":null,\"expires_at\":1710331240,\"failed_at\":null,\"last_error\":null,\"step_details\":{\"type\":\"message_creation\",\"message_creation\":{\"message_id\":\"msg_001\"}},\"usage\":null}\n\nevent: thread.message.created\ndata: {\"id\":\"msg_001\",\"object\":\"thread.message\",\"created_at\":1710330641,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"run_id\":\"run_123\",\"status\":\"in_progress\",\"incomplete_details\":null,\"incomplete_at\":null,\"completed_at\":null,\"role\":\"assistant\",\"content\":[],\"metadata\":{}}\n\nevent: thread.message.in_progress\ndata: {\"id\":\"msg_001\",\"object\":\"thread.message\",\"created_at\":1710330641,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"run_id\":\"run_123\",\"status\":\"in_progress\",\"incomplete_details\":null,\"incomplete_at\":null,\"completed_at\":null,\"role\":\"assistant\",\"content\":[],\"metadata\":{}}\n\nevent: thread.message.delta\ndata: {\"id\":\"msg_001\",\"object\":\"thread.message.delta\",\"delta\":{\"content\":[{\"index\":0,\"type\":\"text\",\"text\":{\"value\":\"Hello\",\"annotations\":[]}}]}}\n\n...\n\nevent: thread.message.delta\ndata: {\"id\":\"msg_001\",\"object\":\"thread.message.delta\",\"delta\":{\"content\":[{\"index\":0,\"type\":\"text\",\"text\":{\"value\":\" today\"}}]}}\n\nevent: thread.message.delta\ndata: {\"id\":\"msg_001\",\"object\":\"thread.message.delta\",\"delta\":{\"content\":[{\"index\":0,\"type\":\"text\",\"text\":{\"value\":\"?\"}}]}}\n\nevent: thread.message.completed\ndata: {\"id\":\"msg_001\",\"object\":\"thread.message\",\"created_at\":1710330641,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"run_id\":\"run_123\",\"status\":\"completed\",\"incomplete_details\":null,\"incomplete_at\":null,\"completed_at\":1710330642,\"role\":\"assistant\",\"content\":[{\"type\":\"text\",\"text\":{\"value\":\"Hello! How can I assist you today?\",\"annotations\":[]}}],\"metadata\":{}}\n\nevent: thread.run.step.completed\ndata: {\"id\":\"step_001\",\"object\":\"thread.run.step\",\"created_at\":1710330641,\"run_id\":\"run_123\",\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"type\":\"message_creation\",\"status\":\"completed\",\"cancelled_at\":null,\"completed_at\":1710330642,\"expires_at\":1710331240,\"failed_at\":null,\"last_error\":null,\"step_details\":{\"type\":\"message_creation\",\"message_creation\":{\"message_id\":\"msg_001\"}},\"usage\":{\"prompt_tokens\":20,\"completion_tokens\":11,\"total_tokens\":31}}\n\nevent: thread.run.completed\ndata: {\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710330640,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"completed\",\"started_at\":1710330641,\"expires_at\":null,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":1710330642,\"required_action\":null,\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[],\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":{\"prompt_tokens\":20,\"completion_tokens\":11,\"total_tokens\":31},\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}}\n\nevent: done\ndata: [DONE]\n"
          - title: Streaming with Functions
            request:
              curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"assistant_id\": \"asst_abc123\",\n    \"tools\": [\n      {\n        \"type\": \"function\",\n        \"function\": {\n          \"name\": \"get_current_weather\",\n          \"description\": \"Get the current weather in a given location\",\n          \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n              \"location\": {\n                \"type\": \"string\",\n                \"description\": \"The city and state, e.g. San Francisco, CA\"\n              },\n              \"unit\": {\n                \"type\": \"string\",\n                \"enum\": [\"celsius\", \"fahrenheit\"]\n              }\n            },\n            \"required\": [\"location\"]\n          }\n        }\n      }\n    ],\n    \"stream\": true\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\ntools = [\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"get_current_weather\",\n      \"description\": \"Get the current weather in a given location\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"location\": {\n            \"type\": \"string\",\n            \"description\": \"The city and state, e.g. San Francisco, CA\",\n          },\n          \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n        },\n        \"required\": [\"location\"],\n      },\n    }\n  }\n]\n\nstream = client.beta.threads.runs.create(\n  thread_id=\"thread_abc123\",\n  assistant_id=\"asst_abc123\",\n  tools=tools,\n  stream=True\n)\n\nfor event in stream:\n  print(event)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nconst tools = [\n    {\n      \"type\": \"function\",\n      \"function\": {\n        \"name\": \"get_current_weather\",\n        \"description\": \"Get the current weather in a given location\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"location\": {\n              \"type\": \"string\",\n              \"description\": \"The city and state, e.g. San Francisco, CA\",\n            },\n            \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n          },\n          \"required\": [\"location\"],\n        },\n      }\n    }\n];\n\nasync function main() {\n  const stream = await openai.beta.threads.runs.create(\n    \"thread_abc123\",\n    {\n      assistant_id: \"asst_abc123\",\n      tools: tools,\n      stream: true\n    }\n  );\n\n  for await (const event of stream) {\n    console.log(event);\n  }\n}\n\nmain();\n"
            response: "event: thread.run.created\ndata: {\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710348075,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"queued\",\"started_at\":null,\"expires_at\":1710348675,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":null,\"required_action\":null,\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[],\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":null,\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}}\n\nevent: thread.run.queued\ndata: {\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710348075,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"queued\",\"started_at\":null,\"expires_at\":1710348675,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":null,\"required_action\":null,\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[],\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":null,\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}}\n\nevent: thread.run.in_progress\ndata: {\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710348075,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"in_progress\",\"started_at\":1710348075,\"expires_at\":1710348675,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":null,\"required_action\":null,\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[],\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":null,\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}}\n\nevent: thread.run.step.created\ndata: {\"id\":\"step_001\",\"object\":\"thread.run.step\",\"created_at\":1710348076,\"run_id\":\"run_123\",\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"type\":\"message_creation\",\"status\":\"in_progress\",\"cancelled_at\":null,\"completed_at\":null,\"expires_at\":1710348675,\"failed_at\":null,\"last_error\":null,\"step_details\":{\"type\":\"message_creation\",\"message_creation\":{\"message_id\":\"msg_001\"}},\"usage\":null}\n\nevent: thread.run.step.in_progress\ndata: {\"id\":\"step_001\",\"object\":\"thread.run.step\",\"created_at\":1710348076,\"run_id\":\"run_123\",\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"type\":\"message_creation\",\"status\":\"in_progress\",\"cancelled_at\":null,\"completed_at\":null,\"expires_at\":1710348675,\"failed_at\":null,\"last_error\":null,\"step_details\":{\"type\":\"message_creation\",\"message_creation\":{\"message_id\":\"msg_001\"}},\"usage\":null}\n\nevent: thread.message.created\ndata: {\"id\":\"msg_001\",\"object\":\"thread.message\",\"created_at\":1710348076,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"run_id\":\"run_123\",\"status\":\"in_progress\",\"incomplete_details\":null,\"incomplete_at\":null,\"completed_at\":null,\"role\":\"assistant\",\"content\":[],\"metadata\":{}}\n\nevent: thread.message.in_progress\ndata: {\"id\":\"msg_001\",\"object\":\"thread.message\",\"created_at\":1710348076,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"run_id\":\"run_123\",\"status\":\"in_progress\",\"incomplete_details\":null,\"incomplete_at\":null,\"completed_at\":null,\"role\":\"assistant\",\"content\":[],\"metadata\":{}}\n\nevent: thread.message.delta\ndata: {\"id\":\"msg_001\",\"object\":\"thread.message.delta\",\"delta\":{\"content\":[{\"index\":0,\"type\":\"text\",\"text\":{\"value\":\"Hello\",\"annotations\":[]}}]}}\n\n...\n\nevent: thread.message.delta\ndata: {\"id\":\"msg_001\",\"object\":\"thread.message.delta\",\"delta\":{\"content\":[{\"index\":0,\"type\":\"text\",\"text\":{\"value\":\" today\"}}]}}\n\nevent: thread.message.delta\ndata: {\"id\":\"msg_001\",\"object\":\"thread.message.delta\",\"delta\":{\"content\":[{\"index\":0,\"type\":\"text\",\"text\":{\"value\":\"?\"}}]}}\n\nevent: thread.message.completed\ndata: {\"id\":\"msg_001\",\"object\":\"thread.message\",\"created_at\":1710348076,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"run_id\":\"run_123\",\"status\":\"completed\",\"incomplete_details\":null,\"incomplete_at\":null,\"completed_at\":1710348077,\"role\":\"assistant\",\"content\":[{\"type\":\"text\",\"text\":{\"value\":\"Hello! How can I assist you today?\",\"annotations\":[]}}],\"metadata\":{}}\n\nevent: thread.run.step.completed\ndata: {\"id\":\"step_001\",\"object\":\"thread.run.step\",\"created_at\":1710348076,\"run_id\":\"run_123\",\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"type\":\"message_creation\",\"status\":\"completed\",\"cancelled_at\":null,\"completed_at\":1710348077,\"expires_at\":1710348675,\"failed_at\":null,\"last_error\":null,\"step_details\":{\"type\":\"message_creation\",\"message_creation\":{\"message_id\":\"msg_001\"}},\"usage\":{\"prompt_tokens\":20,\"completion_tokens\":11,\"total_tokens\":31}}\n\nevent: thread.run.completed\ndata: {\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710348075,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"completed\",\"started_at\":1710348075,\"expires_at\":null,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":1710348077,\"required_action\":null,\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[],\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":{\"prompt_tokens\":20,\"completion_tokens\":11,\"total_tokens\":31},\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}}\n\nevent: done\ndata: [DONE]\n"
  '/threads/{thread_id}/runs/{run_id}':
    get:
      tags:
        - Assistants
      summary: Retrieves a run.
      operationId: getRun
      parameters:
        - name: thread_id
          in: path
          description: 'The ID of the [thread](/docs/api-reference/threads) that was run.'
          required: true
          schema:
            type: string
        - name: run_id
          in: path
          description: The ID of the run to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Retrieve run
        group: threads
        beta: true
        returns: 'The [run](/docs/api-reference/runs/object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nrun = client.beta.threads.runs.retrieve(\n  thread_id=\"thread_abc123\",\n  run_id=\"run_abc123\"\n)\n\nprint(run)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const run = await openai.beta.threads.runs.retrieve(\n    \"thread_abc123\",\n    \"run_abc123\"\n  );\n\n  console.log(run);\n}\n\nmain();\n"
          response: "{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699075072,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"completed\",\n  \"started_at\": 1699075072,\n  \"expires_at\": null,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": 1699075073,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": null,\n  \"incomplete_details\": null,\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  },\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\": 1000,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\n"
    post:
      tags:
        - Assistants
      summary: Modifies a run.
      operationId: modifyRun
      parameters:
        - name: thread_id
          in: path
          description: 'The ID of the [thread](/docs/api-reference/threads) that was run.'
          required: true
          schema:
            type: string
        - name: run_id
          in: path
          description: The ID of the run to modify.
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyRunRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Modify run
        group: threads
        beta: true
        returns: 'The modified [run](/docs/api-reference/runs/object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"metadata\": {\n      \"user_id\": \"user_abc123\"\n    }\n  }'\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nrun = client.beta.threads.runs.update(\n  thread_id=\"thread_abc123\",\n  run_id=\"run_abc123\",\n  metadata={\"user_id\": \"user_abc123\"},\n)\n\nprint(run)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const run = await openai.beta.threads.runs.update(\n    \"thread_abc123\",\n    \"run_abc123\",\n    {\n      metadata: {\n        user_id: \"user_abc123\",\n      },\n    }\n  );\n\n  console.log(run);\n}\n\nmain();\n"
          response: "{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699075072,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"completed\",\n  \"started_at\": 1699075072,\n  \"expires_at\": null,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": 1699075073,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": null,\n  \"incomplete_details\": null,\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"tool_resources\": {\n    \"code_interpreter\": {\n      \"file_ids\": [\n        \"file-abc123\",\n        \"file-abc456\"\n      ]\n    }\n  },\n  \"metadata\": {\n    \"user_id\": \"user_abc123\"\n  },\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  },\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\": 1000,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\n"
  '/threads/{thread_id}/runs/{run_id}/cancel':
    post:
      tags:
        - Assistants
      summary: Cancels a run that is `in_progress`.
      operationId: cancelRun
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread to which this run belongs.
          required: true
          schema:
            type: string
        - name: run_id
          in: path
          description: The ID of the run to cancel.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Cancel a run
        group: threads
        beta: true
        returns: 'The modified [run](/docs/api-reference/runs/object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -X POST\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nrun = client.beta.threads.runs.cancel(\n  thread_id=\"thread_abc123\",\n  run_id=\"run_abc123\"\n)\n\nprint(run)\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const run = await openai.beta.threads.runs.cancel(\n    \"thread_abc123\",\n    \"run_abc123\"\n  );\n\n  console.log(run);\n}\n\nmain();\n"
          response: "{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699076126,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"cancelling\",\n  \"started_at\": 1699076126,\n  \"expires_at\": 1699076726,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": null,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You summarize books.\",\n  \"tools\": [\n    {\n      \"type\": \"file_search\"\n    }\n  ],\n  \"tool_resources\": {\n    \"file_search\": {\n      \"vector_store_ids\": [\"vs_123\"]\n    }\n  },\n  \"metadata\": {},\n  \"usage\": null,\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\n"
  '/threads/{thread_id}/runs/{run_id}/steps':
    get:
      tags:
        - Assistants
      summary: Returns a list of run steps belonging to a run.
      operationId: listRunSteps
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread the run and run steps belong to.
          required: true
          schema:
            type: string
        - name: run_id
          in: path
          description: The ID of the run the run steps belong to.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: before
          in: query
          description: "A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n"
          schema:
            type: string
        - name: 'include[]'
          in: query
          description: "A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.\n\nSee the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n"
          schema:
            type: array
            items:
              enum:
                - 'step_details.tool_calls[*].file_search.results[*].content'
              type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListRunStepsResponse'
      x-oaiMeta:
        name: List run steps
        group: threads
        beta: true
        returns: 'A list of [run step](/docs/api-reference/run-steps/step-object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nrun_steps = client.beta.threads.runs.steps.list(\n    thread_id=\"thread_abc123\",\n    run_id=\"run_abc123\"\n)\n\nprint(run_steps)\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\nasync function main() {\n  const runStep = await openai.beta.threads.runs.steps.list(\n    \"thread_abc123\",\n    \"run_abc123\"\n  );\n  console.log(runStep);\n}\n\nmain();\n"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"step_abc123\",\n      \"object\": \"thread.run.step\",\n      \"created_at\": 1699063291,\n      \"run_id\": \"run_abc123\",\n      \"assistant_id\": \"asst_abc123\",\n      \"thread_id\": \"thread_abc123\",\n      \"type\": \"message_creation\",\n      \"status\": \"completed\",\n      \"cancelled_at\": null,\n      \"completed_at\": 1699063291,\n      \"expired_at\": null,\n      \"failed_at\": null,\n      \"last_error\": null,\n      \"step_details\": {\n        \"type\": \"message_creation\",\n        \"message_creation\": {\n          \"message_id\": \"msg_abc123\"\n        }\n      },\n      \"usage\": {\n        \"prompt_tokens\": 123,\n        \"completion_tokens\": 456,\n        \"total_tokens\": 579\n      }\n    }\n  ],\n  \"first_id\": \"step_abc123\",\n  \"last_id\": \"step_abc456\",\n  \"has_more\": false\n}\n"
  '/threads/{thread_id}/runs/{run_id}/steps/{step_id}':
    get:
      tags:
        - Assistants
      summary: Retrieves a run step.
      operationId: getRunStep
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread to which the run and run step belongs.
          required: true
          schema:
            type: string
        - name: run_id
          in: path
          description: The ID of the run to which the run step belongs.
          required: true
          schema:
            type: string
        - name: step_id
          in: path
          description: The ID of the run step to retrieve.
          required: true
          schema:
            type: string
        - name: 'include[]'
          in: query
          description: "A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.\n\nSee the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n"
          schema:
            type: array
            items:
              enum:
                - 'step_details.tool_calls[*].file_search.results[*].content'
              type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunStepObject'
      x-oaiMeta:
        name: Retrieve run step
        group: threads
        beta: true
        returns: 'The [run step](/docs/api-reference/run-steps/step-object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nrun_step = client.beta.threads.runs.steps.retrieve(\n    thread_id=\"thread_abc123\",\n    run_id=\"run_abc123\",\n    step_id=\"step_abc123\"\n)\n\nprint(run_step)\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\nasync function main() {\n  const runStep = await openai.beta.threads.runs.steps.retrieve(\n    \"thread_abc123\",\n    \"run_abc123\",\n    \"step_abc123\"\n  );\n  console.log(runStep);\n}\n\nmain();\n"
          response: "{\n  \"id\": \"step_abc123\",\n  \"object\": \"thread.run.step\",\n  \"created_at\": 1699063291,\n  \"run_id\": \"run_abc123\",\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"type\": \"message_creation\",\n  \"status\": \"completed\",\n  \"cancelled_at\": null,\n  \"completed_at\": 1699063291,\n  \"expired_at\": null,\n  \"failed_at\": null,\n  \"last_error\": null,\n  \"step_details\": {\n    \"type\": \"message_creation\",\n    \"message_creation\": {\n      \"message_id\": \"msg_abc123\"\n    }\n  },\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  }\n}\n"
  '/threads/{thread_id}/runs/{run_id}/submit_tool_outputs':
    post:
      tags:
        - Assistants
      summary: "When a run has the `status: \"requires_action\"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.\n"
      operationId: submitToolOuputsToRun
      parameters:
        - name: thread_id
          in: path
          description: 'The ID of the [thread](/docs/api-reference/threads) to which this run belongs.'
          required: true
          schema:
            type: string
        - name: run_id
          in: path
          description: The ID of the run that requires the tool output submission.
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/SubmitToolOutputsRunRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Submit tool outputs to run
        group: threads
        beta: true
        returns: 'The modified [run](/docs/api-reference/runs/object) object matching the specified ID.'
        examples:
          - title: Default
            request:
              curl: "curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"tool_outputs\": [\n      {\n        \"tool_call_id\": \"call_001\",\n        \"output\": \"70 degrees and sunny.\"\n      }\n    ]\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\nrun = client.beta.threads.runs.submit_tool_outputs(\n  thread_id=\"thread_123\",\n  run_id=\"run_123\",\n  tool_outputs=[\n    {\n      \"tool_call_id\": \"call_001\",\n      \"output\": \"70 degrees and sunny.\"\n    }\n  ]\n)\n\nprint(run)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const run = await openai.beta.threads.runs.submitToolOutputs(\n    \"thread_123\",\n    \"run_123\",\n    {\n      tool_outputs: [\n        {\n          tool_call_id: \"call_001\",\n          output: \"70 degrees and sunny.\",\n        },\n      ],\n    }\n  );\n\n  console.log(run);\n}\n\nmain();\n"
            response: "{\n  \"id\": \"run_123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699075592,\n  \"assistant_id\": \"asst_123\",\n  \"thread_id\": \"thread_123\",\n  \"status\": \"queued\",\n  \"started_at\": 1699075592,\n  \"expires_at\": 1699076192,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": null,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": null,\n  \"tools\": [\n    {\n      \"type\": \"function\",\n      \"function\": {\n        \"name\": \"get_current_weather\",\n        \"description\": \"Get the current weather in a given location\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"location\": {\n              \"type\": \"string\",\n              \"description\": \"The city and state, e.g. San Francisco, CA\"\n            },\n            \"unit\": {\n              \"type\": \"string\",\n              \"enum\": [\"celsius\", \"fahrenheit\"]\n            }\n          },\n          \"required\": [\"location\"]\n        }\n      }\n    }\n  ],\n  \"metadata\": {},\n  \"usage\": null,\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\": 1000,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\n"
          - title: Streaming
            request:
              curl: "curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"tool_outputs\": [\n      {\n        \"tool_call_id\": \"call_001\",\n        \"output\": \"70 degrees and sunny.\"\n      }\n    ],\n    \"stream\": true\n  }'\n"
              python: "from openai import OpenAI\nclient = OpenAI()\n\nstream = client.beta.threads.runs.submit_tool_outputs(\n  thread_id=\"thread_123\",\n  run_id=\"run_123\",\n  tool_outputs=[\n    {\n      \"tool_call_id\": \"call_001\",\n      \"output\": \"70 degrees and sunny.\"\n    }\n  ],\n  stream=True\n)\n\nfor event in stream:\n  print(event)\n"
              node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const stream = await openai.beta.threads.runs.submitToolOutputs(\n    \"thread_123\",\n    \"run_123\",\n    {\n      tool_outputs: [\n        {\n          tool_call_id: \"call_001\",\n          output: \"70 degrees and sunny.\",\n        },\n      ],\n    }\n  );\n\n  for await (const event of stream) {\n    console.log(event);\n  }\n}\n\nmain();\n"
            response: "event: thread.run.step.completed\ndata: {\"id\":\"step_001\",\"object\":\"thread.run.step\",\"created_at\":1710352449,\"run_id\":\"run_123\",\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"type\":\"tool_calls\",\"status\":\"completed\",\"cancelled_at\":null,\"completed_at\":1710352475,\"expires_at\":1710353047,\"failed_at\":null,\"last_error\":null,\"step_details\":{\"type\":\"tool_calls\",\"tool_calls\":[{\"id\":\"call_iWr0kQ2EaYMaxNdl0v3KYkx7\",\"type\":\"function\",\"function\":{\"name\":\"get_current_weather\",\"arguments\":\"{\\\"location\\\":\\\"San Francisco, CA\\\",\\\"unit\\\":\\\"fahrenheit\\\"}\",\"output\":\"70 degrees and sunny.\"}}]},\"usage\":{\"prompt_tokens\":291,\"completion_tokens\":24,\"total_tokens\":315}}\n\nevent: thread.run.queued\ndata: {\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710352447,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"queued\",\"started_at\":1710352448,\"expires_at\":1710353047,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":null,\"required_action\":null,\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"get_current_weather\",\"description\":\"Get the current weather in a given location\",\"parameters\":{\"type\":\"object\",\"properties\":{\"location\":{\"type\":\"string\",\"description\":\"The city and state, e.g. San Francisco, CA\"},\"unit\":{\"type\":\"string\",\"enum\":[\"celsius\",\"fahrenheit\"]}},\"required\":[\"location\"]}}}],\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":null,\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}}\n\nevent: thread.run.in_progress\ndata: {\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710352447,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"in_progress\",\"started_at\":1710352475,\"expires_at\":1710353047,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":null,\"required_action\":null,\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"get_current_weather\",\"description\":\"Get the current weather in a given location\",\"parameters\":{\"type\":\"object\",\"properties\":{\"location\":{\"type\":\"string\",\"description\":\"The city and state, e.g. San Francisco, CA\"},\"unit\":{\"type\":\"string\",\"enum\":[\"celsius\",\"fahrenheit\"]}},\"required\":[\"location\"]}}}],\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":null,\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}}\n\nevent: thread.run.step.created\ndata: {\"id\":\"step_002\",\"object\":\"thread.run.step\",\"created_at\":1710352476,\"run_id\":\"run_123\",\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"type\":\"message_creation\",\"status\":\"in_progress\",\"cancelled_at\":null,\"completed_at\":null,\"expires_at\":1710353047,\"failed_at\":null,\"last_error\":null,\"step_details\":{\"type\":\"message_creation\",\"message_creation\":{\"message_id\":\"msg_002\"}},\"usage\":null}\n\nevent: thread.run.step.in_progress\ndata: {\"id\":\"step_002\",\"object\":\"thread.run.step\",\"created_at\":1710352476,\"run_id\":\"run_123\",\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"type\":\"message_creation\",\"status\":\"in_progress\",\"cancelled_at\":null,\"completed_at\":null,\"expires_at\":1710353047,\"failed_at\":null,\"last_error\":null,\"step_details\":{\"type\":\"message_creation\",\"message_creation\":{\"message_id\":\"msg_002\"}},\"usage\":null}\n\nevent: thread.message.created\ndata: {\"id\":\"msg_002\",\"object\":\"thread.message\",\"created_at\":1710352476,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"run_id\":\"run_123\",\"status\":\"in_progress\",\"incomplete_details\":null,\"incomplete_at\":null,\"completed_at\":null,\"role\":\"assistant\",\"content\":[],\"metadata\":{}}\n\nevent: thread.message.in_progress\ndata: {\"id\":\"msg_002\",\"object\":\"thread.message\",\"created_at\":1710352476,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"run_id\":\"run_123\",\"status\":\"in_progress\",\"incomplete_details\":null,\"incomplete_at\":null,\"completed_at\":null,\"role\":\"assistant\",\"content\":[],\"metadata\":{}}\n\nevent: thread.message.delta\ndata: {\"id\":\"msg_002\",\"object\":\"thread.message.delta\",\"delta\":{\"content\":[{\"index\":0,\"type\":\"text\",\"text\":{\"value\":\"The\",\"annotations\":[]}}]}}\n\nevent: thread.message.delta\ndata: {\"id\":\"msg_002\",\"object\":\"thread.message.delta\",\"delta\":{\"content\":[{\"index\":0,\"type\":\"text\",\"text\":{\"value\":\" current\"}}]}}\n\nevent: thread.message.delta\ndata: {\"id\":\"msg_002\",\"object\":\"thread.message.delta\",\"delta\":{\"content\":[{\"index\":0,\"type\":\"text\",\"text\":{\"value\":\" weather\"}}]}}\n\n...\n\nevent: thread.message.delta\ndata: {\"id\":\"msg_002\",\"object\":\"thread.message.delta\",\"delta\":{\"content\":[{\"index\":0,\"type\":\"text\",\"text\":{\"value\":\" sunny\"}}]}}\n\nevent: thread.message.delta\ndata: {\"id\":\"msg_002\",\"object\":\"thread.message.delta\",\"delta\":{\"content\":[{\"index\":0,\"type\":\"text\",\"text\":{\"value\":\".\"}}]}}\n\nevent: thread.message.completed\ndata: {\"id\":\"msg_002\",\"object\":\"thread.message\",\"created_at\":1710352476,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"run_id\":\"run_123\",\"status\":\"completed\",\"incomplete_details\":null,\"incomplete_at\":null,\"completed_at\":1710352477,\"role\":\"assistant\",\"content\":[{\"type\":\"text\",\"text\":{\"value\":\"The current weather in San Francisco, CA is 70 degrees Fahrenheit and sunny.\",\"annotations\":[]}}],\"metadata\":{}}\n\nevent: thread.run.step.completed\ndata: {\"id\":\"step_002\",\"object\":\"thread.run.step\",\"created_at\":1710352476,\"run_id\":\"run_123\",\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"type\":\"message_creation\",\"status\":\"completed\",\"cancelled_at\":null,\"completed_at\":1710352477,\"expires_at\":1710353047,\"failed_at\":null,\"last_error\":null,\"step_details\":{\"type\":\"message_creation\",\"message_creation\":{\"message_id\":\"msg_002\"}},\"usage\":{\"prompt_tokens\":329,\"completion_tokens\":18,\"total_tokens\":347}}\n\nevent: thread.run.completed\ndata: {\"id\":\"run_123\",\"object\":\"thread.run\",\"created_at\":1710352447,\"assistant_id\":\"asst_123\",\"thread_id\":\"thread_123\",\"status\":\"completed\",\"started_at\":1710352475,\"expires_at\":null,\"cancelled_at\":null,\"failed_at\":null,\"completed_at\":1710352477,\"required_action\":null,\"last_error\":null,\"model\":\"gpt-4o\",\"instructions\":null,\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"get_current_weather\",\"description\":\"Get the current weather in a given location\",\"parameters\":{\"type\":\"object\",\"properties\":{\"location\":{\"type\":\"string\",\"description\":\"The city and state, e.g. San Francisco, CA\"},\"unit\":{\"type\":\"string\",\"enum\":[\"celsius\",\"fahrenheit\"]}},\"required\":[\"location\"]}}}],\"metadata\":{},\"temperature\":1.0,\"top_p\":1.0,\"max_completion_tokens\":null,\"max_prompt_tokens\":null,\"truncation_strategy\":{\"type\":\"auto\",\"last_messages\":null},\"incomplete_details\":null,\"usage\":{\"prompt_tokens\":20,\"completion_tokens\":11,\"total_tokens\":31},\"response_format\":\"auto\",\"tool_choice\":\"auto\",\"parallel_tool_calls\":true}}\n\nevent: done\ndata: [DONE]\n"
  /uploads:
    post:
      tags:
        - Uploads
      summary: "Creates an intermediate [Upload](/docs/api-reference/uploads/object) object that you can add [Parts](/docs/api-reference/uploads/part-object) to. Currently, an Upload can accept at most 8 GB in total and expires after an hour after you create it.\n\nOnce you complete the Upload, we will create a [File](/docs/api-reference/files/object) object that contains all the parts you uploaded. This File is usable in the rest of our platform as a regular File object.\n\nFor certain `purpose`s, the correct `mime_type` must be specified. Please refer to documentation for the supported MIME types for your use case:\n- [Assistants](/docs/assistants/tools/file-search#supported-files)\n\nFor guidance on the proper filename extensions for each purpose, please follow the documentation on [creating a File](/docs/api-reference/files/create).\n"
      operationId: createUpload
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateUploadRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Upload'
      x-oaiMeta:
        name: Create upload
        group: uploads
        returns: 'The [Upload](/docs/api-reference/uploads/object) object with status `pending`.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/uploads \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"purpose\": \"fine-tune\",\n    \"filename\": \"training_examples.jsonl\",\n    \"bytes\": 2147483648,\n    \"mime_type\": \"text/jsonl\"\n  }'\n"
          response: "{\n  \"id\": \"upload_abc123\",\n  \"object\": \"upload\",\n  \"bytes\": 2147483648,\n  \"created_at\": 1719184911,\n  \"filename\": \"training_examples.jsonl\",\n  \"purpose\": \"fine-tune\",\n  \"status\": \"pending\",\n  \"expires_at\": 1719127296\n}\n"
  '/uploads/{upload_id}/cancel':
    post:
      tags:
        - Uploads
      summary: "Cancels the Upload. No Parts may be added after an Upload is cancelled.\n"
      operationId: cancelUpload
      parameters:
        - name: upload_id
          in: path
          description: "The ID of the Upload.\n"
          required: true
          schema:
            type: string
            example: upload_abc123
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Upload'
      x-oaiMeta:
        name: Cancel upload
        group: uploads
        returns: 'The [Upload](/docs/api-reference/uploads/object) object with status `cancelled`.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/uploads/upload_abc123/cancel\n"
          response: "{\n  \"id\": \"upload_abc123\",\n  \"object\": \"upload\",\n  \"bytes\": 2147483648,\n  \"created_at\": 1719184911,\n  \"filename\": \"training_examples.jsonl\",\n  \"purpose\": \"fine-tune\",\n  \"status\": \"cancelled\",\n  \"expires_at\": 1719127296\n}\n"
  '/uploads/{upload_id}/complete':
    post:
      tags:
        - Uploads
      summary: "Completes the [Upload](/docs/api-reference/uploads/object). \n\nWithin the returned Upload object, there is a nested [File](/docs/api-reference/files/object) object that is ready to use in the rest of the platform.\n\nYou can specify the order of the Parts by passing in an ordered list of the Part IDs.\n\nThe number of bytes uploaded upon completion must match the number of bytes initially specified when creating the Upload object. No Parts may be added after an Upload is completed.\n"
      operationId: completeUpload
      parameters:
        - name: upload_id
          in: path
          description: "The ID of the Upload.\n"
          required: true
          schema:
            type: string
            example: upload_abc123
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CompleteUploadRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Upload'
      x-oaiMeta:
        name: Complete upload
        group: uploads
        returns: 'The [Upload](/docs/api-reference/uploads/object) object with status `completed` with an additional `file` property containing the created usable File object.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/uploads/upload_abc123/complete\n  -d '{\n    \"part_ids\": [\"part_def456\", \"part_ghi789\"]\n  }'\n"
          response: "{\n  \"id\": \"upload_abc123\",\n  \"object\": \"upload\",\n  \"bytes\": 2147483648,\n  \"created_at\": 1719184911,\n  \"filename\": \"training_examples.jsonl\",\n  \"purpose\": \"fine-tune\",\n  \"status\": \"completed\",\n  \"expires_at\": 1719127296,\n  \"file\": {\n    \"id\": \"file-xyz321\",\n    \"object\": \"file\",\n    \"bytes\": 2147483648,\n    \"created_at\": 1719186911,\n    \"filename\": \"training_examples.jsonl\",\n    \"purpose\": \"fine-tune\",\n  }\n}\n"
  '/uploads/{upload_id}/parts':
    post:
      tags:
        - Uploads
      summary: "Adds a [Part](/docs/api-reference/uploads/part-object) to an [Upload](/docs/api-reference/uploads/object) object. A Part represents a chunk of bytes from the file you are trying to upload. \n\nEach Part can be at most 64 MB, and you can add Parts until you hit the Upload maximum of 8 GB.\n\nIt is possible to add multiple Parts in parallel. You can decide the intended order of the Parts when you [complete the Upload](/docs/api-reference/uploads/complete).\n"
      operationId: addUploadPart
      parameters:
        - name: upload_id
          in: path
          description: "The ID of the Upload.\n"
          required: true
          schema:
            type: string
            example: upload_abc123
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/AddUploadPartRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UploadPart'
      x-oaiMeta:
        name: Add upload part
        group: uploads
        returns: 'The upload [Part](/docs/api-reference/uploads/part-object) object.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/uploads/upload_abc123/parts\n  -F data=\"aHR0cHM6Ly9hcGkub3BlbmFpLmNvbS92MS91cGxvYWRz...\"\n"
          response: "{\n  \"id\": \"part_def456\",\n  \"object\": \"upload.part\",\n  \"created_at\": 1719185911,\n  \"upload_id\": \"upload_abc123\"\n}\n"
  /vector_stores:
    get:
      tags:
        - Vector stores
      summary: Returns a list of vector stores.
      operationId: listVectorStores
      parameters:
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: before
          in: query
          description: "A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoresResponse'
      x-oaiMeta:
        name: List vector stores
        group: vector_stores
        beta: true
        returns: 'A list of [vector store](/docs/api-reference/vector-stores/object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_stores = client.beta.vector_stores.list()\nprint(vector_stores)\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\nasync function main() {\n  const vectorStores = await openai.beta.vectorStores.list();\n  console.log(vectorStores);\n}\n\nmain();\n"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"vs_abc123\",\n      \"object\": \"vector_store\",\n      \"created_at\": 1699061776,\n      \"name\": \"Support FAQ\",\n      \"bytes\": 139920,\n      \"file_counts\": {\n        \"in_progress\": 0,\n        \"completed\": 3,\n        \"failed\": 0,\n        \"cancelled\": 0,\n        \"total\": 3\n      }\n    },\n    {\n      \"id\": \"vs_abc456\",\n      \"object\": \"vector_store\",\n      \"created_at\": 1699061776,\n      \"name\": \"Support FAQ v2\",\n      \"bytes\": 139920,\n      \"file_counts\": {\n        \"in_progress\": 0,\n        \"completed\": 3,\n        \"failed\": 0,\n        \"cancelled\": 0,\n        \"total\": 3\n      }\n    }\n  ],\n  \"first_id\": \"vs_abc123\",\n  \"last_id\": \"vs_abc456\",\n  \"has_more\": false\n}\n"
    post:
      tags:
        - Vector stores
      summary: Create a vector store.
      operationId: createVectorStore
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
      x-oaiMeta:
        name: Create vector store
        group: vector_stores
        beta: true
        returns: 'A [vector store](/docs/api-reference/vector-stores/object) object.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n  -d '{\n    \"name\": \"Support FAQ\"\n  }'\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_store = client.beta.vector_stores.create(\n  name=\"Support FAQ\"\n)\nprint(vector_store)\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\nasync function main() {\n  const vectorStore = await openai.beta.vectorStores.create({\n    name: \"Support FAQ\"\n  });\n  console.log(vectorStore);\n}\n\nmain();\n"
          response: "{\n  \"id\": \"vs_abc123\",\n  \"object\": \"vector_store\",\n  \"created_at\": 1699061776,\n  \"name\": \"Support FAQ\",\n  \"bytes\": 139920,\n  \"file_counts\": {\n    \"in_progress\": 0,\n    \"completed\": 3,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 3\n  }\n}\n"
  '/vector_stores/{vector_store_id}':
    get:
      tags:
        - Vector stores
      summary: Retrieves a vector store.
      operationId: getVectorStore
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
      x-oaiMeta:
        name: Retrieve vector store
        group: vector_stores
        beta: true
        returns: 'The [vector store](/docs/api-reference/vector-stores/object) object matching the specified ID.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_store = client.beta.vector_stores.retrieve(\n  vector_store_id=\"vs_abc123\"\n)\nprint(vector_store)\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\nasync function main() {\n  const vectorStore = await openai.beta.vectorStores.retrieve(\n    \"vs_abc123\"\n  );\n  console.log(vectorStore);\n}\n\nmain();\n"
          response: "{\n  \"id\": \"vs_abc123\",\n  \"object\": \"vector_store\",\n  \"created_at\": 1699061776\n}\n"
    post:
      tags:
        - Vector stores
      summary: Modifies a vector store.
      operationId: modifyVectorStore
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store to modify.
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateVectorStoreRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
      x-oaiMeta:
        name: Modify vector store
        group: vector_stores
        beta: true
        returns: 'The modified [vector store](/docs/api-reference/vector-stores/object) object.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n  -d '{\n    \"name\": \"Support FAQ\"\n  }'\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_store = client.beta.vector_stores.update(\n  vector_store_id=\"vs_abc123\",\n  name=\"Support FAQ\"\n)\nprint(vector_store)\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\nasync function main() {\n  const vectorStore = await openai.beta.vectorStores.update(\n    \"vs_abc123\",\n    {\n      name: \"Support FAQ\"\n    }\n  );\n  console.log(vectorStore);\n}\n\nmain();\n"
          response: "{\n  \"id\": \"vs_abc123\",\n  \"object\": \"vector_store\",\n  \"created_at\": 1699061776,\n  \"name\": \"Support FAQ\",\n  \"bytes\": 139920,\n  \"file_counts\": {\n    \"in_progress\": 0,\n    \"completed\": 3,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 3\n  }\n}\n"
    delete:
      tags:
        - Vector stores
      summary: Delete a vector store.
      operationId: deleteVectorStore
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store to delete.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteVectorStoreResponse'
      x-oaiMeta:
        name: Delete vector store
        group: vector_stores
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -X DELETE\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\ndeleted_vector_store = client.beta.vector_stores.delete(\n  vector_store_id=\"vs_abc123\"\n)\nprint(deleted_vector_store)\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\nasync function main() {\n  const deletedVectorStore = await openai.beta.vectorStores.del(\n    \"vs_abc123\"\n  );\n  console.log(deletedVectorStore);\n}\n\nmain();\n"
          response: "{\n  id: \"vs_abc123\",\n  object: \"vector_store.deleted\",\n  deleted: true\n}\n"
  '/vector_stores/{vector_store_id}/file_batches':
    post:
      tags:
        - Vector stores
      summary: Create a vector store file batch.
      operationId: createVectorStoreFileBatch
      parameters:
        - name: vector_store_id
          in: path
          description: "The ID of the vector store for which to create a File Batch.\n"
          required: true
          schema:
            type: string
            example: vs_abc123
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreFileBatchRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
      x-oaiMeta:
        name: Create vector store file batch
        group: vector_stores
        beta: true
        returns: 'A [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \\\n    -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n    -H \"Content-Type: application/json \\\n    -H \"OpenAI-Beta: assistants=v2\" \\\n    -d '{\n      \"file_ids\": [\"file-abc123\", \"file-abc456\"]\n    }'\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_store_file_batch = client.beta.vector_stores.file_batches.create(\n  vector_store_id=\"vs_abc123\",\n  file_ids=[\"file-abc123\", \"file-abc456\"]\n)\nprint(vector_store_file_batch)\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\nasync function main() {\n  const myVectorStoreFileBatch = await openai.beta.vectorStores.fileBatches.create(\n    \"vs_abc123\",\n    {\n      file_ids: [\"file-abc123\", \"file-abc456\"]\n    }\n  );\n  console.log(myVectorStoreFileBatch);\n}\n\nmain();\n"
          response: "{\n  \"id\": \"vsfb_abc123\",\n  \"object\": \"vector_store.file_batch\",\n  \"created_at\": 1699061776,\n  \"vector_store_id\": \"vs_abc123\",\n  \"status\": \"in_progress\",\n  \"file_counts\": {\n    \"in_progress\": 1,\n    \"completed\": 1,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 0,\n  }\n}\n"
  '/vector_stores/{vector_store_id}/file_batches/{batch_id}':
    get:
      tags:
        - Vector stores
      summary: Retrieves a vector store file batch.
      operationId: getVectorStoreFileBatch
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store that the file batch belongs to.
          required: true
          schema:
            type: string
            example: vs_abc123
        - name: batch_id
          in: path
          description: The ID of the file batch being retrieved.
          required: true
          schema:
            type: string
            example: vsfb_abc123
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
      x-oaiMeta:
        name: Retrieve vector store file batch
        group: vector_stores
        beta: true
        returns: 'The [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_store_file_batch = client.beta.vector_stores.file_batches.retrieve(\n  vector_store_id=\"vs_abc123\",\n  batch_id=\"vsfb_abc123\"\n)\nprint(vector_store_file_batch)\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\nasync function main() {\n  const vectorStoreFileBatch = await openai.beta.vectorStores.fileBatches.retrieve(\n    \"vs_abc123\",\n    \"vsfb_abc123\"\n  );\n  console.log(vectorStoreFileBatch);\n}\n\nmain();\n"
          response: "{\n  \"id\": \"vsfb_abc123\",\n  \"object\": \"vector_store.file_batch\",\n  \"created_at\": 1699061776,\n  \"vector_store_id\": \"vs_abc123\",\n  \"status\": \"in_progress\",\n  \"file_counts\": {\n    \"in_progress\": 1,\n    \"completed\": 1,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 0,\n  }\n}\n"
  '/vector_stores/{vector_store_id}/file_batches/{batch_id}/cancel':
    post:
      tags:
        - Vector stores
      summary: Cancel a vector store file batch. This attempts to cancel the processing of files in this batch as soon as possible.
      operationId: cancelVectorStoreFileBatch
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store that the file batch belongs to.
          required: true
          schema:
            type: string
        - name: batch_id
          in: path
          description: The ID of the file batch to cancel.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
      x-oaiMeta:
        name: Cancel vector store file batch
        group: vector_stores
        beta: true
        returns: The modified vector store file batch object.
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -X POST\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\ndeleted_vector_store_file_batch = client.beta.vector_stores.file_batches.cancel(\n    vector_store_id=\"vs_abc123\",\n    file_batch_id=\"vsfb_abc123\"\n)\nprint(deleted_vector_store_file_batch)\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\nasync function main() {\n  const deletedVectorStoreFileBatch = await openai.vector_stores.fileBatches.cancel(\n    \"vs_abc123\",\n    \"vsfb_abc123\"\n  );\n  console.log(deletedVectorStoreFileBatch);\n}\n\nmain();\n"
          response: "{\n  \"id\": \"vsfb_abc123\",\n  \"object\": \"vector_store.file_batch\",\n  \"created_at\": 1699061776,\n  \"vector_store_id\": \"vs_abc123\",\n  \"status\": \"cancelling\",\n  \"file_counts\": {\n    \"in_progress\": 12,\n    \"completed\": 3,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 15,\n  }\n}\n"
  '/vector_stores/{vector_store_id}/file_batches/{batch_id}/files':
    get:
      tags:
        - Vector stores
      summary: Returns a list of vector store files in a batch.
      operationId: listFilesInVectorStoreBatch
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store that the files belong to.
          required: true
          schema:
            type: string
        - name: batch_id
          in: path
          description: The ID of the file batch that the files belong to.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: before
          in: query
          description: "A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n"
          schema:
            type: string
        - name: filter
          in: query
          description: 'Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.'
          schema:
            enum:
              - in_progress
              - completed
              - failed
              - cancelled
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoreFilesResponse'
      x-oaiMeta:
        name: List vector store files in a batch
        group: vector_stores
        beta: true
        returns: 'A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_store_files = client.beta.vector_stores.file_batches.list_files(\n  vector_store_id=\"vs_abc123\",\n  batch_id=\"vsfb_abc123\"\n)\nprint(vector_store_files)\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\nasync function main() {\n  const vectorStoreFiles = await openai.beta.vectorStores.fileBatches.listFiles(\n    \"vs_abc123\",\n    \"vsfb_abc123\"\n  );\n  console.log(vectorStoreFiles);\n}\n\nmain();\n"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"vector_store.file\",\n      \"created_at\": 1699061776,\n      \"vector_store_id\": \"vs_abc123\"\n    },\n    {\n      \"id\": \"file-abc456\",\n      \"object\": \"vector_store.file\",\n      \"created_at\": 1699061776,\n      \"vector_store_id\": \"vs_abc123\"\n    }\n  ],\n  \"first_id\": \"file-abc123\",\n  \"last_id\": \"file-abc456\",\n  \"has_more\": false\n}\n"
  '/vector_stores/{vector_store_id}/files':
    get:
      tags:
        - Vector stores
      summary: Returns a list of vector store files.
      operationId: listVectorStoreFiles
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store that the files belong to.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: before
          in: query
          description: "A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n"
          schema:
            type: string
        - name: filter
          in: query
          description: 'Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.'
          schema:
            enum:
              - in_progress
              - completed
              - failed
              - cancelled
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoreFilesResponse'
      x-oaiMeta:
        name: List vector store files
        group: vector_stores
        beta: true
        returns: 'A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_store_files = client.beta.vector_stores.files.list(\n  vector_store_id=\"vs_abc123\"\n)\nprint(vector_store_files)\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\nasync function main() {\n  const vectorStoreFiles = await openai.beta.vectorStores.files.list(\n    \"vs_abc123\"\n  );\n  console.log(vectorStoreFiles);\n}\n\nmain();\n"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"vector_store.file\",\n      \"created_at\": 1699061776,\n      \"vector_store_id\": \"vs_abc123\"\n    },\n    {\n      \"id\": \"file-abc456\",\n      \"object\": \"vector_store.file\",\n      \"created_at\": 1699061776,\n      \"vector_store_id\": \"vs_abc123\"\n    }\n  ],\n  \"first_id\": \"file-abc123\",\n  \"last_id\": \"file-abc456\",\n  \"has_more\": false\n}\n"
    post:
      tags:
        - Vector stores
      summary: 'Create a vector store file by attaching a [File](/docs/api-reference/files) to a [vector store](/docs/api-reference/vector-stores/object).'
      operationId: createVectorStoreFile
      parameters:
        - name: vector_store_id
          in: path
          description: "The ID of the vector store for which to create a File.\n"
          required: true
          schema:
            type: string
            example: vs_abc123
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreFileRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileObject'
      x-oaiMeta:
        name: Create vector store file
        group: vector_stores
        beta: true
        returns: 'A [vector store file](/docs/api-reference/vector-stores-files/file-object) object.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files \\\n    -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n    -H \"Content-Type: application/json\" \\\n    -H \"OpenAI-Beta: assistants=v2\" \\\n    -d '{\n      \"file_id\": \"file-abc123\"\n    }'\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_store_file = client.beta.vector_stores.files.create(\n  vector_store_id=\"vs_abc123\",\n  file_id=\"file-abc123\"\n)\nprint(vector_store_file)\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\nasync function main() {\n  const myVectorStoreFile = await openai.beta.vectorStores.files.create(\n    \"vs_abc123\",\n    {\n      file_id: \"file-abc123\"\n    }\n  );\n  console.log(myVectorStoreFile);\n}\n\nmain();\n"
          response: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"vector_store.file\",\n  \"created_at\": 1699061776,\n  \"usage_bytes\": 1234,\n  \"vector_store_id\": \"vs_abcd\",\n  \"status\": \"completed\",\n  \"last_error\": null\n}\n"
  '/vector_stores/{vector_store_id}/files/{file_id}':
    get:
      tags:
        - Vector stores
      summary: Retrieves a vector store file.
      operationId: getVectorStoreFile
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store that the file belongs to.
          required: true
          schema:
            type: string
            example: vs_abc123
        - name: file_id
          in: path
          description: The ID of the file being retrieved.
          required: true
          schema:
            type: string
            example: file-abc123
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileObject'
      x-oaiMeta:
        name: Retrieve vector store file
        group: vector_stores
        beta: true
        returns: 'The [vector store file](/docs/api-reference/vector-stores-files/file-object) object.'
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_store_file = client.beta.vector_stores.files.retrieve(\n  vector_store_id=\"vs_abc123\",\n  file_id=\"file-abc123\"\n)\nprint(vector_store_file)\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\nasync function main() {\n  const vectorStoreFile = await openai.beta.vectorStores.files.retrieve(\n    \"vs_abc123\",\n    \"file-abc123\"\n  );\n  console.log(vectorStoreFile);\n}\n\nmain();\n"
          response: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"vector_store.file\",\n  \"created_at\": 1699061776,\n  \"vector_store_id\": \"vs_abcd\",\n  \"status\": \"completed\",\n  \"last_error\": null\n}\n"
    delete:
      tags:
        - Vector stores
      summary: 'Delete a vector store file. This will remove the file from the vector store but the file itself will not be deleted. To delete the file, use the [delete file](/docs/api-reference/files/delete) endpoint.'
      operationId: deleteVectorStoreFile
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store that the file belongs to.
          required: true
          schema:
            type: string
        - name: file_id
          in: path
          description: The ID of the file to delete.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteVectorStoreFileResponse'
      x-oaiMeta:
        name: Delete vector store file
        group: vector_stores
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -X DELETE\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\ndeleted_vector_store_file = client.beta.vector_stores.files.delete(\n    vector_store_id=\"vs_abc123\",\n    file_id=\"file-abc123\"\n)\nprint(deleted_vector_store_file)\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\nasync function main() {\n  const deletedVectorStoreFile = await openai.beta.vectorStores.files.del(\n    \"vs_abc123\",\n    \"file-abc123\"\n  );\n  console.log(deletedVectorStoreFile);\n}\n\nmain();\n"
          response: "{\n  id: \"file-abc123\",\n  object: \"vector_store.file.deleted\",\n  deleted: true\n}\n"
components:
  schemas:
    AddUploadPartRequest:
      required:
        - data
      type: object
      properties:
        data:
          type: string
          description: "The chunk of bytes for this Part.\n"
          format: binary
      additionalProperties: false
    AssistantObject:
      title: Assistant
      required:
        - id
        - object
        - created_at
        - name
        - description
        - model
        - instructions
        - tools
        - metadata
      type: object
      properties:
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints.'
        object:
          enum:
            - assistant
          type: string
          description: 'The object type, which is always `assistant`.'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the assistant was created.
        name:
          maxLength: 256
          type: string
          description: "The name of the assistant. The maximum length is 256 characters.\n"
          nullable: true
        description:
          maxLength: 512
          type: string
          description: "The description of the assistant. The maximum length is 512 characters.\n"
          nullable: true
        model:
          type: string
          description: "ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.\n"
        instructions:
          maxLength: 256000
          type: string
          description: "The system instructions that the assistant uses. The maximum length is 256,000 characters.\n"
          nullable: true
        tools:
          maxItems: 128
          type: array
          items:
            oneOf:
              - $ref: '#/components/schemas/AssistantToolsCode'
              - $ref: '#/components/schemas/AssistantToolsFileSearch'
              - $ref: '#/components/schemas/AssistantToolsFunction'
            x-oaiExpandable: true
          description: "A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.\n"
        tool_resources:
          type: object
          properties:
            code_interpreter:
              type: object
              properties:
                file_ids:
                  maxItems: 20
                  type: array
                  items:
                    type: string
                  description: "A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter`` tool. There can be a maximum of 20 files associated with the tool.\n"
            file_search:
              type: object
              properties:
                vector_store_ids:
                  maxItems: 1
                  type: array
                  items:
                    type: string
                  description: "The ID of the [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.\n"
          description: "A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n"
          nullable: true
        metadata:
          type: object
          description: "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
          nullable: true
          x-oaiTypeLabel: map
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n"
          default: 1
          nullable: true
          example: 1
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n"
          default: 1
          nullable: true
          example: 1
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
      description: Represents an `assistant` that can call the model and use tools.
      x-oaiMeta:
        name: The assistant object
        beta: true
        example: "{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n  \"created_at\": 1698984975,\n  \"name\": \"Math Tutor\",\n  \"description\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You are a personal math tutor. When asked a question, write and run Python code to answer the question.\",\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n  \"top_p\": 1.0,\n  \"temperature\": 1.0,\n  \"response_format\": \"auto\"\n}\n"
    AssistantStreamEvent:
      oneOf:
        - $ref: '#/components/schemas/ThreadStreamEvent'
        - $ref: '#/components/schemas/RunStreamEvent'
        - $ref: '#/components/schemas/RunStepStreamEvent'
        - $ref: '#/components/schemas/MessageStreamEvent'
        - $ref: '#/components/schemas/ErrorEvent'
        - $ref: '#/components/schemas/DoneEvent'
      description: "Represents an event emitted when streaming a Run.\n\nEach event in a server-sent events stream has an `event` and `data` property:\n\n```\nevent: thread.created\ndata: {\"id\": \"thread_123\", \"object\": \"thread\", ...}\n```\n\nWe emit events whenever a new object is created, transitions to a new state, or is being\nstreamed in parts (deltas). For example, we emit `thread.run.created` when a new run\nis created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses\nto create a message during a run, we emit a `thread.message.created event`, a\n`thread.message.in_progress` event, many `thread.message.delta` events, and finally a\n`thread.message.completed` event.\n\nWe may add additional events over time, so we recommend handling unknown events gracefully\nin your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to\nintegrate the Assistants API with streaming.\n"
      x-oaiMeta:
        name: Assistant stream events
        beta: true
    AssistantToolsCode:
      title: Code interpreter tool
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - code_interpreter
          type: string
          description: 'The type of tool being defined: `code_interpreter`'
    AssistantToolsFileSearch:
      title: FileSearch tool
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - file_search
          type: string
          description: 'The type of tool being defined: `file_search`'
        file_search:
          type: object
          properties:
            max_num_results:
              maximum: 50
              minimum: 1
              type: integer
              description: "The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.\n\nNote that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n"
            ranking_options:
              $ref: '#/components/schemas/FileSearchRankingOptions'
          description: Overrides for the file search tool.
    AssistantToolsFileSearchTypeOnly:
      title: FileSearch tool
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - file_search
          type: string
          description: 'The type of tool being defined: `file_search`'
    AssistantToolsFunction:
      title: Function tool
      required:
        - type
        - function
      type: object
      properties:
        type:
          enum:
            - function
          type: string
          description: 'The type of tool being defined: `function`'
        function:
          $ref: '#/components/schemas/FunctionObject'
    AssistantsApiResponseFormatOption:
      oneOf:
        - enum:
            - auto
          type: string
          description: "`auto` is the default value\n"
        - $ref: '#/components/schemas/ResponseFormatText'
        - $ref: '#/components/schemas/ResponseFormatJsonObject'
        - $ref: '#/components/schemas/ResponseFormatJsonSchema'
      description: "Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.\n\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n"
      x-oaiExpandable: true
    AssistantsApiToolChoiceOption:
      oneOf:
        - enum:
            - none
            - auto
            - required
          type: string
          description: "`none` means the model will not call any tools and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user.\n"
        - $ref: '#/components/schemas/AssistantsNamedToolChoice'
      description: "Controls which (if any) tool is called by the model.\n`none` means the model will not call any tools and instead generates a message.\n`auto` is the default value and means the model can pick between generating a message or calling one or more tools.\n`required` means the model must call one or more tools before responding to the user.\nSpecifying a particular tool like `{\"type\": \"file_search\"}` or `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to call that tool.\n"
      x-oaiExpandable: true
    AssistantsNamedToolChoice:
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - function
            - code_interpreter
            - file_search
          type: string
          description: 'The type of the tool. If type is `function`, the function name must be set'
        function:
          required:
            - name
          type: object
          properties:
            name:
              type: string
              description: The name of the function to call.
      description: Specifies a tool the model should use. Use to force the model to call a specific tool.
    AudioResponseFormat:
      enum:
        - json
        - text
        - srt
        - verbose_json
        - vtt
      type: string
      description: "The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.\n"
      default: json
    AuditLog:
      required:
        - id
        - type
        - effective_at
        - actor
      type: object
      properties:
        id:
          type: string
          description: The ID of this log.
        type:
          $ref: '#/components/schemas/AuditLogEventType'
        effective_at:
          type: integer
          description: The Unix timestamp (in seconds) of the event.
        project:
          type: object
          properties:
            id:
              type: string
              description: The project ID.
            name:
              type: string
              description: The project title.
          description: The project that the action was scoped to. Absent for actions not scoped to projects.
        actor:
          $ref: '#/components/schemas/AuditLogActor'
        api_key.created:
          type: object
          properties:
            id:
              type: string
              description: The tracking ID of the API key.
            data:
              type: object
              properties:
                scopes:
                  type: array
                  items:
                    type: string
                  description: 'A list of scopes allowed for the API key, e.g. `["api.model.request"]`'
              description: The payload used to create the API key.
          description: The details for events with this `type`.
        api_key.updated:
          type: object
          properties:
            id:
              type: string
              description: The tracking ID of the API key.
            changes_requested:
              type: object
              properties:
                scopes:
                  type: array
                  items:
                    type: string
                  description: 'A list of scopes allowed for the API key, e.g. `["api.model.request"]`'
              description: The payload used to update the API key.
          description: The details for events with this `type`.
        api_key.deleted:
          type: object
          properties:
            id:
              type: string
              description: The tracking ID of the API key.
          description: The details for events with this `type`.
        invite.sent:
          type: object
          properties:
            id:
              type: string
              description: The ID of the invite.
            data:
              type: object
              properties:
                email:
                  type: string
                  description: The email invited to the organization.
                role:
                  type: string
                  description: The role the email was invited to be. Is either `owner` or `member`.
              description: The payload used to create the invite.
          description: The details for events with this `type`.
        invite.accepted:
          type: object
          properties:
            id:
              type: string
              description: The ID of the invite.
          description: The details for events with this `type`.
        invite.deleted:
          type: object
          properties:
            id:
              type: string
              description: The ID of the invite.
          description: The details for events with this `type`.
        login.failed:
          type: object
          properties:
            error_code:
              type: string
              description: The error code of the failure.
            error_message:
              type: string
              description: The error message of the failure.
          description: The details for events with this `type`.
        logout.failed:
          type: object
          properties:
            error_code:
              type: string
              description: The error code of the failure.
            error_message:
              type: string
              description: The error message of the failure.
          description: The details for events with this `type`.
        organization.updated:
          type: object
          properties:
            id:
              type: string
              description: The organization ID.
            changes_requested:
              type: object
              properties:
                title:
                  type: string
                  description: The organization title.
                description:
                  type: string
                  description: The organization description.
                name:
                  type: string
                  description: The organization name.
                settings:
                  type: object
                  properties:
                    threads_ui_visibility:
                      type: string
                      description: 'Visibility of the threads page which shows messages created with the Assistants API and Playground. One of `ANY_ROLE`, `OWNERS`, or `NONE`.'
                    usage_dashboard_visibility:
                      type: string
                      description: Visibility of the usage dashboard which shows activity and costs for your organization. One of `ANY_ROLE` or `OWNERS`.
              description: The payload used to update the organization settings.
          description: The details for events with this `type`.
        project.created:
          type: object
          properties:
            id:
              type: string
              description: The project ID.
            data:
              type: object
              properties:
                name:
                  type: string
                  description: The project name.
                title:
                  type: string
                  description: The title of the project as seen on the dashboard.
              description: The payload used to create the project.
          description: The details for events with this `type`.
        project.updated:
          type: object
          properties:
            id:
              type: string
              description: The project ID.
            changes_requested:
              type: object
              properties:
                title:
                  type: string
                  description: The title of the project as seen on the dashboard.
              description: The payload used to update the project.
          description: The details for events with this `type`.
        project.archived:
          type: object
          properties:
            id:
              type: string
              description: The project ID.
          description: The details for events with this `type`.
        rate_limit.updated:
          type: object
          properties:
            id:
              type: string
              description: The rate limit ID
            changes_requested:
              type: object
              properties:
                max_requests_per_1_minute:
                  type: integer
                  description: The maximum requests per minute.
                max_tokens_per_1_minute:
                  type: integer
                  description: The maximum tokens per minute.
                max_images_per_1_minute:
                  type: integer
                  description: The maximum images per minute. Only relevant for certain models.
                max_audio_megabytes_per_1_minute:
                  type: integer
                  description: The maximum audio megabytes per minute. Only relevant for certain models.
                max_requests_per_1_day:
                  type: integer
                  description: The maximum requests per day. Only relevant for certain models.
                batch_1_day_max_input_tokens:
                  type: integer
                  description: The maximum batch input tokens per day. Only relevant for certain models.
              description: The payload used to update the rate limits.
          description: The details for events with this `type`.
        rate_limit.deleted:
          type: object
          properties:
            id:
              type: string
              description: The rate limit ID
          description: The details for events with this `type`.
        service_account.created:
          type: object
          properties:
            id:
              type: string
              description: The service account ID.
            data:
              type: object
              properties:
                role:
                  type: string
                  description: The role of the service account. Is either `owner` or `member`.
              description: The payload used to create the service account.
          description: The details for events with this `type`.
        service_account.updated:
          type: object
          properties:
            id:
              type: string
              description: The service account ID.
            changes_requested:
              type: object
              properties:
                role:
                  type: string
                  description: The role of the service account. Is either `owner` or `member`.
              description: The payload used to updated the service account.
          description: The details for events with this `type`.
        service_account.deleted:
          type: object
          properties:
            id:
              type: string
              description: The service account ID.
          description: The details for events with this `type`.
        user.added:
          type: object
          properties:
            id:
              type: string
              description: The user ID.
            data:
              type: object
              properties:
                role:
                  type: string
                  description: The role of the user. Is either `owner` or `member`.
              description: The payload used to add the user to the project.
          description: The details for events with this `type`.
        user.updated:
          type: object
          properties:
            id:
              type: string
              description: The project ID.
            changes_requested:
              type: object
              properties:
                role:
                  type: string
                  description: The role of the user. Is either `owner` or `member`.
              description: The payload used to update the user.
          description: The details for events with this `type`.
        user.deleted:
          type: object
          properties:
            id:
              type: string
              description: The user ID.
          description: The details for events with this `type`.
      description: A log of a user action or configuration change within this organization.
      x-oaiMeta:
        name: The audit log object
        example: "{\n    \"id\": \"req_xxx_20240101\",\n    \"type\": \"api_key.created\",\n    \"effective_at\": 1720804090,\n    \"actor\": {\n        \"type\": \"session\",\n        \"session\": {\n            \"user\": {\n                \"id\": \"user-xxx\",\n                \"email\": \"user@example.com\"\n            },\n            \"ip_address\": \"127.0.0.1\",\n            \"user_agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n        }\n    },\n    \"api_key.created\": {\n        \"id\": \"key_xxxx\",\n        \"data\": {\n            \"scopes\": [\"resource.operation\"]\n        }\n    }\n}\n"
    AuditLogActor:
      type: object
      properties:
        type:
          enum:
            - session
            - api_key
          type: string
          description: The type of actor. Is either `session` or `api_key`.
        session:
          $ref: '#/components/schemas/AuditLogActorSession'
        api_key:
          $ref: '#/components/schemas/AuditLogActorApiKey'
      description: The actor who performed the audit logged action.
    AuditLogActorApiKey:
      type: object
      properties:
        id:
          type: string
          description: The tracking id of the API key.
        type:
          enum:
            - user
            - service_account
          type: string
          description: The type of API key. Can be either `user` or `service_account`.
        user:
          $ref: '#/components/schemas/AuditLogActorUser'
        service_account:
          $ref: '#/components/schemas/AuditLogActorServiceAccount'
      description: The API Key used to perform the audit logged action.
    AuditLogActorServiceAccount:
      type: object
      properties:
        id:
          type: string
          description: The service account id.
      description: The service account that performed the audit logged action.
    AuditLogActorSession:
      type: object
      properties:
        user:
          $ref: '#/components/schemas/AuditLogActorUser'
        ip_address:
          type: string
          description: The IP address from which the action was performed.
      description: The session in which the audit logged action was performed.
    AuditLogActorUser:
      type: object
      properties:
        id:
          type: string
          description: The user id.
        email:
          type: string
          description: The user email.
      description: The user who performed the audit logged action.
    AuditLogEventType:
      enum:
        - api_key.created
        - api_key.updated
        - api_key.deleted
        - invite.sent
        - invite.accepted
        - invite.deleted
        - login.succeeded
        - login.failed
        - logout.succeeded
        - logout.failed
        - organization.updated
        - project.created
        - project.updated
        - project.archived
        - service_account.created
        - service_account.updated
        - service_account.deleted
        - rate_limit.updated
        - rate_limit.deleted
        - user.added
        - user.updated
        - user.deleted
      type: string
      description: The event type.
      x-oaiExpandable: true
    AutoChunkingStrategyRequestParam:
      title: Auto Chunking Strategy
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - auto
          type: string
          description: Always `auto`.
      additionalProperties: false
      description: The default strategy. This strategy currently uses a `max_chunk_size_tokens` of `800` and `chunk_overlap_tokens` of `400`.
    Batch:
      required:
        - id
        - object
        - endpoint
        - input_file_id
        - completion_window
        - status
        - created_at
      type: object
      properties:
        id:
          type: string
        object:
          enum:
            - batch
          type: string
          description: 'The object type, which is always `batch`.'
        endpoint:
          type: string
          description: The OpenAI API endpoint used by the batch.
        errors:
          type: object
          properties:
            object:
              type: string
              description: 'The object type, which is always `list`.'
            data:
              type: array
              items:
                type: object
                properties:
                  code:
                    type: string
                    description: An error code identifying the error type.
                  message:
                    type: string
                    description: A human-readable message providing more details about the error.
                  param:
                    type: string
                    description: 'The name of the parameter that caused the error, if applicable.'
                    nullable: true
                  line:
                    type: integer
                    description: 'The line number of the input file where the error occurred, if applicable.'
                    nullable: true
        input_file_id:
          type: string
          description: The ID of the input file for the batch.
        completion_window:
          type: string
          description: The time frame within which the batch should be processed.
        status:
          enum:
            - validating
            - failed
            - in_progress
            - finalizing
            - completed
            - expired
            - cancelling
            - cancelled
          type: string
          description: The current status of the batch.
        output_file_id:
          type: string
          description: The ID of the file containing the outputs of successfully executed requests.
        error_file_id:
          type: string
          description: The ID of the file containing the outputs of requests with errors.
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch was created.
        in_progress_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch started processing.
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch will expire.
        finalizing_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch started finalizing.
        completed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch was completed.
        failed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch failed.
        expired_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch expired.
        cancelling_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch started cancelling.
        cancelled_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch was cancelled.
        request_counts:
          required:
            - total
            - completed
            - failed
          type: object
          properties:
            total:
              type: integer
              description: Total number of requests in the batch.
            completed:
              type: integer
              description: Number of requests that have been completed successfully.
            failed:
              type: integer
              description: Number of requests that have failed.
          description: The request counts for different statuses within the batch.
        metadata:
          type: object
          description: "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
          nullable: true
          x-oaiTypeLabel: map
      x-oaiMeta:
        name: The batch object
        example: "{\n  \"id\": \"batch_abc123\",\n  \"object\": \"batch\",\n  \"endpoint\": \"/v1/completions\",\n  \"errors\": null,\n  \"input_file_id\": \"file-abc123\",\n  \"completion_window\": \"24h\",\n  \"status\": \"completed\",\n  \"output_file_id\": \"file-cvaTdG\",\n  \"error_file_id\": \"file-HOWS94\",\n  \"created_at\": 1711471533,\n  \"in_progress_at\": 1711471538,\n  \"expires_at\": 1711557933,\n  \"finalizing_at\": 1711493133,\n  \"completed_at\": 1711493163,\n  \"failed_at\": null,\n  \"expired_at\": null,\n  \"cancelling_at\": null,\n  \"cancelled_at\": null,\n  \"request_counts\": {\n    \"total\": 100,\n    \"completed\": 95,\n    \"failed\": 5\n  },\n  \"metadata\": {\n    \"customer_id\": \"user_123456789\",\n    \"batch_description\": \"Nightly eval job\",\n  }\n}\n"
    BatchRequestInput:
      type: object
      properties:
        custom_id:
          type: string
          description: A developer-provided per-request id that will be used to match outputs to inputs. Must be unique for each request in a batch.
        method:
          enum:
            - POST
          type: string
          description: The HTTP method to be used for the request. Currently only `POST` is supported.
        url:
          type: string
          description: 'The OpenAI API relative URL to be used for the request. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported.'
      description: The per-line object of the batch input file
      x-oaiMeta:
        name: The request input object
        example: "{\"custom_id\": \"request-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4o-mini\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"What is 2+2?\"}]}}\n"
    BatchRequestOutput:
      type: object
      properties:
        id:
          type: string
        custom_id:
          type: string
          description: A developer-provided per-request id that will be used to match outputs to inputs.
        response:
          type: object
          properties:
            status_code:
              type: integer
              description: The HTTP status code of the response
            request_id:
              type: string
              description: An unique identifier for the OpenAI API request. Please include this request ID when contacting support.
            body:
              type: object
              description: The JSON body of the response
              x-oaiTypeLabel: map
          nullable: true
        error:
          type: object
          properties:
            code:
              type: string
              description: A machine-readable error code.
            message:
              type: string
              description: A human-readable error message.
          description: 'For requests that failed with a non-HTTP error, this will contain more information on the cause of the failure.'
          nullable: true
      description: The per-line object of the batch output and error files
      x-oaiMeta:
        name: The request output object
        example: "{\"id\": \"batch_req_wnaDys\", \"custom_id\": \"request-2\", \"response\": {\"status_code\": 200, \"request_id\": \"req_c187b3\", \"body\": {\"id\": \"chatcmpl-9758Iw\", \"object\": \"chat.completion\", \"created\": 1711475054, \"model\": \"gpt-4o-mini\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"2 + 2 equals 4.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 24, \"completion_tokens\": 15, \"total_tokens\": 39}, \"system_fingerprint\": null}}, \"error\": null}\n"
    CancelUploadRequest:
      type: object
      additionalProperties: false
    ChatCompletionFunctionCallOption:
      required:
        - name
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call.
      description: "Specifying a particular function via `{\"name\": \"my_function\"}` forces the model to call that function.\n"
    ChatCompletionFunctions:
      required:
        - name
      type: object
      properties:
        description:
          type: string
          description: 'A description of what the function does, used by the model to choose when and how to call the function.'
        name:
          type: string
          description: 'The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'
        parameters:
          $ref: '#/components/schemas/FunctionParameters'
      deprecated: true
    ChatCompletionMessageToolCall:
      required:
        - id
        - type
        - function
      type: object
      properties:
        id:
          type: string
          description: The ID of the tool call.
        type:
          enum:
            - function
          type: string
          description: 'The type of the tool. Currently, only `function` is supported.'
        function:
          required:
            - name
            - arguments
          type: object
          properties:
            name:
              type: string
              description: The name of the function to call.
            arguments:
              type: string
              description: 'The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.'
          description: The function that the model called.
    ChatCompletionMessageToolCallChunk:
      required:
        - index
      type: object
      properties:
        index:
          type: integer
        id:
          type: string
          description: The ID of the tool call.
        type:
          enum:
            - function
          type: string
          description: 'The type of the tool. Currently, only `function` is supported.'
        function:
          type: object
          properties:
            name:
              type: string
              description: The name of the function to call.
            arguments:
              type: string
              description: 'The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.'
    ChatCompletionMessageToolCalls:
      type: array
      items:
        $ref: '#/components/schemas/ChatCompletionMessageToolCall'
      description: 'The tool calls generated by the model, such as function calls.'
    ChatCompletionModalities:
      type: array
      items:
        enum:
          - text
          - audio
        type: string
      description: "Output types that you would like the model to generate for this request.\nMost models are capable of generating text, which is the default:\n\n`[\"text\"]`\n\nThe `gpt-4o-audio-preview` model can also be used to [generate audio](/docs/guides/audio). To\nrequest that this model generate both text and audio responses, you can\nuse:\n\n`[\"text\", \"audio\"]`\n"
      nullable: true
    ChatCompletionNamedToolChoice:
      required:
        - type
        - function
      type: object
      properties:
        type:
          enum:
            - function
          type: string
          description: 'The type of the tool. Currently, only `function` is supported.'
        function:
          required:
            - name
          type: object
          properties:
            name:
              type: string
              description: The name of the function to call.
      description: Specifies a tool the model should use. Use to force the model to call a specific function.
    ChatCompletionRequestAssistantMessage:
      title: Assistant message
      required:
        - role
      type: object
      properties:
        content:
          oneOf:
            - title: Text content
              type: string
              description: The contents of the assistant message.
            - title: Array of content parts
              minItems: 1
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionRequestAssistantMessageContentPart'
              description: 'An array of content parts with a defined type. Can be one or more of type `text`, or exactly one of type `refusal`.'
          description: "The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified.\n"
          nullable: true
          x-oaiExpandable: true
        refusal:
          type: string
          description: The refusal message by the assistant.
          nullable: true
        role:
          enum:
            - assistant
          type: string
          description: 'The role of the messages author, in this case `assistant`.'
        name:
          type: string
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
        audio:
          required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "Unique identifier for a previous audio response from the model.\n"
          description: "Data about a previous audio response from the model. \n[Learn more](/docs/guides/audio).\n"
          nullable: true
          x-oaiExpandable: true
        tool_calls:
          $ref: '#/components/schemas/ChatCompletionMessageToolCalls'
        function_call:
          required:
            - arguments
            - name
          type: object
          properties:
            arguments:
              type: string
              description: 'The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.'
            name:
              type: string
              description: The name of the function to call.
          description: 'Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model.'
          nullable: true
          deprecated: true
    ChatCompletionRequestAssistantMessageContentPart:
      oneOf:
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartRefusal'
      x-oaiExpandable: true
    ChatCompletionRequestFunctionMessage:
      title: Function message
      required:
        - role
        - content
        - name
      type: object
      properties:
        role:
          enum:
            - function
          type: string
          description: 'The role of the messages author, in this case `function`.'
        content:
          type: string
          description: The contents of the function message.
          nullable: true
        name:
          type: string
          description: The name of the function to call.
      deprecated: true
    ChatCompletionRequestMessage:
      oneOf:
        - $ref: '#/components/schemas/ChatCompletionRequestSystemMessage'
        - $ref: '#/components/schemas/ChatCompletionRequestUserMessage'
        - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage'
        - $ref: '#/components/schemas/ChatCompletionRequestToolMessage'
        - $ref: '#/components/schemas/ChatCompletionRequestFunctionMessage'
      x-oaiExpandable: true
    ChatCompletionRequestMessageContentPartAudio:
      title: Audio content part
      required:
        - type
        - input_audio
      type: object
      properties:
        type:
          enum:
            - input_audio
          type: string
          description: The type of the content part. Always `input_audio`.
        input_audio:
          required:
            - data
            - format
          type: object
          properties:
            data:
              type: string
              description: Base64 encoded audio data.
            format:
              enum:
                - wav
                - mp3
              type: string
              description: "The format of the encoded audio data. Currently supports \"wav\" and \"mp3\".\n"
      description: "Learn about [audio inputs](/docs/guides/audio).\n"
    ChatCompletionRequestMessageContentPartImage:
      title: Image content part
      required:
        - type
        - image_url
      type: object
      properties:
        type:
          enum:
            - image_url
          type: string
          description: The type of the content part.
        image_url:
          required:
            - url
          type: object
          properties:
            url:
              type: string
              description: Either a URL of the image or the base64 encoded image data.
              format: uri
            detail:
              enum:
                - auto
                - low
                - high
              type: string
              description: 'Specifies the detail level of the image. Learn more in the [Vision guide](/docs/guides/vision#low-or-high-fidelity-image-understanding).'
              default: auto
      description: "Learn about [image inputs](/docs/guides/vision).\n"
    ChatCompletionRequestMessageContentPartRefusal:
      title: Refusal content part
      required:
        - type
        - refusal
      type: object
      properties:
        type:
          enum:
            - refusal
          type: string
          description: The type of the content part.
        refusal:
          type: string
          description: The refusal message generated by the model.
    ChatCompletionRequestMessageContentPartText:
      title: Text content part
      required:
        - type
        - text
      type: object
      properties:
        type:
          enum:
            - text
          type: string
          description: The type of the content part.
        text:
          type: string
          description: The text content.
      description: "Learn about [text inputs](/docs/guides/text-generation).\n"
    ChatCompletionRequestSystemMessage:
      title: System message
      required:
        - content
        - role
      type: object
      properties:
        content:
          oneOf:
            - title: Text content
              type: string
              description: The contents of the system message.
            - title: Array of content parts
              minItems: 1
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionRequestSystemMessageContentPart'
              description: 'An array of content parts with a defined type. For system messages, only type `text` is supported.'
          description: The contents of the system message.
        role:
          enum:
            - system
          type: string
          description: 'The role of the messages author, in this case `system`.'
        name:
          type: string
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
    ChatCompletionRequestSystemMessageContentPart:
      oneOf:
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
      x-oaiExpandable: true
    ChatCompletionRequestToolMessage:
      title: Tool message
      required:
        - role
        - content
        - tool_call_id
      type: object
      properties:
        role:
          enum:
            - tool
          type: string
          description: 'The role of the messages author, in this case `tool`.'
        content:
          oneOf:
            - title: Text content
              type: string
              description: The contents of the tool message.
            - title: Array of content parts
              minItems: 1
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionRequestToolMessageContentPart'
              description: 'An array of content parts with a defined type. For tool messages, only type `text` is supported.'
          description: The contents of the tool message.
        tool_call_id:
          type: string
          description: Tool call that this message is responding to.
    ChatCompletionRequestToolMessageContentPart:
      oneOf:
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
      x-oaiExpandable: true
    ChatCompletionRequestUserMessage:
      title: User message
      required:
        - content
        - role
      type: object
      properties:
        content:
          oneOf:
            - title: Text content
              type: string
              description: The text contents of the message.
            - title: Array of content parts
              minItems: 1
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionRequestUserMessageContentPart'
              description: 'An array of content parts with a defined type. Supported options differ based on the [model](/docs/models) being used to generate the response. Can contain text, image, or audio inputs.'
          description: "The contents of the user message.\n"
          x-oaiExpandable: true
        role:
          enum:
            - user
          type: string
          description: 'The role of the messages author, in this case `user`.'
        name:
          type: string
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
    ChatCompletionRequestUserMessageContentPart:
      oneOf:
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartImage'
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartAudio'
      x-oaiExpandable: true
    ChatCompletionResponseMessage:
      required:
        - role
      type: object
      properties:
        content:
          type: string
          description: The contents of the message.
          nullable: true
        refusal:
          type: string
          description: The refusal message generated by the model.
          nullable: true
        tool_calls:
          $ref: '#/components/schemas/ChatCompletionMessageToolCalls'
        role:
          enum:
            - assistant
          type: string
          description: The role of the author of this message.
        function_call:
          required:
            - name
            - arguments
          type: object
          properties:
            arguments:
              type: string
              description: 'The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.'
            name:
              type: string
              description: The name of the function to call.
          description: 'Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model.'
          deprecated: true
        audio:
          required:
            - id
            - expires_at
            - data
            - transcript
          type: object
          properties:
            id:
              type: string
              description: Unique identifier for this audio response.
            expires_at:
              type: integer
              description: "The Unix timestamp (in seconds) for when this audio response will\nno longer be accessible on the server for use in multi-turn\nconversations.\n"
            data:
              type: string
              description: "Base64 encoded audio bytes generated by the model, in the format\nspecified in the request.\n"
            transcript:
              type: string
              description: Transcript of the audio generated by the model.
          description: "If the audio output modality is requested, this object contains data\nabout the audio response from the model. [Learn more](/docs/guides/audio).\n"
          nullable: true
          x-oaiExpandable: true
      description: A chat completion message generated by the model.
    ChatCompletionRole:
      enum:
        - system
        - user
        - assistant
        - tool
        - function
      type: string
      description: The role of the author of a message
    ChatCompletionStreamOptions:
      type: object
      properties:
        include_usage:
          type: boolean
          description: "If set, an additional chunk will be streamed before the `data: [DONE]` message. The `usage` field on this chunk shows the token usage statistics for the entire request, and the `choices` field will always be an empty array. All other chunks will also include a `usage` field, but with a null value.\n"
      description: "Options for streaming response. Only set this when you set `stream: true`.\n"
      default: 
      nullable: true
    ChatCompletionStreamResponseDelta:
      type: object
      properties:
        content:
          type: string
          description: The contents of the chunk message.
          nullable: true
        function_call:
          type: object
          properties:
            arguments:
              type: string
              description: 'The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.'
            name:
              type: string
              description: The name of the function to call.
          description: 'Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model.'
          deprecated: true
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionMessageToolCallChunk'
        role:
          enum:
            - system
            - user
            - assistant
            - tool
          type: string
          description: The role of the author of this message.
        refusal:
          type: string
          description: The refusal message generated by the model.
          nullable: true
      description: A chat completion delta generated by streamed model responses.
    ChatCompletionTokenLogprob:
      required:
        - token
        - logprob
        - bytes
        - top_logprobs
      type: object
      properties:
        token:
          type: string
          description: The token.
        logprob:
          type: number
          description: 'The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely.'
        bytes:
          type: array
          items:
            type: integer
          description: A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
          nullable: true
        top_logprobs:
          type: array
          items:
            required:
              - token
              - logprob
              - bytes
            type: object
            properties:
              token:
                type: string
                description: The token.
              logprob:
                type: number
                description: 'The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely.'
              bytes:
                type: array
                items:
                  type: integer
                description: A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
                nullable: true
          description: 'List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number of requested `top_logprobs` returned.'
    ChatCompletionTool:
      required:
        - type
        - function
      type: object
      properties:
        type:
          enum:
            - function
          type: string
          description: 'The type of the tool. Currently, only `function` is supported.'
        function:
          $ref: '#/components/schemas/FunctionObject'
    ChatCompletionToolChoiceOption:
      oneOf:
        - enum:
            - none
            - auto
            - required
          type: string
          description: "`none` means the model will not call any tool and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools.\n"
        - $ref: '#/components/schemas/ChatCompletionNamedToolChoice'
      description: "Controls which (if any) tool is called by the model.\n`none` means the model will not call any tool and instead generates a message.\n`auto` means the model can pick between generating a message or calling one or more tools.\n`required` means the model must call one or more tools.\nSpecifying a particular tool via `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to call that tool.\n\n`none` is the default when no tools are present. `auto` is the default if tools are present.\n"
      x-oaiExpandable: true
    ChunkingStrategyRequestParam:
      type: object
      oneOf:
        - $ref: '#/components/schemas/AutoChunkingStrategyRequestParam'
        - $ref: '#/components/schemas/StaticChunkingStrategyRequestParam'
      description: 'The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.'
      x-oaiExpandable: true
    CompleteUploadRequest:
      required:
        - part_ids
      type: object
      properties:
        part_ids:
          type: array
          items:
            type: string
          description: "The ordered list of Part IDs.\n"
        md5:
          type: string
          description: "The optional md5 checksum for the file contents to verify if the bytes uploaded matches what you expect.\n"
      additionalProperties: false
    CompletionUsage:
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      type: object
      properties:
        completion_tokens:
          type: integer
          description: Number of tokens in the generated completion.
        prompt_tokens:
          type: integer
          description: Number of tokens in the prompt.
        total_tokens:
          type: integer
          description: Total number of tokens used in the request (prompt + completion).
        completion_tokens_details:
          type: object
          properties:
            accepted_prediction_tokens:
              type: integer
              description: "When using Predicted Outputs, the number of tokens in the\nprediction that appeared in the completion.\n"
            audio_tokens:
              type: integer
              description: Audio input tokens generated by the model.
            reasoning_tokens:
              type: integer
              description: Tokens generated by the model for reasoning.
            rejected_prediction_tokens:
              type: integer
              description: "When using Predicted Outputs, the number of tokens in the\nprediction that did not appear in the completion. However, like\nreasoning tokens, these tokens are still counted in the total\ncompletion tokens for purposes of billing, output, and context window\nlimits.\n"
          description: Breakdown of tokens used in a completion.
        prompt_tokens_details:
          type: object
          properties:
            audio_tokens:
              type: integer
              description: Audio input tokens present in the prompt.
            cached_tokens:
              type: integer
              description: Cached tokens present in the prompt.
          description: Breakdown of tokens used in the prompt.
      description: Usage statistics for the completion request.
    CostsResult:
      required:
        - object
        - sessions
      type: object
      properties:
        object:
          enum:
            - organization.costs.result
          type: string
        amount:
          type: object
          properties:
            value:
              type: number
              description: The numeric value of the cost.
            currency:
              type: string
              description: Lowercase ISO-4217 currency e.g. "usd"
          description: The monetary value in its associated currency.
        line_item:
          type: string
          description: 'When `group_by=line_item`, this field provides the line item of the grouped costs result.'
        project_id:
          type: string
          description: 'When `group_by=project_id`, this field provides the project ID of the grouped costs result.'
      description: The aggregated costs details of the specific time bucket.
      x-oaiMeta:
        name: Costs object
        example: "{\n    \"object\": \"orgainzation.costs.result\",\n    \"amount\": {\n      \"value\": 0.06,\n      \"currency\": \"usd\"\n    },\n    \"line_item\": \"Image models\",\n    \"project_id\": \"proj_abc\"\n}\n"
    CreateAssistantRequest:
      required:
        - model
      type: object
      properties:
        model:
          anyOf:
            - type: string
            - enum:
                - gpt-4o
                - gpt-4o-2024-11-20
                - gpt-4o-2024-08-06
                - gpt-4o-2024-05-13
                - gpt-4o-mini
                - gpt-4o-mini-2024-07-18
                - gpt-4-turbo
                - gpt-4-turbo-2024-04-09
                - gpt-4-0125-preview
                - gpt-4-turbo-preview
                - gpt-4-1106-preview
                - gpt-4-vision-preview
                - gpt-4
                - gpt-4-0314
                - gpt-4-0613
                - gpt-4-32k
                - gpt-4-32k-0314
                - gpt-4-32k-0613
                - gpt-3.5-turbo
                - gpt-3.5-turbo-16k
                - gpt-3.5-turbo-0613
                - gpt-3.5-turbo-1106
                - gpt-3.5-turbo-0125
                - gpt-3.5-turbo-16k-0613
              type: string
          description: "ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.\n"
          example: gpt-4o
          x-oaiTypeLabel: string
        name:
          maxLength: 256
          type: string
          description: "The name of the assistant. The maximum length is 256 characters.\n"
          nullable: true
        description:
          maxLength: 512
          type: string
          description: "The description of the assistant. The maximum length is 512 characters.\n"
          nullable: true
        instructions:
          maxLength: 256000
          type: string
          description: "The system instructions that the assistant uses. The maximum length is 256,000 characters.\n"
          nullable: true
        tools:
          maxItems: 128
          type: array
          items:
            oneOf:
              - $ref: '#/components/schemas/AssistantToolsCode'
              - $ref: '#/components/schemas/AssistantToolsFileSearch'
              - $ref: '#/components/schemas/AssistantToolsFunction'
            x-oaiExpandable: true
          description: "A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.\n"
        tool_resources:
          type: object
          properties:
            code_interpreter:
              type: object
              properties:
                file_ids:
                  maxItems: 20
                  type: array
                  items:
                    type: string
                  description: "A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n"
            file_search:
              type: object
              oneOf:
                - required:
                    - vector_store_ids
                - required:
                    - vector_stores
              properties:
                vector_store_ids:
                  maxItems: 1
                  type: array
                  items:
                    type: string
                  description: "The [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.\n"
                vector_stores:
                  maxItems: 1
                  type: array
                  items:
                    type: object
                    properties:
                      file_ids:
                        maxItems: 10000
                        type: array
                        items:
                          type: string
                        description: "A list of [file](/docs/api-reference/files) IDs to add to the vector store. There can be a maximum of 10000 files in a vector store.\n"
                      chunking_strategy:
                        type: object
                        oneOf:
                          - title: Auto Chunking Strategy
                            required:
                              - type
                            type: object
                            properties:
                              type:
                                enum:
                                  - auto
                                type: string
                                description: Always `auto`.
                            additionalProperties: false
                            description: The default strategy. This strategy currently uses a `max_chunk_size_tokens` of `800` and `chunk_overlap_tokens` of `400`.
                          - title: Static Chunking Strategy
                            required:
                              - type
                              - static
                            type: object
                            properties:
                              type:
                                enum:
                                  - static
                                type: string
                                description: Always `static`.
                              static:
                                required:
                                  - max_chunk_size_tokens
                                  - chunk_overlap_tokens
                                type: object
                                properties:
                                  max_chunk_size_tokens:
                                    maximum: 4096
                                    minimum: 100
                                    type: integer
                                    description: The maximum number of tokens in each chunk. The default value is `800`. The minimum value is `100` and the maximum value is `4096`.
                                  chunk_overlap_tokens:
                                    type: integer
                                    description: "The number of tokens that overlap between chunks. The default value is `400`.\n\nNote that the overlap must not exceed half of `max_chunk_size_tokens`.\n"
                                additionalProperties: false
                            additionalProperties: false
                        description: 'The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.'
                        x-oaiExpandable: true
                      metadata:
                        type: object
                        description: "Set of 16 key-value pairs that can be attached to a vector store. This can be useful for storing additional information about the vector store in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
                        x-oaiTypeLabel: map
                  description: "A helper to create a [vector store](/docs/api-reference/vector-stores/object) with file_ids and attach it to this assistant. There can be a maximum of 1 vector store attached to the assistant.\n"
          description: "A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n"
          nullable: true
        metadata:
          type: object
          description: "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
          nullable: true
          x-oaiTypeLabel: map
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n"
          default: 1
          nullable: true
          example: 1
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n"
          default: 1
          nullable: true
          example: 1
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
      additionalProperties: false
    CreateChatCompletionFunctionResponse:
      required:
        - choices
        - created
        - id
        - model
        - object
      type: object
      properties:
        id:
          type: string
          description: A unique identifier for the chat completion.
        choices:
          type: array
          items:
            required:
              - finish_reason
              - index
              - message
              - logprobs
            type: object
            properties:
              finish_reason:
                enum:
                  - stop
                  - length
                  - function_call
                  - content_filter
                type: string
                description: "The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence, `length` if the maximum number of tokens specified in the request was reached, `content_filter` if content was omitted due to a flag from our content filters, or `function_call` if the model called a function.\n"
              index:
                type: integer
                description: The index of the choice in the list of choices.
              message:
                $ref: '#/components/schemas/ChatCompletionResponseMessage'
          description: A list of chat completion choices. Can be more than one if `n` is greater than 1.
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion was created.
        model:
          type: string
          description: The model used for the chat completion.
        system_fingerprint:
          type: string
          description: "This fingerprint represents the backend configuration that the model runs with.\n\nCan be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.\n"
        object:
          enum:
            - chat.completion
          type: string
          description: 'The object type, which is always `chat.completion`.'
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      description: 'Represents a chat completion response returned by model, based on the provided input.'
      x-oaiMeta:
        name: The chat completion object
        group: chat
        example: "{\n  \"id\": \"chatcmpl-abc123\",\n  \"object\": \"chat.completion\",\n  \"created\": 1699896916,\n  \"model\": \"gpt-4o-mini\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": null,\n        \"tool_calls\": [\n          {\n            \"id\": \"call_abc123\",\n            \"type\": \"function\",\n            \"function\": {\n              \"name\": \"get_current_weather\",\n              \"arguments\": \"{\\n\\\"location\\\": \\\"Boston, MA\\\"\\n}\"\n            }\n          }\n        ]\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"tool_calls\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 82,\n    \"completion_tokens\": 17,\n    \"total_tokens\": 99,\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\": 0,\n      \"accepted_prediction_tokens\": 0,\n      \"rejected_prediction_tokens\": 0\n    }\n  }\n}\n"
    CreateChatCompletionImageResponse:
      type: object
      description: 'Represents a streamed chunk of a chat completion response returned by model, based on the provided input.'
      x-oaiMeta:
        name: The chat completion chunk object
        group: chat
        example: "{\n  \"id\": \"chatcmpl-123\",\n  \"object\": \"chat.completion\",\n  \"created\": 1677652288,\n  \"model\": \"gpt-4o-mini\",\n  \"system_fingerprint\": \"fp_44709d6fcb\",\n  \"choices\": [{\n    \"index\": 0,\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"\\n\\nThis image shows a wooden boardwalk extending through a lush green marshland.\",\n    },\n    \"logprobs\": null,\n    \"finish_reason\": \"stop\"\n  }],\n  \"usage\": {\n    \"prompt_tokens\": 9,\n    \"completion_tokens\": 12,\n    \"total_tokens\": 21,\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\": 0,\n      \"accepted_prediction_tokens\": 0,\n      \"rejected_prediction_tokens\": 0\n    }\n  }\n}\n"
    CreateChatCompletionRequest:
      required:
        - model
        - messages
      type: object
      properties:
        messages:
          minItems: 1
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionRequestMessage'
          description: "A list of messages comprising the conversation so far. Depending on the\n[model](/docs/models) you use, different message types (modalities) are\nsupported, like [text](/docs/guides/text-generation),\n[images](/docs/guides/vision), and [audio](/docs/guides/audio).\n"
        model:
          anyOf:
            - type: string
            - enum:
                - o1-preview
                - o1-preview-2024-09-12
                - o1-mini
                - o1-mini-2024-09-12
                - gpt-4o
                - gpt-4o-2024-11-20
                - gpt-4o-2024-08-06
                - gpt-4o-2024-05-13
                - gpt-4o-realtime-preview
                - gpt-4o-realtime-preview-2024-10-01
                - gpt-4o-audio-preview
                - gpt-4o-audio-preview-2024-10-01
                - chatgpt-4o-latest
                - gpt-4o-mini
                - gpt-4o-mini-2024-07-18
                - gpt-4-turbo
                - gpt-4-turbo-2024-04-09
                - gpt-4-0125-preview
                - gpt-4-turbo-preview
                - gpt-4-1106-preview
                - gpt-4-vision-preview
                - gpt-4
                - gpt-4-0314
                - gpt-4-0613
                - gpt-4-32k
                - gpt-4-32k-0314
                - gpt-4-32k-0613
                - gpt-3.5-turbo
                - gpt-3.5-turbo-16k
                - gpt-3.5-turbo-0301
                - gpt-3.5-turbo-0613
                - gpt-3.5-turbo-1106
                - gpt-3.5-turbo-0125
                - gpt-3.5-turbo-16k-0613
              type: string
          description: 'ID of the model to use. See the [model endpoint compatibility](/docs/models#model-endpoint-compatibility) table for details on which models work with the Chat API.'
          example: gpt-4o
          x-oaiTypeLabel: string
        store:
          type: boolean
          description: "Whether or not to store the output of this chat completion request\nfor use in our [model distillation](/docs/guides/distillation) or [evals](/docs/guides/evals) products.\n"
          default: false
          nullable: true
        metadata:
          type: object
          additionalProperties:
            type: string
          description: "Developer-defined tags and values used for filtering completions\nin the [dashboard](https://platform.openai.com/chat-completions).\n"
          nullable: true
        frequency_penalty:
          maximum: 2
          minimum: -2
          type: number
          description: "Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\n\n[See more information about frequency and presence penalties.](/docs/guides/text-generation)\n"
          default: 0
          nullable: true
        logit_bias:
          type: object
          additionalProperties:
            type: integer
          description: "Modify the likelihood of specified tokens appearing in the completion.\n\nAccepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.\n"
          default: 
          nullable: true
          x-oaiTypeLabel: map
        logprobs:
          type: boolean
          description: 'Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`.'
          default: false
          nullable: true
        top_logprobs:
          maximum: 20
          minimum: 0
          type: integer
          description: 'An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.'
          nullable: true
        max_tokens:
          type: integer
          description: "The maximum number of [tokens](/tokenizer) that can be generated in the chat completion. This value can be used to control [costs](https://openai.com/api/pricing/) for text generated via API.\n\nThis value is now deprecated in favor of `max_completion_tokens`, and is not compatible with [o1 series models](/docs/guides/reasoning).\n"
          nullable: true
          deprecated: true
        max_completion_tokens:
          type: integer
          description: "An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).\n"
          nullable: true
        n:
          maximum: 128
          minimum: 1
          type: integer
          description: How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.
          default: 1
          nullable: true
          example: 1
        modalities:
          $ref: '#/components/schemas/ChatCompletionModalities'
        prediction:
          oneOf:
            - $ref: '#/components/schemas/PredictionContent'
          description: "Configuration for a [Predicted Output](/docs/guides/predicted-outputs),\nwhich can greatly improve response times when large parts of the model\nresponse are known ahead of time. This is most common when you are\nregenerating a file with only minor changes to most of the content.\n"
          nullable: true
          x-oaiExpandable: true
        audio:
          required:
            - voice
            - format
          type: object
          properties:
            voice:
              enum:
                - alloy
                - ash
                - ballad
                - coral
                - echo
                - sage
                - shimmer
                - verse
              type: string
              description: "The voice the model uses to respond. Supported voices are `ash`, `ballad`, `coral`, `sage`, and `verse` (also supported but not recommended are `alloy`, `echo`, and `shimmer`; these voices are less expressive).\n"
            format:
              enum:
                - wav
                - mp3
                - flac
                - opus
                - pcm16
              type: string
              description: "Specifies the output audio format. Must be one of `wav`, `mp3`, `flac`,\n`opus`, or `pcm16`.\n"
          description: "Parameters for audio output. Required when audio output is requested with\n`modalities: [\"audio\"]`. [Learn more](/docs/guides/audio).\n"
          nullable: true
          x-oaiExpandable: true
        presence_penalty:
          maximum: 2
          minimum: -2
          type: number
          description: "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.\n\n[See more information about frequency and presence penalties.](/docs/guides/text-generation)\n"
          default: 0
          nullable: true
        response_format:
          oneOf:
            - $ref: '#/components/schemas/ResponseFormatText'
            - $ref: '#/components/schemas/ResponseFormatJsonObject'
            - $ref: '#/components/schemas/ResponseFormatJsonSchema'
          description: "An object specifying the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4o mini](/docs/models#gpt-4o-mini), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4) and all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.\n\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n"
          x-oaiExpandable: true
        seed:
          maximum: 9223372036854776000
          minimum: -9223372036854776000
          type: integer
          description: "This feature is in Beta.\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.\nDeterminism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.\n"
          nullable: true
          x-oaiMeta:
            beta: true
        service_tier:
          enum:
            - auto
            - default
          type: string
          description: "Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:\n  - If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.\n  - If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.\n  - If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.\n  - When not set, the default behavior is 'auto'.\n\n  When this parameter is set, the response body will include the `service_tier` utilized.\n"
          default: auto
          nullable: true
        stop:
          oneOf:
            - type: string
              nullable: true
            - maxItems: 4
              minItems: 1
              type: array
              items:
                type: string
          description: "Up to 4 sequences where the API will stop generating further tokens.\n"
          default: 
        stream:
          type: boolean
          description: "If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n"
          default: false
          nullable: true
        stream_options:
          $ref: '#/components/schemas/ChatCompletionStreamOptions'
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\nWe generally recommend altering this or `top_p` but not both.\n"
          default: 1
          nullable: true
          example: 1
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or `temperature` but not both.\n"
          default: 1
          nullable: true
          example: 1
        tools:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionTool'
          description: "A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.\n"
        tool_choice:
          $ref: '#/components/schemas/ChatCompletionToolChoiceOption'
        parallel_tool_calls:
          $ref: '#/components/schemas/ParallelToolCalls'
        user:
          type: string
          description: "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).\n"
          example: user-1234
        function_call:
          oneOf:
            - enum:
                - none
                - auto
              type: string
              description: "`none` means the model will not call a function and instead generates a message. `auto` means the model can pick between generating a message or calling a function.\n"
            - $ref: '#/components/schemas/ChatCompletionFunctionCallOption'
          description: "Deprecated in favor of `tool_choice`.\n\nControls which (if any) function is called by the model.\n`none` means the model will not call a function and instead generates a message.\n`auto` means the model can pick between generating a message or calling a function.\nSpecifying a particular function via `{\"name\": \"my_function\"}` forces the model to call that function.\n\n`none` is the default when no functions are present. `auto` is the default if functions are present.\n"
          deprecated: true
          x-oaiExpandable: true
        functions:
          maxItems: 128
          minItems: 1
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionFunctions'
          description: "Deprecated in favor of `tools`.\n\nA list of functions the model may generate JSON inputs for.\n"
          deprecated: true
    CreateChatCompletionResponse:
      required:
        - choices
        - created
        - id
        - model
        - object
      type: object
      properties:
        id:
          type: string
          description: A unique identifier for the chat completion.
        choices:
          type: array
          items:
            required:
              - finish_reason
              - index
              - message
            type: object
            properties:
              finish_reason:
                enum:
                  - stop
                  - length
                  - tool_calls
                  - content_filter
                  - function_call
                type: string
                description: "The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,\n`length` if the maximum number of tokens specified in the request was reached,\n`content_filter` if content was omitted due to a flag from our content filters,\n`tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.\n"
              index:
                type: integer
                description: The index of the choice in the list of choices.
              message:
                $ref: '#/components/schemas/ChatCompletionResponseMessage'
              logprobs:
                required:
                  - content
                  - refusal
                type: object
                properties:
                  content:
                    type: array
                    items:
                      $ref: '#/components/schemas/ChatCompletionTokenLogprob'
                    description: A list of message content tokens with log probability information.
                    nullable: true
                  refusal:
                    type: array
                    items:
                      $ref: '#/components/schemas/ChatCompletionTokenLogprob'
                    description: A list of message refusal tokens with log probability information.
                    nullable: true
                description: Log probability information for the choice.
                nullable: true
          description: A list of chat completion choices. Can be more than one if `n` is greater than 1.
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion was created.
        model:
          type: string
          description: The model used for the chat completion.
        service_tier:
          enum:
            - scale
            - default
          type: string
          description: The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.
          nullable: true
          example: scale
        system_fingerprint:
          type: string
          description: "This fingerprint represents the backend configuration that the model runs with.\n\nCan be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.\n"
        object:
          enum:
            - chat.completion
          type: string
          description: 'The object type, which is always `chat.completion`.'
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      description: 'Represents a chat completion response returned by model, based on the provided input.'
      x-oaiMeta:
        name: The chat completion object
        group: chat
        example: "{\n  \"id\": \"chatcmpl-123456\",\n  \"object\": \"chat.completion\",\n  \"created\": 1728933352,\n  \"model\": \"gpt-4o-2024-08-06\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"Hi there! How can I assist you today?\",\n        \"refusal\": null\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 19,\n    \"completion_tokens\": 10,\n    \"total_tokens\": 29,\n    \"prompt_tokens_details\": {\n      \"cached_tokens\": 0\n    },\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\": 0,\n      \"accepted_prediction_tokens\": 0,\n      \"rejected_prediction_tokens\": 0\n    }\n  },\n  \"system_fingerprint\": \"fp_6b68a8204b\"\n}\n"
    CreateChatCompletionStreamResponse:
      required:
        - choices
        - created
        - id
        - model
        - object
      type: object
      properties:
        id:
          type: string
          description: A unique identifier for the chat completion. Each chunk has the same ID.
        choices:
          type: array
          items:
            required:
              - delta
              - finish_reason
              - index
            type: object
            properties:
              delta:
                $ref: '#/components/schemas/ChatCompletionStreamResponseDelta'
              logprobs:
                required:
                  - content
                  - refusal
                type: object
                properties:
                  content:
                    type: array
                    items:
                      $ref: '#/components/schemas/ChatCompletionTokenLogprob'
                    description: A list of message content tokens with log probability information.
                    nullable: true
                  refusal:
                    type: array
                    items:
                      $ref: '#/components/schemas/ChatCompletionTokenLogprob'
                    description: A list of message refusal tokens with log probability information.
                    nullable: true
                description: Log probability information for the choice.
                nullable: true
              finish_reason:
                enum:
                  - stop
                  - length
                  - tool_calls
                  - content_filter
                  - function_call
                type: string
                description: "The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,\n`length` if the maximum number of tokens specified in the request was reached,\n`content_filter` if content was omitted due to a flag from our content filters,\n`tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.\n"
                nullable: true
              index:
                type: integer
                description: The index of the choice in the list of choices.
          description: "A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the\nlast chunk if you set `stream_options: {\"include_usage\": true}`.\n"
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.
        model:
          type: string
          description: The model to generate the completion.
        service_tier:
          enum:
            - scale
            - default
          type: string
          description: The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.
          nullable: true
          example: scale
        system_fingerprint:
          type: string
          description: "This fingerprint represents the backend configuration that the model runs with.\nCan be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.\n"
        object:
          enum:
            - chat.completion.chunk
          type: string
          description: 'The object type, which is always `chat.completion.chunk`.'
        usage:
          required:
            - prompt_tokens
            - completion_tokens
            - total_tokens
          type: object
          properties:
            completion_tokens:
              type: integer
              description: Number of tokens in the generated completion.
            prompt_tokens:
              type: integer
              description: Number of tokens in the prompt.
            total_tokens:
              type: integer
              description: Total number of tokens used in the request (prompt + completion).
          description: "An optional field that will only be present when you set `stream_options: {\"include_usage\": true}` in your request.\nWhen present, it contains a null value except for the last chunk which contains the token usage statistics for the entire request.\n"
          nullable: true
      description: 'Represents a streamed chunk of a chat completion response returned by model, based on the provided input.'
      x-oaiMeta:
        name: The chat completion chunk object
        group: chat
        example: "{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-4o-mini\", \"system_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\"},\"logprobs\":null,\"finish_reason\":null}]}\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-4o-mini\", \"system_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{\"content\":\"Hello\"},\"logprobs\":null,\"finish_reason\":null}]}\n\n....\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-4o-mini\", \"system_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{},\"logprobs\":null,\"finish_reason\":\"stop\"}]}\n"
    CreateCompletionRequest:
      required:
        - model
        - prompt
      type: object
      properties:
        model:
          anyOf:
            - type: string
            - enum:
                - gpt-3.5-turbo-instruct
                - davinci-002
                - babbage-002
              type: string
          description: "ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.\n"
          x-oaiTypeLabel: string
        prompt:
          oneOf:
            - type: string
              default: ''
              example: This is a test.
            - type: array
              items:
                type: string
                default: ''
                example: This is a test.
            - minItems: 1
              type: array
              items:
                type: integer
              example: '[1212, 318, 257, 1332, 13]'
            - minItems: 1
              type: array
              items:
                minItems: 1
                type: array
                items:
                  type: integer
              example: '[[1212, 318, 257, 1332, 13]]'
          description: "The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.\n\nNote that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.\n"
          default: <|endoftext|>
          nullable: true
        best_of:
          maximum: 20
          minimum: 0
          type: integer
          description: "Generates `best_of` completions server-side and returns the \"best\" (the one with the highest log probability per token). Results cannot be streamed.\n\nWhen used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return – `best_of` must be greater than `n`.\n\n**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.\n"
          default: 1
          nullable: true
        echo:
          type: boolean
          description: "Echo back the prompt in addition to the completion\n"
          default: false
          nullable: true
        frequency_penalty:
          maximum: 2
          minimum: -2
          type: number
          description: "Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\n\n[See more information about frequency and presence penalties.](/docs/guides/text-generation)\n"
          default: 0
          nullable: true
        logit_bias:
          type: object
          additionalProperties:
            type: integer
          description: "Modify the likelihood of specified tokens appearing in the completion.\n\nAccepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.\n\nAs an example, you can pass `{\"50256\": -100}` to prevent the <|endoftext|> token from being generated.\n"
          default: 
          nullable: true
          x-oaiTypeLabel: map
        logprobs:
          maximum: 5
          minimum: 0
          type: integer
          description: "Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.\n\nThe maximum value for `logprobs` is 5.\n"
          default: 
          nullable: true
        max_tokens:
          minimum: 0
          type: integer
          description: "The maximum number of [tokens](/tokenizer) that can be generated in the completion.\n\nThe token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.\n"
          default: 16
          nullable: true
          example: 16
        n:
          maximum: 128
          minimum: 1
          type: integer
          description: "How many completions to generate for each prompt.\n\n**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.\n"
          default: 1
          nullable: true
          example: 1
        presence_penalty:
          maximum: 2
          minimum: -2
          type: number
          description: "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.\n\n[See more information about frequency and presence penalties.](/docs/guides/text-generation)\n"
          default: 0
          nullable: true
        seed:
          maximum: 9223372036854776000
          minimum: -9223372036854776000
          type: integer
          description: "If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.\n\nDeterminism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.\n"
          nullable: true
        stop:
          oneOf:
            - type: string
              default: <|endoftext|>
              nullable: true
              example: "\n"
            - maxItems: 4
              minItems: 1
              type: array
              items:
                type: string
                example: '["\n"]'
          description: "Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.\n"
          default: 
          nullable: true
        stream:
          type: boolean
          description: "Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n"
          default: false
          nullable: true
        stream_options:
          $ref: '#/components/schemas/ChatCompletionStreamOptions'
        suffix:
          type: string
          description: "The suffix that comes after a completion of inserted text.\n\nThis parameter is only supported for `gpt-3.5-turbo-instruct`.\n"
          default: 
          nullable: true
          example: test.
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\nWe generally recommend altering this or `top_p` but not both.\n"
          default: 1
          nullable: true
          example: 1
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or `temperature` but not both.\n"
          default: 1
          nullable: true
          example: 1
        user:
          type: string
          description: "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).\n"
          example: user-1234
    CreateCompletionResponse:
      required:
        - id
        - object
        - created
        - model
        - choices
      type: object
      properties:
        id:
          type: string
          description: A unique identifier for the completion.
        choices:
          type: array
          items:
            required:
              - finish_reason
              - index
              - logprobs
              - text
            type: object
            properties:
              finish_reason:
                enum:
                  - stop
                  - length
                  - content_filter
                type: string
                description: "The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,\n`length` if the maximum number of tokens specified in the request was reached,\nor `content_filter` if content was omitted due to a flag from our content filters.\n"
              index:
                type: integer
              logprobs:
                type: object
                properties:
                  text_offset:
                    type: array
                    items:
                      type: integer
                  token_logprobs:
                    type: array
                    items:
                      type: number
                  tokens:
                    type: array
                    items:
                      type: string
                  top_logprobs:
                    type: array
                    items:
                      type: object
                      additionalProperties:
                        type: number
                nullable: true
              text:
                type: string
          description: The list of completion choices the model generated for the input prompt.
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the completion was created.
        model:
          type: string
          description: The model used for completion.
        system_fingerprint:
          type: string
          description: "This fingerprint represents the backend configuration that the model runs with.\n\nCan be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.\n"
        object:
          enum:
            - text_completion
          type: string
          description: 'The object type, which is always "text_completion"'
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      description: "Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).\n"
      x-oaiMeta:
        name: The completion object
        legacy: true
        example: "{\n  \"id\": \"cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7\",\n  \"object\": \"text_completion\",\n  \"created\": 1589478378,\n  \"model\": \"gpt-4-turbo\",\n  \"choices\": [\n    {\n      \"text\": \"\\n\\nThis is indeed a test\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"finish_reason\": \"length\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 5,\n    \"completion_tokens\": 7,\n    \"total_tokens\": 12\n  }\n}\n"
    CreateEmbeddingRequest:
      required:
        - model
        - input
      type: object
      properties:
        input:
          oneOf:
            - title: string
              type: string
              description: The string that will be turned into an embedding.
              default: ''
              example: This is a test.
            - title: array
              maxItems: 2048
              minItems: 1
              type: array
              items:
                type: string
                default: ''
                example: '[''This is a test.'']'
              description: The array of strings that will be turned into an embedding.
            - title: array
              maxItems: 2048
              minItems: 1
              type: array
              items:
                type: integer
              description: The array of integers that will be turned into an embedding.
              example: '[1212, 318, 257, 1332, 13]'
            - title: array
              maxItems: 2048
              minItems: 1
              type: array
              items:
                minItems: 1
                type: array
                items:
                  type: integer
              description: The array of arrays containing integers that will be turned into an embedding.
              example: '[[1212, 318, 257, 1332, 13]]'
          description: "Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.\n"
          example: The quick brown fox jumped over the lazy dog
          x-oaiExpandable: true
        model:
          anyOf:
            - type: string
            - enum:
                - text-embedding-ada-002
                - text-embedding-3-small
                - text-embedding-3-large
              type: string
          description: "ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.\n"
          example: text-embedding-3-small
          x-oaiTypeLabel: string
        encoding_format:
          enum:
            - float
            - base64
          type: string
          description: 'The format to return the embeddings in. Can be either `float` or [`base64`](https://pypi.org/project/pybase64/).'
          default: float
          example: float
        dimensions:
          minimum: 1
          type: integer
          description: "The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.\n"
          nullable: true
        user:
          type: string
          description: "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).\n"
          example: user-1234
      additionalProperties: false
    CreateEmbeddingResponse:
      required:
        - object
        - model
        - data
        - usage
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/Embedding'
          description: The list of embeddings generated by the model.
        model:
          type: string
          description: The name of the model used to generate the embedding.
        object:
          enum:
            - list
          type: string
          description: 'The object type, which is always "list".'
        usage:
          required:
            - prompt_tokens
            - total_tokens
          type: object
          properties:
            prompt_tokens:
              type: integer
              description: The number of tokens used by the prompt.
            total_tokens:
              type: integer
              description: The total number of tokens used by the request.
          description: The usage information for the request.
    CreateFileRequest:
      required:
        - file
        - purpose
      type: object
      properties:
        file:
          type: string
          description: "The File object (not file name) to be uploaded.\n"
          format: binary
        purpose:
          enum:
            - assistants
            - batch
            - fine-tune
            - vision
          type: string
          description: "The intended purpose of the uploaded file.\n\nUse \"assistants\" for [Assistants](/docs/api-reference/assistants) and [Message](/docs/api-reference/messages) files, \"vision\" for Assistants image file inputs, \"batch\" for [Batch API](/docs/guides/batch), and \"fine-tune\" for [Fine-tuning](/docs/api-reference/fine-tuning).\n"
      additionalProperties: false
    CreateFineTuningJobRequest:
      required:
        - model
        - training_file
      type: object
      properties:
        model:
          anyOf:
            - type: string
            - enum:
                - babbage-002
                - davinci-002
                - gpt-3.5-turbo
                - gpt-4o-mini
              type: string
          description: "The name of the model to fine-tune. You can select one of the\n[supported models](/docs/guides/fine-tuning#which-models-can-be-fine-tuned).\n"
          example: gpt-4o-mini
          x-oaiTypeLabel: string
        training_file:
          type: string
          description: "The ID of an uploaded file that contains training data.\n\nSee [upload file](/docs/api-reference/files/create) for how to upload a file.\n\nYour dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.\n\nThe contents of the file should differ depending on if the model uses the [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) format.\n\nSee the [fine-tuning guide](/docs/guides/fine-tuning) for more details.\n"
          example: file-abc123
        hyperparameters:
          type: object
          properties:
            batch_size:
              oneOf:
                - enum:
                    - auto
                  type: string
                - maximum: 256
                  minimum: 1
                  type: integer
              description: "Number of examples in each batch. A larger batch size means that model parameters\nare updated less frequently, but with lower variance.\n"
              default: auto
            learning_rate_multiplier:
              oneOf:
                - enum:
                    - auto
                  type: string
                - minimum: 0
                  exclusiveMinimum: true
                  type: number
              description: "Scaling factor for the learning rate. A smaller learning rate may be useful to avoid\noverfitting.\n"
              default: auto
            n_epochs:
              oneOf:
                - enum:
                    - auto
                  type: string
                - maximum: 50
                  minimum: 1
                  type: integer
              description: "The number of epochs to train the model for. An epoch refers to one full cycle\nthrough the training dataset.\n"
              default: auto
          description: The hyperparameters used for the fine-tuning job.
        suffix:
          maxLength: 64
          minLength: 1
          type: string
          description: "A string of up to 64 characters that will be added to your fine-tuned model name.\n\nFor example, a `suffix` of \"custom-model-name\" would produce a model name like `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.\n"
          default: 
          nullable: true
        validation_file:
          type: string
          description: "The ID of an uploaded file that contains validation data.\n\nIf you provide this file, the data is used to generate validation\nmetrics periodically during fine-tuning. These metrics can be viewed in\nthe fine-tuning results file.\nThe same data should not be present in both train and validation files.\n\nYour dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.\n\nSee the [fine-tuning guide](/docs/guides/fine-tuning) for more details.\n"
          nullable: true
          example: file-abc123
        integrations:
          type: array
          items:
            required:
              - type
              - wandb
            type: object
            properties:
              type:
                oneOf:
                  - enum:
                      - wandb
                    type: string
                description: "The type of integration to enable. Currently, only \"wandb\" (Weights and Biases) is supported.\n"
              wandb:
                required:
                  - project
                type: object
                properties:
                  project:
                    type: string
                    description: "The name of the project that the new run will be created under.\n"
                    example: my-wandb-project
                  name:
                    type: string
                    description: "A display name to set for the run. If not set, we will use the Job ID as the name.\n"
                    nullable: true
                  entity:
                    type: string
                    description: "The entity to use for the run. This allows you to set the team or username of the WandB user that you would\nlike associated with the run. If not set, the default entity for the registered WandB API key is used.\n"
                    nullable: true
                  tags:
                    type: array
                    items:
                      type: string
                      example: custom-tag
                    description: "A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some\ndefault tags are generated by OpenAI: \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n"
                description: "The settings for your integration with Weights and Biases. This payload specifies the project that\nmetrics will be sent to. Optionally, you can set an explicit display name for your run, add tags\nto your run, and set a default entity (team, username, etc) to be associated with your run.\n"
          description: A list of integrations to enable for your fine-tuning job.
          nullable: true
        seed:
          maximum: 2147483647
          minimum: 0
          type: integer
          description: "The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.\nIf a seed is not specified, one will be generated for you.\n"
          nullable: true
          example: 42
    CreateImageEditRequest:
      required:
        - prompt
        - image
      type: object
      properties:
        image:
          type: string
          description: 'The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.'
          format: binary
        prompt:
          type: string
          description: A text description of the desired image(s). The maximum length is 1000 characters.
          example: A cute baby sea otter wearing a beret
        mask:
          type: string
          description: 'An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.'
          format: binary
        model:
          anyOf:
            - type: string
            - enum:
                - dall-e-2
              type: string
          description: The model to use for image generation. Only `dall-e-2` is supported at this time.
          default: dall-e-2
          nullable: true
          example: dall-e-2
          x-oaiTypeLabel: string
        n:
          maximum: 10
          minimum: 1
          type: integer
          description: The number of images to generate. Must be between 1 and 10.
          default: 1
          nullable: true
          example: 1
        size:
          enum:
            - 256x256
            - 512x512
            - 1024x1024
          type: string
          description: 'The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.'
          default: 1024x1024
          nullable: true
          example: 1024x1024
        response_format:
          enum:
            - url
            - b64_json
          type: string
          description: The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.
          default: url
          nullable: true
          example: url
        user:
          type: string
          description: "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).\n"
          example: user-1234
    CreateImageRequest:
      required:
        - prompt
      type: object
      properties:
        prompt:
          type: string
          description: A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.
          example: A cute baby sea otter
        model:
          anyOf:
            - type: string
            - enum:
                - dall-e-2
                - dall-e-3
              type: string
          description: The model to use for image generation.
          default: dall-e-2
          nullable: true
          example: dall-e-3
          x-oaiTypeLabel: string
        n:
          maximum: 10
          minimum: 1
          type: integer
          description: 'The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.'
          default: 1
          nullable: true
          example: 1
        quality:
          enum:
            - standard
            - hd
          type: string
          description: The quality of the image that will be generated. `hd` creates images with finer details and greater consistency across the image. This param is only supported for `dall-e-3`.
          default: standard
          example: standard
        response_format:
          enum:
            - url
            - b64_json
          type: string
          description: The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.
          default: url
          nullable: true
          example: url
        size:
          enum:
            - 256x256
            - 512x512
            - 1024x1024
            - 1792x1024
            - 1024x1792
          type: string
          description: 'The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3` models.'
          default: 1024x1024
          nullable: true
          example: 1024x1024
        style:
          enum:
            - vivid
            - natural
          type: string
          description: 'The style of the generated images. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This param is only supported for `dall-e-3`.'
          default: vivid
          nullable: true
          example: vivid
        user:
          type: string
          description: "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).\n"
          example: user-1234
    CreateImageVariationRequest:
      required:
        - image
      type: object
      properties:
        image:
          type: string
          description: 'The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.'
          format: binary
        model:
          anyOf:
            - type: string
            - enum:
                - dall-e-2
              type: string
          description: The model to use for image generation. Only `dall-e-2` is supported at this time.
          default: dall-e-2
          nullable: true
          example: dall-e-2
          x-oaiTypeLabel: string
        n:
          maximum: 10
          minimum: 1
          type: integer
          description: 'The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.'
          default: 1
          nullable: true
          example: 1
        response_format:
          enum:
            - url
            - b64_json
          type: string
          description: The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.
          default: url
          nullable: true
          example: url
        size:
          enum:
            - 256x256
            - 512x512
            - 1024x1024
          type: string
          description: 'The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.'
          default: 1024x1024
          nullable: true
          example: 1024x1024
        user:
          type: string
          description: "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).\n"
          example: user-1234
    CreateMessageRequest:
      required:
        - role
        - content
      type: object
      properties:
        role:
          enum:
            - user
            - assistant
          type: string
          description: "The role of the entity that is creating the message. Allowed values include:\n- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.\n- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.\n"
        content:
          oneOf:
            - title: Text content
              type: string
              description: The text contents of the message.
            - title: Array of content parts
              minItems: 1
              type: array
              items:
                oneOf:
                  - $ref: '#/components/schemas/MessageContentImageFileObject'
                  - $ref: '#/components/schemas/MessageContentImageUrlObject'
                  - $ref: '#/components/schemas/MessageRequestContentTextObject'
                x-oaiExpandable: true
              description: 'An array of content parts with a defined type, each can be of type `text` or images can be passed with `image_url` or `image_file`. Image types are only supported on [Vision-compatible models](/docs/models).'
          x-oaiExpandable: true
        attachments:
          required:
            - file_id
            - tools
          type: array
          items:
            type: object
            properties:
              file_id:
                type: string
                description: The ID of the file to attach to the message.
              tools:
                type: array
                items:
                  oneOf:
                    - $ref: '#/components/schemas/AssistantToolsCode'
                    - $ref: '#/components/schemas/AssistantToolsFileSearchTypeOnly'
                  x-oaiExpandable: true
                description: The tools to add this file to.
          description: 'A list of files attached to the message, and the tools they should be added to.'
          nullable: true
        metadata:
          type: object
          description: "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
          nullable: true
          x-oaiTypeLabel: map
      additionalProperties: false
    CreateModerationRequest:
      required:
        - input
      type: object
      properties:
        input:
          oneOf:
            - type: string
              description: A string of text to classify for moderation.
              default: ''
              example: I want to kill them.
            - type: array
              items:
                type: string
                default: ''
                example: I want to kill them.
              description: An array of strings to classify for moderation.
            - type: array
              items:
                oneOf:
                  - required:
                      - type
                      - image_url
                    type: object
                    properties:
                      type:
                        enum:
                          - image_url
                        type: string
                        description: Always `image_url`.
                      image_url:
                        required:
                          - url
                        type: object
                        properties:
                          url:
                            type: string
                            description: Either a URL of the image or the base64 encoded image data.
                            format: uri
                            example: https://example.com/image.jpg
                        description: Contains either an image URL or a data URL for a base64 encoded image.
                    description: An object describing an image to classify.
                  - required:
                      - type
                      - text
                    type: object
                    properties:
                      type:
                        enum:
                          - text
                        type: string
                        description: Always `text`.
                      text:
                        type: string
                        description: A string of text to classify.
                        example: I want to kill them
                    description: An object describing text to classify.
                x-oaiExpandable: true
              description: An array of multi-modal inputs to the moderation model.
          description: "Input (or inputs) to classify. Can be a single string, an array of strings, or\nan array of multi-modal input objects similar to other models.\n"
          x-oaiExpandable: true
        model:
          anyOf:
            - type: string
            - enum:
                - omni-moderation-latest
                - omni-moderation-2024-09-26
                - text-moderation-latest
                - text-moderation-stable
              type: string
          description: "The content moderation model you would like to use. Learn more in\n[the moderation guide](/docs/guides/moderation), and learn about\navailable models [here](/docs/models#moderation).\n"
          default: omni-moderation-latest
          example: omni-moderation-2024-09-26
          x-oaiTypeLabel: string
    CreateModerationResponse:
      required:
        - id
        - model
        - results
      type: object
      properties:
        id:
          type: string
          description: The unique identifier for the moderation request.
        model:
          type: string
          description: The model used to generate the moderation results.
        results:
          type: array
          items:
            required:
              - flagged
              - categories
              - category_scores
              - category_applied_input_types
            type: object
            properties:
              flagged:
                type: boolean
                description: Whether any of the below categories are flagged.
              categories:
                required:
                  - hate
                  - hate/threatening
                  - harassment
                  - harassment/threatening
                  - illicit
                  - illicit/violent
                  - self-harm
                  - self-harm/intent
                  - self-harm/instructions
                  - sexual
                  - sexual/minors
                  - violence
                  - violence/graphic
                type: object
                properties:
                  hate:
                    type: boolean
                    description: 'Content that expresses, incites, or promotes hate based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste. Hateful content aimed at non-protected groups (e.g., chess players) is harassment.'
                  hate/threatening:
                    type: boolean
                    description: 'Hateful content that also includes violence or serious harm towards the targeted group based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste.'
                  harassment:
                    type: boolean
                    description: 'Content that expresses, incites, or promotes harassing language towards any target.'
                  harassment/threatening:
                    type: boolean
                    description: Harassment content that also includes violence or serious harm towards any target.
                  illicit:
                    type: boolean
                    description: 'Content that includes instructions or advice that facilitate the planning or execution of wrongdoing, or that gives advice or instruction on how to commit illicit acts. For example, "how to shoplift" would fit this category.'
                  illicit/violent:
                    type: boolean
                    description: 'Content that includes instructions or advice that facilitate the planning or execution of wrongdoing that also includes violence, or that gives advice or instruction on the procurement of any weapon.'
                  self-harm:
                    type: boolean
                    description: 'Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting, and eating disorders.'
                  self-harm/intent:
                    type: boolean
                    description: 'Content where the speaker expresses that they are engaging or intend to engage in acts of self-harm, such as suicide, cutting, and eating disorders.'
                  self-harm/instructions:
                    type: boolean
                    description: 'Content that encourages performing acts of self-harm, such as suicide, cutting, and eating disorders, or that gives instructions or advice on how to commit such acts.'
                  sexual:
                    type: boolean
                    description: 'Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education and wellness).'
                  sexual/minors:
                    type: boolean
                    description: Sexual content that includes an individual who is under 18 years old.
                  violence:
                    type: boolean
                    description: 'Content that depicts death, violence, or physical injury.'
                  violence/graphic:
                    type: boolean
                    description: 'Content that depicts death, violence, or physical injury in graphic detail.'
                description: 'A list of the categories, and whether they are flagged or not.'
              category_scores:
                required:
                  - hate
                  - hate/threatening
                  - harassment
                  - harassment/threatening
                  - illicit
                  - illicit/violent
                  - self-harm
                  - self-harm/intent
                  - self-harm/instructions
                  - sexual
                  - sexual/minors
                  - violence
                  - violence/graphic
                type: object
                properties:
                  hate:
                    type: number
                    description: The score for the category 'hate'.
                  hate/threatening:
                    type: number
                    description: The score for the category 'hate/threatening'.
                  harassment:
                    type: number
                    description: The score for the category 'harassment'.
                  harassment/threatening:
                    type: number
                    description: The score for the category 'harassment/threatening'.
                  illicit:
                    type: number
                    description: The score for the category 'illicit'.
                  illicit/violent:
                    type: number
                    description: The score for the category 'illicit/violent'.
                  self-harm:
                    type: number
                    description: The score for the category 'self-harm'.
                  self-harm/intent:
                    type: number
                    description: The score for the category 'self-harm/intent'.
                  self-harm/instructions:
                    type: number
                    description: The score for the category 'self-harm/instructions'.
                  sexual:
                    type: number
                    description: The score for the category 'sexual'.
                  sexual/minors:
                    type: number
                    description: The score for the category 'sexual/minors'.
                  violence:
                    type: number
                    description: The score for the category 'violence'.
                  violence/graphic:
                    type: number
                    description: The score for the category 'violence/graphic'.
                description: A list of the categories along with their scores as predicted by model.
              category_applied_input_types:
                required:
                  - hate
                  - hate/threatening
                  - harassment
                  - harassment/threatening
                  - illicit
                  - illicit/violent
                  - self-harm
                  - self-harm/intent
                  - self-harm/instructions
                  - sexual
                  - sexual/minors
                  - violence
                  - violence/graphic
                type: object
                properties:
                  hate:
                    type: array
                    items:
                      enum:
                        - text
                      type: string
                    description: The applied input type(s) for the category 'hate'.
                  hate/threatening:
                    type: array
                    items:
                      enum:
                        - text
                      type: string
                    description: The applied input type(s) for the category 'hate/threatening'.
                  harassment:
                    type: array
                    items:
                      enum:
                        - text
                      type: string
                    description: The applied input type(s) for the category 'harassment'.
                  harassment/threatening:
                    type: array
                    items:
                      enum:
                        - text
                      type: string
                    description: The applied input type(s) for the category 'harassment/threatening'.
                  illicit:
                    type: array
                    items:
                      enum:
                        - text
                      type: string
                    description: The applied input type(s) for the category 'illicit'.
                  illicit/violent:
                    type: array
                    items:
                      enum:
                        - text
                      type: string
                    description: The applied input type(s) for the category 'illicit/violent'.
                  self-harm:
                    type: array
                    items:
                      enum:
                        - text
                        - image
                      type: string
                    description: The applied input type(s) for the category 'self-harm'.
                  self-harm/intent:
                    type: array
                    items:
                      enum:
                        - text
                        - image
                      type: string
                    description: The applied input type(s) for the category 'self-harm/intent'.
                  self-harm/instructions:
                    type: array
                    items:
                      enum:
                        - text
                        - image
                      type: string
                    description: The applied input type(s) for the category 'self-harm/instructions'.
                  sexual:
                    type: array
                    items:
                      enum:
                        - text
                        - image
                      type: string
                    description: The applied input type(s) for the category 'sexual'.
                  sexual/minors:
                    type: array
                    items:
                      enum:
                        - text
                      type: string
                    description: The applied input type(s) for the category 'sexual/minors'.
                  violence:
                    type: array
                    items:
                      enum:
                        - text
                        - image
                      type: string
                    description: The applied input type(s) for the category 'violence'.
                  violence/graphic:
                    type: array
                    items:
                      enum:
                        - text
                        - image
                      type: string
                    description: The applied input type(s) for the category 'violence/graphic'.
                description: A list of the categories along with the input type(s) that the score applies to.
          description: A list of moderation objects.
      description: Represents if a given text input is potentially harmful.
      x-oaiMeta:
        name: The moderation object
        example: "{\n  \"id\": \"modr-0d9740456c391e43c445bf0f010940c7\",\n  \"model\": \"omni-moderation-latest\",\n  \"results\": [\n    {\n      \"flagged\": true,\n      \"categories\": {\n        \"harassment\": true,\n        \"harassment/threatening\": true,\n        \"sexual\": false,\n        \"hate\": false,\n        \"hate/threatening\": false,\n        \"illicit\": false,\n        \"illicit/violent\": false,\n        \"self-harm/intent\": false,\n        \"self-harm/instructions\": false,\n        \"self-harm\": false,\n        \"sexual/minors\": false,\n        \"violence\": true,\n        \"violence/graphic\": true\n      },\n      \"category_scores\": {\n        \"harassment\": 0.8189693396524255,\n        \"harassment/threatening\": 0.804985420696006,\n        \"sexual\": 1.573112165348997e-6,\n        \"hate\": 0.007562942636942845,\n        \"hate/threatening\": 0.004208854591835476,\n        \"illicit\": 0.030535955153511665,\n        \"illicit/violent\": 0.008925306722380033,\n        \"self-harm/intent\": 0.00023023930975076432,\n        \"self-harm/instructions\": 0.0002293869201073356,\n        \"self-harm\": 0.012598046106750154,\n        \"sexual/minors\": 2.212566909570261e-8,\n        \"violence\": 0.9999992735124786,\n        \"violence/graphic\": 0.843064871157054\n      },\n      \"category_applied_input_types\": {\n        \"harassment\": [\n          \"text\"\n        ],\n        \"harassment/threatening\": [\n          \"text\"\n        ],\n        \"sexual\": [\n          \"text\",\n          \"image\"\n        ],\n        \"hate\": [\n          \"text\"\n        ],\n        \"hate/threatening\": [\n          \"text\"\n        ],\n        \"illicit\": [\n          \"text\"\n        ],\n        \"illicit/violent\": [\n          \"text\"\n        ],\n        \"self-harm/intent\": [\n          \"text\",\n          \"image\"\n        ],\n        \"self-harm/instructions\": [\n          \"text\",\n          \"image\"\n        ],\n        \"self-harm\": [\n          \"text\",\n          \"image\"\n        ],\n        \"sexual/minors\": [\n          \"text\"\n        ],\n        \"violence\": [\n          \"text\",\n          \"image\"\n        ],\n        \"violence/graphic\": [\n          \"text\",\n          \"image\"\n        ]\n      }\n    }\n  ]\n}\n"
    CreateRunRequest:
      required:
        - assistant_id
      type: object
      properties:
        assistant_id:
          type: string
          description: 'The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.'
        model:
          anyOf:
            - type: string
            - enum:
                - gpt-4o
                - gpt-4o-2024-11-20
                - gpt-4o-2024-08-06
                - gpt-4o-2024-05-13
                - gpt-4o-mini
                - gpt-4o-mini-2024-07-18
                - gpt-4-turbo
                - gpt-4-turbo-2024-04-09
                - gpt-4-0125-preview
                - gpt-4-turbo-preview
                - gpt-4-1106-preview
                - gpt-4-vision-preview
                - gpt-4
                - gpt-4-0314
                - gpt-4-0613
                - gpt-4-32k
                - gpt-4-32k-0314
                - gpt-4-32k-0613
                - gpt-3.5-turbo
                - gpt-3.5-turbo-16k
                - gpt-3.5-turbo-0613
                - gpt-3.5-turbo-1106
                - gpt-3.5-turbo-0125
                - gpt-3.5-turbo-16k-0613
              type: string
          description: 'The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.'
          nullable: true
          example: gpt-4o
          x-oaiTypeLabel: string
        instructions:
          type: string
          description: 'Overrides the [instructions](/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.'
          nullable: true
        additional_instructions:
          type: string
          description: Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.
          nullable: true
        additional_messages:
          type: array
          items:
            $ref: '#/components/schemas/CreateMessageRequest'
          description: Adds additional messages to the thread before creating the run.
          nullable: true
        tools:
          maxItems: 20
          type: array
          items:
            oneOf:
              - $ref: '#/components/schemas/AssistantToolsCode'
              - $ref: '#/components/schemas/AssistantToolsFileSearch'
              - $ref: '#/components/schemas/AssistantToolsFunction'
            x-oaiExpandable: true
          description: Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.
          nullable: true
        metadata:
          type: object
          description: "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
          nullable: true
          x-oaiTypeLabel: map
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n"
          default: 1
          nullable: true
          example: 1
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n"
          default: 1
          nullable: true
          example: 1
        stream:
          type: boolean
          description: "If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.\n"
          nullable: true
        max_prompt_tokens:
          minimum: 256
          type: integer
          description: "The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.\n"
          nullable: true
        max_completion_tokens:
          minimum: 256
          type: integer
          description: "The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.\n"
          nullable: true
        truncation_strategy:
          $ref: '#/components/schemas/TruncationObject'
        tool_choice:
          $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
        parallel_tool_calls:
          $ref: '#/components/schemas/ParallelToolCalls'
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
      additionalProperties: false
    CreateSpeechRequest:
      required:
        - model
        - input
        - voice
      type: object
      properties:
        model:
          anyOf:
            - type: string
            - enum:
                - tts-1
                - tts-1-hd
              type: string
          description: "One of the available [TTS models](/docs/models#tts): `tts-1` or `tts-1-hd`\n"
          x-oaiTypeLabel: string
        input:
          maxLength: 4096
          type: string
          description: The text to generate audio for. The maximum length is 4096 characters.
        voice:
          enum:
            - alloy
            - echo
            - fable
            - onyx
            - nova
            - shimmer
          type: string
          description: 'The voice to use when generating the audio. Supported voices are `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews of the voices are available in the [Text to speech guide](/docs/guides/text-to-speech#voice-options).'
        response_format:
          enum:
            - mp3
            - opus
            - aac
            - flac
            - wav
            - pcm
          type: string
          description: 'The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`.'
          default: mp3
        speed:
          maximum: 4
          minimum: 0.25
          type: number
          description: The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default.
          default: 1
      additionalProperties: false
    CreateThreadAndRunRequest:
      required:
        - assistant_id
      type: object
      properties:
        assistant_id:
          type: string
          description: 'The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.'
        thread:
          $ref: '#/components/schemas/CreateThreadRequest'
        model:
          anyOf:
            - type: string
            - enum:
                - gpt-4o
                - gpt-4o-2024-11-20
                - gpt-4o-2024-08-06
                - gpt-4o-2024-05-13
                - gpt-4o-mini
                - gpt-4o-mini-2024-07-18
                - gpt-4-turbo
                - gpt-4-turbo-2024-04-09
                - gpt-4-0125-preview
                - gpt-4-turbo-preview
                - gpt-4-1106-preview
                - gpt-4-vision-preview
                - gpt-4
                - gpt-4-0314
                - gpt-4-0613
                - gpt-4-32k
                - gpt-4-32k-0314
                - gpt-4-32k-0613
                - gpt-3.5-turbo
                - gpt-3.5-turbo-16k
                - gpt-3.5-turbo-0613
                - gpt-3.5-turbo-1106
                - gpt-3.5-turbo-0125
                - gpt-3.5-turbo-16k-0613
              type: string
          description: 'The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.'
          nullable: true
          example: gpt-4o
          x-oaiTypeLabel: string
        instructions:
          type: string
          description: Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.
          nullable: true
        tools:
          maxItems: 20
          type: array
          items:
            oneOf:
              - $ref: '#/components/schemas/AssistantToolsCode'
              - $ref: '#/components/schemas/AssistantToolsFileSearch'
              - $ref: '#/components/schemas/AssistantToolsFunction'
          description: Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.
          nullable: true
        tool_resources:
          type: object
          properties:
            code_interpreter:
              type: object
              properties:
                file_ids:
                  maxItems: 20
                  type: array
                  items:
                    type: string
                  description: "A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n"
            file_search:
              type: object
              properties:
                vector_store_ids:
                  maxItems: 1
                  type: array
                  items:
                    type: string
                  description: "The ID of the [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.\n"
          description: "A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n"
          nullable: true
        metadata:
          type: object
          description: "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
          nullable: true
          x-oaiTypeLabel: map
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n"
          default: 1
          nullable: true
          example: 1
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n"
          default: 1
          nullable: true
          example: 1
        stream:
          type: boolean
          description: "If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.\n"
          nullable: true
        max_prompt_tokens:
          minimum: 256
          type: integer
          description: "The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.\n"
          nullable: true
        max_completion_tokens:
          minimum: 256
          type: integer
          description: "The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.\n"
          nullable: true
        truncation_strategy:
          $ref: '#/components/schemas/TruncationObject'
        tool_choice:
          $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
        parallel_tool_calls:
          $ref: '#/components/schemas/ParallelToolCalls'
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
      additionalProperties: false
    CreateThreadRequest:
      type: object
      properties:
        messages:
          type: array
          items:
            $ref: '#/components/schemas/CreateMessageRequest'
          description: 'A list of [messages](/docs/api-reference/messages) to start the thread with.'
        tool_resources:
          type: object
          properties:
            code_interpreter:
              type: object
              properties:
                file_ids:
                  maxItems: 20
                  type: array
                  items:
                    type: string
                  description: "A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n"
            file_search:
              type: object
              oneOf:
                - required:
                    - vector_store_ids
                - required:
                    - vector_stores
              properties:
                vector_store_ids:
                  maxItems: 1
                  type: array
                  items:
                    type: string
                  description: "The [vector store](/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.\n"
                vector_stores:
                  maxItems: 1
                  type: array
                  items:
                    type: object
                    properties:
                      file_ids:
                        maxItems: 10000
                        type: array
                        items:
                          type: string
                        description: "A list of [file](/docs/api-reference/files) IDs to add to the vector store. There can be a maximum of 10000 files in a vector store.\n"
                      chunking_strategy:
                        type: object
                        oneOf:
                          - title: Auto Chunking Strategy
                            required:
                              - type
                            type: object
                            properties:
                              type:
                                enum:
                                  - auto
                                type: string
                                description: Always `auto`.
                            additionalProperties: false
                            description: The default strategy. This strategy currently uses a `max_chunk_size_tokens` of `800` and `chunk_overlap_tokens` of `400`.
                          - title: Static Chunking Strategy
                            required:
                              - type
                              - static
                            type: object
                            properties:
                              type:
                                enum:
                                  - static
                                type: string
                                description: Always `static`.
                              static:
                                required:
                                  - max_chunk_size_tokens
                                  - chunk_overlap_tokens
                                type: object
                                properties:
                                  max_chunk_size_tokens:
                                    maximum: 4096
                                    minimum: 100
                                    type: integer
                                    description: The maximum number of tokens in each chunk. The default value is `800`. The minimum value is `100` and the maximum value is `4096`.
                                  chunk_overlap_tokens:
                                    type: integer
                                    description: "The number of tokens that overlap between chunks. The default value is `400`.\n\nNote that the overlap must not exceed half of `max_chunk_size_tokens`.\n"
                                additionalProperties: false
                            additionalProperties: false
                        description: 'The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.'
                        x-oaiExpandable: true
                      metadata:
                        type: object
                        description: "Set of 16 key-value pairs that can be attached to a vector store. This can be useful for storing additional information about the vector store in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
                        x-oaiTypeLabel: map
                    x-oaiExpandable: true
                  description: "A helper to create a [vector store](/docs/api-reference/vector-stores/object) with file_ids and attach it to this thread. There can be a maximum of 1 vector store attached to the thread.\n"
          description: "A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n"
          nullable: true
        metadata:
          type: object
          description: "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
          nullable: true
          x-oaiTypeLabel: map
      additionalProperties: false
    CreateTranscriptionRequest:
      required:
        - file
        - model
      type: object
      properties:
        file:
          type: string
          description: "The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n"
          format: binary
          x-oaiTypeLabel: file
        model:
          anyOf:
            - type: string
            - enum:
                - whisper-1
              type: string
          description: "ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.\n"
          example: whisper-1
          x-oaiTypeLabel: string
        language:
          type: string
          description: "The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.\n"
        prompt:
          type: string
          description: "An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should match the audio language.\n"
        response_format:
          $ref: '#/components/schemas/AudioResponseFormat'
        temperature:
          type: number
          description: "The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.\n"
          default: 0
        'timestamp_granularities[]':
          type: array
          items:
            enum:
              - word
              - segment
            type: string
          description: "The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.\n"
          default:
            - segment
      additionalProperties: false
    CreateTranscriptionResponseJson:
      required:
        - text
      type: object
      properties:
        text:
          type: string
          description: The transcribed text.
      description: 'Represents a transcription response returned by model, based on the provided input.'
      x-oaiMeta:
        name: The transcription object (JSON)
        group: audio
        example: "{\n  \"text\": \"Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that.\"\n}\n"
    CreateTranscriptionResponseVerboseJson:
      required:
        - language
        - duration
        - text
      type: object
      properties:
        language:
          type: string
          description: The language of the input audio.
        duration:
          type: string
          description: The duration of the input audio.
        text:
          type: string
          description: The transcribed text.
        words:
          type: array
          items:
            $ref: '#/components/schemas/TranscriptionWord'
          description: Extracted words and their corresponding timestamps.
        segments:
          type: array
          items:
            $ref: '#/components/schemas/TranscriptionSegment'
          description: Segments of the transcribed text and their corresponding details.
      description: 'Represents a verbose json transcription response returned by model, based on the provided input.'
      x-oaiMeta:
        name: The transcription object (Verbose JSON)
        group: audio
        example: "{\n  \"task\": \"transcribe\",\n  \"language\": \"english\",\n  \"duration\": 8.470000267028809,\n  \"text\": \"The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.\",\n  \"segments\": [\n    {\n      \"id\": 0,\n      \"seek\": 0,\n      \"start\": 0.0,\n      \"end\": 3.319999933242798,\n      \"text\": \" The beach was a popular spot on a hot summer day.\",\n      \"tokens\": [\n        50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530\n      ],\n      \"temperature\": 0.0,\n      \"avg_logprob\": -0.2860786020755768,\n      \"compression_ratio\": 1.2363636493682861,\n      \"no_speech_prob\": 0.00985979475080967\n    },\n    ...\n  ]\n}\n"
    CreateTranslationRequest:
      required:
        - file
        - model
      type: object
      properties:
        file:
          type: string
          description: "The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n"
          format: binary
          x-oaiTypeLabel: file
        model:
          anyOf:
            - type: string
            - enum:
                - whisper-1
              type: string
          description: "ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.\n"
          example: whisper-1
          x-oaiTypeLabel: string
        prompt:
          type: string
          description: "An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should be in English.\n"
        response_format:
          $ref: '#/components/schemas/AudioResponseFormat'
        temperature:
          type: number
          description: "The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.\n"
          default: 0
      additionalProperties: false
    CreateTranslationResponseJson:
      required:
        - text
      type: object
      properties:
        text:
          type: string
    CreateTranslationResponseVerboseJson:
      required:
        - language
        - duration
        - text
      type: object
      properties:
        language:
          type: string
          description: The language of the output translation (always `english`).
        duration:
          type: string
          description: The duration of the input audio.
        text:
          type: string
          description: The translated text.
        segments:
          type: array
          items:
            $ref: '#/components/schemas/TranscriptionSegment'
          description: Segments of the translated text and their corresponding details.
    CreateUploadRequest:
      required:
        - filename
        - purpose
        - bytes
        - mime_type
      type: object
      properties:
        filename:
          type: string
          description: "The name of the file to upload.\n"
        purpose:
          enum:
            - assistants
            - batch
            - fine-tune
            - vision
          type: string
          description: "The intended purpose of the uploaded file.\n\nSee the [documentation on File purposes](/docs/api-reference/files/create#files-create-purpose).\n"
        bytes:
          type: integer
          description: "The number of bytes in the file you are uploading.\n"
        mime_type:
          type: string
          description: "The MIME type of the file.\n\nThis must fall within the supported MIME types for your file purpose. See the supported MIME types for assistants and vision.\n"
      additionalProperties: false
    CreateVectorStoreFileBatchRequest:
      required:
        - file_ids
      type: object
      properties:
        file_ids:
          maxItems: 500
          minItems: 1
          type: array
          items:
            type: string
          description: 'A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.'
        chunking_strategy:
          $ref: '#/components/schemas/ChunkingStrategyRequestParam'
      additionalProperties: false
    CreateVectorStoreFileRequest:
      required:
        - file_id
      type: object
      properties:
        file_id:
          type: string
          description: 'A [File](/docs/api-reference/files) ID that the vector store should use. Useful for tools like `file_search` that can access files.'
        chunking_strategy:
          $ref: '#/components/schemas/ChunkingStrategyRequestParam'
      additionalProperties: false
    CreateVectorStoreRequest:
      type: object
      properties:
        file_ids:
          maxItems: 500
          type: array
          items:
            type: string
          description: 'A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.'
        name:
          type: string
          description: The name of the vector store.
        expires_after:
          $ref: '#/components/schemas/VectorStoreExpirationAfter'
        chunking_strategy:
          type: object
          oneOf:
            - $ref: '#/components/schemas/AutoChunkingStrategyRequestParam'
            - $ref: '#/components/schemas/StaticChunkingStrategyRequestParam'
          description: 'The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy. Only applicable if `file_ids` is non-empty.'
          x-oaiExpandable: true
        metadata:
          type: object
          description: "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
          nullable: true
          x-oaiTypeLabel: map
      additionalProperties: false
    DefaultProjectErrorResponse:
      required:
        - code
        - message
      type: object
      properties:
        code:
          type: integer
        message:
          type: string
    DeleteAssistantResponse:
      required:
        - id
        - object
        - deleted
      type: object
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
            - assistant.deleted
          type: string
    DeleteFileResponse:
      required:
        - id
        - object
        - deleted
      type: object
      properties:
        id:
          type: string
        object:
          enum:
            - file
          type: string
        deleted:
          type: boolean
    DeleteMessageResponse:
      required:
        - id
        - object
        - deleted
      type: object
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
            - thread.message.deleted
          type: string
    DeleteModelResponse:
      required:
        - id
        - object
        - deleted
      type: object
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          type: string
    DeleteThreadResponse:
      required:
        - id
        - object
        - deleted
      type: object
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
            - thread.deleted
          type: string
    DeleteVectorStoreFileResponse:
      required:
        - id
        - object
        - deleted
      type: object
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
            - vector_store.file.deleted
          type: string
    DeleteVectorStoreResponse:
      required:
        - id
        - object
        - deleted
      type: object
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
            - vector_store.deleted
          type: string
    DoneEvent:
      required:
        - event
        - data
      type: object
      properties:
        event:
          enum:
            - done
          type: string
        data:
          enum:
            - '[DONE]'
          type: string
      description: Occurs when a stream ends.
      x-oaiMeta:
        dataDescription: '`data` is `[DONE]`'
    Embedding:
      required:
        - index
        - object
        - embedding
      type: object
      properties:
        index:
          type: integer
          description: The index of the embedding in the list of embeddings.
        embedding:
          type: array
          items:
            type: number
          description: "The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](/docs/guides/embeddings).\n"
        object:
          enum:
            - embedding
          type: string
          description: 'The object type, which is always "embedding".'
      description: "Represents an embedding vector returned by embedding endpoint.\n"
      x-oaiMeta:
        name: The embedding object
        example: "{\n  \"object\": \"embedding\",\n  \"embedding\": [\n    0.0023064255,\n    -0.009327292,\n    .... (1536 floats total for ada-002)\n    -0.0028842222,\n  ],\n  \"index\": 0\n}\n"
    Error:
      required:
        - type
        - message
        - param
        - code
      type: object
      properties:
        code:
          type: string
          nullable: true
        message:
          type: string
        param:
          type: string
          nullable: true
        type:
          type: string
    ErrorEvent:
      required:
        - event
        - data
      type: object
      properties:
        event:
          enum:
            - error
          type: string
        data:
          $ref: '#/components/schemas/Error'
      description: 'Occurs when an [error](/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.'
      x-oaiMeta:
        dataDescription: '`data` is an [error](/docs/guides/error-codes#api-errors)'
    ErrorResponse:
      required:
        - error
      type: object
      properties:
        error:
          $ref: '#/components/schemas/Error'
    FileSearchRankingOptions:
      title: File search tool call ranking options
      required:
        - score_threshold
      type: object
      properties:
        ranker:
          enum:
            - auto
            - default_2024_08_21
          type: string
          description: The ranker to use for the file search. If not specified will use the `auto` ranker.
        score_threshold:
          maximum: 1
          minimum: 0
          type: number
          description: The score threshold for the file search. All values must be a floating point number between 0 and 1.
      description: "The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.\n\nSee the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n"
    FineTuneChatCompletionRequestAssistantMessage:
      required:
        - role
      allOf:
        - title: Assistant message
          type: object
          properties:
            weight:
              enum:
                - 0
                - 1
              type: integer
              description: Controls whether the assistant message is trained against (0 or 1)
        - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage'
    FineTuningIntegration:
      title: Fine-Tuning Job Integration
      required:
        - type
        - wandb
      type: object
      properties:
        type:
          enum:
            - wandb
          type: string
          description: The type of the integration being enabled for the fine-tuning job
        wandb:
          required:
            - project
          type: object
          properties:
            project:
              type: string
              description: "The name of the project that the new run will be created under.\n"
              example: my-wandb-project
            name:
              type: string
              description: "A display name to set for the run. If not set, we will use the Job ID as the name.\n"
              nullable: true
            entity:
              type: string
              description: "The entity to use for the run. This allows you to set the team or username of the WandB user that you would\nlike associated with the run. If not set, the default entity for the registered WandB API key is used.\n"
              nullable: true
            tags:
              type: array
              items:
                type: string
                example: custom-tag
              description: "A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some\ndefault tags are generated by OpenAI: \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n"
          description: "The settings for your integration with Weights and Biases. This payload specifies the project that\nmetrics will be sent to. Optionally, you can set an explicit display name for your run, add tags\nto your run, and set a default entity (team, username, etc) to be associated with your run.\n"
    FineTuningJob:
      title: FineTuningJob
      required:
        - created_at
        - error
        - finished_at
        - fine_tuned_model
        - hyperparameters
        - id
        - model
        - object
        - organization_id
        - result_files
        - status
        - trained_tokens
        - training_file
        - validation_file
        - seed
      type: object
      properties:
        id:
          type: string
          description: 'The object identifier, which can be referenced in the API endpoints.'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the fine-tuning job was created.
        error:
          required:
            - code
            - message
            - param
          type: object
          properties:
            code:
              type: string
              description: A machine-readable error code.
            message:
              type: string
              description: A human-readable error message.
            param:
              type: string
              description: 'The parameter that was invalid, usually `training_file` or `validation_file`. This field will be null if the failure was not parameter-specific.'
              nullable: true
          description: 'For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.'
          nullable: true
        fine_tuned_model:
          type: string
          description: The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.
          nullable: true
        finished_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.
          nullable: true
        hyperparameters:
          required:
            - n_epochs
          type: object
          properties:
            n_epochs:
              oneOf:
                - enum:
                    - auto
                  type: string
                - maximum: 50
                  minimum: 1
                  type: integer
              description: "The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n\"auto\" decides the optimal number of epochs based on the size of the dataset. If setting the number manually, we support any number between 1 and 50 epochs."
              default: auto
          description: 'The hyperparameters used for the fine-tuning job. See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.'
        model:
          type: string
          description: The base model that is being fine-tuned.
        object:
          enum:
            - fine_tuning.job
          type: string
          description: 'The object type, which is always "fine_tuning.job".'
        organization_id:
          type: string
          description: The organization that owns the fine-tuning job.
        result_files:
          type: array
          items:
            type: string
            example: file-abc123
          description: 'The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents).'
        status:
          enum:
            - validating_files
            - queued
            - running
            - succeeded
            - failed
            - cancelled
          type: string
          description: 'The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.'
        trained_tokens:
          type: integer
          description: The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.
          nullable: true
        training_file:
          type: string
          description: 'The file ID used for training. You can retrieve the training data with the [Files API](/docs/api-reference/files/retrieve-contents).'
        validation_file:
          type: string
          description: 'The file ID used for validation. You can retrieve the validation results with the [Files API](/docs/api-reference/files/retrieve-contents).'
          nullable: true
        integrations:
          maxItems: 5
          type: array
          items:
            oneOf:
              - $ref: '#/components/schemas/FineTuningIntegration'
            x-oaiExpandable: true
          description: A list of integrations to enable for this fine-tuning job.
          nullable: true
        seed:
          type: integer
          description: The seed used for the fine-tuning job.
        estimated_finish:
          type: integer
          description: The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running.
          nullable: true
      description: "The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.\n"
      x-oaiMeta:
        name: The fine-tuning job object
        example: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"davinci-002\",\n  \"created_at\": 1692661014,\n  \"finished_at\": 1692661190,\n  \"fine_tuned_model\": \"ft:davinci-002:my-org:custom_suffix:7q8mpxmy\",\n  \"organization_id\": \"org-123\",\n  \"result_files\": [\n      \"file-abc123\"\n  ],\n  \"status\": \"succeeded\",\n  \"validation_file\": null,\n  \"training_file\": \"file-abc123\",\n  \"hyperparameters\": {\n      \"n_epochs\": 4,\n      \"batch_size\": 1,\n      \"learning_rate_multiplier\": 1.0\n  },\n  \"trained_tokens\": 5768,\n  \"integrations\": [],\n  \"seed\": 0,\n  \"estimated_finish\": 0\n}\n"
    FineTuningJobCheckpoint:
      title: FineTuningJobCheckpoint
      required:
        - created_at
        - fine_tuning_job_id
        - fine_tuned_model_checkpoint
        - id
        - metrics
        - object
        - step_number
      type: object
      properties:
        id:
          type: string
          description: 'The checkpoint identifier, which can be referenced in the API endpoints.'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the checkpoint was created.
        fine_tuned_model_checkpoint:
          type: string
          description: The name of the fine-tuned checkpoint model that is created.
        step_number:
          type: integer
          description: The step number that the checkpoint was created at.
        metrics:
          type: object
          properties:
            step:
              type: number
            train_loss:
              type: number
            train_mean_token_accuracy:
              type: number
            valid_loss:
              type: number
            valid_mean_token_accuracy:
              type: number
            full_valid_loss:
              type: number
            full_valid_mean_token_accuracy:
              type: number
          description: Metrics at the step number during the fine-tuning job.
        fine_tuning_job_id:
          type: string
          description: The name of the fine-tuning job that this checkpoint was created from.
        object:
          enum:
            - fine_tuning.job.checkpoint
          type: string
          description: 'The object type, which is always "fine_tuning.job.checkpoint".'
      description: "The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.\n"
      x-oaiMeta:
        name: The fine-tuning job checkpoint object
        example: "{\n  \"object\": \"fine_tuning.job.checkpoint\",\n  \"id\": \"ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P\",\n  \"created_at\": 1712211699,\n  \"fine_tuned_model_checkpoint\": \"ft:gpt-4o-mini-2024-07-18:my-org:custom_suffix:9ABel2dg:ckpt-step-88\",\n  \"fine_tuning_job_id\": \"ftjob-fpbNQ3H1GrMehXRf8cO97xTN\",\n  \"metrics\": {\n    \"step\": 88,\n    \"train_loss\": 0.478,\n    \"train_mean_token_accuracy\": 0.924,\n    \"valid_loss\": 10.112,\n    \"valid_mean_token_accuracy\": 0.145,\n    \"full_valid_loss\": 0.567,\n    \"full_valid_mean_token_accuracy\": 0.944\n  },\n  \"step_number\": 88\n}\n"
    FineTuningJobEvent:
      required:
        - id
        - object
        - created_at
        - level
        - message
      type: object
      properties:
        id:
          type: string
        created_at:
          type: integer
        level:
          enum:
            - info
            - warn
            - error
          type: string
        message:
          type: string
        object:
          enum:
            - fine_tuning.job.event
          type: string
      description: Fine-tuning job event object
      x-oaiMeta:
        name: The fine-tuning job event object
        example: "{\n  \"object\": \"fine_tuning.job.event\",\n  \"id\": \"ftevent-abc123\"\n  \"created_at\": 1677610602,\n  \"level\": \"info\",\n  \"message\": \"Created fine-tuning job\"\n}\n"
    FinetuneChatRequestInput:
      type: object
      properties:
        messages:
          minItems: 1
          type: array
          items:
            oneOf:
              - $ref: '#/components/schemas/ChatCompletionRequestSystemMessage'
              - $ref: '#/components/schemas/ChatCompletionRequestUserMessage'
              - $ref: '#/components/schemas/FineTuneChatCompletionRequestAssistantMessage'
              - $ref: '#/components/schemas/ChatCompletionRequestToolMessage'
              - $ref: '#/components/schemas/ChatCompletionRequestFunctionMessage'
            x-oaiExpandable: true
        tools:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionTool'
          description: A list of tools the model may generate JSON inputs for.
        parallel_tool_calls:
          $ref: '#/components/schemas/ParallelToolCalls'
        functions:
          maxItems: 128
          minItems: 1
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionFunctions'
          description: A list of functions the model may generate JSON inputs for.
          deprecated: true
      description: The per-line training example of a fine-tuning input file for chat models
      x-oaiMeta:
        name: Training format for chat models
        example: "{\n  \"messages\": [\n    { \"role\": \"user\", \"content\": \"What is the weather in San Francisco?\" },\n    {\n      \"role\": \"assistant\",\n      \"tool_calls\": [\n        {\n          \"id\": \"call_id\",\n          \"type\": \"function\",\n          \"function\": {\n            \"name\": \"get_current_weather\",\n            \"arguments\": \"{\\\"location\\\": \\\"San Francisco, USA\\\", \\\"format\\\": \\\"celsius\\\"}\"\n          }\n        }\n      ]\n    }\n  ],\n  \"parallel_tool_calls\": false,\n  \"tools\": [\n    {\n      \"type\": \"function\",\n      \"function\": {\n        \"name\": \"get_current_weather\",\n        \"description\": \"Get the current weather\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"location\": {\n                \"type\": \"string\",\n                \"description\": \"The city and country, eg. San Francisco, USA\"\n            },\n            \"format\": { \"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"] }\n          },\n          \"required\": [\"location\", \"format\"]\n        }\n      }\n    }\n  ]\n}\n"
    FinetuneCompletionRequestInput:
      type: object
      properties:
        prompt:
          type: string
          description: The input prompt for this training example.
        completion:
          type: string
          description: The desired completion for this training example.
      description: The per-line training example of a fine-tuning input file for completions models
      x-oaiMeta:
        name: Training format for completions models
        example: "{\n  \"prompt\": \"What is the answer to 2+2\",\n  \"completion\": \"4\"\n}\n"
    FunctionObject:
      required:
        - name
      type: object
      properties:
        description:
          type: string
          description: 'A description of what the function does, used by the model to choose when and how to call the function.'
        name:
          type: string
          description: 'The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'
        parameters:
          $ref: '#/components/schemas/FunctionParameters'
        strict:
          type: boolean
          description: 'Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](docs/guides/function-calling).'
          default: false
          nullable: true
    FunctionParameters:
      type: object
      description: "The parameters the functions accepts, described as a JSON Schema object. See the [guide](/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format. \n\nOmitting `parameters` defines a function with an empty parameter list."
    Image:
      type: object
      properties:
        b64_json:
          type: string
          description: 'The base64-encoded JSON of the generated image, if `response_format` is `b64_json`.'
        url:
          type: string
          description: 'The URL of the generated image, if `response_format` is `url` (default).'
        revised_prompt:
          type: string
          description: 'The prompt that was used to generate the image, if there was any revision to the prompt.'
      description: Represents the url or the content of an image generated by the OpenAI API.
      x-oaiMeta:
        name: The image object
        example: "{\n  \"url\": \"...\",\n  \"revised_prompt\": \"...\"\n}\n"
    ImagesResponse:
      required:
        - created
        - data
      properties:
        created:
          type: integer
        data:
          type: array
          items:
            $ref: '#/components/schemas/Image'
    Invite:
      required:
        - object
        - id
        - email
        - role
        - status
        - invited_at
        - expires_at
      type: object
      properties:
        object:
          enum:
            - organization.invite
          type: string
          description: 'The object type, which is always `organization.invite`'
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints'
        email:
          type: string
          description: The email address of the individual to whom the invite was sent
        role:
          enum:
            - owner
            - reader
          type: string
          description: '`owner` or `reader`'
        status:
          enum:
            - accepted
            - expired
            - pending
          type: string
          description: '`accepted`,`expired`, or `pending`'
        invited_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the invite was sent.
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the invite expires.
        accepted_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the invite was accepted.
      description: Represents an individual `invite` to the organization.
      x-oaiMeta:
        name: The invite object
        example: "{\n  \"object\": \"organization.invite\",\n  \"id\": \"invite-abc\",\n  \"email\": \"user@example.com\",\n  \"role\": \"owner\",\n  \"status\": \"accepted\",\n  \"invited_at\": 1711471533,\n  \"expires_at\": 1711471533,\n  \"accepted_at\": 1711471533\n}\n"
    InviteDeleteResponse:
      required:
        - object
        - id
        - deleted
      type: object
      properties:
        object:
          enum:
            - organization.invite.deleted
          type: string
          description: 'The object type, which is always `organization.invite.deleted`'
        id:
          type: string
        deleted:
          type: boolean
    InviteListResponse:
      required:
        - object
        - data
      type: object
      properties:
        object:
          enum:
            - list
          type: string
          description: 'The object type, which is always `list`'
        data:
          type: array
          items:
            $ref: '#/components/schemas/Invite'
        first_id:
          type: string
          description: The first `invite_id` in the retrieved `list`
        last_id:
          type: string
          description: The last `invite_id` in the retrieved `list`
        has_more:
          type: boolean
          description: The `has_more` property is used for pagination to indicate there are additional results.
    InviteRequest:
      required:
        - email
        - role
      type: object
      properties:
        email:
          type: string
          description: Send an email to this address
        role:
          enum:
            - reader
            - owner
          type: string
          description: '`owner` or `reader`'
    ListAssistantsResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        object:
          type: string
          example: list
        data:
          type: array
          items:
            $ref: '#/components/schemas/AssistantObject'
        first_id:
          type: string
          example: asst_abc123
        last_id:
          type: string
          example: asst_abc456
        has_more:
          type: boolean
          example: false
      x-oaiMeta:
        name: List assistants response object
        group: chat
        example: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"asst_abc123\",\n      \"object\": \"assistant\",\n      \"created_at\": 1698982736,\n      \"name\": \"Coding Tutor\",\n      \"description\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": \"You are a helpful assistant designed to make me better at coding!\",\n      \"tools\": [],\n      \"tool_resources\": {},\n      \"metadata\": {},\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\": \"auto\"\n    },\n    {\n      \"id\": \"asst_abc456\",\n      \"object\": \"assistant\",\n      \"created_at\": 1698982718,\n      \"name\": \"My Assistant\",\n      \"description\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": \"You are a helpful assistant designed to make me better at coding!\",\n      \"tools\": [],\n      \"tool_resources\": {},\n      \"metadata\": {},\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\": \"auto\"\n    },\n    {\n      \"id\": \"asst_abc789\",\n      \"object\": \"assistant\",\n      \"created_at\": 1698982643,\n      \"name\": null,\n      \"description\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": null,\n      \"tools\": [],\n      \"tool_resources\": {},\n      \"metadata\": {},\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\": \"auto\"\n    }\n  ],\n  \"first_id\": \"asst_abc123\",\n  \"last_id\": \"asst_abc789\",\n  \"has_more\": false\n}\n"
    ListAuditLogsResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        object:
          enum:
            - list
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/AuditLog'
        first_id:
          type: string
          example: audit_log-defb456h8dks
        last_id:
          type: string
          example: audit_log-hnbkd8s93s
        has_more:
          type: boolean
    ListBatchesResponse:
      required:
        - object
        - data
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/Batch'
        first_id:
          type: string
          example: batch_abc123
        last_id:
          type: string
          example: batch_abc456
        has_more:
          type: boolean
        object:
          enum:
            - list
          type: string
    ListFilesResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        object:
          type: string
          example: list
        data:
          type: array
          items:
            $ref: '#/components/schemas/OpenAIFile'
        first_id:
          type: string
          example: file-abc123
        last_id:
          type: string
          example: file-abc456
        has_more:
          type: boolean
          example: false
    ListFineTuningJobCheckpointsResponse:
      required:
        - object
        - data
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuningJobCheckpoint'
        object:
          enum:
            - list
          type: string
        first_id:
          type: string
          nullable: true
        last_id:
          type: string
          nullable: true
        has_more:
          type: boolean
    ListFineTuningJobEventsResponse:
      required:
        - object
        - data
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuningJobEvent'
        object:
          enum:
            - list
          type: string
    ListMessagesResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      properties:
        object:
          type: string
          example: list
        data:
          type: array
          items:
            $ref: '#/components/schemas/MessageObject'
        first_id:
          type: string
          example: msg_abc123
        last_id:
          type: string
          example: msg_abc123
        has_more:
          type: boolean
          example: false
    ListModelsResponse:
      required:
        - object
        - data
      type: object
      properties:
        object:
          enum:
            - list
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/Model'
    ListPaginatedFineTuningJobsResponse:
      required:
        - object
        - data
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuningJob'
        has_more:
          type: boolean
        object:
          enum:
            - list
          type: string
    ListRunStepsResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      properties:
        object:
          type: string
          example: list
        data:
          type: array
          items:
            $ref: '#/components/schemas/RunStepObject'
        first_id:
          type: string
          example: step_abc123
        last_id:
          type: string
          example: step_abc456
        has_more:
          type: boolean
          example: false
    ListRunsResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        object:
          type: string
          example: list
        data:
          type: array
          items:
            $ref: '#/components/schemas/RunObject'
        first_id:
          type: string
          example: run_abc123
        last_id:
          type: string
          example: run_abc456
        has_more:
          type: boolean
          example: false
    ListThreadsResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      properties:
        object:
          type: string
          example: list
        data:
          type: array
          items:
            $ref: '#/components/schemas/ThreadObject'
        first_id:
          type: string
          example: asst_abc123
        last_id:
          type: string
          example: asst_abc456
        has_more:
          type: boolean
          example: false
    ListVectorStoreFilesResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      properties:
        object:
          type: string
          example: list
        data:
          type: array
          items:
            $ref: '#/components/schemas/VectorStoreFileObject'
        first_id:
          type: string
          example: file-abc123
        last_id:
          type: string
          example: file-abc456
        has_more:
          type: boolean
          example: false
    ListVectorStoresResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      properties:
        object:
          type: string
          example: list
        data:
          type: array
          items:
            $ref: '#/components/schemas/VectorStoreObject'
        first_id:
          type: string
          example: vs_abc123
        last_id:
          type: string
          example: vs_abc456
        has_more:
          type: boolean
          example: false
    MessageContentImageFileObject:
      title: Image file
      required:
        - type
        - image_file
      type: object
      properties:
        type:
          enum:
            - image_file
          type: string
          description: Always `image_file`.
        image_file:
          required:
            - file_id
          type: object
          properties:
            file_id:
              type: string
              description: 'The [File](/docs/api-reference/files) ID of the image in the message content. Set `purpose="vision"` when uploading the File if you need to later display the file content.'
            detail:
              enum:
                - auto
                - low
                - high
              type: string
              description: 'Specifies the detail level of the image if specified by the user. `low` uses fewer tokens, you can opt in to high resolution using `high`.'
              default: auto
      description: 'References an image [File](/docs/api-reference/files) in the content of a message.'
    MessageContentImageUrlObject:
      title: Image URL
      required:
        - type
        - image_url
      type: object
      properties:
        type:
          enum:
            - image_url
          type: string
          description: The type of the content part.
        image_url:
          required:
            - url
          type: object
          properties:
            url:
              type: string
              description: 'The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp.'
              format: uri
            detail:
              enum:
                - auto
                - low
                - high
              type: string
              description: 'Specifies the detail level of the image. `low` uses fewer tokens, you can opt in to high resolution using `high`. Default value is `auto`'
              default: auto
      description: References an image URL in the content of a message.
    MessageContentRefusalObject:
      title: Refusal
      required:
        - type
        - refusal
      type: object
      properties:
        type:
          enum:
            - refusal
          type: string
          description: Always `refusal`.
        refusal:
          type: string
      description: The refusal content generated by the assistant.
    MessageContentTextAnnotationsFileCitationObject:
      title: File citation
      required:
        - type
        - text
        - file_citation
        - start_index
        - end_index
      type: object
      properties:
        type:
          enum:
            - file_citation
          type: string
          description: Always `file_citation`.
        text:
          type: string
          description: The text in the message content that needs to be replaced.
        file_citation:
          required:
            - file_id
          type: object
          properties:
            file_id:
              type: string
              description: The ID of the specific File the citation is from.
        start_index:
          minimum: 0
          type: integer
        end_index:
          minimum: 0
          type: integer
      description: A citation within the message that points to a specific quote from a specific File associated with the assistant or the message. Generated when the assistant uses the "file_search" tool to search files.
    MessageContentTextAnnotationsFilePathObject:
      title: File path
      required:
        - type
        - text
        - file_path
        - start_index
        - end_index
      type: object
      properties:
        type:
          enum:
            - file_path
          type: string
          description: Always `file_path`.
        text:
          type: string
          description: The text in the message content that needs to be replaced.
        file_path:
          required:
            - file_id
          type: object
          properties:
            file_id:
              type: string
              description: The ID of the file that was generated.
        start_index:
          minimum: 0
          type: integer
        end_index:
          minimum: 0
          type: integer
      description: A URL for the file that's generated when the assistant used the `code_interpreter` tool to generate a file.
    MessageContentTextObject:
      title: Text
      required:
        - type
        - text
      type: object
      properties:
        type:
          enum:
            - text
          type: string
          description: Always `text`.
        text:
          required:
            - value
            - annotations
          type: object
          properties:
            value:
              type: string
              description: The data that makes up the text.
            annotations:
              type: array
              items:
                oneOf:
                  - $ref: '#/components/schemas/MessageContentTextAnnotationsFileCitationObject'
                  - $ref: '#/components/schemas/MessageContentTextAnnotationsFilePathObject'
                x-oaiExpandable: true
      description: The text content that is part of a message.
    MessageDeltaContentImageFileObject:
      title: Image file
      required:
        - index
        - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the content part in the message.
        type:
          enum:
            - image_file
          type: string
          description: Always `image_file`.
        image_file:
          type: object
          properties:
            file_id:
              type: string
              description: 'The [File](/docs/api-reference/files) ID of the image in the message content. Set `purpose="vision"` when uploading the File if you need to later display the file content.'
            detail:
              enum:
                - auto
                - low
                - high
              type: string
              description: 'Specifies the detail level of the image if specified by the user. `low` uses fewer tokens, you can opt in to high resolution using `high`.'
              default: auto
      description: 'References an image [File](/docs/api-reference/files) in the content of a message.'
    MessageDeltaContentImageUrlObject:
      title: Image URL
      required:
        - index
        - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the content part in the message.
        type:
          enum:
            - image_url
          type: string
          description: Always `image_url`.
        image_url:
          type: object
          properties:
            url:
              type: string
              description: 'The URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp.'
            detail:
              enum:
                - auto
                - low
                - high
              type: string
              description: 'Specifies the detail level of the image. `low` uses fewer tokens, you can opt in to high resolution using `high`.'
              default: auto
      description: References an image URL in the content of a message.
    MessageDeltaContentRefusalObject:
      title: Refusal
      required:
        - index
        - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the refusal part in the message.
        type:
          enum:
            - refusal
          type: string
          description: Always `refusal`.
        refusal:
          type: string
      description: The refusal content that is part of a message.
    MessageDeltaContentTextAnnotationsFileCitationObject:
      title: File citation
      required:
        - index
        - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the annotation in the text content part.
        type:
          enum:
            - file_citation
          type: string
          description: Always `file_citation`.
        text:
          type: string
          description: The text in the message content that needs to be replaced.
        file_citation:
          type: object
          properties:
            file_id:
              type: string
              description: The ID of the specific File the citation is from.
            quote:
              type: string
              description: The specific quote in the file.
        start_index:
          minimum: 0
          type: integer
        end_index:
          minimum: 0
          type: integer
      description: A citation within the message that points to a specific quote from a specific File associated with the assistant or the message. Generated when the assistant uses the "file_search" tool to search files.
    MessageDeltaContentTextAnnotationsFilePathObject:
      title: File path
      required:
        - index
        - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the annotation in the text content part.
        type:
          enum:
            - file_path
          type: string
          description: Always `file_path`.
        text:
          type: string
          description: The text in the message content that needs to be replaced.
        file_path:
          type: object
          properties:
            file_id:
              type: string
              description: The ID of the file that was generated.
        start_index:
          minimum: 0
          type: integer
        end_index:
          minimum: 0
          type: integer
      description: A URL for the file that's generated when the assistant used the `code_interpreter` tool to generate a file.
    MessageDeltaContentTextObject:
      title: Text
      required:
        - index
        - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the content part in the message.
        type:
          enum:
            - text
          type: string
          description: Always `text`.
        text:
          type: object
          properties:
            value:
              type: string
              description: The data that makes up the text.
            annotations:
              type: array
              items:
                oneOf:
                  - $ref: '#/components/schemas/MessageDeltaContentTextAnnotationsFileCitationObject'
                  - $ref: '#/components/schemas/MessageDeltaContentTextAnnotationsFilePathObject'
                x-oaiExpandable: true
      description: The text content that is part of a message.
    MessageDeltaObject:
      title: Message delta object
      required:
        - id
        - object
        - delta
      type: object
      properties:
        id:
          type: string
          description: 'The identifier of the message, which can be referenced in API endpoints.'
        object:
          enum:
            - thread.message.delta
          type: string
          description: 'The object type, which is always `thread.message.delta`.'
        delta:
          type: object
          properties:
            role:
              enum:
                - user
                - assistant
              type: string
              description: The entity that produced the message. One of `user` or `assistant`.
            content:
              type: array
              items:
                oneOf:
                  - $ref: '#/components/schemas/MessageDeltaContentImageFileObject'
                  - $ref: '#/components/schemas/MessageDeltaContentTextObject'
                  - $ref: '#/components/schemas/MessageDeltaContentRefusalObject'
                  - $ref: '#/components/schemas/MessageDeltaContentImageUrlObject'
                x-oaiExpandable: true
              description: The content of the message in array of text and/or images.
          description: The delta containing the fields that have changed on the Message.
      description: "Represents a message delta i.e. any changed fields on a message during streaming.\n"
      x-oaiMeta:
        name: The message delta object
        beta: true
        example: "{\n  \"id\": \"msg_123\",\n  \"object\": \"thread.message.delta\",\n  \"delta\": {\n    \"content\": [\n      {\n        \"index\": 0,\n        \"type\": \"text\",\n        \"text\": { \"value\": \"Hello\", \"annotations\": [] }\n      }\n    ]\n  }\n}\n"
    MessageObject:
      title: The message object
      required:
        - id
        - object
        - created_at
        - thread_id
        - role
        - content
        - assistant_id
        - run_id
        - attachments
        - metadata
      type: object
      properties:
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints.'
        object:
          enum:
            - thread.message
          type: string
          description: 'The object type, which is always `thread.message`.'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the message was created.
        thread_id:
          type: string
          description: 'The [thread](/docs/api-reference/threads) ID that this message belongs to.'
        status:
          enum:
            - in_progress
            - incomplete
            - completed
          type: string
          description: 'The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.'
        incomplete_details:
          required:
            - reason
          type: object
          properties:
            reason:
              enum:
                - content_filter
                - max_tokens
                - run_cancelled
                - run_expired
                - run_failed
              type: string
              description: The reason the message is incomplete.
          description: 'On an incomplete message, details about why the message is incomplete.'
          nullable: true
        completed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the message was completed.
          nullable: true
        incomplete_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the message was marked as incomplete.
          nullable: true
        role:
          enum:
            - user
            - assistant
          type: string
          description: The entity that produced the message. One of `user` or `assistant`.
        content:
          type: array
          items:
            oneOf:
              - $ref: '#/components/schemas/MessageContentImageFileObject'
              - $ref: '#/components/schemas/MessageContentImageUrlObject'
              - $ref: '#/components/schemas/MessageContentTextObject'
              - $ref: '#/components/schemas/MessageContentRefusalObject'
            x-oaiExpandable: true
          description: The content of the message in array of text and/or images.
        assistant_id:
          type: string
          description: 'If applicable, the ID of the [assistant](/docs/api-reference/assistants) that authored this message.'
          nullable: true
        run_id:
          type: string
          description: 'The ID of the [run](/docs/api-reference/runs) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.'
          nullable: true
        attachments:
          type: array
          items:
            type: object
            properties:
              file_id:
                type: string
                description: The ID of the file to attach to the message.
              tools:
                type: array
                items:
                  oneOf:
                    - $ref: '#/components/schemas/AssistantToolsCode'
                    - $ref: '#/components/schemas/AssistantToolsFileSearchTypeOnly'
                  x-oaiExpandable: true
                description: The tools to add this file to.
          description: 'A list of files attached to the message, and the tools they were added to.'
          nullable: true
        metadata:
          type: object
          description: "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
          nullable: true
          x-oaiTypeLabel: map
      description: 'Represents a message within a [thread](/docs/api-reference/threads).'
      x-oaiMeta:
        name: The message object
        beta: true
        example: "{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\",\n  \"created_at\": 1698983503,\n  \"thread_id\": \"thread_abc123\",\n  \"role\": \"assistant\",\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"value\": \"Hi! How can I help you today?\",\n        \"annotations\": []\n      }\n    }\n  ],\n  \"assistant_id\": \"asst_abc123\",\n  \"run_id\": \"run_abc123\",\n  \"attachments\": [],\n  \"metadata\": {}\n}\n"
    MessageRequestContentTextObject:
      title: Text
      required:
        - type
        - text
      type: object
      properties:
        type:
          enum:
            - text
          type: string
          description: Always `text`.
        text:
          type: string
          description: Text content to be sent to the model
      description: The text content that is part of a message.
    MessageStreamEvent:
      oneOf:
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.message.created
              type: string
            data:
              $ref: '#/components/schemas/MessageObject'
          description: 'Occurs when a [message](/docs/api-reference/messages/object) is created.'
          x-oaiMeta:
            dataDescription: '`data` is a [message](/docs/api-reference/messages/object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.message.in_progress
              type: string
            data:
              $ref: '#/components/schemas/MessageObject'
          description: 'Occurs when a [message](/docs/api-reference/messages/object) moves to an `in_progress` state.'
          x-oaiMeta:
            dataDescription: '`data` is a [message](/docs/api-reference/messages/object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.message.delta
              type: string
            data:
              $ref: '#/components/schemas/MessageDeltaObject'
          description: 'Occurs when parts of a [Message](/docs/api-reference/messages/object) are being streamed.'
          x-oaiMeta:
            dataDescription: '`data` is a [message delta](/docs/api-reference/assistants-streaming/message-delta-object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.message.completed
              type: string
            data:
              $ref: '#/components/schemas/MessageObject'
          description: 'Occurs when a [message](/docs/api-reference/messages/object) is completed.'
          x-oaiMeta:
            dataDescription: '`data` is a [message](/docs/api-reference/messages/object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.message.incomplete
              type: string
            data:
              $ref: '#/components/schemas/MessageObject'
          description: 'Occurs when a [message](/docs/api-reference/messages/object) ends before it is completed.'
          x-oaiMeta:
            dataDescription: '`data` is a [message](/docs/api-reference/messages/object)'
    Model:
      title: Model
      required:
        - id
        - object
        - created
        - owned_by
      properties:
        id:
          type: string
          description: 'The model identifier, which can be referenced in the API endpoints.'
        created:
          type: integer
          description: The Unix timestamp (in seconds) when the model was created.
        object:
          enum:
            - model
          type: string
          description: 'The object type, which is always "model".'
        owned_by:
          type: string
          description: The organization that owns the model.
      description: Describes an OpenAI model offering that can be used with the API.
      x-oaiMeta:
        name: The model object
        example: "{\n  \"id\": \"VAR_chat_model_id\",\n  \"object\": \"model\",\n  \"created\": 1686935002,\n  \"owned_by\": \"openai\"\n}\n"
    ModifyAssistantRequest:
      type: object
      properties:
        model:
          anyOf:
            - type: string
          description: "ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.\n"
        name:
          maxLength: 256
          type: string
          description: "The name of the assistant. The maximum length is 256 characters.\n"
          nullable: true
        description:
          maxLength: 512
          type: string
          description: "The description of the assistant. The maximum length is 512 characters.\n"
          nullable: true
        instructions:
          maxLength: 256000
          type: string
          description: "The system instructions that the assistant uses. The maximum length is 256,000 characters.\n"
          nullable: true
        tools:
          maxItems: 128
          type: array
          items:
            oneOf:
              - $ref: '#/components/schemas/AssistantToolsCode'
              - $ref: '#/components/schemas/AssistantToolsFileSearch'
              - $ref: '#/components/schemas/AssistantToolsFunction'
            x-oaiExpandable: true
          description: "A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.\n"
        tool_resources:
          type: object
          properties:
            code_interpreter:
              type: object
              properties:
                file_ids:
                  maxItems: 20
                  type: array
                  items:
                    type: string
                  description: "Overrides the list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n"
            file_search:
              type: object
              properties:
                vector_store_ids:
                  maxItems: 1
                  type: array
                  items:
                    type: string
                  description: "Overrides the [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.\n"
          description: "A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n"
          nullable: true
        metadata:
          type: object
          description: "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
          nullable: true
          x-oaiTypeLabel: map
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n"
          default: 1
          nullable: true
          example: 1
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n"
          default: 1
          nullable: true
          example: 1
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
      additionalProperties: false
    ModifyMessageRequest:
      type: object
      properties:
        metadata:
          type: object
          description: "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
          nullable: true
          x-oaiTypeLabel: map
      additionalProperties: false
    ModifyRunRequest:
      type: object
      properties:
        metadata:
          type: object
          description: "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
          nullable: true
          x-oaiTypeLabel: map
      additionalProperties: false
    ModifyThreadRequest:
      type: object
      properties:
        tool_resources:
          type: object
          properties:
            code_interpreter:
              type: object
              properties:
                file_ids:
                  maxItems: 20
                  type: array
                  items:
                    type: string
                  description: "A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n"
            file_search:
              type: object
              properties:
                vector_store_ids:
                  maxItems: 1
                  type: array
                  items:
                    type: string
                  description: "The [vector store](/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.\n"
          description: "A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n"
          nullable: true
        metadata:
          type: object
          description: "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
          nullable: true
          x-oaiTypeLabel: map
      additionalProperties: false
    OpenAIFile:
      title: OpenAIFile
      required:
        - id
        - object
        - bytes
        - created_at
        - filename
        - purpose
        - status
      properties:
        id:
          type: string
          description: 'The file identifier, which can be referenced in the API endpoints.'
        bytes:
          type: integer
          description: 'The size of the file, in bytes.'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the file was created.
        filename:
          type: string
          description: The name of the file.
        object:
          enum:
            - file
          type: string
          description: 'The object type, which is always `file`.'
        purpose:
          enum:
            - assistants
            - assistants_output
            - batch
            - batch_output
            - fine-tune
            - fine-tune-results
            - vision
          type: string
          description: 'The intended purpose of the file. Supported values are `assistants`, `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results` and `vision`.'
        status:
          enum:
            - uploaded
            - processed
            - error
          type: string
          description: 'Deprecated. The current status of the file, which can be either `uploaded`, `processed`, or `error`.'
          deprecated: true
        status_details:
          type: string
          description: 'Deprecated. For details on why a fine-tuning training file failed validation, see the `error` field on `fine_tuning.job`.'
          deprecated: true
      description: The `File` object represents a document that has been uploaded to OpenAI.
      x-oaiMeta:
        name: The file object
        example: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"bytes\": 120000,\n  \"created_at\": 1677610602,\n  \"filename\": \"salesOverview.pdf\",\n  \"purpose\": \"assistants\",\n}\n"
    OtherChunkingStrategyResponseParam:
      title: Other Chunking Strategy
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - other
          type: string
          description: Always `other`.
      additionalProperties: false
      description: 'This is returned when the chunking strategy is unknown. Typically, this is because the file was indexed before the `chunking_strategy` concept was introduced in the API.'
    ParallelToolCalls:
      type: boolean
      description: 'Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.'
      nullable: true
    PredictionContent:
      title: Static Content
      required:
        - type
        - content
      type: object
      properties:
        type:
          enum:
            - content
          type: string
          description: "The type of the predicted content you want to provide. This type is\ncurrently always `content`.\n"
        content:
          oneOf:
            - title: Text content
              type: string
              description: "The content used for a Predicted Output. This is often the\ntext of a file you are regenerating with minor changes.\n"
            - title: Array of content parts
              minItems: 1
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
              description: 'An array of content parts with a defined type. Supported options differ based on the [model](/docs/models) being used to generate the response. Can contain text inputs.'
          description: "The content that should be matched when generating a model response.\nIf generated tokens would match this content, the entire model response\ncan be returned much more quickly.\n"
          x-oaiExpandable: true
      description: "Static predicted output content, such as the content of a text file that is\nbeing regenerated.\n"
    Project:
      required:
        - id
        - object
        - name
        - created_at
        - status
      type: object
      properties:
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints'
        object:
          enum:
            - organization.project
          type: string
          description: 'The object type, which is always `organization.project`'
        name:
          type: string
          description: The name of the project. This appears in reporting.
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the project was created.
        archived_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the project was archived or `null`.
          nullable: true
        status:
          enum:
            - active
            - archived
          type: string
          description: '`active` or `archived`'
      description: Represents an individual project.
      x-oaiMeta:
        name: The project object
        example: "{\n    \"id\": \"proj_abc\",\n    \"object\": \"organization.project\",\n    \"name\": \"Project example\",\n    \"created_at\": 1711471533,\n    \"archived_at\": null,\n    \"status\": \"active\"\n}\n"
    ProjectApiKey:
      required:
        - object
        - redacted_value
        - name
        - created_at
        - id
        - owner
      type: object
      properties:
        object:
          enum:
            - organization.project.api_key
          type: string
          description: 'The object type, which is always `organization.project.api_key`'
        redacted_value:
          type: string
          description: The redacted value of the API key
        name:
          type: string
          description: The name of the API key
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the API key was created
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints'
        owner:
          type: object
          properties:
            type:
              enum:
                - user
                - service_account
              type: string
              description: '`user` or `service_account`'
            user:
              $ref: '#/components/schemas/ProjectUser'
            service_account:
              $ref: '#/components/schemas/ProjectServiceAccount'
      description: Represents an individual API key in a project.
      x-oaiMeta:
        name: The project API key object
        example: "{\n    \"object\": \"organization.project.api_key\",\n    \"redacted_value\": \"sk-abc...def\",\n    \"name\": \"My API Key\",\n    \"created_at\": 1711471533,\n    \"id\": \"key_abc\",\n    \"owner\": {\n        \"type\": \"user\",\n        \"user\": {\n            \"object\": \"organization.project.user\",\n            \"id\": \"user_abc\",\n            \"name\": \"First Last\",\n            \"email\": \"user@example.com\",\n            \"role\": \"owner\",\n            \"created_at\": 1711471533\n        }\n    }\n}\n"
    ProjectApiKeyDeleteResponse:
      required:
        - object
        - id
        - deleted
      type: object
      properties:
        object:
          enum:
            - organization.project.api_key.deleted
          type: string
        id:
          type: string
        deleted:
          type: boolean
    ProjectApiKeyListResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        object:
          enum:
            - list
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/ProjectApiKey'
        first_id:
          type: string
        last_id:
          type: string
        has_more:
          type: boolean
    ProjectCreateRequest:
      required:
        - name
      type: object
      properties:
        name:
          type: string
          description: 'The friendly name of the project, this name appears in reports.'
    ProjectListResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        object:
          enum:
            - list
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/Project'
        first_id:
          type: string
        last_id:
          type: string
        has_more:
          type: boolean
    ProjectRateLimit:
      required:
        - object
        - id
        - model
        - max_requests_per_1_minute
        - max_tokens_per_1_minute
      type: object
      properties:
        object:
          enum:
            - project.rate_limit
          type: string
          description: 'The object type, which is always `project.rate_limit`'
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints.'
        model:
          type: string
          description: The model this rate limit applies to.
        max_requests_per_1_minute:
          type: integer
          description: The maximum requests per minute.
        max_tokens_per_1_minute:
          type: integer
          description: The maximum tokens per minute.
        max_images_per_1_minute:
          type: integer
          description: The maximum images per minute. Only present for relevant models.
        max_audio_megabytes_per_1_minute:
          type: integer
          description: The maximum audio megabytes per minute. Only present for relevant models.
        max_requests_per_1_day:
          type: integer
          description: The maximum requests per day. Only present for relevant models.
        batch_1_day_max_input_tokens:
          type: integer
          description: The maximum batch input tokens per day. Only present for relevant models.
      description: Represents a project rate limit config.
      x-oaiMeta:
        name: The project rate limit object
        example: "{\n    \"object\": \"project.rate_limit\",\n    \"id\": \"rl_ada\",\n    \"model\": \"ada\",\n    \"max_requests_per_1_minute\": 600,\n    \"max_tokens_per_1_minute\": 150000,\n    \"max_images_per_1_minute\": 10\n}\n"
    ProjectRateLimitListResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        object:
          enum:
            - list
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/ProjectRateLimit'
        first_id:
          type: string
        last_id:
          type: string
        has_more:
          type: boolean
    ProjectRateLimitUpdateRequest:
      type: object
      properties:
        max_requests_per_1_minute:
          type: integer
          description: The maximum requests per minute.
        max_tokens_per_1_minute:
          type: integer
          description: The maximum tokens per minute.
        max_images_per_1_minute:
          type: integer
          description: The maximum images per minute. Only relevant for certain models.
        max_audio_megabytes_per_1_minute:
          type: integer
          description: The maximum audio megabytes per minute. Only relevant for certain models.
        max_requests_per_1_day:
          type: integer
          description: The maximum requests per day. Only relevant for certain models.
        batch_1_day_max_input_tokens:
          type: integer
          description: The maximum batch input tokens per day. Only relevant for certain models.
    ProjectServiceAccount:
      required:
        - object
        - id
        - name
        - role
        - created_at
      type: object
      properties:
        object:
          enum:
            - organization.project.service_account
          type: string
          description: 'The object type, which is always `organization.project.service_account`'
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints'
        name:
          type: string
          description: The name of the service account
        role:
          enum:
            - owner
            - member
          type: string
          description: '`owner` or `member`'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the service account was created
      description: Represents an individual service account in a project.
      x-oaiMeta:
        name: The project service account object
        example: "{\n    \"object\": \"organization.project.service_account\",\n    \"id\": \"svc_acct_abc\",\n    \"name\": \"Service Account\",\n    \"role\": \"owner\",\n    \"created_at\": 1711471533\n}\n"
    ProjectServiceAccountApiKey:
      required:
        - object
        - value
        - name
        - created_at
        - id
      type: object
      properties:
        object:
          enum:
            - organization.project.service_account.api_key
          type: string
          description: 'The object type, which is always `organization.project.service_account.api_key`'
        value:
          type: string
        name:
          type: string
        created_at:
          type: integer
        id:
          type: string
    ProjectServiceAccountCreateRequest:
      required:
        - name
      type: object
      properties:
        name:
          type: string
          description: The name of the service account being created.
    ProjectServiceAccountCreateResponse:
      required:
        - object
        - id
        - name
        - role
        - created_at
        - api_key
      type: object
      properties:
        object:
          enum:
            - organization.project.service_account
          type: string
        id:
          type: string
        name:
          type: string
        role:
          enum:
            - member
          type: string
          description: Service accounts can only have one role of type `member`
        created_at:
          type: integer
        api_key:
          $ref: '#/components/schemas/ProjectServiceAccountApiKey'
    ProjectServiceAccountDeleteResponse:
      required:
        - object
        - id
        - deleted
      type: object
      properties:
        object:
          enum:
            - organization.project.service_account.deleted
          type: string
        id:
          type: string
        deleted:
          type: boolean
    ProjectServiceAccountListResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        object:
          enum:
            - list
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/ProjectServiceAccount'
        first_id:
          type: string
        last_id:
          type: string
        has_more:
          type: boolean
    ProjectUpdateRequest:
      required:
        - name
      type: object
      properties:
        name:
          type: string
          description: 'The updated name of the project, this name appears in reports.'
    ProjectUser:
      required:
        - object
        - id
        - name
        - email
        - role
        - added_at
      type: object
      properties:
        object:
          enum:
            - organization.project.user
          type: string
          description: 'The object type, which is always `organization.project.user`'
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints'
        name:
          type: string
          description: The name of the user
        email:
          type: string
          description: The email address of the user
        role:
          enum:
            - owner
            - member
          type: string
          description: '`owner` or `member`'
        added_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the project was added.
      description: Represents an individual user in a project.
      x-oaiMeta:
        name: The project user object
        example: "{\n    \"object\": \"organization.project.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\n"
    ProjectUserCreateRequest:
      required:
        - user_id
        - role
      type: object
      properties:
        user_id:
          type: string
          description: The ID of the user.
        role:
          enum:
            - owner
            - member
          type: string
          description: '`owner` or `member`'
    ProjectUserDeleteResponse:
      required:
        - object
        - id
        - deleted
      type: object
      properties:
        object:
          enum:
            - organization.project.user.deleted
          type: string
        id:
          type: string
        deleted:
          type: boolean
    ProjectUserListResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        object:
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/ProjectUser'
        first_id:
          type: string
        last_id:
          type: string
        has_more:
          type: boolean
    ProjectUserUpdateRequest:
      required:
        - role
      type: object
      properties:
        role:
          enum:
            - owner
            - member
          type: string
          description: '`owner` or `member`'
    RealtimeClientEventConversationItemCreate:
      required:
        - type
        - item
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        type:
          enum:
            - conversation.item.create
          type: string
          description: 'The event type, must be `conversation.item.create`.'
        previous_item_id:
          type: string
          description: "The ID of the preceding item after which the new item will be inserted. \nIf not set, the new item will be appended to the end of the conversation. \nIf set, it allows an item to be inserted mid-conversation. If the ID \ncannot be found, an error will be returned and the item will not be added.\n"
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
      description: "Add a new Item to the Conversation's context, including messages, function \ncalls, and function call responses. This event can be used both to populate a \n\"history\" of the conversation and to add new items mid-stream, but has the \ncurrent limitation that it cannot populate assistant audio messages.\n\nIf successful, the server will respond with a `conversation.item.created` \nevent, otherwise an `error` event will be sent.\n"
      x-oaiMeta:
        name: conversation.item.create
        group: realtime
        example: "{\n    \"event_id\": \"event_345\",\n    \"type\": \"conversation.item.create\",\n    \"previous_item_id\": null,\n    \"item\": {\n        \"id\": \"msg_001\",\n        \"type\": \"message\",\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"input_text\",\n                \"text\": \"Hello, how are you?\"\n            }\n        ]\n    }\n}\n"
    RealtimeClientEventConversationItemDelete:
      required:
        - type
        - item_id
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        type:
          enum:
            - conversation.item.delete
          type: string
          description: 'The event type, must be `conversation.item.delete`.'
        item_id:
          type: string
          description: The ID of the item to delete.
      description: "Send this event when you want to remove any item from the conversation \nhistory. The server will respond with a `conversation.item.deleted` event, \nunless the item does not exist in the conversation history, in which case the \nserver will respond with an error.\n"
      x-oaiMeta:
        name: conversation.item.delete
        group: realtime
        example: "{\n    \"event_id\": \"event_901\",\n    \"type\": \"conversation.item.delete\",\n    \"item_id\": \"msg_003\"\n}\n"
    RealtimeClientEventConversationItemTruncate:
      required:
        - type
        - item_id
        - content_index
        - audio_end_ms
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        type:
          enum:
            - conversation.item.truncate
          type: string
          description: 'The event type, must be `conversation.item.truncate`.'
        item_id:
          type: string
          description: "The ID of the assistant message item to truncate. Only assistant message \nitems can be truncated.\n"
        content_index:
          type: integer
          description: The index of the content part to truncate. Set this to 0.
        audio_end_ms:
          type: integer
          description: "Inclusive duration up to which audio is truncated, in milliseconds. If \nthe audio_end_ms is greater than the actual audio duration, the server \nwill respond with an error.\n"
      description: "Send this event to truncate a previous assistant message’s audio. The server \nwill produce audio faster than realtime, so this event is useful when the user \ninterrupts to truncate audio that has already been sent to the client but not \nyet played. This will synchronize the server's understanding of the audio with \nthe client's playback.\n\nTruncating audio will delete the server-side text transcript to ensure there \nis not text in the context that hasn't been heard by the user.\n\nIf successful, the server will respond with a `conversation.item.truncated` \nevent. \n"
      x-oaiMeta:
        name: conversation.item.truncate
        group: realtime
        example: "{\n    \"event_id\": \"event_678\",\n    \"type\": \"conversation.item.truncate\",\n    \"item_id\": \"msg_002\",\n    \"content_index\": 0,\n    \"audio_end_ms\": 1500\n}\n"
    RealtimeClientEventInputAudioBufferAppend:
      required:
        - type
        - audio
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        type:
          enum:
            - input_audio_buffer.append
          type: string
          description: 'The event type, must be `input_audio_buffer.append`.'
        audio:
          type: string
          description: "Base64-encoded audio bytes. This must be in the format specified by the \n`input_audio_format` field in the session configuration.\n"
      description: "Send this event to append audio bytes to the input audio buffer. The audio \nbuffer is temporary storage you can write to and later commit. In Server VAD \nmode, the audio buffer is used to detect speech and the server will decide \nwhen to commit. When Server VAD is disabled, you must commit the audio buffer\nmanually.\n\nThe client may choose how much audio to place in each event up to a maximum \nof 15 MiB, for example streaming smaller chunks from the client may allow the \nVAD to be more responsive. Unlike made other client events, the server will \nnot send a confirmation response to this event.\n"
      x-oaiMeta:
        name: input_audio_buffer.append
        group: realtime
        example: "{\n    \"event_id\": \"event_456\",\n    \"type\": \"input_audio_buffer.append\",\n    \"audio\": \"Base64EncodedAudioData\"\n}\n"
    RealtimeClientEventInputAudioBufferClear:
      required:
        - type
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        type:
          enum:
            - input_audio_buffer.clear
          type: string
          description: 'The event type, must be `input_audio_buffer.clear`.'
      description: "Send this event to clear the audio bytes in the buffer. The server will \nrespond with an `input_audio_buffer.cleared` event.\n"
      x-oaiMeta:
        name: input_audio_buffer.clear
        group: realtime
        example: "{\n    \"event_id\": \"event_012\",\n    \"type\": \"input_audio_buffer.clear\"\n}\n"
    RealtimeClientEventInputAudioBufferCommit:
      required:
        - type
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        type:
          enum:
            - input_audio_buffer.commit
          type: string
          description: 'The event type, must be `input_audio_buffer.commit`.'
      description: "Send this event to commit the user input audio buffer, which will create a \nnew user message item in the conversation. This event will produce an error \nif the input audio buffer is empty. When in Server VAD mode, the client does \nnot need to send this event, the server will commit the audio buffer \nautomatically.\n\nCommitting the input audio buffer will trigger input audio transcription \n(if enabled in session configuration), but it will not create a response \nfrom the model. The server will respond with an `input_audio_buffer.committed` \nevent.\n"
      x-oaiMeta:
        name: input_audio_buffer.commit
        group: realtime
        example: "{\n    \"event_id\": \"event_789\",\n    \"type\": \"input_audio_buffer.commit\"\n}\n"
    RealtimeClientEventResponseCancel:
      required:
        - type
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        type:
          enum:
            - response.cancel
          type: string
          description: 'The event type, must be `response.cancel`.'
      description: "Send this event to cancel an in-progress response. The server will respond \nwith a `response.cancelled` event or an error if there is no response to \ncancel.\n"
      x-oaiMeta:
        name: response.cancel
        group: realtime
        example: "{\n    \"event_id\": \"event_567\",\n    \"type\": \"response.cancel\"\n}\n"
    RealtimeClientEventResponseCreate:
      required:
        - type
        - response
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        type:
          enum:
            - response.create
          type: string
          description: 'The event type, must be `response.create`.'
        response:
          $ref: '#/components/schemas/RealtimeSession'
      description: "This event instructs the server to create a Response, which means triggering \nmodel inference. When in Server VAD mode, the server will create Responses \nautomatically.\n\nA Response will include at least one Item, and may have two, in which case \nthe second will be a function call. These Items will be appended to the \nconversation history.\n\nThe server will respond with a `response.created` event, events for Items \nand content created, and finally a `response.done` event to indicate the \nResponse is complete.\n\nThe `response.create` event includes inference configuration like \n`instructions`, and `temperature`. These fields will override the Session's \nconfiguration for this Response only.\n"
      x-oaiMeta:
        name: response.create
        group: realtime
        example: "{\n    \"event_id\": \"event_234\",\n    \"type\": \"response.create\",\n    \"response\": {\n        \"modalities\": [\"text\", \"audio\"],\n        \"instructions\": \"Please assist the user.\",\n        \"voice\": \"sage\",\n        \"output_audio_format\": \"pcm16\",\n        \"tools\": [\n            {\n                \"type\": \"function\",\n                \"name\": \"calculate_sum\",\n                \"description\": \"Calculates the sum of two numbers.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"a\": { \"type\": \"number\" },\n                        \"b\": { \"type\": \"number\" }\n                    },\n                    \"required\": [\"a\", \"b\"]\n                }\n            }\n        ],\n        \"tool_choice\": \"auto\",\n        \"temperature\": 0.7,\n        \"max_output_tokens\": 150\n    }\n}\n"
    RealtimeClientEventSessionUpdate:
      required:
        - type
        - session
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        type:
          enum:
            - session.update
          type: string
          description: 'The event type, must be `session.update`.'
        session:
          $ref: '#/components/schemas/RealtimeSession'
      description: "Send this event to update the session’s default configuration. The client may \nsend this event at any time to update the session configuration, and any \nfield may be updated at any time, except for \"voice\". The server will respond \nwith a `session.updated` event that shows the full effective configuration. \nOnly fields that are present are updated, thus the correct way to clear a \nfield like \"instructions\" is to pass an empty string.\n"
      x-oaiMeta:
        name: session.update
        group: realtime
        example: "{\n    \"event_id\": \"event_123\",\n    \"type\": \"session.update\",\n    \"session\": {\n        \"modalities\": [\"text\", \"audio\"],\n        \"instructions\": \"You are a helpful assistant.\",\n        \"voice\": \"sage\",\n        \"input_audio_format\": \"pcm16\",\n        \"output_audio_format\": \"pcm16\",\n        \"input_audio_transcription\": {\n            \"model\": \"whisper-1\"\n        },\n        \"turn_detection\": {\n            \"type\": \"server_vad\",\n            \"threshold\": 0.5,\n            \"prefix_padding_ms\": 300,\n            \"silence_duration_ms\": 500\n        },\n        \"tools\": [\n            {\n                \"type\": \"function\",\n                \"name\": \"get_weather\",\n                \"description\": \"Get the current weather...\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"location\": { \"type\": \"string\" }\n                    },\n                    \"required\": [\"location\"]\n                }\n            }\n        ],\n        \"tool_choice\": \"auto\",\n        \"temperature\": 0.8,\n        \"max_response_output_tokens\": \"inf\"\n    }\n}\n"
    RealtimeConversationItem:
      type: object
      properties:
        id:
          type: string
          description: The unique ID of the item.
          example: msg_003
        object:
          enum:
            - realtime.item
          type: string
          description: 'The object type, must be "realtime.item".'
          example: realtime.item
        type:
          enum:
            - message
            - function_call
            - function_call_output
          type: string
          description: The type of the item.
          example: message
        status:
          enum:
            - completed
            - in_progress
            - incomplete
          type: string
          description: The status of the item.
          example: completed
        role:
          enum:
            - user
            - assistant
            - system
          type: string
          description: The role of the message sender.
          example: user
        content:
          type: array
          items:
            type: object
            properties:
              type:
                enum:
                  - input_text
                  - input_audio
                  - text
                  - audio
                type: string
                description: The content type.
                example: input_text
              text:
                type: string
                description: The text content (for text or input_text items).
                example: 'Hello, how are you?'
              audio:
                type: string
                description: Base64-encoded audio bytes (for audio or input_audio items).
              transcript:
                type: string
                description: The transcript of the audio (for audio items).
              call_id:
                type: string
                description: The ID of the function call (for function_call items).
              name:
                type: string
                description: The name of the function being called (for function_call items).
              arguments:
                type: string
                description: The arguments of the function call (for function_call items).
              output:
                type: string
                description: The output of the function call (for function_call_output items).
          description: The content of the message.
      description: "A realtime Item is of three types: message, function_call, or function_call_output.\n\nA message item can contain text or audio.\nA function_call item indicates a model's desire to call a function, which is the only tool supported for now\nA function_call_output item indicates a function response.\nThe client may add and remove message and function_call_output Items using conversation.item.create and conversation.item.delete.\n"
    RealtimeResponse:
      type: object
      properties:
        id:
          type: string
          description: The unique ID of the response.
          example: resp_001
        object:
          enum:
            - realtime.response
          type: string
          description: 'The object type, must be "realtime.response".'
          example: realtime.response
        status:
          enum:
            - completed
            - in_progress
            - cancelled
            - failed
            - incomplete
          type: string
          description: The status of the response.
          example: in_progress
        status_details:
          type: object
          description: Additional details about the status.
          example: 
        output:
          type: array
          items:
            $ref: '#/components/schemas/RealtimeConversationItem'
          description: The list of output items generated by the response.
        usage:
          type: object
          properties:
            total_tokens:
              type: integer
              description: The total number of tokens used.
              example: 50
            input_tokens:
              type: integer
              description: The number of input tokens used.
              example: 20
            output_tokens:
              type: integer
              description: The number of output tokens used.
              example: 30
          description: Usage statistics for the response.
      description: The response resource.
    RealtimeServerEventConversationCreated:
      required:
        - event_id
        - type
        - conversation
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - conversation.created
          type: string
          description: 'The event type, must be `conversation.created`.'
        conversation:
          type: object
          properties:
            id:
              type: string
              description: The unique ID of the conversation.
            object:
              type: string
              description: 'The object type, must be `realtime.conversation`.'
          description: The conversation resource.
      description: "Returned when a conversation is created. Emitted right after session creation.\n"
      x-oaiMeta:
        name: conversation.created
        group: realtime
        example: "{\n    \"event_id\": \"event_9101\",\n    \"type\": \"conversation.created\",\n    \"conversation\": {\n        \"id\": \"conv_001\",\n        \"object\": \"realtime.conversation\"\n    }\n}\n"
    RealtimeServerEventConversationItemCreated:
      required:
        - event_id
        - type
        - previous_item_id
        - item
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - conversation.item.created
          type: string
          description: 'The event type, must be `conversation.item.created`.'
        previous_item_id:
          type: string
          description: "The ID of the preceding item in the Conversation context, allows the \nclient to understand the order of the conversation.\n"
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
      description: "Returned when a conversation item is created. There are several scenarios that \nproduce this event:\n  - The server is generating a Response, which if successful will produce \n    either one or two Items, which will be of type `message` \n    (role `assistant`) or type `function_call`.\n  - The input audio buffer has been committed, either by the client or the \n    server (in `server_vad` mode). The server will take the content of the \n    input audio buffer and add it to a new user message Item.\n  - The client has sent a `conversation.item.create` event to add a new Item \n    to the Conversation.\n"
      x-oaiMeta:
        name: conversation.item.created
        group: realtime
        example: "{\n    \"event_id\": \"event_1920\",\n    \"type\": \"conversation.item.created\",\n    \"previous_item_id\": \"msg_002\",\n    \"item\": {\n        \"id\": \"msg_003\",\n        \"object\": \"realtime.item\",\n        \"type\": \"message\",\n        \"status\": \"completed\",\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"input_audio\",\n                \"transcript\": \"hello how are you\",\n                \"audio\": \"base64encodedaudio==\"\n            }\n        ]\n    }\n}\n"
    RealtimeServerEventConversationItemDeleted:
      required:
        - event_id
        - type
        - item_id
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - conversation.item.deleted
          type: string
          description: 'The event type, must be `conversation.item.deleted`.'
        item_id:
          type: string
          description: The ID of the item that was deleted.
      description: "Returned when an item in the conversation is deleted by the client with a \n`conversation.item.delete` event. This event is used to synchronize the \nserver's understanding of the conversation history with the client's view.\n"
      x-oaiMeta:
        name: conversation.item.deleted
        group: realtime
        example: "{\n    \"event_id\": \"event_2728\",\n    \"type\": \"conversation.item.deleted\",\n    \"item_id\": \"msg_005\"\n}\n"
    RealtimeServerEventConversationItemInputAudioTranscriptionCompleted:
      required:
        - event_id
        - type
        - item_id
        - content_index
        - transcript
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - conversation.item.input_audio_transcription.completed
          type: string
          description: "The event type, must be\n`conversation.item.input_audio_transcription.completed`.\n"
        item_id:
          type: string
          description: The ID of the user message item containing the audio.
        content_index:
          type: integer
          description: The index of the content part containing the audio.
        transcript:
          type: string
          description: The transcribed text.
      description: "This event is the output of audio transcription for user audio written to the \nuser audio buffer. Transcription begins when the input audio buffer is \ncommitted by the client or server (in `server_vad` mode). Transcription runs \nasynchronously with Response creation, so this event may come before or after \nthe Response events.\n\nRealtime API models accept audio natively, and thus input transcription is a \nseparate process run on a separate ASR (Automatic Speech Recognition) model, \ncurrently always `whisper-1`. Thus the transcript may diverge somewhat from \nthe model's interpretation, and should be treated as a rough guide.\n"
      x-oaiMeta:
        name: conversation.item.input_audio_transcription.completed
        group: realtime
        example: "{\n    \"event_id\": \"event_2122\",\n    \"type\": \"conversation.item.input_audio_transcription.completed\",\n    \"item_id\": \"msg_003\",\n    \"content_index\": 0,\n    \"transcript\": \"Hello, how are you?\"\n}\n"
    RealtimeServerEventConversationItemInputAudioTranscriptionFailed:
      required:
        - event_id
        - type
        - item_id
        - content_index
        - error
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - conversation.item.input_audio_transcription.failed
          type: string
          description: "The event type, must be\n`conversation.item.input_audio_transcription.failed`.\n"
        item_id:
          type: string
          description: The ID of the user message item.
        content_index:
          type: integer
          description: The index of the content part containing the audio.
        error:
          type: object
          properties:
            type:
              type: string
              description: The type of error.
            code:
              type: string
              description: 'Error code, if any.'
            message:
              type: string
              description: A human-readable error message.
            param:
              type: string
              description: 'Parameter related to the error, if any.'
          description: Details of the transcription error.
      description: "Returned when input audio transcription is configured, and a transcription \nrequest for a user message failed. These events are separate from other \n`error` events so that the client can identify the related Item.\n"
      x-oaiMeta:
        name: conversation.item.input_audio_transcription.failed
        group: realtime
        example: "{\n    \"event_id\": \"event_2324\",\n    \"type\": \"conversation.item.input_audio_transcription.failed\",\n    \"item_id\": \"msg_003\",\n    \"content_index\": 0,\n    \"error\": {\n        \"type\": \"transcription_error\",\n        \"code\": \"audio_unintelligible\",\n        \"message\": \"The audio could not be transcribed.\",\n        \"param\": null\n    }\n}\n"
    RealtimeServerEventConversationItemTruncated:
      required:
        - event_id
        - type
        - item_id
        - content_index
        - audio_end_ms
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - conversation.item.truncated
          type: string
          description: 'The event type, must be `conversation.item.truncated`.'
        item_id:
          type: string
          description: The ID of the assistant message item that was truncated.
        content_index:
          type: integer
          description: The index of the content part that was truncated.
        audio_end_ms:
          type: integer
          description: "The duration up to which the audio was truncated, in milliseconds.\n"
      description: "Returned when an earlier assistant audio message item is truncated by the \nclient with a `conversation.item.truncate` event. This event is used to \nsynchronize the server's understanding of the audio with the client's playback.\n\nThis action will truncate the audio and remove the server-side text transcript \nto ensure there is no text in the context that hasn't been heard by the user.\n"
      x-oaiMeta:
        name: conversation.item.truncated
        group: realtime
        example: "{\n    \"event_id\": \"event_2526\",\n    \"type\": \"conversation.item.truncated\",\n    \"item_id\": \"msg_004\",\n    \"content_index\": 0,\n    \"audio_end_ms\": 1500\n}\n"
    RealtimeServerEventError:
      required:
        - event_id
        - type
        - error
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - error
          type: string
          description: 'The event type, must be `error`.'
        error:
          type: object
          properties:
            type:
              type: string
              description: "The type of error (e.g., \"invalid_request_error\", \"server_error\").\n"
            code:
              type: string
              description: 'Error code, if any.'
            message:
              type: string
              description: A human-readable error message.
            param:
              type: string
              description: 'Parameter related to the error, if any.'
            event_id:
              type: string
              description: "The event_id of the client event that caused the error, if applicable.\n"
          description: Details of the error.
      description: "Returned when an error occurs, which could be a client problem or a server \nproblem. Most errors are recoverable and the session will stay open, we \nrecommend to implementors to monitor and log error messages by default.\n"
      x-oaiMeta:
        name: error
        group: realtime
        example: "{\n    \"event_id\": \"event_890\",\n    \"type\": \"error\",\n    \"error\": {\n        \"type\": \"invalid_request_error\",\n        \"code\": \"invalid_event\",\n        \"message\": \"The 'type' field is missing.\",\n        \"param\": null,\n        \"event_id\": \"event_567\"\n    }\n}\n"
    RealtimeServerEventInputAudioBufferCleared:
      required:
        - event_id
        - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - input_audio_buffer.cleared
          type: string
          description: 'The event type, must be `input_audio_buffer.cleared`.'
      description: "Returned when the input audio buffer is cleared by the client with a \n`input_audio_buffer.clear` event.\n"
      x-oaiMeta:
        name: input_audio_buffer.cleared
        group: realtime
        example: "{\n    \"event_id\": \"event_1314\",\n    \"type\": \"input_audio_buffer.cleared\"\n}\n"
    RealtimeServerEventInputAudioBufferCommitted:
      required:
        - event_id
        - type
        - previous_item_id
        - item_id
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - input_audio_buffer.committed
          type: string
          description: 'The event type, must be `input_audio_buffer.committed`.'
        previous_item_id:
          type: string
          description: "The ID of the preceding item after which the new item will be inserted.\n"
        item_id:
          type: string
          description: The ID of the user message item that will be created.
      description: "Returned when an input audio buffer is committed, either by the client or \nautomatically in server VAD mode. The `item_id` property is the ID of the user\nmessage item that will be created, thus a `conversation.item.created` event \nwill also be sent to the client.\n"
      x-oaiMeta:
        name: input_audio_buffer.committed
        group: realtime
        example: "{\n    \"event_id\": \"event_1121\",\n    \"type\": \"input_audio_buffer.committed\",\n    \"previous_item_id\": \"msg_001\",\n    \"item_id\": \"msg_002\"\n}\n"
    RealtimeServerEventInputAudioBufferSpeechStarted:
      required:
        - event_id
        - type
        - audio_start_ms
        - item_id
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - input_audio_buffer.speech_started
          type: string
          description: 'The event type, must be `input_audio_buffer.speech_started`.'
        audio_start_ms:
          type: integer
          description: "Milliseconds from the start of all audio written to the buffer during the \nsession when speech was first detected. This will correspond to the \nbeginning of audio sent to the model, and thus includes the \n`prefix_padding_ms` configured in the Session.\n"
        item_id:
          type: string
          description: "The ID of the user message item that will be created when speech stops.\n"
      description: "Sent by the server when in `server_vad` mode to indicate that speech has been \ndetected in the audio buffer. This can happen any time audio is added to the \nbuffer (unless speech is already detected). The client may want to use this \nevent to interrupt audio playback or provide visual feedback to the user. \n\nThe client should expect to receive a `input_audio_buffer.speech_stopped` event \nwhen speech stops. The `item_id` property is the ID of the user message item \nthat will be created when speech stops and will also be included in the \n`input_audio_buffer.speech_stopped` event (unless the client manually commits \nthe audio buffer during VAD activation).\n"
      x-oaiMeta:
        name: input_audio_buffer.speech_started
        group: realtime
        example: "{\n    \"event_id\": \"event_1516\",\n    \"type\": \"input_audio_buffer.speech_started\",\n    \"audio_start_ms\": 1000,\n    \"item_id\": \"msg_003\"\n}\n"
    RealtimeServerEventInputAudioBufferSpeechStopped:
      required:
        - event_id
        - type
        - audio_end_ms
        - item_id
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - input_audio_buffer.speech_stopped
          type: string
          description: 'The event type, must be `input_audio_buffer.speech_stopped`.'
        audio_end_ms:
          type: integer
          description: "Milliseconds since the session started when speech stopped. This will \ncorrespond to the end of audio sent to the model, and thus includes the \n`min_silence_duration_ms` configured in the Session.\n"
        item_id:
          type: string
          description: The ID of the user message item that will be created.
      description: "Returned in `server_vad` mode when the server detects the end of speech in \nthe audio buffer. The server will also send an `conversation.item.created` \nevent with the user message item that is created from the audio buffer.\n"
      x-oaiMeta:
        name: input_audio_buffer.speech_stopped
        group: realtime
        example: "{\n    \"event_id\": \"event_1718\",\n    \"type\": \"input_audio_buffer.speech_stopped\",\n    \"audio_end_ms\": 2000,\n    \"item_id\": \"msg_003\"\n}\n"
    RealtimeServerEventRateLimitsUpdated:
      required:
        - event_id
        - type
        - rate_limits
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - rate_limits.updated
          type: string
          description: 'The event type, must be `rate_limits.updated`.'
        rate_limits:
          type: array
          items:
            type: object
            properties:
              name:
                type: string
                description: 'The name of the rate limit (`requests`, `tokens`).'
              limit:
                type: integer
                description: The maximum allowed value for the rate limit.
              remaining:
                type: integer
                description: The remaining value before the limit is reached.
              reset_seconds:
                type: number
                description: Seconds until the rate limit resets.
          description: List of rate limit information.
      description: "Emitted at the beginning of a Response to indicate the updated rate limits. \nWhen a Response is created some tokens will be \"reserved\" for the output \ntokens, the rate limits shown here reflect that reservation, which is then \nadjusted accordingly once the Response is completed.\n"
      x-oaiMeta:
        name: rate_limits.updated
        group: realtime
        example: "{\n    \"event_id\": \"event_5758\",\n    \"type\": \"rate_limits.updated\",\n    \"rate_limits\": [\n        {\n            \"name\": \"requests\",\n            \"limit\": 1000,\n            \"remaining\": 999,\n            \"reset_seconds\": 60\n        },\n        {\n            \"name\": \"tokens\",\n            \"limit\": 50000,\n            \"remaining\": 49950,\n            \"reset_seconds\": 60\n        }\n    ]\n}\n"
    RealtimeServerEventResponseAudioDelta:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - content_index
        - delta
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - response.audio.delta
          type: string
          description: 'The event type, must be `response.audio.delta`.'
        response_id:
          type: string
          description: The ID of the response.
        item_id:
          type: string
          description: The ID of the item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
        delta:
          type: string
          description: Base64-encoded audio data delta.
      description: Returned when the model-generated audio is updated.
      x-oaiMeta:
        name: response.audio.delta
        group: realtime
        example: "{\n    \"event_id\": \"event_4950\",\n    \"type\": \"response.audio.delta\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_008\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"delta\": \"Base64EncodedAudioDelta\"\n}\n"
    RealtimeServerEventResponseAudioDone:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - content_index
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - response.audio.done
          type: string
          description: 'The event type, must be `response.audio.done`.'
        response_id:
          type: string
          description: The ID of the response.
        item_id:
          type: string
          description: The ID of the item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
      description: "Returned when the model-generated audio is done. Also emitted when a Response\nis interrupted, incomplete, or cancelled.\n"
      x-oaiMeta:
        name: response.audio.done
        group: realtime
        example: "{\n    \"event_id\": \"event_5152\",\n    \"type\": \"response.audio.done\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_008\",\n    \"output_index\": 0,\n    \"content_index\": 0\n}\n"
    RealtimeServerEventResponseAudioTranscriptDelta:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - content_index
        - delta
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - response.audio_transcript.delta
          type: string
          description: 'The event type, must be `response.audio_transcript.delta`.'
        response_id:
          type: string
          description: The ID of the response.
        item_id:
          type: string
          description: The ID of the item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
        delta:
          type: string
          description: The transcript delta.
      description: "Returned when the model-generated transcription of audio output is updated.\n"
      x-oaiMeta:
        name: response.audio_transcript.delta
        group: realtime
        example: "{\n    \"event_id\": \"event_4546\",\n    \"type\": \"response.audio_transcript.delta\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_008\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"delta\": \"Hello, how can I a\"\n}\n"
    RealtimeServerEventResponseAudioTranscriptDone:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - content_index
        - transcript
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - response.audio_transcript.done
          type: string
          description: 'The event type, must be `response.audio_transcript.done`.'
        response_id:
          type: string
          description: The ID of the response.
        item_id:
          type: string
          description: The ID of the item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
        transcript:
          type: string
          description: The final transcript of the audio.
      description: "Returned when the model-generated transcription of audio output is done\nstreaming. Also emitted when a Response is interrupted, incomplete, or\ncancelled.\n"
      x-oaiMeta:
        name: response.audio_transcript.done
        group: realtime
        example: "{\n    \"event_id\": \"event_4748\",\n    \"type\": \"response.audio_transcript.done\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_008\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"transcript\": \"Hello, how can I assist you today?\"\n}\n"
    RealtimeServerEventResponseContentPartAdded:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - content_index
        - part
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - response.content_part.added
          type: string
          description: 'The event type, must be `response.content_part.added`.'
        response_id:
          type: string
          description: The ID of the response.
        item_id:
          type: string
          description: The ID of the item to which the content part was added.
        output_index:
          type: integer
          description: The index of the output item in the response.
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
        part:
          type: object
          properties:
            type:
              enum:
                - audio
                - text
              type: string
              description: 'The content type ("text", "audio").'
            text:
              type: string
              description: The text content (if type is "text").
            audio:
              type: string
              description: Base64-encoded audio data (if type is "audio").
            transcript:
              type: string
              description: The transcript of the audio (if type is "audio").
          description: The content part that was added.
      description: "Returned when a new content part is added to an assistant message item during\nresponse generation.\n"
      x-oaiMeta:
        name: response.content_part.added
        group: realtime
        example: "{\n    \"event_id\": \"event_3738\",\n    \"type\": \"response.content_part.added\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_007\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"part\": {\n        \"type\": \"text\",\n        \"text\": \"\"\n    }\n}\n"
    RealtimeServerEventResponseContentPartDone:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - content_index
        - part
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - response.content_part.done
          type: string
          description: 'The event type, must be `response.content_part.done`.'
        response_id:
          type: string
          description: The ID of the response.
        item_id:
          type: string
          description: The ID of the item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
        part:
          type: object
          properties:
            type:
              type: string
              description: 'The content type ("text", "audio").'
            text:
              type: string
              description: The text content (if type is "text").
            audio:
              type: string
              description: Base64-encoded audio data (if type is "audio").
            transcript:
              type: string
              description: The transcript of the audio (if type is "audio").
          description: The content part that is done.
      description: "Returned when a content part is done streaming in an assistant message item.\nAlso emitted when a Response is interrupted, incomplete, or cancelled.\n"
      x-oaiMeta:
        name: response.content_part.done
        group: realtime
        example: "{\n    \"event_id\": \"event_3940\",\n    \"type\": \"response.content_part.done\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_007\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"part\": {\n        \"type\": \"text\",\n        \"text\": \"Sure, I can help with that.\"\n    }\n}\n"
    RealtimeServerEventResponseCreated:
      required:
        - event_id
        - type
        - response
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - response.created
          type: string
          description: 'The event type, must be `response.created`.'
        response:
          $ref: '#/components/schemas/RealtimeResponse'
      description: "Returned when a new Response is created. The first event of response creation,\nwhere the response is in an initial state of `in_progress`.\n"
      x-oaiMeta:
        name: response.created
        group: realtime
        example: "{\n    \"event_id\": \"event_2930\",\n    \"type\": \"response.created\",\n    \"response\": {\n        \"id\": \"resp_001\",\n        \"object\": \"realtime.response\",\n        \"status\": \"in_progress\",\n        \"status_details\": null,\n        \"output\": [],\n        \"usage\": null\n    }\n}\n"
    RealtimeServerEventResponseDone:
      required:
        - event_id
        - type
        - response
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - response.done
          type: string
          description: 'The event type, must be `response.done`.'
        response:
          $ref: '#/components/schemas/RealtimeResponse'
      description: "Returned when a Response is done streaming. Always emitted, no matter the \nfinal state. The Response object included in the `response.done` event will \ninclude all output Items in the Response but will omit the raw audio data.\n"
      x-oaiMeta:
        name: response.done
        group: realtime
        example: "{\n    \"event_id\": \"event_3132\",\n    \"type\": \"response.done\",\n    \"response\": {\n        \"id\": \"resp_001\",\n        \"object\": \"realtime.response\",\n        \"status\": \"completed\",\n        \"status_details\": null,\n        \"output\": [\n            {\n                \"id\": \"msg_006\",\n                \"object\": \"realtime.item\",\n                \"type\": \"message\",\n                \"status\": \"completed\",\n                \"role\": \"assistant\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"Sure, how can I assist you today?\"\n                    }\n                ]\n            }\n        ],\n        \"usage\": {\n            \"total_tokens\":275,\n            \"input_tokens\":127,\n            \"output_tokens\":148,\n            \"input_token_details\": {\n                \"cached_tokens\":384,\n                \"text_tokens\":119,\n                \"audio_tokens\":8,\n                \"cached_tokens_details\": {\n                    \"text_tokens\": 128,\n                    \"audio_tokens\": 256\n                }\n            },\n            \"output_token_details\": {\n              \"text_tokens\":36,\n              \"audio_tokens\":112\n            }\n        }\n    }\n}\n"
    RealtimeServerEventResponseFunctionCallArgumentsDelta:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - call_id
        - delta
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - response.function_call_arguments.delta
          type: string
          description: "The event type, must be `response.function_call_arguments.delta`.\n"
        response_id:
          type: string
          description: The ID of the response.
        item_id:
          type: string
          description: The ID of the function call item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        call_id:
          type: string
          description: The ID of the function call.
        delta:
          type: string
          description: The arguments delta as a JSON string.
      description: "Returned when the model-generated function call arguments are updated.\n"
      x-oaiMeta:
        name: response.function_call_arguments.delta
        group: realtime
        example: "{\n    \"event_id\": \"event_5354\",\n    \"type\": \"response.function_call_arguments.delta\",\n    \"response_id\": \"resp_002\",\n    \"item_id\": \"fc_001\",\n    \"output_index\": 0,\n    \"call_id\": \"call_001\",\n    \"delta\": \"{\\\"location\\\": \\\"San\\\"\"\n}\n"
    RealtimeServerEventResponseFunctionCallArgumentsDone:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - call_id
        - arguments
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - response.function_call_arguments.done
          type: string
          description: "The event type, must be `response.function_call_arguments.done`.\n"
        response_id:
          type: string
          description: The ID of the response.
        item_id:
          type: string
          description: The ID of the function call item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        call_id:
          type: string
          description: The ID of the function call.
        arguments:
          type: string
          description: The final arguments as a JSON string.
      description: "Returned when the model-generated function call arguments are done streaming.\nAlso emitted when a Response is interrupted, incomplete, or cancelled.\n"
      x-oaiMeta:
        name: response.function_call_arguments.done
        group: realtime
        example: "{\n    \"event_id\": \"event_5556\",\n    \"type\": \"response.function_call_arguments.done\",\n    \"response_id\": \"resp_002\",\n    \"item_id\": \"fc_001\",\n    \"output_index\": 0,\n    \"call_id\": \"call_001\",\n    \"arguments\": \"{\\\"location\\\": \\\"San Francisco\\\"}\"\n}\n"
    RealtimeServerEventResponseOutputItemAdded:
      required:
        - event_id
        - type
        - response_id
        - output_index
        - item
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - response.output_item.added
          type: string
          description: 'The event type, must be `response.output_item.added`.'
        response_id:
          type: string
          description: The ID of the Response to which the item belongs.
        output_index:
          type: integer
          description: The index of the output item in the Response.
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
      description: Returned when a new Item is created during Response generation.
      x-oaiMeta:
        name: response.output_item.added
        group: realtime
        example: "{\n    \"event_id\": \"event_3334\",\n    \"type\": \"response.output_item.added\",\n    \"response_id\": \"resp_001\",\n    \"output_index\": 0,\n    \"item\": {\n        \"id\": \"msg_007\",\n        \"object\": \"realtime.item\",\n        \"type\": \"message\",\n        \"status\": \"in_progress\",\n        \"role\": \"assistant\",\n        \"content\": []\n    }\n}\n"
    RealtimeServerEventResponseOutputItemDone:
      required:
        - event_id
        - type
        - response_id
        - output_index
        - item
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - response.output_item.done
          type: string
          description: 'The event type, must be `response.output_item.done`.'
        response_id:
          type: string
          description: The ID of the Response to which the item belongs.
        output_index:
          type: integer
          description: The index of the output item in the Response.
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
      description: "Returned when an Item is done streaming. Also emitted when a Response is \ninterrupted, incomplete, or cancelled.\n"
      x-oaiMeta:
        name: response.output_item.done
        group: realtime
        example: "{\n    \"event_id\": \"event_3536\",\n    \"type\": \"response.output_item.done\",\n    \"response_id\": \"resp_001\",\n    \"output_index\": 0,\n    \"item\": {\n        \"id\": \"msg_007\",\n        \"object\": \"realtime.item\",\n        \"type\": \"message\",\n        \"status\": \"completed\",\n        \"role\": \"assistant\",\n        \"content\": [\n            {\n                \"type\": \"text\",\n                \"text\": \"Sure, I can help with that.\"\n            }\n        ]\n    }\n}\n"
    RealtimeServerEventResponseTextDelta:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - content_index
        - delta
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - response.text.delta
          type: string
          description: 'The event type, must be `response.text.delta`.'
        response_id:
          type: string
          description: The ID of the response.
        item_id:
          type: string
          description: The ID of the item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
        delta:
          type: string
          description: The text delta.
      description: Returned when the text value of a "text" content part is updated.
      x-oaiMeta:
        name: response.text.delta
        group: realtime
        example: "{\n    \"event_id\": \"event_4142\",\n    \"type\": \"response.text.delta\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_007\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"delta\": \"Sure, I can h\"\n}\n"
    RealtimeServerEventResponseTextDone:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - content_index
        - text
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - response.text.done
          type: string
          description: 'The event type, must be `response.text.done`.'
        response_id:
          type: string
          description: The ID of the response.
        item_id:
          type: string
          description: The ID of the item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
        text:
          type: string
          description: The final text content.
      description: "Returned when the text value of a \"text\" content part is done streaming. Also\nemitted when a Response is interrupted, incomplete, or cancelled.\n"
      x-oaiMeta:
        name: response.text.done
        group: realtime
        example: "{\n    \"event_id\": \"event_4344\",\n    \"type\": \"response.text.done\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_007\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"text\": \"Sure, I can help with that.\"\n}\n"
    RealtimeServerEventSessionCreated:
      required:
        - event_id
        - type
        - session
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - session.created
          type: string
          description: 'The event type, must be `session.created`.'
        session:
          $ref: '#/components/schemas/RealtimeSession'
      description: "Returned when a Session is created. Emitted automatically when a new \nconnection is established as the first server event. This event will contain \nthe default Session configuration.\n"
      x-oaiMeta:
        name: session.created
        group: realtime
        example: "{\n    \"event_id\": \"event_1234\",\n    \"type\": \"session.created\",\n    \"session\": {\n        \"id\": \"sess_001\",\n        \"object\": \"realtime.session\",\n        \"model\": \"gpt-4o-realtime-preview-2024-10-01\",\n        \"modalities\": [\"text\", \"audio\"],\n        \"instructions\": \"...model instructions here...\",\n        \"voice\": \"sage\",\n        \"input_audio_format\": \"pcm16\",\n        \"output_audio_format\": \"pcm16\",\n        \"input_audio_transcription\": null,\n        \"turn_detection\": {\n            \"type\": \"server_vad\",\n            \"threshold\": 0.5,\n            \"prefix_padding_ms\": 300,\n            \"silence_duration_ms\": 200\n        },\n        \"tools\": [],\n        \"tool_choice\": \"auto\",\n        \"temperature\": 0.8,\n        \"max_response_output_tokens\": \"inf\"\n    }\n}\n"
    RealtimeServerEventSessionUpdated:
      required:
        - event_id
        - type
        - session
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - session.updated
          type: string
          description: 'The event type, must be `session.updated`.'
        session:
          $ref: '#/components/schemas/RealtimeSession'
      description: "Returned when a session is updated with a `session.update` event, unless \nthere is an error.\n"
      x-oaiMeta:
        name: session.updated
        group: realtime
        example: "{\n    \"event_id\": \"event_5678\",\n    \"type\": \"session.updated\",\n    \"session\": {\n        \"id\": \"sess_001\",\n        \"object\": \"realtime.session\",\n        \"model\": \"gpt-4o-realtime-preview-2024-10-01\",\n        \"modalities\": [\"text\"],\n        \"instructions\": \"New instructions\",\n        \"voice\": \"sage\",\n        \"input_audio_format\": \"pcm16\",\n        \"output_audio_format\": \"pcm16\",\n        \"input_audio_transcription\": {\n            \"model\": \"whisper-1\"\n        },\n        \"turn_detection\": null,\n        \"tools\": [],\n        \"tool_choice\": \"none\",\n        \"temperature\": 0.7,\n        \"max_response_output_tokens\": 200\n    }\n}\n"
    RealtimeSession:
      type: object
      properties:
        id:
          type: string
          description: The unique ID of the session.
          example: sess_001
        object:
          enum:
            - realtime.session
          type: string
          description: 'The object type, must be "realtime.session".'
          example: realtime.session
        model:
          type: string
          description: The default model used for this session.
          example: gpt-4o-realtime-preview-2024-10-01
        modalities:
          type: array
          items:
            type: string
          description: 'The set of modalities the model can respond with. To disable audio, set this to ["text"].'
          example:
            - text
            - audio
        instructions:
          type: string
          description: The default system instructions prepended to model calls.
          example: Your knowledge cutoff is 2023-10. You are a helpful assistant.
        voice:
          enum:
            - alloy
            - echo
            - shimmer
          type: string
          description: The voice the model uses to respond. Cannot be changed once the model has responded with audio at least once.
          example: alloy
        input_audio_format:
          $ref: '#/components/schemas/RealtimeAudioFormat'
        output_audio_format:
          $ref: '#/components/schemas/RealtimeAudioFormat'
        input_audio_transcription:
          type: object
          properties:
            enabled:
              type: boolean
              description: Whether transcription is enabled.
              example: true
            model:
              type: string
              description: The model to use for transcription.
              example: whisper-1
          description: Configuration for input audio transcription. Can be set to null to turn off.
        turn_detection:
          type: object
          properties:
            type:
              enum:
                - server_vad
                - none
              type: string
              description: The type of turn detection.
              example: server_vad
            threshold:
              type: number
              description: Activation threshold for VAD (0.0 to 1.0).
              example: 0.5
            prefix_padding_ms:
              type: integer
              description: Amount of audio to include before speech starts (in milliseconds).
              example: 300
            silence_duration_ms:
              type: integer
              description: Duration of silence to detect speech stop (in milliseconds).
              example: 200
          description: Configuration for turn detection. Can be set to null to turn off.
        tools:
          type: array
          items:
            type: object
            properties:
              type:
                type: string
                description: 'The type of the tool, e.g., "function".'
                example: function
              name:
                type: string
                description: The name of the function.
                example: get_weather
              description:
                type: string
                description: The description of the function.
                example: Get the current weather for a location.
              parameters:
                type: object
                description: Parameters of the function in JSON Schema.
          description: Tools (functions) available to the model.
        tool_choice:
          enum:
            - auto
            - none
            - required
          type: string
          description: How the model chooses tools.
          example: auto
        temperature:
          type: number
          description: Sampling temperature for the model.
          example: 0.8
        max_output_tokens:
          oneOf:
            - type: integer
            - enum:
                - inf
              type: string
          description: 'Maximum number of output tokens for a single assistant response, inclusive of tool calls. Provide an integer between 1 and 4096 to limit output tokens, or "inf" for the maximum available tokens for a given model. Defaults to "inf".'
          default: inf
      description: "A session refers to a single WebSocket connection between a client and the server.\n\nOnce a client creates a session, it then sends JSON-formatted events containing text and audio chunks.\nThe server will respond in kind with audio containing voice output, a text transcript of that voice output,\nand function calls (if functions are provided by the client).\n\nA realtime Session represents the overall client-server interaction, and contains default configuration.\n\nIt has a set of default values which can be updated at any time (via session.update) or on a per-response level (via response.create).\n"
    ResponseFormatJsonObject:
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - json_object
          type: string
          description: 'The type of response format being defined: `json_object`'
    ResponseFormatJsonSchema:
      required:
        - type
        - json_schema
      type: object
      properties:
        type:
          enum:
            - json_schema
          type: string
          description: 'The type of response format being defined: `json_schema`'
        json_schema:
          required:
            - type
            - name
          type: object
          properties:
            description:
              type: string
              description: 'A description of what the response format is for, used by the model to determine how to respond in the format.'
            name:
              type: string
              description: 'The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'
            schema:
              $ref: '#/components/schemas/ResponseFormatJsonSchemaSchema'
            strict:
              type: boolean
              description: 'Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the `schema` field. Only a subset of JSON Schema is supported when `strict` is `true`. To learn more, read the [Structured Outputs guide](/docs/guides/structured-outputs).'
              default: false
              nullable: true
    ResponseFormatJsonSchemaSchema:
      type: object
      description: 'The schema for the response format, described as a JSON Schema object.'
    ResponseFormatText:
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - text
          type: string
          description: 'The type of response format being defined: `text`'
    RunCompletionUsage:
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      type: object
      properties:
        completion_tokens:
          type: integer
          description: Number of completion tokens used over the course of the run.
        prompt_tokens:
          type: integer
          description: Number of prompt tokens used over the course of the run.
        total_tokens:
          type: integer
          description: Total number of tokens used (prompt + completion).
      description: 'Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).'
      nullable: true
    RunObject:
      title: A run on a thread
      required:
        - id
        - object
        - created_at
        - thread_id
        - assistant_id
        - status
        - required_action
        - last_error
        - expires_at
        - started_at
        - cancelled_at
        - failed_at
        - completed_at
        - model
        - instructions
        - tools
        - metadata
        - usage
        - incomplete_details
        - max_prompt_tokens
        - max_completion_tokens
        - truncation_strategy
        - tool_choice
        - parallel_tool_calls
        - response_format
      type: object
      properties:
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints.'
        object:
          enum:
            - thread.run
          type: string
          description: 'The object type, which is always `thread.run`.'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run was created.
        thread_id:
          type: string
          description: 'The ID of the [thread](/docs/api-reference/threads) that was executed on as a part of this run.'
        assistant_id:
          type: string
          description: 'The ID of the [assistant](/docs/api-reference/assistants) used for execution of this run.'
        status:
          enum:
            - queued
            - in_progress
            - requires_action
            - cancelling
            - cancelled
            - failed
            - completed
            - incomplete
            - expired
          type: string
          description: 'The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.'
        required_action:
          required:
            - type
            - submit_tool_outputs
          type: object
          properties:
            type:
              enum:
                - submit_tool_outputs
              type: string
              description: 'For now, this is always `submit_tool_outputs`.'
            submit_tool_outputs:
              required:
                - tool_calls
              type: object
              properties:
                tool_calls:
                  type: array
                  items:
                    $ref: '#/components/schemas/RunToolCallObject'
                  description: A list of the relevant tool calls.
              description: Details on the tool outputs needed for this run to continue.
          description: Details on the action required to continue the run. Will be `null` if no action is required.
          nullable: true
        last_error:
          required:
            - code
            - message
          type: object
          properties:
            code:
              enum:
                - server_error
                - rate_limit_exceeded
                - invalid_prompt
              type: string
              description: 'One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.'
            message:
              type: string
              description: A human-readable description of the error.
          description: The last error associated with this run. Will be `null` if there are no errors.
          nullable: true
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run will expire.
          nullable: true
        started_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run was started.
          nullable: true
        cancelled_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run was cancelled.
          nullable: true
        failed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run failed.
          nullable: true
        completed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run was completed.
          nullable: true
        incomplete_details:
          type: object
          properties:
            reason:
              enum:
                - max_completion_tokens
                - max_prompt_tokens
              type: string
              description: The reason why the run is incomplete. This will point to which specific token limit was reached over the course of the run.
          description: Details on why the run is incomplete. Will be `null` if the run is not incomplete.
          nullable: true
        model:
          type: string
          description: 'The model that the [assistant](/docs/api-reference/assistants) used for this run.'
        instructions:
          type: string
          description: 'The instructions that the [assistant](/docs/api-reference/assistants) used for this run.'
        tools:
          maxItems: 20
          type: array
          items:
            oneOf:
              - $ref: '#/components/schemas/AssistantToolsCode'
              - $ref: '#/components/schemas/AssistantToolsFileSearch'
              - $ref: '#/components/schemas/AssistantToolsFunction'
            x-oaiExpandable: true
          description: 'The list of tools that the [assistant](/docs/api-reference/assistants) used for this run.'
        metadata:
          type: object
          description: "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
          nullable: true
          x-oaiTypeLabel: map
        usage:
          $ref: '#/components/schemas/RunCompletionUsage'
        temperature:
          type: number
          description: 'The sampling temperature used for this run. If not set, defaults to 1.'
          nullable: true
        top_p:
          type: number
          description: 'The nucleus sampling value used for this run. If not set, defaults to 1.'
          nullable: true
        max_prompt_tokens:
          minimum: 256
          type: integer
          description: "The maximum number of prompt tokens specified to have been used over the course of the run.\n"
          nullable: true
        max_completion_tokens:
          minimum: 256
          type: integer
          description: "The maximum number of completion tokens specified to have been used over the course of the run.\n"
          nullable: true
        truncation_strategy:
          $ref: '#/components/schemas/TruncationObject'
        tool_choice:
          $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
        parallel_tool_calls:
          $ref: '#/components/schemas/ParallelToolCalls'
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
      description: 'Represents an execution run on a [thread](/docs/api-reference/threads).'
      x-oaiMeta:
        name: The run object
        beta: true
        example: "{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1698107661,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"completed\",\n  \"started_at\": 1699073476,\n  \"expires_at\": null,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": 1699073498,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": null,\n  \"tools\": [{\"type\": \"file_search\"}, {\"type\": \"code_interpreter\"}],\n  \"metadata\": {},\n  \"incomplete_details\": null,\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  },\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\": 1000,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\n"
    RunStepCompletionUsage:
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      type: object
      properties:
        completion_tokens:
          type: integer
          description: Number of completion tokens used over the course of the run step.
        prompt_tokens:
          type: integer
          description: Number of prompt tokens used over the course of the run step.
        total_tokens:
          type: integer
          description: Total number of tokens used (prompt + completion).
      description: Usage statistics related to the run step. This value will be `null` while the run step's status is `in_progress`.
      nullable: true
    RunStepDeltaObject:
      title: Run step delta object
      required:
        - id
        - object
        - delta
      type: object
      properties:
        id:
          type: string
          description: 'The identifier of the run step, which can be referenced in API endpoints.'
        object:
          enum:
            - thread.run.step.delta
          type: string
          description: 'The object type, which is always `thread.run.step.delta`.'
        delta:
          type: object
          properties:
            step_details:
              type: object
              oneOf:
                - $ref: '#/components/schemas/RunStepDeltaStepDetailsMessageCreationObject'
                - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsObject'
              description: The details of the run step.
              x-oaiExpandable: true
          description: The delta containing the fields that have changed on the run step.
      description: "Represents a run step delta i.e. any changed fields on a run step during streaming.\n"
      x-oaiMeta:
        name: The run step delta object
        beta: true
        example: "{\n  \"id\": \"step_123\",\n  \"object\": \"thread.run.step.delta\",\n  \"delta\": {\n    \"step_details\": {\n      \"type\": \"tool_calls\",\n      \"tool_calls\": [\n        {\n          \"index\": 0,\n          \"id\": \"call_123\",\n          \"type\": \"code_interpreter\",\n          \"code_interpreter\": { \"input\": \"\", \"outputs\": [] }\n        }\n      ]\n    }\n  }\n}\n"
    RunStepDeltaStepDetailsMessageCreationObject:
      title: Message creation
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - message_creation
          type: string
          description: Always `message_creation`.
        message_creation:
          type: object
          properties:
            message_id:
              type: string
              description: The ID of the message that was created by this run step.
      description: Details of the message creation by the run step.
    RunStepDeltaStepDetailsToolCallsCodeObject:
      title: Code interpreter tool call
      required:
        - index
        - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the tool call in the tool calls array.
        id:
          type: string
          description: The ID of the tool call.
        type:
          enum:
            - code_interpreter
          type: string
          description: The type of tool call. This is always going to be `code_interpreter` for this type of tool call.
        code_interpreter:
          type: object
          properties:
            input:
              type: string
              description: The input to the Code Interpreter tool call.
            outputs:
              type: array
              items:
                type: object
                oneOf:
                  - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject'
                  - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputImageObject'
                x-oaiExpandable: true
              description: 'The outputs from the Code Interpreter tool call. Code Interpreter can output one or more items, including text (`logs`) or images (`image`). Each of these are represented by a different object type.'
          description: The Code Interpreter tool call definition.
      description: Details of the Code Interpreter tool call the run step was involved in.
    RunStepDeltaStepDetailsToolCallsCodeOutputImageObject:
      title: Code interpreter image output
      required:
        - index
        - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the output in the outputs array.
        type:
          enum:
            - image
          type: string
          description: Always `image`.
        image:
          type: object
          properties:
            file_id:
              type: string
              description: 'The [file](/docs/api-reference/files) ID of the image.'
    RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject:
      title: Code interpreter log output
      required:
        - index
        - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the output in the outputs array.
        type:
          enum:
            - logs
          type: string
          description: Always `logs`.
        logs:
          type: string
          description: The text output from the Code Interpreter tool call.
      description: Text output from the Code Interpreter tool call as part of a run step.
    RunStepDeltaStepDetailsToolCallsFileSearchObject:
      title: File search tool call
      required:
        - index
        - type
        - file_search
      type: object
      properties:
        index:
          type: integer
          description: The index of the tool call in the tool calls array.
        id:
          type: string
          description: The ID of the tool call object.
        type:
          enum:
            - file_search
          type: string
          description: The type of tool call. This is always going to be `file_search` for this type of tool call.
        file_search:
          type: object
          description: 'For now, this is always going to be an empty object.'
          x-oaiTypeLabel: map
    RunStepDeltaStepDetailsToolCallsFunctionObject:
      title: Function tool call
      required:
        - index
        - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the tool call in the tool calls array.
        id:
          type: string
          description: The ID of the tool call object.
        type:
          enum:
            - function
          type: string
          description: The type of tool call. This is always going to be `function` for this type of tool call.
        function:
          type: object
          properties:
            name:
              type: string
              description: The name of the function.
            arguments:
              type: string
              description: The arguments passed to the function.
            output:
              type: string
              description: 'The output of the function. This will be `null` if the outputs have not been [submitted](/docs/api-reference/runs/submitToolOutputs) yet.'
              nullable: true
          description: The definition of the function that was called.
    RunStepDeltaStepDetailsToolCallsObject:
      title: Tool calls
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - tool_calls
          type: string
          description: Always `tool_calls`.
        tool_calls:
          type: array
          items:
            oneOf:
              - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObject'
              - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsFileSearchObject'
              - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsFunctionObject'
            x-oaiExpandable: true
          description: "An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`.\n"
      description: Details of the tool call.
    RunStepDetailsMessageCreationObject:
      title: Message creation
      required:
        - type
        - message_creation
      type: object
      properties:
        type:
          enum:
            - message_creation
          type: string
          description: Always `message_creation`.
        message_creation:
          required:
            - message_id
          type: object
          properties:
            message_id:
              type: string
              description: The ID of the message that was created by this run step.
      description: Details of the message creation by the run step.
    RunStepDetailsToolCallsCodeObject:
      title: Code Interpreter tool call
      required:
        - id
        - type
        - code_interpreter
      type: object
      properties:
        id:
          type: string
          description: The ID of the tool call.
        type:
          enum:
            - code_interpreter
          type: string
          description: The type of tool call. This is always going to be `code_interpreter` for this type of tool call.
        code_interpreter:
          required:
            - input
            - outputs
          type: object
          properties:
            input:
              type: string
              description: The input to the Code Interpreter tool call.
            outputs:
              type: array
              items:
                type: object
                oneOf:
                  - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeOutputLogsObject'
                  - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeOutputImageObject'
                x-oaiExpandable: true
              description: 'The outputs from the Code Interpreter tool call. Code Interpreter can output one or more items, including text (`logs`) or images (`image`). Each of these are represented by a different object type.'
          description: The Code Interpreter tool call definition.
      description: Details of the Code Interpreter tool call the run step was involved in.
    RunStepDetailsToolCallsCodeOutputImageObject:
      title: Code Interpreter image output
      required:
        - type
        - image
      type: object
      properties:
        type:
          enum:
            - image
          type: string
          description: Always `image`.
        image:
          required:
            - file_id
          type: object
          properties:
            file_id:
              type: string
              description: 'The [file](/docs/api-reference/files) ID of the image.'
    RunStepDetailsToolCallsCodeOutputLogsObject:
      title: Code Interpreter log output
      required:
        - type
        - logs
      type: object
      properties:
        type:
          enum:
            - logs
          type: string
          description: Always `logs`.
        logs:
          type: string
          description: The text output from the Code Interpreter tool call.
      description: Text output from the Code Interpreter tool call as part of a run step.
    RunStepDetailsToolCallsFileSearchObject:
      title: File search tool call
      required:
        - id
        - type
        - file_search
      type: object
      properties:
        id:
          type: string
          description: The ID of the tool call object.
        type:
          enum:
            - file_search
          type: string
          description: The type of tool call. This is always going to be `file_search` for this type of tool call.
        file_search:
          type: object
          properties:
            ranking_options:
              $ref: '#/components/schemas/RunStepDetailsToolCallsFileSearchRankingOptionsObject'
            results:
              type: array
              items:
                $ref: '#/components/schemas/RunStepDetailsToolCallsFileSearchResultObject'
              description: The results of the file search.
          description: 'For now, this is always going to be an empty object.'
          x-oaiTypeLabel: map
    RunStepDetailsToolCallsFileSearchRankingOptionsObject:
      title: File search tool call ranking options
      required:
        - ranker
        - score_threshold
      type: object
      properties:
        ranker:
          enum:
            - default_2024_08_21
          type: string
          description: The ranker used for the file search.
        score_threshold:
          maximum: 1
          minimum: 0
          type: number
          description: The score threshold for the file search. All values must be a floating point number between 0 and 1.
      description: The ranking options for the file search.
    RunStepDetailsToolCallsFileSearchResultObject:
      title: File search tool call result
      required:
        - file_id
        - file_name
        - score
      type: object
      properties:
        file_id:
          type: string
          description: The ID of the file that result was found in.
        file_name:
          type: string
          description: The name of the file that result was found in.
        score:
          maximum: 1
          minimum: 0
          type: number
          description: The score of the result. All values must be a floating point number between 0 and 1.
        content:
          type: array
          items:
            type: object
            properties:
              type:
                enum:
                  - text
                type: string
                description: The type of the content.
              text:
                type: string
                description: The text content of the file.
          description: The content of the result that was found. The content is only included if requested via the include query parameter.
      description: A result instance of the file search.
      x-oaiTypeLabel: map
    RunStepDetailsToolCallsFunctionObject:
      title: Function tool call
      required:
        - id
        - type
        - function
      type: object
      properties:
        id:
          type: string
          description: The ID of the tool call object.
        type:
          enum:
            - function
          type: string
          description: The type of tool call. This is always going to be `function` for this type of tool call.
        function:
          required:
            - name
            - arguments
            - output
          type: object
          properties:
            name:
              type: string
              description: The name of the function.
            arguments:
              type: string
              description: The arguments passed to the function.
            output:
              type: string
              description: 'The output of the function. This will be `null` if the outputs have not been [submitted](/docs/api-reference/runs/submitToolOutputs) yet.'
              nullable: true
          description: The definition of the function that was called.
    RunStepDetailsToolCallsObject:
      title: Tool calls
      required:
        - type
        - tool_calls
      type: object
      properties:
        type:
          enum:
            - tool_calls
          type: string
          description: Always `tool_calls`.
        tool_calls:
          type: array
          items:
            oneOf:
              - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeObject'
              - $ref: '#/components/schemas/RunStepDetailsToolCallsFileSearchObject'
              - $ref: '#/components/schemas/RunStepDetailsToolCallsFunctionObject'
            x-oaiExpandable: true
          description: "An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`.\n"
      description: Details of the tool call.
    RunStepObject:
      title: Run steps
      required:
        - id
        - object
        - created_at
        - assistant_id
        - thread_id
        - run_id
        - type
        - status
        - step_details
        - last_error
        - cancelled_at
        - failed_at
        - completed_at
        - usage
      type: object
      properties:
        id:
          type: string
          description: 'The identifier of the run step, which can be referenced in API endpoints.'
        object:
          enum:
            - thread.run.step
          type: string
          description: 'The object type, which is always `thread.run.step`.'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step was created.
        assistant_id:
          type: string
          description: 'The ID of the [assistant](/docs/api-reference/assistants) associated with the run step.'
        thread_id:
          type: string
          description: 'The ID of the [thread](/docs/api-reference/threads) that was run.'
        run_id:
          type: string
          description: 'The ID of the [run](/docs/api-reference/runs) that this run step is a part of.'
        type:
          enum:
            - message_creation
            - tool_calls
          type: string
          description: 'The type of run step, which can be either `message_creation` or `tool_calls`.'
        status:
          enum:
            - in_progress
            - cancelled
            - failed
            - completed
            - expired
          type: string
          description: 'The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.'
        step_details:
          type: object
          oneOf:
            - $ref: '#/components/schemas/RunStepDetailsMessageCreationObject'
            - $ref: '#/components/schemas/RunStepDetailsToolCallsObject'
          description: The details of the run step.
          x-oaiExpandable: true
        last_error:
          required:
            - code
            - message
          type: object
          properties:
            code:
              enum:
                - server_error
                - rate_limit_exceeded
              type: string
              description: One of `server_error` or `rate_limit_exceeded`.
            message:
              type: string
              description: A human-readable description of the error.
          description: The last error associated with this run step. Will be `null` if there are no errors.
          nullable: true
        expired_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.
          nullable: true
        cancelled_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step was cancelled.
          nullable: true
        failed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step failed.
          nullable: true
        completed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step completed.
          nullable: true
        metadata:
          type: object
          description: "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
          nullable: true
          x-oaiTypeLabel: map
        usage:
          $ref: '#/components/schemas/RunStepCompletionUsage'
      description: "Represents a step in execution of a run.\n"
      x-oaiMeta:
        name: The run step object
        beta: true
        example: "{\n  \"id\": \"step_abc123\",\n  \"object\": \"thread.run.step\",\n  \"created_at\": 1699063291,\n  \"run_id\": \"run_abc123\",\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"type\": \"message_creation\",\n  \"status\": \"completed\",\n  \"cancelled_at\": null,\n  \"completed_at\": 1699063291,\n  \"expired_at\": null,\n  \"failed_at\": null,\n  \"last_error\": null,\n  \"step_details\": {\n    \"type\": \"message_creation\",\n    \"message_creation\": {\n      \"message_id\": \"msg_abc123\"\n    }\n  },\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  }\n}\n"
    RunStepStreamEvent:
      oneOf:
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.run.step.created
              type: string
            data:
              $ref: '#/components/schemas/RunStepObject'
          description: 'Occurs when a [run step](/docs/api-reference/run-steps/step-object) is created.'
          x-oaiMeta:
            dataDescription: '`data` is a [run step](/docs/api-reference/run-steps/step-object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.run.step.in_progress
              type: string
            data:
              $ref: '#/components/schemas/RunStepObject'
          description: 'Occurs when a [run step](/docs/api-reference/run-steps/step-object) moves to an `in_progress` state.'
          x-oaiMeta:
            dataDescription: '`data` is a [run step](/docs/api-reference/run-steps/step-object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.run.step.delta
              type: string
            data:
              $ref: '#/components/schemas/RunStepDeltaObject'
          description: 'Occurs when parts of a [run step](/docs/api-reference/run-steps/step-object) are being streamed.'
          x-oaiMeta:
            dataDescription: '`data` is a [run step delta](/docs/api-reference/assistants-streaming/run-step-delta-object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.run.step.completed
              type: string
            data:
              $ref: '#/components/schemas/RunStepObject'
          description: 'Occurs when a [run step](/docs/api-reference/run-steps/step-object) is completed.'
          x-oaiMeta:
            dataDescription: '`data` is a [run step](/docs/api-reference/run-steps/step-object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.run.step.failed
              type: string
            data:
              $ref: '#/components/schemas/RunStepObject'
          description: 'Occurs when a [run step](/docs/api-reference/run-steps/step-object) fails.'
          x-oaiMeta:
            dataDescription: '`data` is a [run step](/docs/api-reference/run-steps/step-object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.run.step.cancelled
              type: string
            data:
              $ref: '#/components/schemas/RunStepObject'
          description: 'Occurs when a [run step](/docs/api-reference/run-steps/step-object) is cancelled.'
          x-oaiMeta:
            dataDescription: '`data` is a [run step](/docs/api-reference/run-steps/step-object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.run.step.expired
              type: string
            data:
              $ref: '#/components/schemas/RunStepObject'
          description: 'Occurs when a [run step](/docs/api-reference/run-steps/step-object) expires.'
          x-oaiMeta:
            dataDescription: '`data` is a [run step](/docs/api-reference/run-steps/step-object)'
    RunStreamEvent:
      oneOf:
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.run.created
              type: string
            data:
              $ref: '#/components/schemas/RunObject'
          description: 'Occurs when a new [run](/docs/api-reference/runs/object) is created.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.run.queued
              type: string
            data:
              $ref: '#/components/schemas/RunObject'
          description: 'Occurs when a [run](/docs/api-reference/runs/object) moves to a `queued` status.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.run.in_progress
              type: string
            data:
              $ref: '#/components/schemas/RunObject'
          description: 'Occurs when a [run](/docs/api-reference/runs/object) moves to an `in_progress` status.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.run.requires_action
              type: string
            data:
              $ref: '#/components/schemas/RunObject'
          description: 'Occurs when a [run](/docs/api-reference/runs/object) moves to a `requires_action` status.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.run.completed
              type: string
            data:
              $ref: '#/components/schemas/RunObject'
          description: 'Occurs when a [run](/docs/api-reference/runs/object) is completed.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.run.incomplete
              type: string
            data:
              $ref: '#/components/schemas/RunObject'
          description: 'Occurs when a [run](/docs/api-reference/runs/object) ends with status `incomplete`.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.run.failed
              type: string
            data:
              $ref: '#/components/schemas/RunObject'
          description: 'Occurs when a [run](/docs/api-reference/runs/object) fails.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.run.cancelling
              type: string
            data:
              $ref: '#/components/schemas/RunObject'
          description: 'Occurs when a [run](/docs/api-reference/runs/object) moves to a `cancelling` status.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.run.cancelled
              type: string
            data:
              $ref: '#/components/schemas/RunObject'
          description: 'Occurs when a [run](/docs/api-reference/runs/object) is cancelled.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
        - required:
            - event
            - data
          type: object
          properties:
            event:
              enum:
                - thread.run.expired
              type: string
            data:
              $ref: '#/components/schemas/RunObject'
          description: 'Occurs when a [run](/docs/api-reference/runs/object) expires.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
    RunToolCallObject:
      required:
        - id
        - type
        - function
      type: object
      properties:
        id:
          type: string
          description: 'The ID of the tool call. This ID must be referenced when you submit the tool outputs in using the [Submit tool outputs to run](/docs/api-reference/runs/submitToolOutputs) endpoint.'
        type:
          enum:
            - function
          type: string
          description: 'The type of tool call the output is required for. For now, this is always `function`.'
        function:
          required:
            - name
            - arguments
          type: object
          properties:
            name:
              type: string
              description: The name of the function.
            arguments:
              type: string
              description: The arguments that the model expects you to pass to the function.
          description: The function definition.
      description: Tool call objects
    StaticChunkingStrategy:
      required:
        - max_chunk_size_tokens
        - chunk_overlap_tokens
      type: object
      properties:
        max_chunk_size_tokens:
          maximum: 4096
          minimum: 100
          type: integer
          description: The maximum number of tokens in each chunk. The default value is `800`. The minimum value is `100` and the maximum value is `4096`.
        chunk_overlap_tokens:
          type: integer
          description: "The number of tokens that overlap between chunks. The default value is `400`.\n\nNote that the overlap must not exceed half of `max_chunk_size_tokens`.\n"
      additionalProperties: false
    StaticChunkingStrategyRequestParam:
      title: Static Chunking Strategy
      required:
        - type
        - static
      type: object
      properties:
        type:
          enum:
            - static
          type: string
          description: Always `static`.
        static:
          $ref: '#/components/schemas/StaticChunkingStrategy'
      additionalProperties: false
    StaticChunkingStrategyResponseParam:
      title: Static Chunking Strategy
      required:
        - type
        - static
      type: object
      properties:
        type:
          enum:
            - static
          type: string
          description: Always `static`.
        static:
          $ref: '#/components/schemas/StaticChunkingStrategy'
      additionalProperties: false
    SubmitToolOutputsRunRequest:
      required:
        - tool_outputs
      type: object
      properties:
        tool_outputs:
          type: array
          items:
            type: object
            properties:
              tool_call_id:
                type: string
                description: The ID of the tool call in the `required_action` object within the run object the output is being submitted for.
              output:
                type: string
                description: The output of the tool call to be submitted to continue the run.
          description: A list of tools for which the outputs are being submitted.
        stream:
          type: boolean
          description: "If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.\n"
          nullable: true
      additionalProperties: false
    ThreadObject:
      title: Thread
      required:
        - id
        - object
        - created_at
        - tool_resources
        - metadata
      type: object
      properties:
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints.'
        object:
          enum:
            - thread
          type: string
          description: 'The object type, which is always `thread`.'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the thread was created.
        tool_resources:
          type: object
          properties:
            code_interpreter:
              type: object
              properties:
                file_ids:
                  maxItems: 20
                  type: array
                  items:
                    type: string
                  description: "A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n"
            file_search:
              type: object
              properties:
                vector_store_ids:
                  maxItems: 1
                  type: array
                  items:
                    type: string
                  description: "The [vector store](/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.\n"
          description: "A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n"
          nullable: true
        metadata:
          type: object
          description: "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
          nullable: true
          x-oaiTypeLabel: map
      description: 'Represents a thread that contains [messages](/docs/api-reference/messages).'
      x-oaiMeta:
        name: The thread object
        beta: true
        example: "{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n  \"created_at\": 1698107661,\n  \"metadata\": {}\n}\n"
    ThreadStreamEvent:
      oneOf:
        - required:
            - event
            - data
          type: object
          properties:
            enabled:
              type: boolean
              description: Whether to enable input audio transcription.
            event:
              enum:
                - thread.created
              type: string
            data:
              $ref: '#/components/schemas/ThreadObject'
          description: 'Occurs when a new [thread](/docs/api-reference/threads/object) is created.'
          x-oaiMeta:
            dataDescription: '`data` is a [thread](/docs/api-reference/threads/object)'
    TranscriptionSegment:
      required:
        - id
        - seek
        - start
        - end
        - text
        - tokens
        - temperature
        - avg_logprob
        - compression_ratio
        - no_speech_prob
      type: object
      properties:
        id:
          type: integer
          description: Unique identifier of the segment.
        seek:
          type: integer
          description: Seek offset of the segment.
        start:
          type: number
          description: Start time of the segment in seconds.
          format: float
        end:
          type: number
          description: End time of the segment in seconds.
          format: float
        text:
          type: string
          description: Text content of the segment.
        tokens:
          type: array
          items:
            type: integer
          description: Array of token IDs for the text content.
        temperature:
          type: number
          description: Temperature parameter used for generating the segment.
          format: float
        avg_logprob:
          type: number
          description: 'Average logprob of the segment. If the value is lower than -1, consider the logprobs failed.'
          format: float
        compression_ratio:
          type: number
          description: 'Compression ratio of the segment. If the value is greater than 2.4, consider the compression failed.'
          format: float
        no_speech_prob:
          type: number
          description: 'Probability of no speech in the segment. If the value is higher than 1.0 and the `avg_logprob` is below -1, consider this segment silent.'
          format: float
    TranscriptionWord:
      required:
        - word
        - start
        - end
      type: object
      properties:
        word:
          type: string
          description: The text content of the word.
        start:
          type: number
          description: Start time of the word in seconds.
          format: float
        end:
          type: number
          description: End time of the word in seconds.
          format: float
    TruncationObject:
      title: Thread Truncation Controls
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - auto
            - last_messages
          type: string
          description: 'The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.'
        last_messages:
          minimum: 1
          type: integer
          description: The number of most recent messages from the thread when constructing the context for the run.
          nullable: true
      description: Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.
    UpdateVectorStoreRequest:
      type: object
      properties:
        name:
          type: string
          description: The name of the vector store.
          nullable: true
        expires_after:
          $ref: '#/components/schemas/VectorStoreExpirationAfter'
        metadata:
          type: object
          description: "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
          nullable: true
          x-oaiTypeLabel: map
      additionalProperties: false
    Upload:
      title: Upload
      required:
        - bytes
        - created_at
        - expires_at
        - filename
        - id
        - purpose
        - status
      type: object
      properties:
        id:
          type: string
          description: 'The Upload unique identifier, which can be referenced in API endpoints.'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the Upload was created.
        filename:
          type: string
          description: The name of the file to be uploaded.
        bytes:
          type: integer
          description: The intended number of bytes to be uploaded.
        purpose:
          type: string
          description: 'The intended purpose of the file. [Please refer here](/docs/api-reference/files/object#files/object-purpose) for acceptable values.'
        status:
          enum:
            - pending
            - completed
            - cancelled
            - expired
          type: string
          description: The status of the Upload.
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the Upload was created.
        object:
          enum:
            - upload
          type: string
          description: 'The object type, which is always "upload".'
        file:
          $ref: '#/components/schemas/OpenAIFile'
      description: "The Upload object can accept byte chunks in the form of Parts.\n"
      x-oaiMeta:
        name: The upload object
        example: "{\n  \"id\": \"upload_abc123\",\n  \"object\": \"upload\",\n  \"bytes\": 2147483648,\n  \"created_at\": 1719184911,\n  \"filename\": \"training_examples.jsonl\",\n  \"purpose\": \"fine-tune\",\n  \"status\": \"completed\",\n  \"expires_at\": 1719127296,\n  \"file\": {\n    \"id\": \"file-xyz321\",\n    \"object\": \"file\",\n    \"bytes\": 2147483648,\n    \"created_at\": 1719186911,\n    \"filename\": \"training_examples.jsonl\",\n    \"purpose\": \"fine-tune\",\n  }\n}\n"
    UploadPart:
      title: UploadPart
      required:
        - created_at
        - id
        - object
        - upload_id
      type: object
      properties:
        id:
          type: string
          description: 'The upload Part unique identifier, which can be referenced in API endpoints.'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the Part was created.
        upload_id:
          type: string
          description: The ID of the Upload object that this Part was added to.
        object:
          enum:
            - upload.part
          type: string
          description: 'The object type, which is always `upload.part`.'
      description: "The upload Part represents a chunk of bytes we can add to an Upload object.\n"
      x-oaiMeta:
        name: The upload part object
        example: "{\n    \"id\": \"part_def456\",\n    \"object\": \"upload.part\",\n    \"created_at\": 1719186911,\n    \"upload_id\": \"upload_abc123\"\n}\n"
    UsageAudioSpeechesResult:
      required:
        - object
        - characters
        - num_model_requests
      type: object
      properties:
        object:
          enum:
            - organization.usage.audio_speeches.result
          type: string
        characters:
          type: integer
          description: The number of characters processed.
        num_model_requests:
          type: integer
          description: The count of requests made to the model.
        project_id:
          type: string
          description: 'When `group_by=project_id`, this field provides the project ID of the grouped usage result.'
        user_id:
          type: string
          description: 'When `group_by=user_id`, this field provides the user ID of the grouped usage result.'
        api_key_id:
          type: string
          description: 'When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.'
        model:
          type: string
          description: 'When `group_by=model`, this field provides the model name of the grouped usage result.'
      description: The aggregated audio speeches usage details of the specific time bucket.
      x-oaiMeta:
        name: Audio speeches usage object
        example: "{\n    \"object\": \"orgainzation.usage.audio_speeches.result\",\n    \"characters\": 45,\n    \"num_model_requests\": 1,\n    \"project_id\": \"proj_abc\",\n    \"user_id\": \"user-abc\",\n    \"api_key_id\": \"key_abc\",\n    \"model\": \"tts-1\"\n}\n"
    UsageAudioTranscriptionsResult:
      required:
        - object
        - seconds
        - num_model_requests
      type: object
      properties:
        object:
          enum:
            - organization.usage.audio_transcriptions.result
          type: string
        seconds:
          type: integer
          description: The number of seconds processed.
        num_model_requests:
          type: integer
          description: The count of requests made to the model.
        project_id:
          type: string
          description: 'When `group_by=project_id`, this field provides the project ID of the grouped usage result.'
        user_id:
          type: string
          description: 'When `group_by=user_id`, this field provides the user ID of the grouped usage result.'
        api_key_id:
          type: string
          description: 'When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.'
        model:
          type: string
          description: 'When `group_by=model`, this field provides the model name of the grouped usage result.'
      description: The aggregated audio transcriptions usage details of the specific time bucket.
      x-oaiMeta:
        name: Audio transcriptions usage object
        example: "{\n    \"object\": \"orgainzation.usage.audio_transcriptions.result\",\n    \"seconds\": 10,\n    \"num_model_requests\": 1,\n    \"project_id\": \"proj_abc\",\n    \"user_id\": \"user-abc\",\n    \"api_key_id\": \"key_abc\",\n    \"model\": \"tts-1\"\n}\n"
    UsageCodeInterpreterSessionsResult:
      required:
        - object
        - sessions
      type: object
      properties:
        object:
          enum:
            - organization.usage.code_interpreter_sessions.result
          type: string
        sessions:
          type: integer
          description: The number of code interpreter sessions.
        project_id:
          type: string
          description: 'When `group_by=project_id`, this field provides the project ID of the grouped usage result.'
      description: The aggregated code interpreter sessions usage details of the specific time bucket.
      x-oaiMeta:
        name: Code interpreter sessions usage object
        example: "{\n    \"object\": \"orgainzation.usage.code_interpreter_sessions.result\",\n    \"sessions\": 1,\n    \"project_id\": \"proj_abc\"\n}\n"
    UsageCompletionsResult:
      required:
        - object
        - input_tokens
        - output_tokens
        - num_model_requests
      type: object
      properties:
        object:
          enum:
            - organization.usage.completions.result
          type: string
        input_tokens:
          type: integer
          description: The number of input tokens used.
        input_cached_tokens:
          type: integer
          description: The number of input tokens that has been cached from previous requests.
        output_tokens:
          type: integer
          description: The number of output tokens used.
        num_model_requests:
          type: integer
          description: The count of requests made to the model.
        project_id:
          type: string
          description: 'When `group_by=project_id`, this field provides the project ID of the grouped usage result.'
        user_id:
          type: string
          description: 'When `group_by=user_id`, this field provides the user ID of the grouped usage result.'
        api_key_id:
          type: string
          description: 'When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.'
        model:
          type: string
          description: 'When `group_by=model`, this field provides the model name of the grouped usage result.'
        batch:
          type: boolean
          description: 'When `group_by=batch`, this field tells whether the grouped usage result is batch or not.'
      description: The aggregated completions usage details of the specific time bucket.
      x-oaiMeta:
        name: Completions usage object
        example: "{\n    \"object\": \"orgainzation.usage.completions.result\",\n    \"input_tokens\": 5000,\n    \"output_tokens\": 1000,\n    \"input_cached_tokens\": 4000,\n    \"num_model_requests\": 5,\n    \"project_id\": \"proj_abc\",\n    \"user_id\": \"user-abc\",\n    \"api_key_id\": \"key_abc\",\n    \"model\": \"gpt-4o-mini-2024-07-18\",\n    \"batch\": false\n}\n"
    UsageEmbeddingsResult:
      required:
        - object
        - input_tokens
        - num_model_requests
      type: object
      properties:
        object:
          enum:
            - organization.usage.embeddings.result
          type: string
        input_tokens:
          type: integer
          description: The number of input tokens used.
        num_model_requests:
          type: integer
          description: The count of requests made to the model.
        project_id:
          type: string
          description: 'When `group_by=project_id`, this field provides the project ID of the grouped usage result.'
        user_id:
          type: string
          description: 'When `group_by=user_id`, this field provides the user ID of the grouped usage result.'
        api_key_id:
          type: string
          description: 'When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.'
        model:
          type: string
          description: 'When `group_by=model`, this field provides the model name of the grouped usage result.'
      description: The aggregated embeddings usage details of the specific time bucket.
      x-oaiMeta:
        name: Embeddings usage object
        example: "{\n    \"object\": \"orgainzation.usage.embeddings.result\",\n    \"input_tokens\": 20,\n    \"num_model_requests\": 2,\n    \"project_id\": \"proj_abc\",\n    \"user_id\": \"user-abc\",\n    \"api_key_id\": \"key_abc\",\n    \"model\": \"text-embedding-ada-002-v2\"\n}\n"
    UsageImagesResult:
      required:
        - object
        - images
        - num_model_requests
      type: object
      properties:
        object:
          enum:
            - organization.usage.images.result
          type: string
        images:
          type: integer
          description: The number of images processed.
        num_model_requests:
          type: integer
          description: The count of requests made to the model.
        source:
          type: string
          description: 'When `group_by=source`, this field provides the source of the grouped usage result, possible values are `image.generation`, `image.edit`, `image.variation`.'
        size:
          type: string
          description: 'When `group_by=size`, this field provides the image size of the grouped usage result.'
        project_id:
          type: string
          description: 'When `group_by=project_id`, this field provides the project ID of the grouped usage result.'
        user_id:
          type: string
          description: 'When `group_by=user_id`, this field provides the user ID of the grouped usage result.'
        api_key_id:
          type: string
          description: 'When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.'
        model:
          type: string
          description: 'When `group_by=model`, this field provides the model name of the grouped usage result.'
      description: The aggregated images usage details of the specific time bucket.
      x-oaiMeta:
        name: Images usage object
        example: "{\n    \"object\": \"orgainzation.usage.images.result\",\n    \"images\": 2,\n    \"num_model_requests\": 2,\n    \"size\": \"1024x1024\",\n    \"source\": \"image.generation\",\n    \"project_id\": \"proj_abc\",\n    \"user_id\": \"user-abc\",\n    \"api_key_id\": \"key_abc\",\n    \"model\": \"dall-e-3\"\n}\n"
    UsageModerationsResult:
      required:
        - object
        - input_tokens
        - num_model_requests
      type: object
      properties:
        object:
          enum:
            - organization.usage.moderations.result
          type: string
        input_tokens:
          type: integer
          description: The number of input tokens used.
        num_model_requests:
          type: integer
          description: The count of requests made to the model.
        project_id:
          type: string
          description: 'When `group_by=project_id`, this field provides the project ID of the grouped usage result.'
        user_id:
          type: string
          description: 'When `group_by=user_id`, this field provides the user ID of the grouped usage result.'
        api_key_id:
          type: string
          description: 'When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.'
        model:
          type: string
          description: 'When `group_by=model`, this field provides the model name of the grouped usage result.'
      description: The aggregated moderations usage details of the specific time bucket.
      x-oaiMeta:
        name: Moderations usage object
        example: "{\n    \"object\": \"orgainzation.usage.moderations.result\",\n    \"input_tokens\": 20,\n    \"num_model_requests\": 2,\n    \"project_id\": \"proj_abc\",\n    \"user_id\": \"user-abc\",\n    \"api_key_id\": \"key_abc\",\n    \"model\": \"text-moderation\"\n}\n"
    UsageResponse:
      required:
        - object
        - data
        - has_more
        - next_page
      type: object
      properties:
        object:
          enum:
            - page
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/UsageTimeBucket'
        has_more:
          type: boolean
        next_page:
          type: string
    UsageTimeBucket:
      required:
        - object
        - start_time
        - end_time
        - result
      type: object
      properties:
        object:
          enum:
            - bucket
          type: string
        start_time:
          type: integer
        end_time:
          type: integer
        result:
          type: array
          items:
            oneOf:
              - $ref: '#/components/schemas/UsageCompletionsResult'
              - $ref: '#/components/schemas/UsageEmbeddingsResult'
              - $ref: '#/components/schemas/UsageModerationsResult'
              - $ref: '#/components/schemas/UsageImagesResult'
              - $ref: '#/components/schemas/UsageAudioSpeechesResult'
              - $ref: '#/components/schemas/UsageAudioTranscriptionsResult'
              - $ref: '#/components/schemas/UsageVectorStoresResult'
              - $ref: '#/components/schemas/UsageCodeInterpreterSessionsResult'
              - $ref: '#/components/schemas/CostsResult'
    UsageVectorStoresResult:
      required:
        - object
        - usage_bytes
      type: object
      properties:
        object:
          enum:
            - organization.usage.vector_stores.result
          type: string
        usage_bytes:
          type: integer
          description: The vector stores usage in bytes.
        project_id:
          type: string
          description: 'When `group_by=project_id`, this field provides the project ID of the grouped usage result.'
      description: The aggregated vector stores usage details of the specific time bucket.
      x-oaiMeta:
        name: Vector stores usage object
        example: "{\n    \"object\": \"orgainzation.usage.vector_stores.result\",\n    \"usage_bytes\": 1024,\n    \"project_id\": \"proj_abc\"\n}\n"
    User:
      required:
        - object
        - id
        - name
        - email
        - role
        - added_at
      type: object
      properties:
        object:
          enum:
            - organization.user
          type: string
          description: 'The object type, which is always `organization.user`'
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints'
        name:
          type: string
          description: The name of the user
        email:
          type: string
          description: The email address of the user
        role:
          enum:
            - owner
            - reader
          type: string
          description: '`owner` or `reader`'
        added_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the user was added.
      description: Represents an individual `user` within an organization.
      x-oaiMeta:
        name: The user object
        example: "{\n    \"object\": \"organization.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\n"
    UserDeleteResponse:
      required:
        - object
        - id
        - deleted
      type: object
      properties:
        object:
          enum:
            - organization.user.deleted
          type: string
        id:
          type: string
        deleted:
          type: boolean
    UserListResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        object:
          enum:
            - list
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/User'
        first_id:
          type: string
        last_id:
          type: string
        has_more:
          type: boolean
    UserRoleUpdateRequest:
      required:
        - role
      type: object
      properties:
        role:
          enum:
            - owner
            - reader
          type: string
          description: '`owner` or `reader`'
    VectorStoreExpirationAfter:
      title: Vector store expiration policy
      required:
        - anchor
        - days
      type: object
      properties:
        anchor:
          enum:
            - last_active_at
          type: string
          description: 'Anchor timestamp after which the expiration policy applies. Supported anchors: `last_active_at`.'
        days:
          maximum: 365
          minimum: 1
          type: integer
          description: The number of days after the anchor time that the vector store will expire.
      description: The expiration policy for a vector store.
    VectorStoreFileBatchObject:
      title: Vector store file batch
      required:
        - id
        - object
        - created_at
        - vector_store_id
        - status
        - file_counts
      type: object
      properties:
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints.'
        object:
          enum:
            - vector_store.files_batch
          type: string
          description: 'The object type, which is always `vector_store.file_batch`.'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store files batch was created.
        vector_store_id:
          type: string
          description: 'The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.'
        status:
          enum:
            - in_progress
            - completed
            - cancelled
            - failed
          type: string
          description: 'The status of the vector store files batch, which can be either `in_progress`, `completed`, `cancelled` or `failed`.'
        file_counts:
          required:
            - in_progress
            - completed
            - cancelled
            - failed
            - total
          type: object
          properties:
            in_progress:
              type: integer
              description: The number of files that are currently being processed.
            completed:
              type: integer
              description: The number of files that have been processed.
            failed:
              type: integer
              description: The number of files that have failed to process.
            cancelled:
              type: integer
              description: The number of files that where cancelled.
            total:
              type: integer
              description: The total number of files.
      description: A batch of files attached to a vector store.
      x-oaiMeta:
        name: The vector store files batch object
        beta: true
        example: "{\n  \"id\": \"vsfb_123\",\n  \"object\": \"vector_store.files_batch\",\n  \"created_at\": 1698107661,\n  \"vector_store_id\": \"vs_abc123\",\n  \"status\": \"completed\",\n  \"file_counts\": {\n    \"in_progress\": 0,\n    \"completed\": 100,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 100\n  }\n}\n"
    VectorStoreFileObject:
      title: Vector store files
      required:
        - id
        - object
        - usage_bytes
        - created_at
        - vector_store_id
        - status
        - last_error
      type: object
      properties:
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints.'
        object:
          enum:
            - vector_store.file
          type: string
          description: 'The object type, which is always `vector_store.file`.'
        usage_bytes:
          type: integer
          description: The total vector store usage in bytes. Note that this may be different from the original file size.
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store file was created.
        vector_store_id:
          type: string
          description: 'The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.'
        status:
          enum:
            - in_progress
            - completed
            - cancelled
            - failed
          type: string
          description: 'The status of the vector store file, which can be either `in_progress`, `completed`, `cancelled`, or `failed`. The status `completed` indicates that the vector store file is ready for use.'
        last_error:
          required:
            - code
            - message
          type: object
          properties:
            code:
              enum:
                - server_error
                - unsupported_file
                - invalid_file
              type: string
              description: One of `server_error` or `rate_limit_exceeded`.
            message:
              type: string
              description: A human-readable description of the error.
          description: The last error associated with this vector store file. Will be `null` if there are no errors.
          nullable: true
        chunking_strategy:
          type: object
          oneOf:
            - $ref: '#/components/schemas/StaticChunkingStrategyResponseParam'
            - $ref: '#/components/schemas/OtherChunkingStrategyResponseParam'
          description: The strategy used to chunk the file.
          x-oaiExpandable: true
      description: A list of files attached to a vector store.
      x-oaiMeta:
        name: The vector store file object
        beta: true
        example: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"vector_store.file\",\n  \"usage_bytes\": 1234,\n  \"created_at\": 1698107661,\n  \"vector_store_id\": \"vs_abc123\",\n  \"status\": \"completed\",\n  \"last_error\": null,\n  \"chunking_strategy\": {\n    \"type\": \"static\",\n    \"static\": {\n      \"max_chunk_size_tokens\": 800,\n      \"chunk_overlap_tokens\": 400\n    }\n  }\n}\n"
    VectorStoreObject:
      title: Vector store
      required:
        - id
        - object
        - usage_bytes
        - created_at
        - status
        - last_active_at
        - name
        - file_counts
        - metadata
      type: object
      properties:
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints.'
        object:
          enum:
            - vector_store
          type: string
          description: 'The object type, which is always `vector_store`.'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store was created.
        name:
          type: string
          description: The name of the vector store.
        usage_bytes:
          type: integer
          description: The total number of bytes used by the files in the vector store.
        file_counts:
          required:
            - in_progress
            - completed
            - failed
            - cancelled
            - total
          type: object
          properties:
            in_progress:
              type: integer
              description: The number of files that are currently being processed.
            completed:
              type: integer
              description: The number of files that have been successfully processed.
            failed:
              type: integer
              description: The number of files that have failed to process.
            cancelled:
              type: integer
              description: The number of files that were cancelled.
            total:
              type: integer
              description: The total number of files.
        status:
          enum:
            - expired
            - in_progress
            - completed
          type: string
          description: 'The status of the vector store, which can be either `expired`, `in_progress`, or `completed`. A status of `completed` indicates that the vector store is ready for use.'
        expires_after:
          $ref: '#/components/schemas/VectorStoreExpirationAfter'
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store will expire.
          nullable: true
        last_active_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store was last active.
          nullable: true
        metadata:
          type: object
          description: "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.\n"
          nullable: true
          x-oaiTypeLabel: map
      description: A vector store is a collection of processed files can be used by the `file_search` tool.
      x-oaiMeta:
        name: The vector store object
        beta: true
        example: "{\n  \"id\": \"vs_123\",\n  \"object\": \"vector_store\",\n  \"created_at\": 1698107661,\n  \"usage_bytes\": 123456,\n  \"last_active_at\": 1698107661,\n  \"name\": \"my_vector_store\",\n  \"status\": \"completed\",\n  \"file_counts\": {\n    \"in_progress\": 0,\n    \"completed\": 100,\n    \"cancelled\": 0,\n    \"failed\": 0,\n    \"total\": 100\n  },\n  \"metadata\": {},\n  \"last_used_at\": 1698107661\n}\n"
    RealtimeServerEventType:
      enum:
        - error
        - session.created
        - session.updated
        - conversation.created
        - input_audio_buffer.committed
        - input_audio_buffer.cleared
        - input_audio_buffer.speech_started
        - input_audio_buffer.speech_stopped
        - conversation.item.created
        - conversation.item.input_audio_transcription.completed
        - conversation.item.input_audio_transcription.failed
        - conversation.item.truncated
        - conversation.item.deleted
        - response.created
        - response.done
        - response.output_item.added
        - response.output_item.done
        - response.content_part.added
        - response.content_part.done
        - response.text.delta
        - response.text.done
        - response.audio_transcript.delta
        - response.audio_transcript.done
        - response.audio.delta
        - response.audio.done
        - response.function_call_arguments.delta
        - response.function_call_arguments.done
        - rate_limits.updated
      type: string
    RealtimeServerEventBase:
      required:
        - type
        - event_id
      type: object
      properties:
        event_id:
          type: string
        type:
          $ref: '#/components/schemas/RealtimeServerEventType'
    RealtimeAudioFormat:
      enum:
        - pcm16
        - g711_ulaw
        - g711_alaw
      type: string
      description: The format of input/output audio.
    RealtimeConversation:
      type: object
      properties:
        id:
          type: string
          description: The unique ID of the conversation.
          example: conv_001
        object:
          enum:
            - realtime.conversation
          type: string
          description: 'The object type, must be "realtime.conversation".'
          example: realtime.conversation
      description: "A realtime Conversation consists of a list of Items.\nBy default, there is only one Conversation, and it gets created at the beginning of the Session.\nIn the future, we may add support for additional conversations.\n"
      example:
        id: conv_001
        object: realtime.conversation
    RealtimeContentPart:
      type: object
      properties:
        type:
          enum:
            - text
            - audio
          type: string
          description: The content type.
          example: text
        text:
          type: string
          description: The text content (if type is "text").
          example: 'Sure, I can help with that.'
        audio:
          type: string
          description: Base64-encoded audio data (if type is "audio").
        transcript:
          type: string
          description: The transcript of the audio (if type is "audio").
      description: The content part that was added.
    RealtimeErrorDetails:
      type: object
      properties:
        type:
          type: string
          description: 'The type of error (e.g., "invalid_request_error", "server_error").'
          example: invalid_request_error
        code:
          type: string
          description: 'Error code, if any.'
          example: invalid_event
        message:
          type: string
          description: A human-readable error message.
          example: The 'type' field is missing.
        param:
          type: string
          description: 'Parameter related to the error, if any.'
          example: 
        event_id:
          type: string
          description: 'The event_id of the client event that caused the error, if applicable.'
          example: event_567
      description: Details of the error.
      example:
        type: invalid_request_error
        code: invalid_event
        message: The 'type' field is missing.
        param: 
        event_id: event_567
    RealtimeSessionUpdate:
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
          example: event_123
        type:
          enum:
            - session.update
          type: string
          description: 'The event type, must be "session.update".'
          example: session.update
        session:
          $ref: '#/components/schemas/RealtimeSession'
      description: Send this event to update the session’s default configuration.
      example:
        event_id: event_123
        type: session.update
        session:
          modalities:
            - text
            - audio
          instructions: Your knowledge cutoff is 2023-10. You are a helpful assistant.
          voice: alloy
          input_audio_format: pcm16
          output_audio_format: pcm16
          input_audio_transcription:
            enabled: true
            model: whisper-1
          turn_detection:
            type: server_vad
            threshold: 0.5
            prefix_padding_ms: 300
            silence_duration_ms: 200
          tools:
            - type: function
              name: get_weather
              description: Get the current weather for a location.
              parameters:
                type: object
                properties:
                  location:
                    type: string
                required:
                  - location
          tool_choice: auto
          temperature: 0.8
          max_output_tokens: 
    RealtimeInputAudioBufferAppend:
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
          example: event_456
        type:
          enum:
            - input_audio_buffer.append
          type: string
          description: 'The event type, must be "input_audio_buffer.append".'
          example: input_audio_buffer.append
        audio:
          type: string
          description: Base64-encoded audio bytes.
          example: Base64EncodedAudioData
      description: Send this event to append audio bytes to the input audio buffer.
      example:
        event_id: event_456
        type: input_audio_buffer.append
        audio: Base64EncodedAudioData
    RealtimeInputAudioBufferCommit:
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
          example: event_789
        type:
          enum:
            - input_audio_buffer.commit
          type: string
          description: 'The event type, must be "input_audio_buffer.commit".'
          example: input_audio_buffer.commit
      description: Send this event to commit audio bytes to a user message.
      example:
        event_id: event_789
        type: input_audio_buffer.commit
    RealtimeInputAudioBufferClear:
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
          example: event_012
        type:
          enum:
            - input_audio_buffer.clear
          type: string
          description: 'The event type, must be "input_audio_buffer.clear".'
          example: input_audio_buffer.clear
      description: Send this event to clear the audio bytes in the buffer.
      example:
        event_id: event_012
        type: input_audio_buffer.clear
    RealtimeConversationItemCreate:
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
          example: event_345
        type:
          enum:
            - conversation.item.create
          type: string
          description: 'The event type, must be "conversation.item.create".'
          example: conversation.item.create
        previous_item_id:
          type: string
          description: The ID of the preceding item after which the new item will be inserted.
          example: 
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
      description: Send this event when adding an item to the conversation.
      example:
        event_id: event_345
        type: conversation.item.create
        previous_item_id: 
        item:
          id: msg_001
          type: message
          status: completed
          role: user
          content:
            - type: input_text
              text: 'Hello, how are you?'
    RealtimeConversationItemTruncate:
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
          example: event_678
        type:
          enum:
            - conversation.item.truncate
          type: string
          description: 'The event type, must be "conversation.item.truncate".'
          example: conversation.item.truncate
        item_id:
          type: string
          description: The ID of the assistant message item to truncate.
          example: msg_002
        content_index:
          type: integer
          description: The index of the content part to truncate.
          example: 0
        audio_end_ms:
          type: integer
          description: 'Inclusive duration up to which audio is truncated, in milliseconds.'
          example: 1500
      description: Send this event when you want to truncate a previous assistant message’s audio.
      example:
        event_id: event_678
        type: conversation.item.truncate
        item_id: msg_002
        content_index: 0
        audio_end_ms: 1500
    RealtimeConversationItemDelete:
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
          example: event_901
        type:
          enum:
            - conversation.item.delete
          type: string
          description: 'The event type, must be "conversation.item.delete".'
          example: conversation.item.delete
        item_id:
          type: string
          description: The ID of the item to delete.
          example: msg_003
      description: Send this event when you want to remove any item from the conversation history.
      example:
        event_id: event_901
        type: conversation.item.delete
        item_id: msg_003
    RealtimeResponseCreate:
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        type:
          enum:
            - response.create
          type: string
          description: 'The event type, must be ''response.create''.'
        response:
          type: object
          properties:
            modalities:
              type: array
              items:
                enum:
                  - text
                  - audio
                type: string
              description: The modalities for the response.
            instructions:
              type: string
              description: Instructions for the model.
            voice:
              enum:
                - alloy
                - echo
                - shimmer
              type: string
              description: The voice the model uses to respond.
            output_audio_format:
              $ref: '#/components/schemas/RealtimeAudioFormat'
            tools:
              type: array
              items:
                type: object
                properties:
                  type:
                    type: string
                    description: The type of the tool.
                  name:
                    type: string
                    description: The name of the function.
                  description:
                    type: string
                    description: The description of the function.
                  parameters:
                    type: object
                    description: Parameters of the function in JSON Schema.
              description: Tools (functions) available to the model.
            tool_choice:
              oneOf:
                - enum:
                    - auto
                    - none
                    - required
                  type: string
                - type: string
              description: "How the model chooses tools. \nOptions are \"auto\", \"none\", \"required\", or specify a function.\n"
            temperature:
              type: number
              description: Sampling temperature.
            max_output_tokens:
              oneOf:
                - type: integer
                - enum:
                    - inf
                  type: string
              description: 'Maximum number of output tokens for a single assistant response, inclusive of tool calls. Provide an integer between 1 and 4096 to limit output tokens, or "inf" for the maximum available tokens for a given model. Defaults to "inf".'
              default: inf
          description: Configuration for the response.
      description: Send this event to trigger a response generation.
    RealtimeResponseCancel:
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
          example: event_567
        type:
          enum:
            - response.cancel
          type: string
          description: 'The event type, must be "response.cancel".'
          example: response.cancel
      description: Send this event to cancel an in-progress response.
      example:
        event_id: event_567
        type: response.cancel
    RealtimeError:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_890
        type:
          enum:
            - error
          type: string
          description: 'The event type, must be "error".'
          example: error
        error:
          $ref: '#/components/schemas/RealtimeErrorDetails'
      description: Returned when an error occurs.
      example:
        event_id: event_890
        type: error
        error:
          type: invalid_request_error
          code: invalid_event
          message: The 'type' field is missing.
          param: 
          event_id: event_567
    RealtimeSessionCreated:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_1234
        type:
          enum:
            - session.created
          type: string
          description: 'The event type, must be "session.created".'
          example: session.created
        session:
          $ref: '#/components/schemas/RealtimeSession'
      description: Returned when a session is created. Emitted automatically when a new connection is established.
    RealtimeSessionUpdated:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_5678
        type:
          enum:
            - session.updated
          type: string
          description: 'The event type, must be "session.updated".'
          example: session.updated
        session:
          $ref: '#/components/schemas/RealtimeSession'
      description: Returned when a session is updated.
    RealtimeConversationCreated:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_9101
        type:
          enum:
            - conversation.created
          type: string
          description: 'The event type, must be "conversation.created".'
          example: conversation.created
        conversation:
          $ref: '#/components/schemas/RealtimeConversation'
      description: Returned when a conversation is created. Emitted right after session creation.
      example:
        event_id: event_9101
        type: conversation.created
        conversation:
          id: conv_001
          object: realtime.conversation
    RealtimeConversationItemCreated:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_1920
        type:
          enum:
            - conversation.item.created
          type: string
          description: 'The event type, must be "conversation.item.created".'
          example: conversation.item.created
        previous_item_id:
          type: string
          description: The ID of the preceding item.
          example: msg_002
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
      description: Returned when a conversation item is created.
      example:
        event_id: event_1920
        type: conversation.item.created
        previous_item_id: msg_002
        item:
          id: msg_003
          object: realtime.item
          type: message
          status: completed
          role: user
          content:
            - type: input_audio
              transcript: 
    RealtimeConversationItemInputAudioTranscriptionCompleted:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_2122
        type:
          enum:
            - conversation.item.input_audio_transcription.completed
          type: string
          description: 'The event type, must be "conversation.item.input_audio_transcription.completed".'
          example: conversation.item.input_audio_transcription.completed
        item_id:
          type: string
          description: The ID of the user message item.
          example: msg_003
        content_index:
          type: integer
          description: The index of the content part containing the audio.
          example: 0
        transcript:
          type: string
          description: The transcribed text.
          example: 'Hello, how are you?'
      description: Returned when input audio transcription is enabled and a transcription succeeds.
      example:
        event_id: event_2122
        type: conversation.item.input_audio_transcription.completed
        item_id: msg_003
        content_index: 0
        transcript: 'Hello, how are you?'
    RealtimeConversationItemInputAudioTranscriptionFailed:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_2324
        type:
          enum:
            - conversation.item.input_audio_transcription.failed
          type: string
          description: 'The event type, must be "conversation.item.input_audio_transcription.failed".'
          example: conversation.item.input_audio_transcription.failed
        item_id:
          type: string
          description: The ID of the user message item.
          example: msg_003
        content_index:
          type: integer
          description: The index of the content part containing the audio.
          example: 0
        error:
          $ref: '#/components/schemas/RealtimeErrorDetails'
      description: 'Returned when input audio transcription is configured, and a transcription request for a user message failed.'
      example:
        event_id: event_2324
        type: conversation.item.input_audio_transcription.failed
        item_id: msg_003
        content_index: 0
        error:
          type: transcription_error
          code: audio_unintelligible
          message: The audio could not be transcribed.
          param: 
    RealtimeConversationItemTruncated:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_2526
        type:
          enum:
            - conversation.item.truncated
          type: string
          description: 'The event type, must be "conversation.item.truncated".'
          example: conversation.item.truncated
        item_id:
          type: string
          description: The ID of the assistant message item that was truncated.
          example: msg_004
        content_index:
          type: integer
          description: The index of the content part that was truncated.
          example: 0
        audio_end_ms:
          type: integer
          description: 'The duration up to which the audio was truncated, in milliseconds.'
          example: 1500
      description: Returned when an earlier assistant audio message item is truncated by the client.
      example:
        event_id: event_2526
        type: conversation.item.truncated
        item_id: msg_004
        content_index: 0
        audio_end_ms: 1500
    RealtimeConversationItemDeleted:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_2728
        type:
          enum:
            - conversation.item.deleted
          type: string
          description: 'The event type, must be "conversation.item.deleted".'
          example: conversation.item.deleted
        item_id:
          type: string
          description: The ID of the item that was deleted.
          example: msg_005
      description: Returned when an item in the conversation is deleted.
      example:
        event_id: event_2728
        type: conversation.item.deleted
        item_id: msg_005
    RealtimeInputAudioBufferCommitted:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_1121
        type:
          enum:
            - input_audio_buffer.committed
          type: string
          description: 'The event type, must be "input_audio_buffer.committed".'
          example: input_audio_buffer.committed
        previous_item_id:
          type: string
          description: The ID of the preceding item after which the new item will be inserted.
          example: msg_001
        item_id:
          type: string
          description: The ID of the user message item that will be created.
          example: msg_002
      description: 'Returned when an input audio buffer is committed, either by the client or automatically in server VAD mode.'
      example:
        event_id: event_1121
        type: input_audio_buffer.committed
        previous_item_id: msg_001
        item_id: msg_002
    RealtimeInputAudioBufferCleared:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_1314
        type:
          enum:
            - input_audio_buffer.cleared
          type: string
          description: 'The event type, must be "input_audio_buffer.cleared".'
          example: input_audio_buffer.cleared
      description: Returned when the input audio buffer is cleared by the client.
      example:
        event_id: event_1314
        type: input_audio_buffer.cleared
    RealtimeInputAudioBufferSpeechStarted:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_1516
        type:
          enum:
            - input_audio_buffer.speech_started
          type: string
          description: 'The event type, must be "input_audio_buffer.speech_started".'
          example: input_audio_buffer.speech_started
        audio_start_ms:
          type: integer
          description: Milliseconds since the session started when speech was detected.
          example: 1000
        item_id:
          type: string
          description: The ID of the user message item that will be created when speech stops.
          example: msg_003
      description: Returned in server turn detection mode when speech is detected.
      example:
        event_id: event_1516
        type: input_audio_buffer.speech_started
        audio_start_ms: 1000
        item_id: msg_003
    RealtimeInputAudioBufferSpeechStopped:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_1718
        type:
          enum:
            - input_audio_buffer.speech_stopped
          type: string
          description: 'The event type, must be "input_audio_buffer.speech_stopped".'
          example: input_audio_buffer.speech_stopped
        audio_end_ms:
          type: integer
          description: Milliseconds since the session started when speech stopped.
          example: 2000
        item_id:
          type: string
          description: The ID of the user message item that will be created.
          example: msg_003
      description: Returned in server turn detection mode when speech stops.
      example:
        event_id: event_1718
        type: input_audio_buffer.speech_stopped
        audio_end_ms: 2000
        item_id: msg_003
    RealtimeResponseCreated:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_2930
        type:
          enum:
            - response.created
          type: string
          description: 'The event type, must be "response.created".'
          example: response.created
        response:
          $ref: '#/components/schemas/RealtimeResponse'
      description: 'Returned when a new Response is created. The first event of response creation, where the response is in an initial state of "in_progress".'
      example:
        event_id: event_2930
        type: response.created
        response:
          id: resp_001
          object: realtime.response
          status: in_progress
          status_details: 
          output: [ ]
          usage: 
    RealtimeResponseDone:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_3132
        type:
          enum:
            - response.done
          type: string
          description: 'The event type, must be "response.done".'
          example: response.done
        response:
          $ref: '#/components/schemas/RealtimeResponse'
      description: 'Returned when a Response is done streaming. Always emitted, no matter the final state.'
      example:
        event_id: event_3132
        type: response.done
        response:
          id: resp_001
          object: realtime.response
          status: completed
          status_details: 
          output:
            - id: msg_006
              object: realtime.item
              type: message
              status: completed
              role: assistant
              content:
                - type: text
                  text: 'Sure, how can I assist you today?'
          usage:
            total_tokens: 50
            input_tokens: 20
            output_tokens: 30
    RealtimeResponseOutputItemAdded:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_3334
        type:
          enum:
            - response.output_item.added
          type: string
          description: 'The event type, must be "response.output_item.added".'
          example: response.output_item.added
        response_id:
          type: string
          description: The ID of the response to which the item belongs.
          example: resp_001
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
      description: Returned when a new Item is created during response generation.
      example:
        event_id: event_3334
        type: response.output_item.added
        response_id: resp_001
        output_index: 0
        item:
          id: msg_007
          object: realtime.item
          type: message
          status: in_progress
          role: assistant
          content: [ ]
    RealtimeResponseOutputItemDone:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_3536
        type:
          enum:
            - response.output_item.done
          type: string
          description: 'The event type, must be "response.output_item.done".'
          example: response.output_item.done
        response_id:
          type: string
          description: The ID of the response to which the item belongs.
          example: resp_001
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
      description: 'Returned when an Item is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.'
      example:
        event_id: event_3536
        type: response.output_item.done
        response_id: resp_001
        output_index: 0
        item:
          id: msg_007
          object: realtime.item
          type: message
          status: completed
          role: assistant
          content:
            - type: text
              text: 'Sure, I can help with that.'
    RealtimeResponseContentPartAdded:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_3738
        type:
          enum:
            - response.content_part.added
          type: string
          description: 'The event type, must be "response.content_part.added".'
          example: response.content_part.added
        response_id:
          type: string
          description: The ID of the response.
          example: resp_001
        item_id:
          type: string
          description: The ID of the item to which the content part was added.
          example: msg_007
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
          example: 0
        part:
          $ref: '#/components/schemas/RealtimeContentPart'
      description: Returned when a new content part is added to an assistant message item during response generation.
      example:
        event_id: event_3738
        type: response.content_part.added
        response_id: resp_001
        item_id: msg_007
        output_index: 0
        content_index: 0
        part:
          type: text
          text: ''
    RealtimeResponseContentPartDone:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_3940
        type:
          enum:
            - response.content_part.done
          type: string
          description: 'The event type, must be "response.content_part.done".'
          example: response.content_part.done
        response_id:
          type: string
          description: The ID of the response.
          example: resp_001
        item_id:
          type: string
          description: The ID of the item.
          example: msg_007
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
          example: 0
        part:
          $ref: '#/components/schemas/RealtimeContentPart'
      description: 'Returned when a content part is done streaming in an assistant message item. Also emitted when a Response is interrupted, incomplete, or cancelled.'
      example:
        event_id: event_3940
        type: response.content_part.done
        response_id: resp_001
        item_id: msg_007
        output_index: 0
        content_index: 0
        part:
          type: text
          text: 'Sure, I can help with that.'
    RealtimeResponseTextDelta:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_4142
        type:
          enum:
            - response.text.delta
          type: string
          description: 'The event type, must be "response.text.delta".'
          example: response.text.delta
        response_id:
          type: string
          description: The ID of the response.
          example: resp_001
        item_id:
          type: string
          description: The ID of the item.
          example: msg_007
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
          example: 0
        delta:
          type: string
          description: The text delta.
          example: 'Sure, I can h'
      description: Returned when the text value of a "text" content part is updated.
      example:
        event_id: event_4142
        type: response.text.delta
        response_id: resp_001
        item_id: msg_007
        output_index: 0
        content_index: 0
        delta: 'Sure, I can h'
    RealtimeResponseTextDone:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_4344
        type:
          enum:
            - response.text.done
          type: string
          description: 'The event type, must be "response.text.done".'
          example: response.text.done
        response_id:
          type: string
          description: The ID of the response.
          example: resp_001
        item_id:
          type: string
          description: The ID of the item.
          example: msg_007
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
          example: 0
        text:
          type: string
          description: The final text content.
          example: 'Sure, I can help with that.'
      description: 'Returned when the text value of a "text" content part is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.'
      example:
        event_id: event_4344
        type: response.text.done
        response_id: resp_001
        item_id: msg_007
        output_index: 0
        content_index: 0
        text: 'Sure, I can help with that.'
    RealtimeResponseAudioTranscriptDelta:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_4546
        type:
          enum:
            - response.audio_transcript.delta
          type: string
          description: 'The event type, must be "response.audio_transcript.delta".'
          example: response.audio_transcript.delta
        response_id:
          type: string
          description: The ID of the response.
          example: resp_001
        item_id:
          type: string
          description: The ID of the item.
          example: msg_008
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
          example: 0
        delta:
          type: string
          description: The transcript delta.
          example: 'Hello, how can I a'
      description: Returned when the model-generated transcription of audio output is updated.
      example:
        event_id: event_4546
        type: response.audio_transcript.delta
        response_id: resp_001
        item_id: msg_008
        output_index: 0
        content_index: 0
        delta: 'Hello, how can I a'
    RealtimeResponseAudioTranscriptDone:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_4748
        type:
          enum:
            - response.audio_transcript.done
          type: string
          description: 'The event type, must be "response.audio_transcript.done".'
          example: response.audio_transcript.done
        response_id:
          type: string
          description: The ID of the response.
          example: resp_001
        item_id:
          type: string
          description: The ID of the item.
          example: msg_008
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
          example: 0
        transcript:
          type: string
          description: The final transcript of the audio.
          example: 'Hello, how can I assist you today?'
      description: 'Returned when the model-generated transcription of audio output is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.'
      example:
        event_id: event_4748
        type: response.audio_transcript.done
        response_id: resp_001
        item_id: msg_008
        output_index: 0
        content_index: 0
        transcript: 'Hello, how can I assist you today?'
    RealtimeResponseAudioDelta:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_4950
        type:
          enum:
            - response.audio.delta
          type: string
          description: 'The event type, must be "response.audio.delta".'
          example: response.audio.delta
        response_id:
          type: string
          description: The ID of the response.
          example: resp_001
        item_id:
          type: string
          description: The ID of the item.
          example: msg_008
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
          example: 0
        delta:
          type: string
          description: Base64-encoded audio data delta.
          example: Base64EncodedAudioDelta
      description: Returned when the model-generated audio is updated.
      example:
        event_id: event_4950
        type: response.audio.delta
        response_id: resp_001
        item_id: msg_008
        output_index: 0
        content_index: 0
        delta: Base64EncodedAudioDelta
    RealtimeResponseAudioDone:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_5152
        type:
          enum:
            - response.audio.done
          type: string
          description: 'The event type, must be "response.audio.done".'
          example: response.audio.done
        response_id:
          type: string
          description: The ID of the response.
          example: resp_001
        item_id:
          type: string
          description: The ID of the item.
          example: msg_008
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
          example: 0
      description: 'Returned when the model-generated audio is done. Also emitted when a Response is interrupted, incomplete, or cancelled.'
      example:
        event_id: event_5152
        type: response.audio.done
        response_id: resp_001
        item_id: msg_008
        output_index: 0
        content_index: 0
    RealtimeResponseFunctionCallArgumentsDelta:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_5354
        type:
          enum:
            - response.function_call_arguments.delta
          type: string
          description: 'The event type, must be "response.function_call_arguments.delta".'
          example: response.function_call_arguments.delta
        response_id:
          type: string
          description: The ID of the response.
          example: resp_002
        item_id:
          type: string
          description: The ID of the function call item.
          example: fc_001
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        call_id:
          type: string
          description: The ID of the function call.
          example: call_001
        delta:
          type: string
          description: The arguments delta as a JSON string.
          example: '{"location": "San"'
      description: Returned when the model-generated function call arguments are updated.
      example:
        event_id: event_5354
        type: response.function_call_arguments.delta
        response_id: resp_002
        item_id: fc_001
        output_index: 0
        call_id: call_001
        delta: '{"location": "San"'
    RealtimeResponseFunctionCallArgumentsDone:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_5556
        type:
          enum:
            - response.function_call_arguments.done
          type: string
          description: 'The event type, must be "response.function_call_arguments.done".'
          example: response.function_call_arguments.done
        response_id:
          type: string
          description: The ID of the response.
          example: resp_002
        item_id:
          type: string
          description: The ID of the function call item.
          example: fc_001
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        call_id:
          type: string
          description: The ID of the function call.
          example: call_001
        arguments:
          type: string
          description: The final arguments as a JSON string.
          example: '{"location": "San Francisco"}'
      description: 'Returned when the model-generated function call arguments are done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.'
      example:
        event_id: event_5556
        type: response.function_call_arguments.done
        response_id: resp_002
        item_id: fc_001
        output_index: 0
        call_id: call_001
        arguments: '{"location": "San Francisco"}'
    RealtimeRateLimitsUpdated:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_5758
        type:
          enum:
            - rate_limits.updated
          type: string
          description: 'The event type, must be "rate_limits.updated".'
          example: rate_limits.updated
        rate_limits:
          type: array
          items:
            type: object
            properties:
              name:
                enum:
                  - requests
                  - tokens
                  - input_tokens
                  - output_tokens
                type: string
                description: The name of the rate limit.
                example: requests
              limit:
                type: integer
                description: The maximum allowed value for the rate limit.
                example: 1000
              remaining:
                type: integer
                description: The remaining value before the limit is reached.
                example: 999
              reset_seconds:
                type: number
                description: Seconds until the rate limit resets.
                example: 60
          description: List of rate limit information.
      description: Emitted after every "response.done" event to indicate the updated rate limits.
      example:
        event_id: event_5758
        type: rate_limits.updated
        rate_limits:
          - name: requests
            limit: 1000
            remaining: 999
            reset_seconds: 60
          - name: tokens
            limit: 50000
            remaining: 49950
            reset_seconds: 60
    RealtimeServerEvent:
      oneOf:
        - $ref: '#/components/schemas/RealtimeError'
        - $ref: '#/components/schemas/RealtimeSessionCreated'
        - $ref: '#/components/schemas/RealtimeSessionUpdated'
        - $ref: '#/components/schemas/RealtimeConversationCreated'
        - $ref: '#/components/schemas/RealtimeConversationItemCreated'
        - $ref: '#/components/schemas/RealtimeConversationItemInputAudioTranscriptionCompleted'
        - $ref: '#/components/schemas/RealtimeConversationItemInputAudioTranscriptionFailed'
        - $ref: '#/components/schemas/RealtimeConversationItemTruncated'
        - $ref: '#/components/schemas/RealtimeConversationItemDeleted'
        - $ref: '#/components/schemas/RealtimeInputAudioBufferCommitted'
        - $ref: '#/components/schemas/RealtimeInputAudioBufferCleared'
        - $ref: '#/components/schemas/RealtimeInputAudioBufferSpeechStarted'
        - $ref: '#/components/schemas/RealtimeInputAudioBufferSpeechStopped'
        - $ref: '#/components/schemas/RealtimeResponseCreated'
        - $ref: '#/components/schemas/RealtimeResponseDone'
        - $ref: '#/components/schemas/RealtimeResponseOutputItemAdded'
        - $ref: '#/components/schemas/RealtimeResponseOutputItemDone'
        - $ref: '#/components/schemas/RealtimeResponseContentPartAdded'
        - $ref: '#/components/schemas/RealtimeResponseContentPartDone'
        - $ref: '#/components/schemas/RealtimeResponseTextDelta'
        - $ref: '#/components/schemas/RealtimeResponseTextDone'
        - $ref: '#/components/schemas/RealtimeResponseAudioTranscriptDelta'
        - $ref: '#/components/schemas/RealtimeResponseAudioTranscriptDone'
        - $ref: '#/components/schemas/RealtimeResponseAudioDelta'
        - $ref: '#/components/schemas/RealtimeResponseAudioDone'
        - $ref: '#/components/schemas/RealtimeResponseFunctionCallArgumentsDelta'
        - $ref: '#/components/schemas/RealtimeResponseFunctionCallArgumentsDone'
        - $ref: '#/components/schemas/RealtimeRateLimitsUpdated'
  securitySchemes:
    ApiKeyAuth:
      type: http
      scheme: bearer
security:
  - ApiKeyAuth: [ ]
tags:
  - name: Assistants
    description: Build Assistants that can call models and use tools.
  - name: Audio
    description: Turn audio into text or text into audio.
  - name: Chat
    description: 'Given a list of messages comprising a conversation, the model will return a response.'
  - name: Completions
    description: 'Given a prompt, the model will return one or more predicted completions, and can also return the probabilities of alternative tokens at each position.'
  - name: Embeddings
    description: Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
  - name: Fine-tuning
    description: Manage fine-tuning jobs to tailor a model to your specific training data.
  - name: Batch
    description: Create large batches of API requests to run asynchronously.
  - name: Files
    description: Files are used to upload documents that can be used with features like Assistants and Fine-tuning.
  - name: Uploads
    description: Use Uploads to upload large files in multiple parts.
  - name: Images
    description: 'Given a prompt and/or an input image, the model will generate a new image.'
  - name: Models
    description: List and describe the various models available in the API.
  - name: Moderations
    description: 'Given text and/or image inputs, classifies if those inputs are potentially harmful.'
  - name: Audit Logs
    description: List user actions and configuration changes within this organization.
x-oaiMeta:
  navigationGroups:
    - id: endpoints
      title: Endpoints
    - id: assistants
      title: Assistants
      beta: true
    - id: administration
      title: Administration
    - id: realtime
      title: Realtime
      beta: true
    - id: legacy
      title: Legacy
  groups:
    - id: audio
      title: Audio
      description: "Learn how to turn audio into text or text into audio.\n\nRelated guide: [Speech to text](/docs/guides/speech-to-text)\n"
      navigationGroup: endpoints
      sections:
        - type: endpoint
          key: createSpeech
          path: createSpeech
        - type: endpoint
          key: createTranscription
          path: createTranscription
        - type: endpoint
          key: createTranslation
          path: createTranslation
        - type: object
          key: CreateTranscriptionResponseJson
          path: json-object
        - type: object
          key: CreateTranscriptionResponseVerboseJson
          path: verbose-json-object
    - id: chat
      title: Chat
      description: "Given a list of messages comprising a conversation, the model will return a response.\nRelated guide: [Chat Completions](/docs/guides/text-generation)\n"
      navigationGroup: endpoints
      sections:
        - type: endpoint
          key: createChatCompletion
          path: create
        - type: object
          key: CreateChatCompletionResponse
          path: object
        - type: object
          key: CreateChatCompletionStreamResponse
          path: streaming
    - id: embeddings
      title: Embeddings
      description: "Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.\nRelated guide: [Embeddings](/docs/guides/embeddings)\n"
      navigationGroup: endpoints
      sections:
        - type: endpoint
          key: createEmbedding
          path: create
        - type: object
          key: Embedding
          path: object
    - id: fine-tuning
      title: Fine-tuning
      description: "Manage fine-tuning jobs to tailor a model to your specific training data.\nRelated guide: [Fine-tune models](/docs/guides/fine-tuning)\n"
      navigationGroup: endpoints
      sections:
        - type: endpoint
          key: createFineTuningJob
          path: create
        - type: endpoint
          key: listPaginatedFineTuningJobs
          path: list
        - type: endpoint
          key: listFineTuningEvents
          path: list-events
        - type: endpoint
          key: listFineTuningJobCheckpoints
          path: list-checkpoints
        - type: endpoint
          key: retrieveFineTuningJob
          path: retrieve
        - type: endpoint
          key: cancelFineTuningJob
          path: cancel
        - type: object
          key: FinetuneChatRequestInput
          path: chat-input
        - type: object
          key: FinetuneCompletionRequestInput
          path: completions-input
        - type: object
          key: FineTuningJob
          path: object
        - type: object
          key: FineTuningJobEvent
          path: event-object
        - type: object
          key: FineTuningJobCheckpoint
          path: checkpoint-object
    - id: batch
      title: Batch
      description: "Create large batches of API requests for asynchronous processing. The Batch API returns completions within 24 hours for a 50% discount.\nRelated guide: [Batch](/docs/guides/batch)\n"
      navigationGroup: endpoints
      sections:
        - type: endpoint
          key: createBatch
          path: create
        - type: endpoint
          key: retrieveBatch
          path: retrieve
        - type: endpoint
          key: cancelBatch
          path: cancel
        - type: endpoint
          key: listBatches
          path: list
        - type: object
          key: Batch
          path: object
        - type: object
          key: BatchRequestInput
          path: request-input
        - type: object
          key: BatchRequestOutput
          path: request-output
    - id: files
      title: Files
      description: "Files are used to upload documents that can be used with features like [Assistants](/docs/api-reference/assistants), [Fine-tuning](/docs/api-reference/fine-tuning), and [Batch API](/docs/guides/batch).\n"
      navigationGroup: endpoints
      sections:
        - type: endpoint
          key: createFile
          path: create
        - type: endpoint
          key: listFiles
          path: list
        - type: endpoint
          key: retrieveFile
          path: retrieve
        - type: endpoint
          key: deleteFile
          path: delete
        - type: endpoint
          key: downloadFile
          path: retrieve-contents
        - type: object
          key: OpenAIFile
          path: object
    - id: uploads
      title: Uploads
      description: "Allows you to upload large files in multiple parts.\n"
      navigationGroup: endpoints
      sections:
        - type: endpoint
          key: createUpload
          path: create
        - type: endpoint
          key: addUploadPart
          path: add-part
        - type: endpoint
          key: completeUpload
          path: complete
        - type: endpoint
          key: cancelUpload
          path: cancel
        - type: object
          key: Upload
          path: object
        - type: object
          key: UploadPart
          path: part-object
    - id: images
      title: Images
      description: "Given a prompt and/or an input image, the model will generate a new image.\nRelated guide: [Image generation](/docs/guides/images)\n"
      navigationGroup: endpoints
      sections:
        - type: endpoint
          key: createImage
          path: create
        - type: endpoint
          key: createImageEdit
          path: createEdit
        - type: endpoint
          key: createImageVariation
          path: createVariation
        - type: object
          key: Image
          path: object
    - id: models
      title: Models
      description: "List and describe the various models available in the API. You can refer to the [Models](/docs/models) documentation to understand what models are available and the differences between them.\n"
      navigationGroup: endpoints
      sections:
        - type: endpoint
          key: listModels
          path: list
        - type: endpoint
          key: retrieveModel
          path: retrieve
        - type: endpoint
          key: deleteModel
          path: delete
        - type: object
          key: Model
          path: object
    - id: moderations
      title: Moderations
      description: "Given text and/or image inputs, classifies if those inputs are potentially harmful across several categories.\nRelated guide: [Moderations](/docs/guides/moderation)\n"
      navigationGroup: endpoints
      sections:
        - type: endpoint
          key: createModeration
          path: create
        - type: object
          key: CreateModerationResponse
          path: object
    - id: assistants
      title: Assistants
      beta: true
      description: "Build assistants that can call models and use tools to perform tasks.\n\n[Get started with the Assistants API](/docs/assistants)\n"
      navigationGroup: assistants
      sections:
        - type: endpoint
          key: createAssistant
          path: createAssistant
        - type: endpoint
          key: listAssistants
          path: listAssistants
        - type: endpoint
          key: getAssistant
          path: getAssistant
        - type: endpoint
          key: modifyAssistant
          path: modifyAssistant
        - type: endpoint
          key: deleteAssistant
          path: deleteAssistant
        - type: object
          key: AssistantObject
          path: object
    - id: threads
      title: Threads
      beta: true
      description: "Create threads that assistants can interact with.\n\nRelated guide: [Assistants](/docs/assistants/overview)\n"
      navigationGroup: assistants
      sections:
        - type: endpoint
          key: createThread
          path: createThread
        - type: endpoint
          key: getThread
          path: getThread
        - type: endpoint
          key: modifyThread
          path: modifyThread
        - type: endpoint
          key: deleteThread
          path: deleteThread
        - type: object
          key: ThreadObject
          path: object
    - id: messages
      title: Messages
      beta: true
      description: "Create messages within threads\n\nRelated guide: [Assistants](/docs/assistants/overview)\n"
      navigationGroup: assistants
      sections:
        - type: endpoint
          key: createMessage
          path: createMessage
        - type: endpoint
          key: listMessages
          path: listMessages
        - type: endpoint
          key: getMessage
          path: getMessage
        - type: endpoint
          key: modifyMessage
          path: modifyMessage
        - type: endpoint
          key: deleteMessage
          path: deleteMessage
        - type: object
          key: MessageObject
          path: object
    - id: runs
      title: Runs
      beta: true
      description: "Represents an execution run on a thread.\n\nRelated guide: [Assistants](/docs/assistants/overview)\n"
      navigationGroup: assistants
      sections:
        - type: endpoint
          key: createRun
          path: createRun
        - type: endpoint
          key: createThreadAndRun
          path: createThreadAndRun
        - type: endpoint
          key: listRuns
          path: listRuns
        - type: endpoint
          key: getRun
          path: getRun
        - type: endpoint
          key: modifyRun
          path: modifyRun
        - type: endpoint
          key: submitToolOuputsToRun
          path: submitToolOutputs
        - type: endpoint
          key: cancelRun
          path: cancelRun
        - type: object
          key: RunObject
          path: object
    - id: run-steps
      title: Run steps
      beta: true
      description: "Represents the steps (model and tool calls) taken during the run.\n\nRelated guide: [Assistants](/docs/assistants/overview)\n"
      navigationGroup: assistants
      sections:
        - type: endpoint
          key: listRunSteps
          path: listRunSteps
        - type: endpoint
          key: getRunStep
          path: getRunStep
        - type: object
          key: RunStepObject
          path: step-object
    - id: vector-stores
      title: Vector stores
      beta: true
      description: "Vector stores are used to store files for use by the `file_search` tool.\n\nRelated guide: [File Search](/docs/assistants/tools/file-search)\n"
      navigationGroup: assistants
      sections:
        - type: endpoint
          key: createVectorStore
          path: create
        - type: endpoint
          key: listVectorStores
          path: list
        - type: endpoint
          key: getVectorStore
          path: retrieve
        - type: endpoint
          key: modifyVectorStore
          path: modify
        - type: endpoint
          key: deleteVectorStore
          path: delete
        - type: object
          key: VectorStoreObject
          path: object
    - id: vector-stores-files
      title: Vector store files
      beta: true
      description: "Vector store files represent files inside a vector store.\n\nRelated guide: [File Search](/docs/assistants/tools/file-search)\n"
      navigationGroup: assistants
      sections:
        - type: endpoint
          key: createVectorStoreFile
          path: createFile
        - type: endpoint
          key: listVectorStoreFiles
          path: listFiles
        - type: endpoint
          key: getVectorStoreFile
          path: getFile
        - type: endpoint
          key: deleteVectorStoreFile
          path: deleteFile
        - type: object
          key: VectorStoreFileObject
          path: file-object
    - id: vector-stores-file-batches
      title: Vector store file batches
      beta: true
      description: "Vector store file batches represent operations to add multiple files to a vector store.\nRelated guide: [File Search](/docs/assistants/tools/file-search)\n"
      navigationGroup: assistants
      sections:
        - type: endpoint
          key: createVectorStoreFileBatch
          path: createBatch
        - type: endpoint
          key: getVectorStoreFileBatch
          path: getBatch
        - type: endpoint
          key: cancelVectorStoreFileBatch
          path: cancelBatch
        - type: endpoint
          key: listFilesInVectorStoreBatch
          path: listBatchFiles
        - type: object
          key: VectorStoreFileBatchObject
          path: batch-object
    - id: assistants-streaming
      title: Streaming
      beta: true
      description: "Stream the result of executing a Run or resuming a Run after submitting tool outputs.\nYou can stream events from the [Create Thread and Run](/docs/api-reference/runs/createThreadAndRun),\n[Create Run](/docs/api-reference/runs/createRun), and [Submit Tool Outputs](/docs/api-reference/runs/submitToolOutputs)\nendpoints by passing `\"stream\": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.\nOur Node and Python SDKs provide helpful utilities to make streaming easy. Reference the\n[Assistants API quickstart](/docs/assistants/overview) to learn more.\n"
      navigationGroup: assistants
      sections:
        - type: object
          key: MessageDeltaObject
          path: message-delta-object
        - type: object
          key: RunStepDeltaObject
          path: run-step-delta-object
        - type: object
          key: AssistantStreamEvent
          path: events
    - id: administration
      title: Administration
      description: "Programmatically manage your organization. \nThe Audit Logs endpoint provides a log of all actions taken in the  organization for security and monitoring purposes.\nTo access these endpoints please generate an Admin API Key through the [API Platform Organization overview](/organization/admin-keys). Admin API keys cannot be used for non-administration endpoints.\nFor best practices on setting up your organization, please refer to this [guide](/docs/guides/production-best-practices#setting-up-your-organization)\n"
      navigationGroup: administration
    - id: invite
      title: Invites
      description: Invite and manage invitations for an organization. Invited users are automatically added to the Default project.
      navigationGroup: administration
      sections:
        - type: endpoint
          key: list-invites
          path: list
        - type: endpoint
          key: inviteUser
          path: create
        - type: endpoint
          key: retrieve-invite
          path: retrieve
        - type: endpoint
          key: delete-invite
          path: delete
        - type: object
          key: Invite
          path: object
    - id: users
      title: Users
      description: "Manage users and their role in an organization. Users will be automatically added to the Default project.\n"
      navigationGroup: administration
      sections:
        - type: endpoint
          key: list-users
          path: list
        - type: endpoint
          key: modify-user
          path: modify
        - type: endpoint
          key: retrieve-user
          path: retrieve
        - type: endpoint
          key: delete-user
          path: delete
        - type: object
          key: User
          path: object
    - id: projects
      title: Projects
      description: "Manage the projects within an orgnanization includes creation, updating, and archiving or projects. \nThe Default project cannot be modified or archived.\n"
      navigationGroup: administration
      sections:
        - type: endpoint
          key: list-projects
          path: list
        - type: endpoint
          key: create-project
          path: create
        - type: endpoint
          key: retrieve-project
          path: retrieve
        - type: endpoint
          key: modify-project
          path: modify
        - type: endpoint
          key: archive-project
          path: archive
        - type: object
          key: Project
          path: object
    - id: project-users
      title: Project users
      description: "Manage users within a project, including adding, updating roles, and removing users. \nUsers cannot be removed from the Default project, unless they are being removed from the organization.\n"
      navigationGroup: administration
      sections:
        - type: endpoint
          key: list-project-users
          path: list
        - type: endpoint
          key: create-project-user
          path: creeate
        - type: endpoint
          key: retrieve-project-user
          path: retrieve
        - type: endpoint
          key: modify-project-user
          path: modify
        - type: endpoint
          key: delete-project-user
          path: delete
        - type: object
          key: ProjectUser
          path: object
    - id: project-service-accounts
      title: Project service accounts
      description: "Manage service accounts within a project. A service account is a bot user that is not associated with a user. \nIf a user leaves an organization, their keys and membership in projects will no longer work. Service accounts \ndo not have this limitation. However, service accounts can also be deleted from a project.\n"
      navigationGroup: administration
      sections:
        - type: endpoint
          key: list-project-service-accounts
          path: list
        - type: endpoint
          key: create-project-service-account
          path: create
        - type: endpoint
          key: retrieve-project-service-account
          path: retrieve
        - type: endpoint
          key: delete-project-service-account
          path: delete
        - type: object
          key: ProjectServiceAccount
          path: object
    - id: project-api-keys
      title: Project API keys
      description: "Manage API keys for a given project. Supports listing and deleting keys for users. \nThis API does not allow issuing keys for users, as users need to authorize themselves to generate keys.\n"
      navigationGroup: administration
      sections:
        - type: endpoint
          key: list-project-api-keys
          path: list
        - type: endpoint
          key: retrieve-project-api-key
          path: retrieve
        - type: endpoint
          key: delete-project-api-key
          path: delete
        - type: object
          key: ProjectApiKey
          path: object
    - id: project-rate-limits
      title: Project rate limits
      description: "Manage rate limits per model for projects. Rate limits may be configured to be equal to or lower than the organization's rate limits.\n"
      navigationGroup: administration
      sections:
        - type: endpoint
          key: list-project-rate-limits
          path: list
        - type: endpoint
          key: update-project-rate-limits
          path: update
        - type: object
          key: ProjectRateLimit
          path: object
    - id: audit-logs
      title: Audit logs
      description: "Logs of user actions and configuration changes within this organization. \nTo log events, you must activate logging in the [Organization Settings](/settings/organization/general). \nOnce activated, for security reasons, logging cannot be deactivated.\n"
      navigationGroup: administration
      sections:
        - type: endpoint
          key: list-audit-logs
          path: list
        - type: object
          key: AuditLog
          path: object
    - id: usage
      title: Usage
      description: "The **Usage API** provides detailed insights into your activity across the OpenAI API. It also includes a separate [Costs endpoint](/docs/api-reference/usage/costs), which offers visibility into your spend, breaking down consumption by invoice line items and project IDs.\n\nWhile the Usage API delivers granular usage data, it may not always reconcile perfectly with the Costs due to minor differences in how usage and spend are recorded. For financial purposes, we recommend using the [Costs endpoint](/docs/api-reference/usage/costs) or the [Costs tab](/settings/organization/usage) in the Usage Dashboard, which will reconcile back to your billing invoice.\n"
      navigationGroup: administration
      sections:
        - type: endpoint
          key: usage-completions
          path: completions
        - type: object
          key: UsageCompletionsResult
          path: completions_object
        - type: endpoint
          key: usage-embeddings
          path: embeddings
        - type: object
          key: UsageEmbeddingsResult
          path: embeddings_object
        - type: endpoint
          key: usage-moderations
          path: moderations
        - type: object
          key: UsageModerationsResult
          path: moderations_object
        - type: endpoint
          key: usage-images
          path: images
        - type: object
          key: UsageImagesResult
          path: images_object
        - type: endpoint
          key: usage-audio-speeches
          path: audio_speeches
        - type: object
          key: UsageAudioSpeechesResult
          path: audio_speeches_object
        - type: endpoint
          key: usage-audio-transcriptions
          path: audio_transcriptions
        - type: object
          key: UsageAudioTranscriptionsResult
          path: audio_transcriptions_object
        - type: endpoint
          key: usage-vector-stores
          path: vector_stores
        - type: object
          key: UsageVectorStoresResult
          path: vector_stores_object
        - type: endpoint
          key: usage-code-interpreter-sessions
          path: code_interpreter_sessions
        - type: object
          key: UsageCodeInterpreterSessionsResult
          path: code_interpreter_sessions_object
        - type: endpoint
          key: usage-costs
          path: costs
        - type: object
          key: CostsResult
          path: costs_object
    - id: realtime
      title: Realtime
      beta: true
      description: "Communicate with a GPT-4o class model live, in real time, over WebSocket.\nProduces both audio and text transcriptions.\n[Learn more about the Realtime API](/docs/guides/realtime).\n"
      navigationGroup: realtime
    - id: realtime-client-events
      title: Client events
      description: "These are events that the OpenAI Realtime WebSocket server will accept from the client.\n"
      navigationGroup: realtime
      sections:
        - type: object
          key: RealtimeClientEventSessionUpdate
          path: <auto>
        - type: object
          key: RealtimeClientEventInputAudioBufferAppend
          path: <auto>
        - type: object
          key: RealtimeClientEventInputAudioBufferCommit
          path: <auto>
        - type: object
          key: RealtimeClientEventInputAudioBufferClear
          path: <auto>
        - type: object
          key: RealtimeClientEventConversationItemCreate
          path: <auto>
        - type: object
          key: RealtimeClientEventConversationItemTruncate
          path: <auto>
        - type: object
          key: RealtimeClientEventConversationItemDelete
          path: <auto>
        - type: object
          key: RealtimeClientEventResponseCreate
          path: <auto>
        - type: object
          key: RealtimeClientEventResponseCancel
          path: <auto>
    - id: realtime-server-events
      title: Server events
      description: "These are events emitted from the OpenAI Realtime WebSocket server to the client.\n"
      navigationGroup: realtime
      sections:
        - type: object
          key: RealtimeServerEventError
          path: <auto>
        - type: object
          key: RealtimeServerEventSessionCreated
          path: <auto>
        - type: object
          key: RealtimeServerEventSessionUpdated
          path: <auto>
        - type: object
          key: RealtimeServerEventConversationCreated
          path: <auto>
        - type: object
          key: RealtimeServerEventConversationItemCreated
          path: <auto>
        - type: object
          key: RealtimeServerEventConversationItemInputAudioTranscriptionCompleted
          path: <auto>
        - type: object
          key: RealtimeServerEventConversationItemInputAudioTranscriptionFailed
          path: <auto>
        - type: object
          key: RealtimeServerEventConversationItemTruncated
          path: <auto>
        - type: object
          key: RealtimeServerEventConversationItemDeleted
          path: <auto>
        - type: object
          key: RealtimeServerEventInputAudioBufferCommitted
          path: <auto>
        - type: object
          key: RealtimeServerEventInputAudioBufferCleared
          path: <auto>
        - type: object
          key: RealtimeServerEventInputAudioBufferSpeechStarted
          path: <auto>
        - type: object
          key: RealtimeServerEventInputAudioBufferSpeechStopped
          path: <auto>
        - type: object
          key: RealtimeServerEventResponseCreated
          path: <auto>
        - type: object
          key: RealtimeServerEventResponseDone
          path: <auto>
        - type: object
          key: RealtimeServerEventResponseOutputItemAdded
          path: <auto>
        - type: object
          key: RealtimeServerEventResponseOutputItemDone
          path: <auto>
        - type: object
          key: RealtimeServerEventResponseContentPartAdded
          path: <auto>
        - type: object
          key: RealtimeServerEventResponseContentPartDone
          path: <auto>
        - type: object
          key: RealtimeServerEventResponseTextDelta
          path: <auto>
        - type: object
          key: RealtimeServerEventResponseTextDone
          path: <auto>
        - type: object
          key: RealtimeServerEventResponseAudioTranscriptDelta
          path: <auto>
        - type: object
          key: RealtimeServerEventResponseAudioTranscriptDone
          path: <auto>
        - type: object
          key: RealtimeServerEventResponseAudioDelta
          path: <auto>
        - type: object
          key: RealtimeServerEventResponseAudioDone
          path: <auto>
        - type: object
          key: RealtimeServerEventResponseFunctionCallArgumentsDelta
          path: <auto>
        - type: object
          key: RealtimeServerEventResponseFunctionCallArgumentsDone
          path: <auto>
        - type: object
          key: RealtimeServerEventRateLimitsUpdated
          path: <auto>
    - id: completions
      title: Completions
      legacy: true
      navigationGroup: legacy
      description: "Given a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our [Chat Completions API](/docs/guides/text-generation#text-generation-models) to leverage our best and newest models.\n"
      sections:
        - type: endpoint
          key: createCompletion
          path: create
        - type: object
          key: CreateCompletionResponse
          path: object