openapi: 3.0.4
info:
  title: OpenAI API
  description: The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
  termsOfService: https://openai.com/policies/terms-of-use
  contact:
    name: OpenAI Support
    url: https://help.openai.com/
  license:
    name: MIT
    url: https://github.com/openai/openai-openapi/blob/master/LICENSE
  version: '2.3.0'
servers:
  - url: https://api.openai.com/v1
paths:
  /assistants:
    get:
      tags:
        - Assistants
      summary: List assistants
      description: Returns a list of assistants.
      operationId: listAssistants
      parameters:
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: before
          in: query
          description: "A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListAssistantsResponse'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/assistants?order=desc&limit=20\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.Beta.Assistants.List(context.TODO(), openai.BetaAssistantListParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.assistants.AssistantListPage;\nimport com.openai.models.beta.assistants.AssistantListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        AssistantListPage page = client.beta().assistants().list();\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const assistant of client.beta.assistants.list()) {\n  console.log(assistant.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.beta.assistants.list()\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.beta.assistants.list\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"asst_abc123\",\n      \"object\": \"assistant\",\n      \"created_at\": 1698982736,\n      \"name\": \"Coding Tutor\",\n      \"description\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": \"You are a helpful assistant designed to make me better at coding!\",\n      \"tools\": [],\n      \"tool_resources\": {},\n      \"metadata\": {},\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\": \"auto\"\n    },\n    {\n      \"id\": \"asst_abc456\",\n      \"object\": \"assistant\",\n      \"created_at\": 1698982718,\n      \"name\": \"My Assistant\",\n      \"description\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": \"You are a helpful assistant designed to make me better at coding!\",\n      \"tools\": [],\n      \"tool_resources\": {},\n      \"metadata\": {},\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\": \"auto\"\n    },\n    {\n      \"id\": \"asst_abc789\",\n      \"object\": \"assistant\",\n      \"created_at\": 1698982643,\n      \"name\": null,\n      \"description\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": null,\n      \"tools\": [],\n      \"tool_resources\": {},\n      \"metadata\": {},\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\": \"auto\"\n    }\n  ],\n  \"first_id\": \"asst_abc123\",\n  \"last_id\": \"asst_abc789\",\n  \"has_more\": false\n}\n"
        group: assistants
        name: List assistants
        returns: 'A list of [assistant](https://platform.openai.com/docs/api-reference/assistants/object) objects.'
    post:
      tags:
        - Assistants
      summary: Create assistant
      description: Create an assistant with a model and instructions.
      operationId: createAssistant
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateAssistantRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantObject'
      x-oaiMeta:
        beta: true
        example:
          request:
            curl: "curl \"https://api.openai.com/v1/assistants\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"instructions\": \"You are a personal math tutor. When asked a question, write and run Python code to answer the question.\",\n    \"name\": \"Math Tutor\",\n    \"tools\": [{\"type\": \"code_interpreter\"}],\n    \"model\": \"gpt-4o\"\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n  \"github.com/openai/openai-go/shared\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  assistant, err := client.Beta.Assistants.New(context.TODO(), openai.BetaAssistantNewParams{\n    Model: shared.ChatModelGPT5,\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", assistant.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.ChatModel;\nimport com.openai.models.beta.assistants.Assistant;\nimport com.openai.models.beta.assistants.AssistantCreateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        AssistantCreateParams params = AssistantCreateParams.builder()\n            .model(ChatModel.GPT_5)\n            .build();\n        Assistant assistant = client.beta().assistants().create(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst assistant = await client.beta.assistants.create({ model: 'gpt-4o' });\n\nconsole.log(assistant.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nassistant = client.beta.assistants.create(\n    model=\"gpt-4o\",\n)\nprint(assistant.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nassistant = openai.beta.assistants.create(model: :\"gpt-5\")\n\nputs(assistant)"
          response: "{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n  \"created_at\": 1698984975,\n  \"name\": \"Math Tutor\",\n  \"description\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You are a personal math tutor. When asked a question, write and run Python code to answer the question.\",\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n  \"top_p\": 1.0,\n  \"temperature\": 1.0,\n  \"response_format\": \"auto\"\n}\n"
          title: Code Interpreter
        group: assistants
        name: Create assistant
        returns: 'An [assistant](https://platform.openai.com/docs/api-reference/assistants/object) object.'
  '/assistants/{assistant_id}':
    delete:
      tags:
        - Assistants
      summary: Delete assistant
      description: Delete an assistant.
      operationId: deleteAssistant
      parameters:
        - name: assistant_id
          in: path
          description: The ID of the assistant to delete.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteAssistantResponse'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/assistants/asst_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -X DELETE\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  assistantDeleted, err := client.Beta.Assistants.Delete(context.TODO(), \"assistant_id\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", assistantDeleted.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.assistants.AssistantDeleteParams;\nimport com.openai.models.beta.assistants.AssistantDeleted;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        AssistantDeleted assistantDeleted = client.beta().assistants().delete(\"assistant_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst assistantDeleted = await client.beta.assistants.delete('assistant_id');\n\nconsole.log(assistantDeleted.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nassistant_deleted = client.beta.assistants.delete(\n    \"assistant_id\",\n)\nprint(assistant_deleted.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nassistant_deleted = openai.beta.assistants.delete(\"assistant_id\")\n\nputs(assistant_deleted)"
          response: "{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant.deleted\",\n  \"deleted\": true\n}\n"
        group: assistants
        name: Delete assistant
        returns: Deletion status
    get:
      tags:
        - Assistants
      summary: Retrieve assistant
      description: Retrieves an assistant.
      operationId: getAssistant
      parameters:
        - name: assistant_id
          in: path
          description: The ID of the assistant to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantObject'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/assistants/asst_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  assistant, err := client.Beta.Assistants.Get(context.TODO(), \"assistant_id\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", assistant.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.assistants.Assistant;\nimport com.openai.models.beta.assistants.AssistantRetrieveParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        Assistant assistant = client.beta().assistants().retrieve(\"assistant_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst assistant = await client.beta.assistants.retrieve('assistant_id');\n\nconsole.log(assistant.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nassistant = client.beta.assistants.retrieve(\n    \"assistant_id\",\n)\nprint(assistant.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nassistant = openai.beta.assistants.retrieve(\"assistant_id\")\n\nputs(assistant)"
          response: "{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n  \"created_at\": 1699009709,\n  \"name\": \"HR Helper\",\n  \"description\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You are an HR bot, and you have access to files to answer employee questions about company policies.\",\n  \"tools\": [\n    {\n      \"type\": \"file_search\"\n    }\n  ],\n  \"metadata\": {},\n  \"top_p\": 1.0,\n  \"temperature\": 1.0,\n  \"response_format\": \"auto\"\n}\n"
        group: assistants
        name: Retrieve assistant
        returns: 'The [assistant](https://platform.openai.com/docs/api-reference/assistants/object) object matching the specified ID.'
    post:
      tags:
        - Assistants
      summary: Modify assistant
      description: Modifies an assistant.
      operationId: modifyAssistant
      parameters:
        - name: assistant_id
          in: path
          description: The ID of the assistant to modify.
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyAssistantRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantObject'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/assistants/asst_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n      \"instructions\": \"You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.\",\n      \"tools\": [{\"type\": \"file_search\"}],\n      \"model\": \"gpt-4o\"\n    }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  assistant, err := client.Beta.Assistants.Update(\n    context.TODO(),\n    \"assistant_id\",\n    openai.BetaAssistantUpdateParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", assistant.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.assistants.Assistant;\nimport com.openai.models.beta.assistants.AssistantUpdateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        Assistant assistant = client.beta().assistants().update(\"assistant_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst assistant = await client.beta.assistants.update('assistant_id');\n\nconsole.log(assistant.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nassistant = client.beta.assistants.update(\n    assistant_id=\"assistant_id\",\n)\nprint(assistant.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nassistant = openai.beta.assistants.update(\"assistant_id\")\n\nputs(assistant)"
          response: "{\n  \"id\": \"asst_123\",\n  \"object\": \"assistant\",\n  \"created_at\": 1699009709,\n  \"name\": \"HR Helper\",\n  \"description\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.\",\n  \"tools\": [\n    {\n      \"type\": \"file_search\"\n    }\n  ],\n  \"tool_resources\": {\n    \"file_search\": {\n      \"vector_store_ids\": []\n    }\n  },\n  \"metadata\": {},\n  \"top_p\": 1.0,\n  \"temperature\": 1.0,\n  \"response_format\": \"auto\"\n}\n"
        group: assistants
        name: Modify assistant
        returns: 'The modified [assistant](https://platform.openai.com/docs/api-reference/assistants/object) object.'
  /audio/speech:
    post:
      tags:
        - Audio
      summary: Create speech
      description: Generates audio from the input text.
      operationId: createSpeech
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateSpeechRequest'
        required: true
      responses:
        '200':
          description: OK
          headers:
            Transfer-Encoding:
              description: chunked
              schema:
                type: string
          content:
            application/octet-stream:
              schema:
                type: string
                format: binary
            text/event-stream:
              schema:
                $ref: '#/components/schemas/CreateSpeechResponseStreamEvent'
      x-oaiMeta:
        example:
          request:
            csharp: "using System;\nusing System.IO;\n\nusing OpenAI.Audio;\n\nAudioClient client = new(\n    model: \"gpt-4o-mini-tts\",\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nBinaryData speech = client.GenerateSpeech(\n    text: \"The quick brown fox jumped over the lazy dog.\",\n    voice: GeneratedSpeechVoice.Alloy\n);\n\nusing FileStream stream = File.OpenWrite(\"speech.mp3\");\nspeech.ToStream().CopyTo(stream);\n"
            curl: "curl https://api.openai.com/v1/audio/speech \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"gpt-4o-mini-tts\",\n    \"input\": \"The quick brown fox jumped over the lazy dog.\",\n    \"voice\": \"alloy\"\n  }' \\\n  --output speech.mp3\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  speech, err := client.Audio.Speech.New(context.TODO(), openai.AudioSpeechNewParams{\n    Input: \"input\",\n    Model: openai.SpeechModelTTS1,\n    Voice: openai.AudioSpeechNewParamsVoiceAlloy,\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", speech)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.core.http.HttpResponse;\nimport com.openai.models.audio.speech.SpeechCreateParams;\nimport com.openai.models.audio.speech.SpeechModel;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        SpeechCreateParams params = SpeechCreateParams.builder()\n            .input(\"input\")\n            .model(SpeechModel.TTS_1)\n            .voice(SpeechCreateParams.Voice.ALLOY)\n            .build();\n        HttpResponse speech = client.audio().speech().create(params);\n    }\n}"
            javascript: "import fs from \"fs\";\nimport path from \"path\";\nimport OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nconst speechFile = path.resolve(\"./speech.mp3\");\n\nasync function main() {\n  const mp3 = await openai.audio.speech.create({\n    model: \"gpt-4o-mini-tts\",\n    voice: \"alloy\",\n    input: \"Today is a wonderful day to build something people love!\",\n  });\n  console.log(speechFile);\n  const buffer = Buffer.from(await mp3.arrayBuffer());\n  await fs.promises.writeFile(speechFile, buffer);\n}\nmain();\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst speech = await client.audio.speech.create({ input: 'input', model: 'string', voice: 'ash' });\n\nconsole.log(speech);\n\nconst content = await speech.blob();\nconsole.log(content);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nspeech = client.audio.speech.create(\n    input=\"input\",\n    model=\"string\",\n    voice=\"ash\",\n)\nprint(speech)\ncontent = speech.read()\nprint(content)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nspeech = openai.audio.speech.create(input: \"input\", model: :\"tts-1\", voice: :alloy)\n\nputs(speech)"
          title: Default
        group: audio
        name: Create speech
        returns: 'The audio file content or a [stream of audio events](https://platform.openai.com/docs/api-reference/audio/speech-audio-delta-event).'
  /audio/transcriptions:
    post:
      tags:
        - Audio
      summary: Create transcription
      description: Transcribes audio into the input language.
      operationId: createTranscription
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateTranscriptionRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                anyOf:
                  - $ref: '#/components/schemas/CreateTranscriptionResponseJson'
                  - $ref: '#/components/schemas/CreateTranscriptionResponseVerboseJson'
            text/event-stream:
              schema:
                $ref: '#/components/schemas/CreateTranscriptionResponseStreamEvent'
      x-oaiMeta:
        example:
          request:
            csharp: "using System;\n\nusing OpenAI.Audio;\nstring audioFilePath = \"audio.mp3\";\n\nAudioClient client = new(\n    model: \"gpt-4o-transcribe\",\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nAudioTranscription transcription = client.TranscribeAudio(audioFilePath);\n\nConsole.WriteLine($\"{transcription.Text}\");\n"
            curl: "curl https://api.openai.com/v1/audio/transcriptions \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F file=\"@/path/to/file/audio.mp3\" \\\n  -F model=\"gpt-4o-transcribe\"\n"
            go: "package main\n\nimport (\n  \"bytes\"\n  \"context\"\n  \"fmt\"\n  \"io\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  transcription, err := client.Audio.Transcriptions.New(context.TODO(), openai.AudioTranscriptionNewParams{\n    File: io.Reader(bytes.NewBuffer([]byte(\"some file contents\"))),\n    Model: openai.AudioModelWhisper1,\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", transcription)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.audio.AudioModel;\nimport com.openai.models.audio.transcriptions.TranscriptionCreateParams;\nimport com.openai.models.audio.transcriptions.TranscriptionCreateResponse;\nimport java.io.ByteArrayInputStream;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        TranscriptionCreateParams params = TranscriptionCreateParams.builder()\n            .file(ByteArrayInputStream(\"some content\".getBytes()))\n            .model(AudioModel.WHISPER_1)\n            .build();\n        TranscriptionCreateResponse transcription = client.audio().transcriptions().create(params);\n    }\n}"
            javascript: "import fs from \"fs\";\nimport OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const transcription = await openai.audio.transcriptions.create({\n    file: fs.createReadStream(\"audio.mp3\"),\n    model: \"gpt-4o-transcribe\",\n  });\n\n  console.log(transcription.text);\n}\nmain();\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst transcription = await client.audio.transcriptions.create({\n  file: fs.createReadStream('speech.mp3'),\n  model: 'gpt-4o-transcribe',\n});\n\nconsole.log(transcription);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\ntranscription = client.audio.transcriptions.create(\n    file=b\"raw file contents\",\n    model=\"gpt-4o-transcribe\",\n)\nprint(transcription)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\ntranscription = openai.audio.transcriptions.create(file: Pathname(__FILE__), model: :\"whisper-1\")\n\nputs(transcription)"
          response: "{\n  \"text\": \"Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that.\",\n  \"usage\": {\n    \"type\": \"tokens\",\n    \"input_tokens\": 14,\n    \"input_token_details\": {\n      \"text_tokens\": 0,\n      \"audio_tokens\": 14\n    },\n    \"output_tokens\": 45,\n    \"total_tokens\": 59\n  }\n}\n"
          title: Default
        group: audio
        name: Create transcription
        returns: 'The [transcription object](https://platform.openai.com/docs/api-reference/audio/json-object), a [verbose transcription object](https://platform.openai.com/docs/api-reference/audio/verbose-json-object) or a [stream of transcript events](https://platform.openai.com/docs/api-reference/audio/transcript-text-delta-event).'
  /audio/translations:
    post:
      tags:
        - Audio
      summary: Create translation
      description: Translates audio into English.
      operationId: createTranslation
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateTranslationRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                anyOf:
                  - $ref: '#/components/schemas/CreateTranslationResponseJson'
                  - $ref: '#/components/schemas/CreateTranslationResponseVerboseJson'
      x-oaiMeta:
        examples:
          request:
            csharp: "using System;\n\nusing OpenAI.Audio;\n\nstring audioFilePath = \"audio.mp3\";\n\nAudioClient client = new(\n    model: \"whisper-1\",\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nAudioTranscription transcription = client.TranscribeAudio(audioFilePath);\n\nConsole.WriteLine($\"{transcription.Text}\");\n"
            curl: "curl https://api.openai.com/v1/audio/translations \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F file=\"@/path/to/file/german.m4a\" \\\n  -F model=\"whisper-1\"\n"
            go: "package main\n\nimport (\n  \"bytes\"\n  \"context\"\n  \"fmt\"\n  \"io\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  translation, err := client.Audio.Translations.New(context.TODO(), openai.AudioTranslationNewParams{\n    File: io.Reader(bytes.NewBuffer([]byte(\"some file contents\"))),\n    Model: openai.AudioModelWhisper1,\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", translation)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.audio.AudioModel;\nimport com.openai.models.audio.translations.TranslationCreateParams;\nimport com.openai.models.audio.translations.TranslationCreateResponse;\nimport java.io.ByteArrayInputStream;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        TranslationCreateParams params = TranslationCreateParams.builder()\n            .file(ByteArrayInputStream(\"some content\".getBytes()))\n            .model(AudioModel.WHISPER_1)\n            .build();\n        TranslationCreateResponse translation = client.audio().translations().create(params);\n    }\n}"
            javascript: "import fs from \"fs\";\nimport OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n    const translation = await openai.audio.translations.create({\n        file: fs.createReadStream(\"speech.mp3\"),\n        model: \"whisper-1\",\n    });\n\n    console.log(translation.text);\n}\nmain();\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst translation = await client.audio.translations.create({\n  file: fs.createReadStream('speech.mp3'),\n  model: 'whisper-1',\n});\n\nconsole.log(translation);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\ntranslation = client.audio.translations.create(\n    file=b\"raw file contents\",\n    model=\"whisper-1\",\n)\nprint(translation)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\ntranslation = openai.audio.translations.create(file: Pathname(__FILE__), model: :\"whisper-1\")\n\nputs(translation)"
          response: "{\n  \"text\": \"Hello, my name is Wolfgang and I come from Germany. Where are you heading today?\"\n}\n"
        group: audio
        name: Create translation
        returns: The translated text.
  /batches:
    get:
      tags:
        - Batch
      summary: List batch
      description: List your organization's batches.
      operationId: listBatches
      parameters:
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
      responses:
        '200':
          description: Batch listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListBatchesResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/batches?limit=2 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.Batches.List(context.TODO(), openai.BatchListParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.batches.BatchListPage;\nimport com.openai.models.batches.BatchListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        BatchListPage page = client.batches().list();\n    }\n}"
            node: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const list = await openai.batches.list();\n\n  for await (const batch of list) {\n    console.log(batch);\n  }\n}\n\nmain();\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const batch of client.batches.list()) {\n  console.log(batch.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.batches.list()\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.batches.list\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"batch_abc123\",\n      \"object\": \"batch\",\n      \"endpoint\": \"/v1/chat/completions\",\n      \"errors\": null,\n      \"input_file_id\": \"file-abc123\",\n      \"completion_window\": \"24h\",\n      \"status\": \"completed\",\n      \"output_file_id\": \"file-cvaTdG\",\n      \"error_file_id\": \"file-HOWS94\",\n      \"created_at\": 1711471533,\n      \"in_progress_at\": 1711471538,\n      \"expires_at\": 1711557933,\n      \"finalizing_at\": 1711493133,\n      \"completed_at\": 1711493163,\n      \"failed_at\": null,\n      \"expired_at\": null,\n      \"cancelling_at\": null,\n      \"cancelled_at\": null,\n      \"request_counts\": {\n        \"total\": 100,\n        \"completed\": 95,\n        \"failed\": 5\n      },\n      \"metadata\": {\n        \"customer_id\": \"user_123456789\",\n        \"batch_description\": \"Nightly job\",\n      }\n    },\n    { ... },\n  ],\n  \"first_id\": \"batch_abc123\",\n  \"last_id\": \"batch_abc456\",\n  \"has_more\": true\n}\n"
        group: batch
        name: List batch
        returns: 'A list of paginated [Batch](https://platform.openai.com/docs/api-reference/batch/object) objects.'
    post:
      tags:
        - Batch
      summary: Create batch
      description: Creates and executes a batch from an uploaded file of requests
      operationId: createBatch
      requestBody:
        content:
          application/json:
            schema:
              required:
                - input_file_id
                - endpoint
                - completion_window
              type: object
              properties:
                completion_window:
                  enum:
                    - 24h
                  type: string
                  description: The time frame within which the batch should be processed. Currently only `24h` is supported.
                endpoint:
                  enum:
                    - /v1/responses
                    - /v1/chat/completions
                    - /v1/embeddings
                    - /v1/completions
                  type: string
                  description: 'The endpoint to be used for all requests in the batch. Currently `/v1/responses`, `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.'
                input_file_id:
                  type: string
                  description: "The ID of an uploaded file that contains requests for the new batch.\n\nSee [upload file](https://platform.openai.com/docs/api-reference/files/create) for how to upload a file.\n\nYour input file must be formatted as a [JSONL file](https://platform.openai.com/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 200 MB in size.\n"
                metadata:
                  $ref: '#/components/schemas/Metadata'
                output_expires_after:
                  $ref: '#/components/schemas/BatchFileExpirationAfter'
        required: true
      responses:
        '200':
          description: Batch created successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/batches \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"input_file_id\": \"file-abc123\",\n    \"endpoint\": \"/v1/chat/completions\",\n    \"completion_window\": \"24h\"\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  batch, err := client.Batches.New(context.TODO(), openai.BatchNewParams{\n    CompletionWindow: openai.BatchNewParamsCompletionWindow24h,\n    Endpoint: openai.BatchNewParamsEndpointV1Responses,\n    InputFileID: \"input_file_id\",\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", batch.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.batches.Batch;\nimport com.openai.models.batches.BatchCreateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        BatchCreateParams params = BatchCreateParams.builder()\n            .completionWindow(BatchCreateParams.CompletionWindow._24H)\n            .endpoint(BatchCreateParams.Endpoint.V1_RESPONSES)\n            .inputFileId(\"input_file_id\")\n            .build();\n        Batch batch = client.batches().create(params);\n    }\n}"
            node: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const batch = await openai.batches.create({\n    input_file_id: \"file-abc123\",\n    endpoint: \"/v1/chat/completions\",\n    completion_window: \"24h\"\n  });\n\n  console.log(batch);\n}\n\nmain();\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst batch = await client.batches.create({\n  completion_window: '24h',\n  endpoint: '/v1/responses',\n  input_file_id: 'input_file_id',\n});\n\nconsole.log(batch.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nbatch = client.batches.create(\n    completion_window=\"24h\",\n    endpoint=\"/v1/responses\",\n    input_file_id=\"input_file_id\",\n)\nprint(batch.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nbatch = openai.batches.create(\n  completion_window: :\"24h\",\n  endpoint: :\"/v1/responses\",\n  input_file_id: \"input_file_id\"\n)\n\nputs(batch)"
          response: "{\n  \"id\": \"batch_abc123\",\n  \"object\": \"batch\",\n  \"endpoint\": \"/v1/chat/completions\",\n  \"errors\": null,\n  \"input_file_id\": \"file-abc123\",\n  \"completion_window\": \"24h\",\n  \"status\": \"validating\",\n  \"output_file_id\": null,\n  \"error_file_id\": null,\n  \"created_at\": 1711471533,\n  \"in_progress_at\": null,\n  \"expires_at\": null,\n  \"finalizing_at\": null,\n  \"completed_at\": null,\n  \"failed_at\": null,\n  \"expired_at\": null,\n  \"cancelling_at\": null,\n  \"cancelled_at\": null,\n  \"request_counts\": {\n    \"total\": 0,\n    \"completed\": 0,\n    \"failed\": 0\n  },\n  \"metadata\": {\n    \"customer_id\": \"user_123456789\",\n    \"batch_description\": \"Nightly eval job\",\n  }\n}\n"
        group: batch
        name: Create batch
        returns: 'The created [Batch](https://platform.openai.com/docs/api-reference/batch/object) object.'
  '/batches/{batch_id}':
    get:
      tags:
        - Batch
      summary: Retrieve batch
      description: Retrieves a batch.
      operationId: retrieveBatch
      parameters:
        - name: batch_id
          in: path
          description: The ID of the batch to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Batch retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/batches/batch_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  batch, err := client.Batches.Get(context.TODO(), \"batch_id\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", batch.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.batches.Batch;\nimport com.openai.models.batches.BatchRetrieveParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        Batch batch = client.batches().retrieve(\"batch_id\");\n    }\n}"
            node: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const batch = await openai.batches.retrieve(\"batch_abc123\");\n\n  console.log(batch);\n}\n\nmain();\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst batch = await client.batches.retrieve('batch_id');\n\nconsole.log(batch.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nbatch = client.batches.retrieve(\n    \"batch_id\",\n)\nprint(batch.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nbatch = openai.batches.retrieve(\"batch_id\")\n\nputs(batch)"
          response: "{\n  \"id\": \"batch_abc123\",\n  \"object\": \"batch\",\n  \"endpoint\": \"/v1/completions\",\n  \"errors\": null,\n  \"input_file_id\": \"file-abc123\",\n  \"completion_window\": \"24h\",\n  \"status\": \"completed\",\n  \"output_file_id\": \"file-cvaTdG\",\n  \"error_file_id\": \"file-HOWS94\",\n  \"created_at\": 1711471533,\n  \"in_progress_at\": 1711471538,\n  \"expires_at\": 1711557933,\n  \"finalizing_at\": 1711493133,\n  \"completed_at\": 1711493163,\n  \"failed_at\": null,\n  \"expired_at\": null,\n  \"cancelling_at\": null,\n  \"cancelled_at\": null,\n  \"request_counts\": {\n    \"total\": 100,\n    \"completed\": 95,\n    \"failed\": 5\n  },\n  \"metadata\": {\n    \"customer_id\": \"user_123456789\",\n    \"batch_description\": \"Nightly eval job\",\n  }\n}\n"
        group: batch
        name: Retrieve batch
        returns: 'The [Batch](https://platform.openai.com/docs/api-reference/batch/object) object matching the specified ID.'
  '/batches/{batch_id}/cancel':
    post:
      tags:
        - Batch
      summary: Cancel batch
      description: 'Cancels an in-progress batch. The batch will be in status `cancelling` for up to 10 minutes, before changing to `cancelled`, where it will have partial results (if any) available in the output file.'
      operationId: cancelBatch
      parameters:
        - name: batch_id
          in: path
          description: The ID of the batch to cancel.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Batch is cancelling. Returns the cancelling batch's details.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/batches/batch_abc123/cancel \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -X POST\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  batch, err := client.Batches.Cancel(context.TODO(), \"batch_id\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", batch.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.batches.Batch;\nimport com.openai.models.batches.BatchCancelParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        Batch batch = client.batches().cancel(\"batch_id\");\n    }\n}"
            node: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n  const batch = await openai.batches.cancel(\"batch_abc123\");\n\n  console.log(batch);\n}\n\nmain();\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst batch = await client.batches.cancel('batch_id');\n\nconsole.log(batch.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nbatch = client.batches.cancel(\n    \"batch_id\",\n)\nprint(batch.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nbatch = openai.batches.cancel(\"batch_id\")\n\nputs(batch)"
          response: "{\n  \"id\": \"batch_abc123\",\n  \"object\": \"batch\",\n  \"endpoint\": \"/v1/chat/completions\",\n  \"errors\": null,\n  \"input_file_id\": \"file-abc123\",\n  \"completion_window\": \"24h\",\n  \"status\": \"cancelling\",\n  \"output_file_id\": null,\n  \"error_file_id\": null,\n  \"created_at\": 1711471533,\n  \"in_progress_at\": 1711471538,\n  \"expires_at\": 1711557933,\n  \"finalizing_at\": null,\n  \"completed_at\": null,\n  \"failed_at\": null,\n  \"expired_at\": null,\n  \"cancelling_at\": 1711475133,\n  \"cancelled_at\": null,\n  \"request_counts\": {\n    \"total\": 100,\n    \"completed\": 23,\n    \"failed\": 1\n  },\n  \"metadata\": {\n    \"customer_id\": \"user_123456789\",\n    \"batch_description\": \"Nightly eval job\",\n  }\n}\n"
        group: batch
        name: Cancel batch
        returns: 'The [Batch](https://platform.openai.com/docs/api-reference/batch/object) object matching the specified ID.'
  /chat/completions:
    get:
      tags:
        - Chat
      summary: List Chat Completions
      description: "List stored Chat Completions. Only Chat Completions that have been stored\nwith the `store` parameter set to `true` will be returned.\n"
      operationId: listChatCompletions
      parameters:
        - name: model
          in: query
          description: The model used to generate the Chat Completions.
          schema:
            type: string
        - name: metadata
          in: query
          description: "A list of metadata keys to filter the Chat Completions by. Example:\n\n`metadata[key1]=value1&metadata[key2]=value2`\n"
          schema:
            $ref: '#/components/schemas/Metadata'
        - name: after
          in: query
          description: Identifier for the last chat completion from the previous pagination request.
          schema:
            type: string
        - name: limit
          in: query
          description: Number of Chat Completions to retrieve.
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: Sort order for Chat Completions by timestamp. Use `asc` for ascending order or `desc` for descending order. Defaults to `asc`.
          schema:
            enum:
              - asc
              - desc
            type: string
            default: asc
      responses:
        '200':
          description: A list of Chat Completions
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionList'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/chat/completions \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.Chat.Completions.List(context.TODO(), openai.ChatCompletionListParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.chat.completions.ChatCompletionListPage;\nimport com.openai.models.chat.completions.ChatCompletionListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ChatCompletionListPage page = client.chat().completions().list();\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const chatCompletion of client.chat.completions.list()) {\n  console.log(chatCompletion.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.chat.completions.list()\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.chat.completions.list\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"chat.completion\",\n      \"id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2\",\n      \"model\": \"gpt-4.1-2025-04-14\",\n      \"created\": 1738960610,\n      \"request_id\": \"req_ded8ab984ec4bf840f37566c1011c417\",\n      \"tool_choice\": null,\n      \"usage\": {\n        \"total_tokens\": 31,\n        \"completion_tokens\": 18,\n        \"prompt_tokens\": 13\n      },\n      \"seed\": 4944116822809979520,\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"presence_penalty\": 0.0,\n      \"frequency_penalty\": 0.0,\n      \"system_fingerprint\": \"fp_50cad350e4\",\n      \"input_user\": null,\n      \"service_tier\": \"default\",\n      \"tools\": null,\n      \"metadata\": {},\n      \"choices\": [\n        {\n          \"index\": 0,\n          \"message\": {\n            \"content\": \"Mind of circuits hum,  \\nLearning patterns in silence—  \\nFuture's quiet spark.\",\n            \"role\": \"assistant\",\n            \"tool_calls\": null,\n            \"function_call\": null\n          },\n          \"finish_reason\": \"stop\",\n          \"logprobs\": null\n        }\n      ],\n      \"response_format\": null\n    }\n  ],\n  \"first_id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2\",\n  \"last_id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2\",\n  \"has_more\": false\n}\n"
        group: chat
        name: List Chat Completions
        path: list
        returns: 'A list of [Chat Completions](https://platform.openai.com/docs/api-reference/chat/list-object) matching the specified filters.'
    post:
      tags:
        - Chat
      summary: Create chat completion
      description: "**Starting a new project?** We recommend trying [Responses](https://platform.openai.com/docs/api-reference/responses) \nto take advantage of the latest OpenAI platform features. Compare\n[Chat Completions with Responses](https://platform.openai.com/docs/guides/responses-vs-chat-completions?api-mode=responses).\n\n---\n\nCreates a model response for the given chat conversation. Learn more in the\n[text generation](https://platform.openai.com/docs/guides/text-generation), [vision](https://platform.openai.com/docs/guides/vision),\nand [audio](https://platform.openai.com/docs/guides/audio) guides.\n\nParameter support can differ depending on the model used to generate the\nresponse, particularly for newer reasoning models. Parameters that are only\nsupported for reasoning models are noted below. For the current state of \nunsupported parameters in reasoning models, \n[refer to the reasoning guide](https://platform.openai.com/docs/guides/reasoning).\n"
      operationId: createChatCompletion
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateChatCompletionRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionResponse'
            text/event-stream:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionStreamResponse'
      x-oaiMeta:
        example:
          request:
            csharp: "using System;\nusing System.Collections.Generic;\n\nusing OpenAI.Chat;\n\nChatClient client = new(\n    model: \"gpt-4.1\",\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nList<ChatMessage> messages =\n[\n    new SystemChatMessage(\"You are a helpful assistant.\"),\n    new UserChatMessage(\"Hello!\")\n];\n\nChatCompletion completion = client.CompleteChat(messages);\n\nConsole.WriteLine(completion.Content[0].Text);\n"
            curl: "curl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"VAR_chat_model_id\",\n    \"messages\": [\n      {\n        \"role\": \"developer\",\n        \"content\": \"You are a helpful assistant.\"\n      },\n      {\n        \"role\": \"user\",\n        \"content\": \"Hello!\"\n      }\n    ]\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n  \"github.com/openai/openai-go/shared\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  chatCompletion, err := client.Chat.Completions.New(context.TODO(), openai.ChatCompletionNewParams{\n    Messages: []openai.ChatCompletionMessageParamUnion{openai.ChatCompletionMessageParamUnion{\n      OfDeveloper: &openai.ChatCompletionDeveloperMessageParam{\n        Content: openai.ChatCompletionDeveloperMessageParamContentUnion{\n          OfString: openai.String(\"string\"),\n        },\n      },\n    }},\n    Model: shared.ChatModelGPT5,\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", chatCompletion)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.ChatModel;\nimport com.openai.models.chat.completions.ChatCompletion;\nimport com.openai.models.chat.completions.ChatCompletionCreateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ChatCompletionCreateParams params = ChatCompletionCreateParams.builder()\n            .addDeveloperMessage(\"string\")\n            .model(ChatModel.GPT_5)\n            .build();\n        ChatCompletion chatCompletion = client.chat().completions().create(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst chatCompletion = await client.chat.completions.create({\n  messages: [{ content: 'string', role: 'developer' }],\n  model: 'gpt-4o',\n});\n\nconsole.log(chatCompletion);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nchat_completion = client.chat.completions.create(\n    messages=[{\n        \"content\": \"string\",\n        \"role\": \"developer\",\n    }],\n    model=\"gpt-4o\",\n)\nprint(chat_completion)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nchat_completion = openai.chat.completions.create(messages: [{content: \"string\", role: :developer}], model: :\"gpt-5\")\n\nputs(chat_completion)"
          response: "{\n  \"id\": \"chatcmpl-B9MBs8CjcvOU2jLn4n570S5qMJKcT\",\n  \"object\": \"chat.completion\",\n  \"created\": 1741569952,\n  \"model\": \"gpt-4.1-2025-04-14\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"Hello! How can I assist you today?\",\n        \"refusal\": null,\n        \"annotations\": []\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 19,\n    \"completion_tokens\": 10,\n    \"total_tokens\": 29,\n    \"prompt_tokens_details\": {\n      \"cached_tokens\": 0,\n      \"audio_tokens\": 0\n    },\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\": 0,\n      \"audio_tokens\": 0,\n      \"accepted_prediction_tokens\": 0,\n      \"rejected_prediction_tokens\": 0\n    }\n  },\n  \"service_tier\": \"default\"\n}\n"
          title: Default
        group: chat
        name: Create chat completion
        path: create
        returns: "Returns a [chat completion](https://platform.openai.com/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](https://platform.openai.com/docs/api-reference/chat/streaming) objects if the request is streamed.\n"
  '/chat/completions/{completion_id}':
    delete:
      tags:
        - Chat
      summary: Delete chat completion
      description: "Delete a stored chat completion. Only Chat Completions that have been\ncreated with the `store` parameter set to `true` can be deleted.\n"
      operationId: deleteChatCompletion
      parameters:
        - name: completion_id
          in: path
          description: The ID of the chat completion to delete.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: The chat completion was deleted successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionDeleted'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/chat/completions/chat_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  chatCompletionDeleted, err := client.Chat.Completions.Delete(context.TODO(), \"completion_id\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", chatCompletionDeleted.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.chat.completions.ChatCompletionDeleteParams;\nimport com.openai.models.chat.completions.ChatCompletionDeleted;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ChatCompletionDeleted chatCompletionDeleted = client.chat().completions().delete(\"completion_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst chatCompletionDeleted = await client.chat.completions.delete('completion_id');\n\nconsole.log(chatCompletionDeleted.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nchat_completion_deleted = client.chat.completions.delete(\n    \"completion_id\",\n)\nprint(chat_completion_deleted.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nchat_completion_deleted = openai.chat.completions.delete(\"completion_id\")\n\nputs(chat_completion_deleted)"
          response: "{\n  \"object\": \"chat.completion.deleted\",\n  \"id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2\",\n  \"deleted\": true\n}\n"
        group: chat
        name: Delete chat completion
        returns: A deletion confirmation object.
    get:
      tags:
        - Chat
      summary: Get chat completion
      description: "Get a stored chat completion. Only Chat Completions that have been created\nwith the `store` parameter set to `true` will be returned.\n"
      operationId: getChatCompletion
      parameters:
        - name: completion_id
          in: path
          description: The ID of the chat completion to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: A chat completion
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/chat/completions/chatcmpl-abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  chatCompletion, err := client.Chat.Completions.Get(context.TODO(), \"completion_id\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", chatCompletion.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.chat.completions.ChatCompletion;\nimport com.openai.models.chat.completions.ChatCompletionRetrieveParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ChatCompletion chatCompletion = client.chat().completions().retrieve(\"completion_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst chatCompletion = await client.chat.completions.retrieve('completion_id');\n\nconsole.log(chatCompletion.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nchat_completion = client.chat.completions.retrieve(\n    \"completion_id\",\n)\nprint(chat_completion.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nchat_completion = openai.chat.completions.retrieve(\"completion_id\")\n\nputs(chat_completion)"
          response: "{\n  \"object\": \"chat.completion\",\n  \"id\": \"chatcmpl-abc123\",\n  \"model\": \"gpt-4o-2024-08-06\",\n  \"created\": 1738960610,\n  \"request_id\": \"req_ded8ab984ec4bf840f37566c1011c417\",\n  \"tool_choice\": null,\n  \"usage\": {\n    \"total_tokens\": 31,\n    \"completion_tokens\": 18,\n    \"prompt_tokens\": 13\n  },\n  \"seed\": 4944116822809979520,\n  \"top_p\": 1.0,\n  \"temperature\": 1.0,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"system_fingerprint\": \"fp_50cad350e4\",\n  \"input_user\": null,\n  \"service_tier\": \"default\",\n  \"tools\": null,\n  \"metadata\": {},\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"content\": \"Mind of circuits hum,  \\nLearning patterns in silence—  \\nFuture's quiet spark.\",\n        \"role\": \"assistant\",\n        \"tool_calls\": null,\n        \"function_call\": null\n      },\n      \"finish_reason\": \"stop\",\n      \"logprobs\": null\n    }\n  ],\n  \"response_format\": null\n}\n"
        group: chat
        name: Get chat completion
        returns: 'The [ChatCompletion](https://platform.openai.com/docs/api-reference/chat/object) object matching the specified ID.'
    post:
      tags:
        - Chat
      summary: Update chat completion
      description: "Modify a stored chat completion. Only Chat Completions that have been\ncreated with the `store` parameter set to `true` can be modified. Currently,\nthe only supported modification is to update the `metadata` field.\n"
      operationId: updateChatCompletion
      parameters:
        - name: completion_id
          in: path
          description: The ID of the chat completion to update.
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              required:
                - metadata
              type: object
              properties:
                metadata:
                  $ref: '#/components/schemas/Metadata'
        required: true
      responses:
        '200':
          description: A chat completion
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/chat/completions/chat_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"metadata\": {\"foo\": \"bar\"}}'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n  \"github.com/openai/openai-go/shared\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  chatCompletion, err := client.Chat.Completions.Update(\n    context.TODO(),\n    \"completion_id\",\n    openai.ChatCompletionUpdateParams{\n      Metadata: shared.Metadata{\n      \"foo\": \"string\",\n      },\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", chatCompletion.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.core.JsonValue;\nimport com.openai.models.chat.completions.ChatCompletion;\nimport com.openai.models.chat.completions.ChatCompletionUpdateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ChatCompletionUpdateParams params = ChatCompletionUpdateParams.builder()\n            .completionId(\"completion_id\")\n            .metadata(ChatCompletionUpdateParams.Metadata.builder()\n                .putAdditionalProperty(\"foo\", JsonValue.from(\"string\"))\n                .build())\n            .build();\n        ChatCompletion chatCompletion = client.chat().completions().update(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst chatCompletion = await client.chat.completions.update('completion_id', { metadata: { foo: 'string' } });\n\nconsole.log(chatCompletion.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nchat_completion = client.chat.completions.update(\n    completion_id=\"completion_id\",\n    metadata={\n        \"foo\": \"string\"\n    },\n)\nprint(chat_completion.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nchat_completion = openai.chat.completions.update(\"completion_id\", metadata: {foo: \"string\"})\n\nputs(chat_completion)"
          response: "{\n  \"object\": \"chat.completion\",\n  \"id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2\",\n  \"model\": \"gpt-4o-2024-08-06\",\n  \"created\": 1738960610,\n  \"request_id\": \"req_ded8ab984ec4bf840f37566c1011c417\",\n  \"tool_choice\": null,\n  \"usage\": {\n    \"total_tokens\": 31,\n    \"completion_tokens\": 18,\n    \"prompt_tokens\": 13\n  },\n  \"seed\": 4944116822809979520,\n  \"top_p\": 1.0,\n  \"temperature\": 1.0,\n  \"presence_penalty\": 0.0,\n  \"frequency_penalty\": 0.0,\n  \"system_fingerprint\": \"fp_50cad350e4\",\n  \"input_user\": null,\n  \"service_tier\": \"default\",\n  \"tools\": null,\n  \"metadata\": {\n    \"foo\": \"bar\"\n  },\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"content\": \"Mind of circuits hum,  \\nLearning patterns in silence—  \\nFuture's quiet spark.\",\n        \"role\": \"assistant\",\n        \"tool_calls\": null,\n        \"function_call\": null\n      },\n      \"finish_reason\": \"stop\",\n      \"logprobs\": null\n    }\n  ],\n  \"response_format\": null\n}\n"
        group: chat
        name: Update chat completion
        returns: 'The [ChatCompletion](https://platform.openai.com/docs/api-reference/chat/object) object matching the specified ID.'
  '/chat/completions/{completion_id}/messages':
    get:
      tags:
        - Chat
      summary: Get chat messages
      description: "Get the messages in a stored chat completion. Only Chat Completions that\nhave been created with the `store` parameter set to `true` will be\nreturned.\n"
      operationId: getChatCompletionMessages
      parameters:
        - name: completion_id
          in: path
          description: The ID of the chat completion to retrieve messages from.
          required: true
          schema:
            type: string
        - name: after
          in: query
          description: Identifier for the last message from the previous pagination request.
          schema:
            type: string
        - name: limit
          in: query
          description: Number of messages to retrieve.
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: Sort order for messages by timestamp. Use `asc` for ascending order or `desc` for descending order. Defaults to `asc`.
          schema:
            enum:
              - asc
              - desc
            type: string
            default: asc
      responses:
        '200':
          description: A list of messages
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionMessageList'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/chat/completions/chat_abc123/messages \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.Chat.Completions.Messages.List(\n    context.TODO(),\n    \"completion_id\",\n    openai.ChatCompletionMessageListParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.chat.completions.messages.MessageListPage;\nimport com.openai.models.chat.completions.messages.MessageListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        MessageListPage page = client.chat().completions().messages().list(\"completion_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const chatCompletionStoreMessage of client.chat.completions.messages.list('completion_id')) {\n  console.log(chatCompletionStoreMessage);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.chat.completions.messages.list(\n    completion_id=\"completion_id\",\n)\npage = page.data[0]\nprint(page)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.chat.completions.messages.list(\"completion_id\")\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0\",\n      \"role\": \"user\",\n      \"content\": \"write a haiku about ai\",\n      \"name\": null,\n      \"content_parts\": null\n    }\n  ],\n  \"first_id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0\",\n  \"last_id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0\",\n  \"has_more\": false\n}\n"
        group: chat
        name: Get chat messages
        returns: 'A list of [messages](https://platform.openai.com/docs/api-reference/chat/message-list) for the specified chat completion.'
  /completions:
    post:
      tags:
        - Completions
      summary: Create completion
      description: Creates a completion for the provided prompt and parameters.
      operationId: createCompletion
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateCompletionRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateCompletionResponse'
      x-oaiMeta:
        example:
          request:
            curl: "curl https://api.openai.com/v1/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"VAR_completion_model_id\",\n    \"prompt\": \"Say this is a test\",\n    \"max_tokens\": 7,\n    \"temperature\": 0\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  completion, err := client.Completions.New(context.TODO(), openai.CompletionNewParams{\n    Model: openai.CompletionNewParamsModelGPT3_5TurboInstruct,\n    Prompt: openai.CompletionNewParamsPromptUnion{\n      OfString: openai.String(\"This is a test.\"),\n    },\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", completion)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.completions.Completion;\nimport com.openai.models.completions.CompletionCreateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        CompletionCreateParams params = CompletionCreateParams.builder()\n            .model(CompletionCreateParams.Model.GPT_3_5_TURBO_INSTRUCT)\n            .prompt(\"This is a test.\")\n            .build();\n        Completion completion = client.completions().create(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst completion = await client.completions.create({ model: 'string', prompt: 'This is a test.' });\n\nconsole.log(completion);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\ncompletion = client.completions.create(\n    model=\"string\",\n    prompt=\"This is a test.\",\n)\nprint(completion)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\ncompletion = openai.completions.create(model: :\"gpt-3.5-turbo-instruct\", prompt: \"This is a test.\")\n\nputs(completion)"
          response: "{\n  \"id\": \"cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7\",\n  \"object\": \"text_completion\",\n  \"created\": 1589478378,\n  \"model\": \"VAR_completion_model_id\",\n  \"system_fingerprint\": \"fp_44709d6fcb\",\n  \"choices\": [\n    {\n      \"text\": \"\\n\\nThis is indeed a test\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"finish_reason\": \"length\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 5,\n    \"completion_tokens\": 7,\n    \"total_tokens\": 12\n  }\n}\n"
          title: No streaming
        group: completions
        legacy: true
        name: Create completion
        returns: "Returns a [completion](https://platform.openai.com/docs/api-reference/completions/object) object, or a sequence of completion objects if the request is streamed.\n"
  /containers:
    get:
      summary: List containers
      description: List Containers
      operationId: ListContainers
      parameters:
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ContainerListResource'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/containers \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.Containers.List(context.TODO(), openai.ContainerListParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.containers.ContainerListPage;\nimport com.openai.models.containers.ContainerListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ContainerListPage page = client.containers().list();\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const containerListResponse of client.containers.list()) {\n  console.log(containerListResponse.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.containers.list()\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.containers.list\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n        \"id\": \"cntr_682dfebaacac8198bbfe9c2474fb6f4a085685cbe3cb5863\",\n        \"object\": \"container\",\n        \"created_at\": 1747844794,\n        \"status\": \"running\",\n        \"expires_after\": {\n            \"anchor\": \"last_active_at\",\n            \"minutes\": 20\n        },\n        \"last_active_at\": 1747844794,\n        \"name\": \"My Container\"\n    }\n  ],\n  \"first_id\": \"container_123\",\n  \"last_id\": \"container_123\",\n  \"has_more\": false\n}\n"
        group: containers
        name: List containers
        path: get
        returns: 'a list of [container](https://platform.openai.com/docs/api-reference/containers/object) objects.'
    post:
      summary: Create container
      description: Create Container
      operationId: CreateContainer
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateContainerBody'
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ContainerResource'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/containers \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n        \"name\": \"My Container\"\n      }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  container, err := client.Containers.New(context.TODO(), openai.ContainerNewParams{\n    Name: \"name\",\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", container.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.containers.ContainerCreateParams;\nimport com.openai.models.containers.ContainerCreateResponse;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ContainerCreateParams params = ContainerCreateParams.builder()\n            .name(\"name\")\n            .build();\n        ContainerCreateResponse container = client.containers().create(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst container = await client.containers.create({ name: 'name' });\n\nconsole.log(container.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\ncontainer = client.containers.create(\n    name=\"name\",\n)\nprint(container.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\ncontainer = openai.containers.create(name: \"name\")\n\nputs(container)"
          response: "{\n    \"id\": \"cntr_682e30645a488191b6363a0cbefc0f0a025ec61b66250591\",\n    \"object\": \"container\",\n    \"created_at\": 1747857508,\n    \"status\": \"running\",\n    \"expires_after\": {\n        \"anchor\": \"last_active_at\",\n        \"minutes\": 20\n    },\n    \"last_active_at\": 1747857508,\n    \"name\": \"My Container\"\n}\n"
        group: containers
        name: Create container
        path: post
        returns: 'The created [container](https://platform.openai.com/docs/api-reference/containers/object) object.'
  '/containers/{container_id}':
    delete:
      summary: Delete a container
      description: Delete Container
      operationId: DeleteContainer
      parameters:
        - name: container_id
          in: path
          description: The ID of the container to delete.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/containers/cntr_682dfebaacac8198bbfe9c2474fb6f4a085685cbe3cb5863 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  err := client.Containers.Delete(context.TODO(), \"container_id\")\n  if err != nil {\n    panic(err.Error())\n  }\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.containers.ContainerDeleteParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        client.containers().delete(\"container_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nawait client.containers.delete('container_id');"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nclient.containers.delete(\n    \"container_id\",\n)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nresult = openai.containers.delete(\"container_id\")\n\nputs(result)"
          response: "{\n    \"id\": \"cntr_682dfebaacac8198bbfe9c2474fb6f4a085685cbe3cb5863\",\n    \"object\": \"container.deleted\",\n    \"deleted\": true\n}\n"
        group: containers
        name: Delete a container
        path: delete
        returns: Deletion Status
    get:
      summary: Retrieve container
      description: Retrieve Container
      operationId: RetrieveContainer
      parameters:
        - name: container_id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ContainerResource'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/containers/cntr_682dfebaacac8198bbfe9c2474fb6f4a085685cbe3cb5863 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  container, err := client.Containers.Get(context.TODO(), \"container_id\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", container.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.containers.ContainerRetrieveParams;\nimport com.openai.models.containers.ContainerRetrieveResponse;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ContainerRetrieveResponse container = client.containers().retrieve(\"container_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst container = await client.containers.retrieve('container_id');\n\nconsole.log(container.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\ncontainer = client.containers.retrieve(\n    \"container_id\",\n)\nprint(container.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\ncontainer = openai.containers.retrieve(\"container_id\")\n\nputs(container)"
          response: "{\n    \"id\": \"cntr_682dfebaacac8198bbfe9c2474fb6f4a085685cbe3cb5863\",\n    \"object\": \"container\",\n    \"created_at\": 1747844794,\n    \"status\": \"running\",\n    \"expires_after\": {\n        \"anchor\": \"last_active_at\",\n        \"minutes\": 20\n    },\n    \"last_active_at\": 1747844794,\n    \"name\": \"My Container\"\n}\n"
        group: containers
        name: Retrieve container
        path: get
        returns: 'The [container](https://platform.openai.com/docs/api-reference/containers/object) object.'
  '/containers/{container_id}/files':
    get:
      summary: List container files
      description: List Container files
      operationId: ListContainerFiles
      parameters:
        - name: container_id
          in: path
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ContainerFileListResource'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/containers/cntr_682e0e7318108198aa783fd921ff305e08e78805b9fdbb04/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.Containers.Files.List(\n    context.TODO(),\n    \"container_id\",\n    openai.ContainerFileListParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.containers.files.FileListPage;\nimport com.openai.models.containers.files.FileListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FileListPage page = client.containers().files().list(\"container_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const fileListResponse of client.containers.files.list('container_id')) {\n  console.log(fileListResponse.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.containers.files.list(\n    container_id=\"container_id\",\n)\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.containers.files.list(\"container_id\")\n\nputs(page)"
          response: "{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"id\": \"cfile_682e0e8a43c88191a7978f477a09bdf5\",\n            \"object\": \"container.file\",\n            \"created_at\": 1747848842,\n            \"bytes\": 880,\n            \"container_id\": \"cntr_682e0e7318108198aa783fd921ff305e08e78805b9fdbb04\",\n            \"path\": \"/mnt/data/88e12fa445d32636f190a0b33daed6cb-tsconfig.json\",\n            \"source\": \"user\"\n        }\n    ],\n    \"first_id\": \"cfile_682e0e8a43c88191a7978f477a09bdf5\",\n    \"has_more\": false,\n    \"last_id\": \"cfile_682e0e8a43c88191a7978f477a09bdf5\"\n}\n"
        group: containers
        name: List container files
        path: get
        returns: 'a list of [container file](https://platform.openai.com/docs/api-reference/container-files/object) objects.'
    post:
      summary: Create container file
      description: "Create a Container File\n\nYou can send either a multipart/form-data request with the raw file content, or a JSON request with a file ID.\n"
      operationId: CreateContainerFile
      parameters:
        - name: container_id
          in: path
          required: true
          schema:
            type: string
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateContainerFileBody'
        required: true
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ContainerFileResource'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/containers/cntr_682e0e7318108198aa783fd921ff305e08e78805b9fdbb04/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -F file=\"@example.txt\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  file, err := client.Containers.Files.New(\n    context.TODO(),\n    \"container_id\",\n    openai.ContainerFileNewParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", file.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.containers.files.FileCreateParams;\nimport com.openai.models.containers.files.FileCreateResponse;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FileCreateResponse file = client.containers().files().create(\"container_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst file = await client.containers.files.create('container_id');\n\nconsole.log(file.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nfile = client.containers.files.create(\n    container_id=\"container_id\",\n)\nprint(file.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nfile = openai.containers.files.create(\"container_id\")\n\nputs(file)"
          response: "{\n  \"id\": \"cfile_682e0e8a43c88191a7978f477a09bdf5\",\n  \"object\": \"container.file\",\n  \"created_at\": 1747848842,\n  \"bytes\": 880,\n  \"container_id\": \"cntr_682e0e7318108198aa783fd921ff305e08e78805b9fdbb04\",\n  \"path\": \"/mnt/data/88e12fa445d32636f190a0b33daed6cb-tsconfig.json\",\n  \"source\": \"user\"\n}\n"
        group: containers
        name: Create container file
        path: post
        returns: 'The created [container file](https://platform.openai.com/docs/api-reference/container-files/object) object.'
  '/containers/{container_id}/files/{file_id}':
    delete:
      summary: Delete a container file
      description: Delete Container File
      operationId: DeleteContainerFile
      parameters:
        - name: container_id
          in: path
          required: true
          schema:
            type: string
        - name: file_id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/containers/cntr_682dfebaacac8198bbfe9c2474fb6f4a085685cbe3cb5863/files/cfile_682e0e8a43c88191a7978f477a09bdf5 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  err := client.Containers.Files.Delete(\n    context.TODO(),\n    \"container_id\",\n    \"file_id\",\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.containers.files.FileDeleteParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FileDeleteParams params = FileDeleteParams.builder()\n            .containerId(\"container_id\")\n            .fileId(\"file_id\")\n            .build();\n        client.containers().files().delete(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nawait client.containers.files.delete('file_id', { container_id: 'container_id' });"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nclient.containers.files.delete(\n    file_id=\"file_id\",\n    container_id=\"container_id\",\n)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nresult = openai.containers.files.delete(\"file_id\", container_id: \"container_id\")\n\nputs(result)"
          response: "{\n    \"id\": \"cfile_682e0e8a43c88191a7978f477a09bdf5\",\n    \"object\": \"container.file.deleted\",\n    \"deleted\": true\n}\n"
        group: containers
        name: Delete a container file
        path: delete
        returns: Deletion Status
    get:
      summary: Retrieve container file
      description: Retrieve Container File
      operationId: RetrieveContainerFile
      parameters:
        - name: container_id
          in: path
          required: true
          schema:
            type: string
        - name: file_id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ContainerFileResource'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/containers/container_123/files/file_456 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  file, err := client.Containers.Files.Get(\n    context.TODO(),\n    \"container_id\",\n    \"file_id\",\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", file.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.containers.files.FileRetrieveParams;\nimport com.openai.models.containers.files.FileRetrieveResponse;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FileRetrieveParams params = FileRetrieveParams.builder()\n            .containerId(\"container_id\")\n            .fileId(\"file_id\")\n            .build();\n        FileRetrieveResponse file = client.containers().files().retrieve(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst file = await client.containers.files.retrieve('file_id', { container_id: 'container_id' });\n\nconsole.log(file.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nfile = client.containers.files.retrieve(\n    file_id=\"file_id\",\n    container_id=\"container_id\",\n)\nprint(file.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nfile = openai.containers.files.retrieve(\"file_id\", container_id: \"container_id\")\n\nputs(file)"
          response: "{\n    \"id\": \"cfile_682e0e8a43c88191a7978f477a09bdf5\",\n    \"object\": \"container.file\",\n    \"created_at\": 1747848842,\n    \"bytes\": 880,\n    \"container_id\": \"cntr_682e0e7318108198aa783fd921ff305e08e78805b9fdbb04\",\n    \"path\": \"/mnt/data/88e12fa445d32636f190a0b33daed6cb-tsconfig.json\",\n    \"source\": \"user\"\n}\n"
        group: containers
        name: Retrieve container file
        path: get
        returns: 'The [container file](https://platform.openai.com/docs/api-reference/container-files/object) object.'
  '/containers/{container_id}/files/{file_id}/content':
    get:
      summary: Retrieve container file content
      description: Retrieve Container File Content
      operationId: RetrieveContainerFileContent
      parameters:
        - name: container_id
          in: path
          required: true
          schema:
            type: string
        - name: file_id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Success
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/containers/container_123/files/cfile_456/content \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  content, err := client.Containers.Files.Content.Get(\n    context.TODO(),\n    \"container_id\",\n    \"file_id\",\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", content)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.core.http.HttpResponse;\nimport com.openai.models.containers.files.content.ContentRetrieveParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ContentRetrieveParams params = ContentRetrieveParams.builder()\n            .containerId(\"container_id\")\n            .fileId(\"file_id\")\n            .build();\n        HttpResponse content = client.containers().files().content().retrieve(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst content = await client.containers.files.content.retrieve('file_id', { container_id: 'container_id' });\n\nconsole.log(content);\n\nconst data = await content.blob();\nconsole.log(data);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\ncontent = client.containers.files.content.retrieve(\n    file_id=\"file_id\",\n    container_id=\"container_id\",\n)\nprint(content)\ndata = content.read()\nprint(data)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\ncontent = openai.containers.files.content.retrieve(\"file_id\", container_id: \"container_id\")\n\nputs(content)"
          response: "<binary content of the file>\n"
        group: containers
        name: Retrieve container file content
        path: get
        returns: The contents of the container file.
  /conversations:
    post:
      tags:
        - Conversations
      summary: Create a conversation
      description: Create a conversation.
      operationId: createConversation
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateConversationRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ConversationResource'
      x-oaiMeta:
        example:
          request:
            csharp: "using System;\nusing System.Collections.Generic;\nusing OpenAI.Conversations;\n\nOpenAIConversationClient client = new(\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nConversation conversation = client.CreateConversation(\n    new CreateConversationOptions\n    {\n        Metadata = new Dictionary<string, string>\n        {\n            { \"topic\", \"demo\" }\n        },\n        Items =\n        {\n            new ConversationMessageInput\n            {\n                Role = \"user\",\n                Content = \"Hello!\"\n            }\n        }\n    }\n);\nConsole.WriteLine(conversation.Id);\n"
            curl: "curl https://api.openai.com/v1/conversations \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"metadata\": {\"topic\": \"demo\"},\n    \"items\": [\n      {\n        \"type\": \"message\",\n        \"role\": \"user\",\n        \"content\": \"Hello!\"\n      }\n    ]\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/conversations\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  conversation, err := client.Conversations.New(context.TODO(), conversations.ConversationNewParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", conversation.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.conversations.Conversation;\nimport com.openai.models.conversations.ConversationCreateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        Conversation conversation = client.conversations().create();\n    }\n}"
            javascript: "import OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst conversation = await client.conversations.create({\n  metadata: { topic: \"demo\" },\n  items: [\n    { type: \"message\", role: \"user\", content: \"Hello!\" }\n  ],\n});\nconsole.log(conversation);\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst conversation = await client.conversations.create();\n\nconsole.log(conversation.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nconversation = client.conversations.create()\nprint(conversation.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nconversation = openai.conversations.create\n\nputs(conversation)"
          response: "{\n  \"id\": \"conv_123\",\n  \"object\": \"conversation\",\n  \"created_at\": 1741900000,\n  \"metadata\": {\"topic\": \"demo\"}\n}\n"
          title: Create a conversation.
        group: conversations
        name: Create a conversation
        path: create
        returns: "Returns a [Conversation](https://platform.openai.com/docs/api-reference/conversations/object) object.\n"
  '/conversations/{conversation_id}':
    delete:
      tags:
        - Conversations
      summary: Delete a conversation
      description: Delete a conversation with the given ID.
      operationId: deleteConversation
      parameters:
        - name: conversation_id
          in: path
          description: The ID of the conversation to delete.
          required: true
          schema:
            type: string
            example: conv_123
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeletedConversationResource'
      x-oaiMeta:
        example:
          request:
            csharp: "using System;\nusing OpenAI.Conversations;\n\nOpenAIConversationClient client = new(\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nDeletedConversation deleted = client.DeleteConversation(\"conv_123\");\nConsole.WriteLine(deleted.Id);\n"
            curl: "curl -X DELETE https://api.openai.com/v1/conversations/conv_123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  conversationDeletedResource, err := client.Conversations.Delete(context.TODO(), \"conv_123\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", conversationDeletedResource.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.conversations.ConversationDeleteParams;\nimport com.openai.models.conversations.ConversationDeletedResource;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ConversationDeletedResource conversationDeletedResource = client.conversations().delete(\"conv_123\");\n    }\n}"
            javascript: "import OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst deleted = await client.conversations.delete(\"conv_123\");\nconsole.log(deleted);\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst conversationDeletedResource = await client.conversations.delete('conv_123');\n\nconsole.log(conversationDeletedResource.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nconversation_deleted_resource = client.conversations.delete(\n    \"conv_123\",\n)\nprint(conversation_deleted_resource.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nconversation_deleted_resource = openai.conversations.delete(\"conv_123\")\n\nputs(conversation_deleted_resource)"
          response: "{\n  \"id\": \"conv_123\",\n  \"object\": \"conversation.deleted\",\n  \"deleted\": true\n}\n"
          title: Delete a conversation
        group: conversations
        name: Delete a conversation
        path: delete
        returns: "A success message.\n"
    get:
      tags:
        - Conversations
      summary: Retrieve a conversation
      description: Get a conversation with the given ID.
      operationId: getConversation
      parameters:
        - name: conversation_id
          in: path
          description: The ID of the conversation to retrieve.
          required: true
          schema:
            type: string
            example: conv_123
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ConversationResource'
      x-oaiMeta:
        example:
          request:
            csharp: "using System;\nusing OpenAI.Conversations;\n\nOpenAIConversationClient client = new(\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nConversation conversation = client.GetConversation(\"conv_123\");\nConsole.WriteLine(conversation.Id);\n"
            curl: "curl https://api.openai.com/v1/conversations/conv_123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  conversation, err := client.Conversations.Get(context.TODO(), \"conv_123\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", conversation.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.conversations.Conversation;\nimport com.openai.models.conversations.ConversationRetrieveParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        Conversation conversation = client.conversations().retrieve(\"conv_123\");\n    }\n}"
            javascript: "import OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst conversation = await client.conversations.retrieve(\"conv_123\");\nconsole.log(conversation);\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst conversation = await client.conversations.retrieve('conv_123');\n\nconsole.log(conversation.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nconversation = client.conversations.retrieve(\n    \"conv_123\",\n)\nprint(conversation.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nconversation = openai.conversations.retrieve(\"conv_123\")\n\nputs(conversation)"
          response: "{\n  \"id\": \"conv_123\",\n  \"object\": \"conversation\",\n  \"created_at\": 1741900000,\n  \"metadata\": {\"topic\": \"demo\"}\n}\n"
          title: Retrieve a conversation
        group: conversations
        name: Retrieve a conversation
        path: retrieve
        returns: "Returns a [Conversation](https://platform.openai.com/docs/api-reference/conversations/object) object.\n"
    post:
      tags:
        - Conversations
      summary: Update a conversation
      description: Update a conversation's metadata with the given ID.
      operationId: updateConversation
      parameters:
        - name: conversation_id
          in: path
          description: The ID of the conversation to update.
          required: true
          schema:
            type: string
            example: conv_123
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateConversationBody'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ConversationResource'
      x-oaiMeta:
        example:
          request:
            csharp: "using System;\nusing System.Collections.Generic;\nusing OpenAI.Conversations;\n\nOpenAIConversationClient client = new(\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nConversation updated = client.UpdateConversation(\n    conversationId: \"conv_123\",\n    new UpdateConversationOptions\n    {\n        Metadata = new Dictionary<string, string>\n        {\n            { \"topic\", \"project-x\" }\n        }\n    }\n);\nConsole.WriteLine(updated.Id);\n"
            curl: "curl https://api.openai.com/v1/conversations/conv_123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"metadata\": {\"topic\": \"project-x\"}\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/conversations\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  conversation, err := client.Conversations.Update(\n    context.TODO(),\n    \"conv_123\",\n    conversations.ConversationUpdateParams{\n      Metadata: map[string]string{\n      \"foo\": \"string\",\n      },\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", conversation.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.core.JsonValue;\nimport com.openai.models.conversations.Conversation;\nimport com.openai.models.conversations.ConversationUpdateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ConversationUpdateParams params = ConversationUpdateParams.builder()\n            .conversationId(\"conv_123\")\n            .metadata(ConversationUpdateParams.Metadata.builder()\n                .putAdditionalProperty(\"foo\", JsonValue.from(\"string\"))\n                .build())\n            .build();\n        Conversation conversation = client.conversations().update(params);\n    }\n}"
            javascript: "import OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst updated = await client.conversations.update(\n  \"conv_123\",\n  { metadata: { topic: \"project-x\" } }\n);\nconsole.log(updated);\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst conversation = await client.conversations.update('conv_123', { metadata: { foo: 'string' } });\n\nconsole.log(conversation.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nconversation = client.conversations.update(\n    conversation_id=\"conv_123\",\n    metadata={\n        \"foo\": \"string\"\n    },\n)\nprint(conversation.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nconversation = openai.conversations.update(\"conv_123\", metadata: {foo: \"string\"})\n\nputs(conversation)"
          response: "{\n  \"id\": \"conv_123\",\n  \"object\": \"conversation\",\n  \"created_at\": 1741900000,\n  \"metadata\": {\"topic\": \"project-x\"}\n}\n"
          title: Update conversation metadata
        group: conversations
        name: Update a conversation
        path: update
        returns: "Returns the updated [Conversation](https://platform.openai.com/docs/api-reference/conversations/object) object.\n"
  '/conversations/{conversation_id}/items':
    get:
      tags:
        - Conversations
      summary: List items
      description: List all items for a conversation with the given ID.
      operationId: listConversationItems
      parameters:
        - name: conversation_id
          in: path
          description: The ID of the conversation to list items for.
          required: true
          schema:
            type: string
            example: conv_123
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between\n1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: "The order to return the input items in. Default is `desc`.\n- `asc`: Return the input items in ascending order.\n- `desc`: Return the input items in descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
        - name: after
          in: query
          description: "An item ID to list items after, used in pagination.\n"
          schema:
            type: string
        - name: include
          in: query
          description: "Specify additional output data to include in the model response. Currently\nsupported values are:\n- `web_search_call.action.sources`: Include the sources of the web search tool call.\n- `code_interpreter_call.outputs`: Includes the outputs of python code execution\n  in code interpreter tool call items.\n- `computer_call_output.output.image_url`: Include image urls from the computer call output.\n- `file_search_call.results`: Include the search results of\n  the file search tool call.\n- `message.input_image.image_url`: Include image urls from the input message.\n- `message.output_text.logprobs`: Include logprobs with assistant messages.\n- `reasoning.encrypted_content`: Includes an encrypted version of reasoning\n  tokens in reasoning item outputs. This enables reasoning items to be used in\n  multi-turn conversations when using the Responses API statelessly (like\n  when the `store` parameter is set to `false`, or when an organization is\n  enrolled in the zero data retention program).\n"
          schema:
            type: array
            items:
              $ref: '#/components/schemas/Includable'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ConversationItemList'
      x-oaiMeta:
        example:
          request:
            csharp: "using System;\nusing OpenAI.Conversations;\n\nOpenAIConversationClient client = new(\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nConversationItemList items = client.ConversationItems.List(\n    conversationId: \"conv_123\",\n    new ListConversationItemsOptions { Limit = 10 }\n);\nConsole.WriteLine(items.Data.Count);\n"
            curl: "curl \"https://api.openai.com/v1/conversations/conv_123/items?limit=10\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/conversations\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.Conversations.Items.List(\n    context.TODO(),\n    \"conv_123\",\n    conversations.ItemListParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.conversations.items.ItemListPage;\nimport com.openai.models.conversations.items.ItemListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ItemListPage page = client.conversations().items().list(\"conv_123\");\n    }\n}"
            javascript: "import OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst items = await client.conversations.items.list(\"conv_123\", { limit: 10 });\nconsole.log(items.data);\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const conversationItem of client.conversations.items.list('conv_123')) {\n  console.log(conversationItem);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.conversations.items.list(\n    conversation_id=\"conv_123\",\n)\npage = page.data[0]\nprint(page)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.conversations.items.list(\"conv_123\")\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"type\": \"message\",\n      \"id\": \"msg_abc\",\n      \"status\": \"completed\",\n      \"role\": \"user\",\n      \"content\": [\n        {\"type\": \"input_text\", \"text\": \"Hello!\"}\n      ]\n    }\n  ],\n  \"first_id\": \"msg_abc\",\n  \"last_id\": \"msg_abc\",\n  \"has_more\": false\n}\n"
          title: List items in a conversation
        group: conversations
        name: List items
        path: list-items
        returns: "Returns a [list object](https://platform.openai.com/docs/api-reference/conversations/list-items-object) containing Conversation items.\n"
    post:
      tags:
        - Conversations
      summary: Create items
      description: Create items in a conversation with the given ID.
      operationId: createConversationItems
      parameters:
        - name: conversation_id
          in: path
          description: The ID of the conversation to add the item to.
          required: true
          schema:
            type: string
            example: conv_123
        - name: include
          in: query
          description: "Additional fields to include in the response. See the `include`\nparameter for [listing Conversation items above](https://platform.openai.com/docs/api-reference/conversations/list-items#conversations_list_items-include) for more information.\n"
          schema:
            type: array
            items:
              $ref: '#/components/schemas/Includable'
      requestBody:
        content:
          application/json:
            schema:
              required:
                - items
              properties:
                items:
                  maxItems: 20
                  type: array
                  items:
                    $ref: '#/components/schemas/InputItem'
                  description: "The items to add to the conversation. You may add up to 20 items at a time.\n"
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ConversationItemList'
      x-oaiMeta:
        example:
          request:
            csharp: "using System;\nusing System.Collections.Generic;\nusing OpenAI.Conversations;\n\nOpenAIConversationClient client = new(\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nConversationItemList created = client.ConversationItems.Create(\n    conversationId: \"conv_123\",\n    new CreateConversationItemsOptions\n    {\n        Items = new List<ConversationItem>\n        {\n            new ConversationMessage\n            {\n                Role = \"user\",\n                Content =\n                {\n                    new ConversationInputText { Text = \"Hello!\" }\n                }\n            },\n            new ConversationMessage\n            {\n                Role = \"user\",\n                Content =\n                {\n                    new ConversationInputText { Text = \"How are you?\" }\n                }\n            }\n        }\n    }\n);\nConsole.WriteLine(created.Data.Count);\n"
            curl: "curl https://api.openai.com/v1/conversations/conv_123/items \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"items\": [\n      {\n        \"type\": \"message\",\n        \"role\": \"user\",\n        \"content\": [\n          {\"type\": \"input_text\", \"text\": \"Hello!\"}\n        ]\n      },\n      {\n        \"type\": \"message\",\n        \"role\": \"user\",\n        \"content\": [\n          {\"type\": \"input_text\", \"text\": \"How are you?\"}\n        ]\n      }\n    ]\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/conversations\"\n  \"github.com/openai/openai-go/option\"\n  \"github.com/openai/openai-go/responses\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  conversationItemList, err := client.Conversations.Items.New(\n    context.TODO(),\n    \"conv_123\",\n    conversations.ItemNewParams{\n      Items: []responses.ResponseInputItemUnionParam{responses.ResponseInputItemUnionParam{\n        OfMessage: &responses.EasyInputMessageParam{\n          Content: responses.EasyInputMessageContentUnionParam{\n            OfString: openai.String(\"string\"),\n          },\n          Role: responses.EasyInputMessageRoleUser,\n        },\n      }},\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", conversationItemList.FirstID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.conversations.items.ConversationItemList;\nimport com.openai.models.conversations.items.ItemCreateParams;\nimport com.openai.models.responses.EasyInputMessage;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ItemCreateParams params = ItemCreateParams.builder()\n            .conversationId(\"conv_123\")\n            .addItem(EasyInputMessage.builder()\n                .content(\"string\")\n                .role(EasyInputMessage.Role.USER)\n                .build())\n            .build();\n        ConversationItemList conversationItemList = client.conversations().items().create(params);\n    }\n}"
            javascript: "import OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst items = await client.conversations.items.create(\n  \"conv_123\",\n  {\n    items: [\n      {\n        type: \"message\",\n        role: \"user\",\n        content: [{ type: \"input_text\", text: \"Hello!\" }],\n      },\n      {\n        type: \"message\",\n        role: \"user\",\n        content: [{ type: \"input_text\", text: \"How are you?\" }],\n      },\n    ],\n  }\n);\nconsole.log(items.data);\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst conversationItemList = await client.conversations.items.create('conv_123', {\n  items: [{ content: 'string', role: 'user' }],\n});\n\nconsole.log(conversationItemList.first_id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nconversation_item_list = client.conversations.items.create(\n    conversation_id=\"conv_123\",\n    items=[{\n        \"content\": \"string\",\n        \"role\": \"user\",\n    }],\n)\nprint(conversation_item_list.first_id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nconversation_item_list = openai.conversations.items.create(\"conv_123\", items: [{content: \"string\", role: :user}])\n\nputs(conversation_item_list)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"type\": \"message\",\n      \"id\": \"msg_abc\",\n      \"status\": \"completed\",\n      \"role\": \"user\",\n      \"content\": [\n        {\"type\": \"input_text\", \"text\": \"Hello!\"}\n      ]\n    },\n    {\n      \"type\": \"message\",\n      \"id\": \"msg_def\",\n      \"status\": \"completed\",\n      \"role\": \"user\",\n      \"content\": [\n        {\"type\": \"input_text\", \"text\": \"How are you?\"}\n      ]\n    }\n  ],\n  \"first_id\": \"msg_abc\",\n  \"last_id\": \"msg_def\",\n  \"has_more\": false\n}\n"
          title: Add a user message to a conversation
        group: conversations
        name: Create items
        path: create-item
        returns: "Returns the list of added [items](https://platform.openai.com/docs/api-reference/conversations/list-items-object).\n"
  '/conversations/{conversation_id}/items/{item_id}':
    delete:
      tags:
        - Conversations
      summary: Delete an item
      description: Delete an item from a conversation with the given IDs.
      operationId: deleteConversationItem
      parameters:
        - name: conversation_id
          in: path
          description: The ID of the conversation that contains the item.
          required: true
          schema:
            type: string
            example: conv_123
        - name: item_id
          in: path
          description: The ID of the item to delete.
          required: true
          schema:
            type: string
            example: msg_abc
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ConversationResource'
      x-oaiMeta:
        example:
          request:
            csharp: "using System;\nusing OpenAI.Conversations;\n\nOpenAIConversationClient client = new(\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nConversation conversation = client.ConversationItems.Delete(\n    conversationId: \"conv_123\",\n    itemId: \"msg_abc\"\n);\nConsole.WriteLine(conversation.Id);\n"
            curl: "curl -X DELETE https://api.openai.com/v1/conversations/conv_123/items/msg_abc \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  conversation, err := client.Conversations.Items.Delete(\n    context.TODO(),\n    \"conv_123\",\n    \"msg_abc\",\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", conversation.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.conversations.Conversation;\nimport com.openai.models.conversations.items.ItemDeleteParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ItemDeleteParams params = ItemDeleteParams.builder()\n            .conversationId(\"conv_123\")\n            .itemId(\"msg_abc\")\n            .build();\n        Conversation conversation = client.conversations().items().delete(params);\n    }\n}"
            javascript: "import OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst conversation = await client.conversations.items.delete(\n  \"conv_123\",\n  \"msg_abc\"\n);\nconsole.log(conversation);\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst conversation = await client.conversations.items.delete('msg_abc', { conversation_id: 'conv_123' });\n\nconsole.log(conversation.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nconversation = client.conversations.items.delete(\n    item_id=\"msg_abc\",\n    conversation_id=\"conv_123\",\n)\nprint(conversation.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nconversation = openai.conversations.items.delete(\"msg_abc\", conversation_id: \"conv_123\")\n\nputs(conversation)"
          response: "{\n  \"id\": \"conv_123\",\n  \"object\": \"conversation\",\n  \"created_at\": 1741900000,\n  \"metadata\": {\"topic\": \"demo\"}\n}\n"
          title: Delete an item
        group: conversations
        name: Delete an item
        path: delete-item
        returns: "Returns the updated [Conversation](https://platform.openai.com/docs/api-reference/conversations/object) object.\n"
    get:
      tags:
        - Conversations
      summary: Retrieve an item
      description: Get a single item from a conversation with the given IDs.
      operationId: getConversationItem
      parameters:
        - name: conversation_id
          in: path
          description: The ID of the conversation that contains the item.
          required: true
          schema:
            type: string
            example: conv_123
        - name: item_id
          in: path
          description: The ID of the item to retrieve.
          required: true
          schema:
            type: string
            example: msg_abc
        - name: include
          in: query
          description: "Additional fields to include in the response. See the `include`\nparameter for [listing Conversation items above](https://platform.openai.com/docs/api-reference/conversations/list-items#conversations_list_items-include) for more information.\n"
          schema:
            type: array
            items:
              $ref: '#/components/schemas/Includable'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ConversationItem'
      x-oaiMeta:
        example:
          request:
            csharp: "using System;\nusing OpenAI.Conversations;\n\nOpenAIConversationClient client = new(\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nConversationItem item = client.ConversationItems.Get(\n    conversationId: \"conv_123\",\n    itemId: \"msg_abc\"\n);\nConsole.WriteLine(item.Id);\n"
            curl: "curl https://api.openai.com/v1/conversations/conv_123/items/msg_abc \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/conversations\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  conversationItem, err := client.Conversations.Items.Get(\n    context.TODO(),\n    \"conv_123\",\n    \"msg_abc\",\n    conversations.ItemGetParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", conversationItem)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.conversations.items.ConversationItem;\nimport com.openai.models.conversations.items.ItemRetrieveParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ItemRetrieveParams params = ItemRetrieveParams.builder()\n            .conversationId(\"conv_123\")\n            .itemId(\"msg_abc\")\n            .build();\n        ConversationItem conversationItem = client.conversations().items().retrieve(params);\n    }\n}"
            javascript: "import OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst item = await client.conversations.items.retrieve(\n  \"conv_123\",\n  \"msg_abc\"\n);\nconsole.log(item);\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst conversationItem = await client.conversations.items.retrieve('msg_abc', {\n  conversation_id: 'conv_123',\n});\n\nconsole.log(conversationItem);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nconversation_item = client.conversations.items.retrieve(\n    item_id=\"msg_abc\",\n    conversation_id=\"conv_123\",\n)\nprint(conversation_item)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nconversation_item = openai.conversations.items.retrieve(\"msg_abc\", conversation_id: \"conv_123\")\n\nputs(conversation_item)"
          response: "{\n  \"type\": \"message\",\n  \"id\": \"msg_abc\",\n  \"status\": \"completed\",\n  \"role\": \"user\",\n  \"content\": [\n    {\"type\": \"input_text\", \"text\": \"Hello!\"}\n  ]\n}\n"
          title: Retrieve an item
        group: conversations
        name: Retrieve an item
        path: get-item
        returns: "Returns a [Conversation Item](https://platform.openai.com/docs/api-reference/conversations/item-object).\n"
  /embeddings:
    post:
      tags:
        - Embeddings
      summary: Create embeddings
      description: Creates an embedding vector representing the input text.
      operationId: createEmbedding
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEmbeddingRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateEmbeddingResponse'
      x-oaiMeta:
        examples:
          request:
            csharp: "using System;\n\nusing OpenAI.Embeddings;\n\nEmbeddingClient client = new(\n    model: \"text-embedding-3-small\",\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nOpenAIEmbedding embedding = client.GenerateEmbedding(input: \"The quick brown fox jumped over the lazy dog\");\nReadOnlyMemory<float> vector = embedding.ToFloats();\n\nfor (int i = 0; i < vector.Length; i++)\n{\n    Console.WriteLine($\"  [{i,4}] = {vector.Span[i]}\");\n}\n"
            curl: "curl https://api.openai.com/v1/embeddings \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"input\": \"The food was delicious and the waiter...\",\n    \"model\": \"text-embedding-ada-002\",\n    \"encoding_format\": \"float\"\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  createEmbeddingResponse, err := client.Embeddings.New(context.TODO(), openai.EmbeddingNewParams{\n    Input: openai.EmbeddingNewParamsInputUnion{\n      OfString: openai.String(\"The quick brown fox jumped over the lazy dog\"),\n    },\n    Model: openai.EmbeddingModelTextEmbeddingAda002,\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", createEmbeddingResponse.Data)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.embeddings.CreateEmbeddingResponse;\nimport com.openai.models.embeddings.EmbeddingCreateParams;\nimport com.openai.models.embeddings.EmbeddingModel;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        EmbeddingCreateParams params = EmbeddingCreateParams.builder()\n            .input(\"The quick brown fox jumped over the lazy dog\")\n            .model(EmbeddingModel.TEXT_EMBEDDING_ADA_002)\n            .build();\n        CreateEmbeddingResponse createEmbeddingResponse = client.embeddings().create(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst createEmbeddingResponse = await client.embeddings.create({\n  input: 'The quick brown fox jumped over the lazy dog',\n  model: 'text-embedding-3-small',\n});\n\nconsole.log(createEmbeddingResponse.data);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\ncreate_embedding_response = client.embeddings.create(\n    input=\"The quick brown fox jumped over the lazy dog\",\n    model=\"text-embedding-3-small\",\n)\nprint(create_embedding_response.data)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\ncreate_embedding_response = openai.embeddings.create(\n  input: \"The quick brown fox jumped over the lazy dog\",\n  model: :\"text-embedding-ada-002\"\n)\n\nputs(create_embedding_response)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"embedding\",\n      \"embedding\": [\n        0.0023064255,\n        -0.009327292,\n        .... (1536 floats total for ada-002)\n        -0.0028842222,\n      ],\n      \"index\": 0\n    }\n  ],\n  \"model\": \"text-embedding-ada-002\",\n  \"usage\": {\n    \"prompt_tokens\": 8,\n    \"total_tokens\": 8\n  }\n}\n"
        group: embeddings
        name: Create embeddings
        returns: 'A list of [embedding](https://platform.openai.com/docs/api-reference/embeddings/object) objects.'
  /evals:
    get:
      tags:
        - Evals
      summary: List evals
      description: "List evaluations for a project.\n"
      operationId: listEvals
      parameters:
        - name: after
          in: query
          description: Identifier for the last eval from the previous pagination request.
          schema:
            type: string
        - name: limit
          in: query
          description: Number of evals to retrieve.
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: Sort order for evals by timestamp. Use `asc` for ascending order or `desc` for descending order.
          schema:
            enum:
              - asc
              - desc
            type: string
            default: asc
        - name: order_by
          in: query
          description: "Evals can be ordered by creation time or last updated time. Use\n`created_at` for creation time or `updated_at` for last updated time.\n"
          schema:
            enum:
              - created_at
              - updated_at
            type: string
            default: created_at
      responses:
        '200':
          description: A list of evals
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EvalList'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/evals?limit=1 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.evals.EvalListPage;\nimport com.openai.models.evals.EvalListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        EvalListPage page = client.evals().list();\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const evalListResponse of client.evals.list()) {\n  console.log(evalListResponse.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.evals.list()\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.evals.list\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n      \"object\": \"eval\",\n      \"data_source_config\": {\n        \"type\": \"stored_completions\",\n        \"metadata\": {\n          \"usecase\": \"push_notifications_summarizer\"\n        },\n        \"schema\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"item\": {\n              \"type\": \"object\"\n            },\n            \"sample\": {\n              \"type\": \"object\"\n            }\n          },\n          \"required\": [\n            \"item\",\n            \"sample\"\n          ]\n        }\n      },\n      \"testing_criteria\": [\n        {\n          \"name\": \"Push Notification Summary Grader\",\n          \"id\": \"Push Notification Summary Grader-9b876f24-4762-4be9-aff4-db7a9b31c673\",\n          \"type\": \"label_model\",\n          \"model\": \"o3-mini\",\n          \"input\": [\n            {\n              \"type\": \"message\",\n              \"role\": \"developer\",\n              \"content\": {\n                \"type\": \"input_text\",\n                \"text\": \"\\nLabel the following push notification summary as either correct or incorrect.\\nThe push notification and the summary will be provided below.\\nA good push notificiation summary is concise and snappy.\\nIf it is good, then label it as correct, if not, then incorrect.\\n\"\n              }\n            },\n            {\n              \"type\": \"message\",\n              \"role\": \"user\",\n              \"content\": {\n                \"type\": \"input_text\",\n                \"text\": \"\\nPush notifications: {{item.input}}\\nSummary: {{sample.output_text}}\\n\"\n              }\n            }\n          ],\n          \"passing_labels\": [\n            \"correct\"\n          ],\n          \"labels\": [\n            \"correct\",\n            \"incorrect\"\n          ],\n          \"sampling_params\": null\n        }\n      ],\n      \"name\": \"Push Notification Summary Grader\",\n      \"created_at\": 1739314509,\n      \"metadata\": {\n        \"description\": \"A stored completions eval for push notification summaries\"\n      }\n    }\n  ],\n  \"first_id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n  \"last_id\": \"eval_67aa884cf6688190b58f657d4441c8b7\",\n  \"has_more\": true\n}\n"
        group: evals
        name: List evals
        path: list
        returns: 'A list of [evals](https://platform.openai.com/docs/api-reference/evals/object) matching the specified filters.'
    post:
      tags:
        - Evals
      summary: Create eval
      description: "Create the structure of an evaluation that can be used to test a model's performance.\nAn evaluation is a set of testing criteria and the config for a data source, which dictates the schema of the data used in the evaluation. After creating an evaluation, you can run it on different models and model parameters. We support several types of graders and datasources.\nFor more information, see the [Evals guide](https://platform.openai.com/docs/guides/evals).\n"
      operationId: createEval
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEvalRequest'
        required: true
      responses:
        '201':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Eval'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/evals \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n        \"name\": \"Sentiment\",\n        \"data_source_config\": {\n          \"type\": \"stored_completions\",\n          \"metadata\": {\n              \"usecase\": \"chatbot\"\n          }\n        },\n        \"testing_criteria\": [\n          {\n            \"type\": \"label_model\",\n            \"model\": \"o3-mini\",\n            \"input\": [\n              {\n                \"role\": \"developer\",\n                \"content\": \"Classify the sentiment of the following statement as one of 'positive', 'neutral', or 'negative'\"\n              },\n              {\n                \"role\": \"user\",\n                \"content\": \"Statement: {{item.input}}\"\n              }\n            ],\n            \"passing_labels\": [\n              \"positive\"\n            ],\n            \"labels\": [\n              \"positive\",\n              \"neutral\",\n              \"negative\"\n            ],\n            \"name\": \"Example label grader\"\n          }\n        ]\n      }'\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.core.JsonValue;\nimport com.openai.models.evals.EvalCreateParams;\nimport com.openai.models.evals.EvalCreateResponse;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        EvalCreateParams params = EvalCreateParams.builder()\n            .customDataSourceConfig(EvalCreateParams.DataSourceConfig.Custom.ItemSchema.builder()\n                .putAdditionalProperty(\"foo\", JsonValue.from(\"bar\"))\n                .build())\n            .addTestingCriterion(EvalCreateParams.TestingCriterion.LabelModel.builder()\n                .addInput(EvalCreateParams.TestingCriterion.LabelModel.Input.SimpleInputMessage.builder()\n                    .content(\"content\")\n                    .role(\"role\")\n                    .build())\n                .addLabel(\"string\")\n                .model(\"model\")\n                .name(\"name\")\n                .addPassingLabel(\"string\")\n                .build())\n            .build();\n        EvalCreateResponse eval = client.evals().create(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst _eval = await client.evals.create({\n  data_source_config: { item_schema: { foo: 'bar' }, type: 'custom' },\n  testing_criteria: [\n    {\n      input: [{ content: 'content', role: 'role' }],\n      labels: ['string'],\n      model: 'model',\n      name: 'name',\n      passing_labels: ['string'],\n      type: 'label_model',\n    },\n  ],\n});\n\nconsole.log(_eval.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\neval = client.evals.create(\n    data_source_config={\n        \"item_schema\": {\n            \"foo\": \"bar\"\n        },\n        \"type\": \"custom\",\n    },\n    testing_criteria=[{\n        \"input\": [{\n            \"content\": \"content\",\n            \"role\": \"role\",\n        }],\n        \"labels\": [\"string\"],\n        \"model\": \"model\",\n        \"name\": \"name\",\n        \"passing_labels\": [\"string\"],\n        \"type\": \"label_model\",\n    }],\n)\nprint(eval.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\neval_ = openai.evals.create(\n  data_source_config: {item_schema: {foo: \"bar\"}, type: :custom},\n  testing_criteria: [\n    {\n      input: [{content: \"content\", role: \"role\"}],\n      labels: [\"string\"],\n      model: \"model\",\n      name: \"name\",\n      passing_labels: [\"string\"],\n      type: :label_model\n    }\n  ]\n)\n\nputs(eval_)"
          response: "{\n  \"object\": \"eval\",\n  \"id\": \"eval_67b7fa9a81a88190ab4aa417e397ea21\",\n  \"data_source_config\": {\n    \"type\": \"stored_completions\",\n    \"metadata\": {\n      \"usecase\": \"chatbot\"\n    },\n    \"schema\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"item\": {\n          \"type\": \"object\"\n        },\n        \"sample\": {\n          \"type\": \"object\"\n        }\n      },\n      \"required\": [\n        \"item\",\n        \"sample\"\n      ]\n  },\n  \"testing_criteria\": [\n    {\n      \"name\": \"Example label grader\",\n      \"type\": \"label_model\",\n      \"model\": \"o3-mini\",\n      \"input\": [\n        {\n          \"type\": \"message\",\n          \"role\": \"developer\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"Classify the sentiment of the following statement as one of positive, neutral, or negative\"\n          }\n        },\n        {\n          \"type\": \"message\",\n          \"role\": \"user\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"Statement: {{item.input}}\"\n          }\n        }\n      ],\n      \"passing_labels\": [\n        \"positive\"\n      ],\n      \"labels\": [\n        \"positive\",\n        \"neutral\",\n        \"negative\"\n      ]\n    }\n  ],\n  \"name\": \"Sentiment\",\n  \"created_at\": 1740110490,\n  \"metadata\": {\n    \"description\": \"An eval for sentiment analysis\"\n  }\n}\n"
        group: evals
        name: Create eval
        path: post
        returns: 'The created [Eval](https://platform.openai.com/docs/api-reference/evals/object) object.'
  '/evals/{eval_id}':
    delete:
      tags:
        - Evals
      summary: Delete an eval
      description: "Delete an evaluation.\n"
      operationId: deleteEval
      parameters:
        - name: eval_id
          in: path
          description: The ID of the evaluation to delete.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Successfully deleted the evaluation.
          content:
            application/json:
              schema:
                required:
                  - object
                  - deleted
                  - eval_id
                type: object
                properties:
                  deleted:
                    type: boolean
                    example: true
                  eval_id:
                    type: string
                    example: eval_abc123
                  object:
                    type: string
                    example: eval.deleted
        '404':
          description: Evaluation not found.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/evals/eval_abc123 \\\n  -X DELETE \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.evals.EvalDeleteParams;\nimport com.openai.models.evals.EvalDeleteResponse;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        EvalDeleteResponse eval = client.evals().delete(\"eval_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst _eval = await client.evals.delete('eval_id');\n\nconsole.log(_eval.eval_id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\neval = client.evals.delete(\n    \"eval_id\",\n)\nprint(eval.eval_id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\neval_ = openai.evals.delete(\"eval_id\")\n\nputs(eval_)"
          response: "{\n  \"object\": \"eval.deleted\",\n  \"deleted\": true,\n  \"eval_id\": \"eval_abc123\"\n}\n"
        group: evals
        name: Delete an eval
        returns: A deletion confirmation object.
    get:
      tags:
        - Evals
      summary: Get an eval
      description: "Get an evaluation by ID.\n"
      operationId: getEval
      parameters:
        - name: eval_id
          in: path
          description: The ID of the evaluation to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: The evaluation
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Eval'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.evals.EvalRetrieveParams;\nimport com.openai.models.evals.EvalRetrieveResponse;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        EvalRetrieveResponse eval = client.evals().retrieve(\"eval_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst _eval = await client.evals.retrieve('eval_id');\n\nconsole.log(_eval.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\neval = client.evals.retrieve(\n    \"eval_id\",\n)\nprint(eval.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\neval_ = openai.evals.retrieve(\"eval_id\")\n\nputs(eval_)"
          response: "{\n  \"object\": \"eval\",\n  \"id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n  \"data_source_config\": {\n    \"type\": \"custom\",\n    \"schema\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"item\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"input\": {\n              \"type\": \"string\"\n            },\n            \"ground_truth\": {\n              \"type\": \"string\"\n            }\n          },\n          \"required\": [\n            \"input\",\n            \"ground_truth\"\n          ]\n        }\n      },\n      \"required\": [\n        \"item\"\n      ]\n    }\n  },\n  \"testing_criteria\": [\n    {\n      \"name\": \"String check\",\n      \"id\": \"String check-2eaf2d8d-d649-4335-8148-9535a7ca73c2\",\n      \"type\": \"string_check\",\n      \"input\": \"{{item.input}}\",\n      \"reference\": \"{{item.ground_truth}}\",\n      \"operation\": \"eq\"\n    }\n  ],\n  \"name\": \"External Data Eval\",\n  \"created_at\": 1739314509,\n  \"metadata\": {},\n}\n"
        group: evals
        name: Get an eval
        path: get
        returns: 'The [Eval](https://platform.openai.com/docs/api-reference/evals/object) object matching the specified ID.'
    post:
      tags:
        - Evals
      summary: Update an eval
      description: "Update certain properties of an evaluation.\n"
      operationId: updateEval
      parameters:
        - name: eval_id
          in: path
          description: The ID of the evaluation to update.
          required: true
          schema:
            type: string
      requestBody:
        description: Request to update an evaluation
        content:
          application/json:
            schema:
              type: object
              properties:
                metadata:
                  $ref: '#/components/schemas/Metadata'
                name:
                  type: string
                  description: Rename the evaluation.
        required: true
      responses:
        '200':
          description: The updated evaluation
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Eval'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"name\": \"Updated Eval\", \"metadata\": {\"description\": \"Updated description\"}}'\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.evals.EvalUpdateParams;\nimport com.openai.models.evals.EvalUpdateResponse;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        EvalUpdateResponse eval = client.evals().update(\"eval_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst _eval = await client.evals.update('eval_id');\n\nconsole.log(_eval.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\neval = client.evals.update(\n    eval_id=\"eval_id\",\n)\nprint(eval.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\neval_ = openai.evals.update(\"eval_id\")\n\nputs(eval_)"
          response: "{\n  \"object\": \"eval\",\n  \"id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n  \"data_source_config\": {\n    \"type\": \"custom\",\n    \"schema\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"item\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"input\": {\n              \"type\": \"string\"\n            },\n            \"ground_truth\": {\n              \"type\": \"string\"\n            }\n          },\n          \"required\": [\n            \"input\",\n            \"ground_truth\"\n          ]\n        }\n      },\n      \"required\": [\n        \"item\"\n      ]\n    }\n  },\n  \"testing_criteria\": [\n    {\n      \"name\": \"String check\",\n      \"id\": \"String check-2eaf2d8d-d649-4335-8148-9535a7ca73c2\",\n      \"type\": \"string_check\",\n      \"input\": \"{{item.input}}\",\n      \"reference\": \"{{item.ground_truth}}\",\n      \"operation\": \"eq\"\n    }\n  ],\n  \"name\": \"Updated Eval\",\n  \"created_at\": 1739314509,\n  \"metadata\": {\"description\": \"Updated description\"},\n}\n"
        group: evals
        name: Update an eval
        path: update
        returns: 'The [Eval](https://platform.openai.com/docs/api-reference/evals/object) object matching the updated version.'
  '/evals/{eval_id}/runs':
    get:
      tags:
        - Evals
      summary: Get eval runs
      description: "Get a list of runs for an evaluation.\n"
      operationId: getEvalRuns
      parameters:
        - name: eval_id
          in: path
          description: The ID of the evaluation to retrieve runs for.
          required: true
          schema:
            type: string
        - name: after
          in: query
          description: Identifier for the last run from the previous pagination request.
          schema:
            type: string
        - name: limit
          in: query
          description: Number of runs to retrieve.
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: Sort order for runs by timestamp. Use `asc` for ascending order or `desc` for descending order. Defaults to `asc`.
          schema:
            enum:
              - asc
              - desc
            type: string
            default: asc
        - name: status
          in: query
          description: Filter runs by status. One of `queued` | `in_progress` | `failed` | `completed` | `canceled`.
          schema:
            enum:
              - queued
              - in_progress
              - completed
              - canceled
              - failed
            type: string
      responses:
        '200':
          description: A list of runs for the evaluation
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EvalRunList'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/evals/egroup_67abd54d9b0081909a86353f6fb9317a/runs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.evals.runs.RunListPage;\nimport com.openai.models.evals.runs.RunListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        RunListPage page = client.evals().runs().list(\"eval_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const runListResponse of client.evals.runs.list('eval_id')) {\n  console.log(runListResponse.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.evals.runs.list(\n    eval_id=\"eval_id\",\n)\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.evals.runs.list(\"eval_id\")\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"eval.run\",\n      \"id\": \"evalrun_67e0c7d31560819090d60c0780591042\",\n      \"eval_id\": \"eval_67e0c726d560819083f19a957c4c640b\",\n      \"report_url\": \"https://platform.openai.com/evaluations/eval_67e0c726d560819083f19a957c4c640b\",\n      \"status\": \"completed\",\n      \"model\": \"o3-mini\",\n      \"name\": \"bulk_with_negative_examples_o3-mini\",\n      \"created_at\": 1742784467,\n      \"result_counts\": {\n        \"total\": 1,\n        \"errored\": 0,\n        \"failed\": 0,\n        \"passed\": 1\n      },\n      \"per_model_usage\": [\n        {\n          \"model_name\": \"o3-mini\",\n          \"invocation_count\": 1,\n          \"prompt_tokens\": 563,\n          \"completion_tokens\": 874,\n          \"total_tokens\": 1437,\n          \"cached_tokens\": 0\n        }\n      ],\n      \"per_testing_criteria_results\": [\n        {\n          \"testing_criteria\": \"Push Notification Summary Grader-1808cd0b-eeec-4e0b-a519-337e79f4f5d1\",\n          \"passed\": 1,\n          \"failed\": 0\n        }\n      ],\n      \"data_source\": {\n        \"type\": \"completions\",\n        \"source\": {\n          \"type\": \"file_content\",\n          \"content\": [\n            {\n              \"item\": {\n                \"notifications\": \"\\n- New message from Sarah: \\\"Can you call me later?\\\"\\n- Your package has been delivered!\\n- Flash sale: 20% off electronics for the next 2 hours!\\n\"\n              }\n            }\n          ]\n        },\n        \"input_messages\": {\n          \"type\": \"template\",\n          \"template\": [\n            {\n              \"type\": \"message\",\n              \"role\": \"developer\",\n              \"content\": {\n                \"type\": \"input_text\",\n                \"text\": \"\\n\\n\\n\\nYou are a helpful assistant that takes in an array of push notifications and returns a collapsed summary of them.\\nThe push notification will be provided as follows:\\n<push_notifications>\\n...notificationlist...\\n</push_notifications>\\n\\nYou should return just the summary and nothing else.\\n\\n\\nYou should return a summary that is concise and snappy.\\n\\n\\nHere is an example of a good summary:\\n<push_notifications>\\n- Traffic alert: Accident reported on Main Street.- Package out for delivery: Expected by 5 PM.- New friend suggestion: Connect with Emma.\\n</push_notifications>\\n<summary>\\nTraffic alert, package expected by 5pm, suggestion for new friend (Emily).\\n</summary>\\n\\n\\nHere is an example of a bad summary:\\n<push_notifications>\\n- Traffic alert: Accident reported on Main Street.- Package out for delivery: Expected by 5 PM.- New friend suggestion: Connect with Emma.\\n</push_notifications>\\n<summary>\\nTraffic alert reported on main street. You have a package that will arrive by 5pm, Emily is a new friend suggested for you.\\n</summary>\\n\"\n              }\n            },\n            {\n              \"type\": \"message\",\n              \"role\": \"user\",\n              \"content\": {\n                \"type\": \"input_text\",\n                \"text\": \"<push_notifications>{{item.notifications}}</push_notifications>\"\n              }\n            }\n          ]\n        },\n        \"model\": \"o3-mini\",\n        \"sampling_params\": null\n      },\n      \"error\": null,\n      \"metadata\": {}\n    }\n  ],\n  \"first_id\": \"evalrun_67e0c7d31560819090d60c0780591042\",\n  \"last_id\": \"evalrun_67e0c7d31560819090d60c0780591042\",\n  \"has_more\": true\n}\n"
        group: evals
        name: Get eval runs
        path: get-runs
        returns: 'A list of [EvalRun](https://platform.openai.com/docs/api-reference/evals/run-object) objects matching the specified ID.'
    post:
      tags:
        - Evals
      summary: Create eval run
      description: "Kicks off a new run for a given evaluation, specifying the data source, and what model configuration to use to test. The datasource will be validated against the schema specified in the config of the evaluation.\n"
      operationId: createEvalRun
      parameters:
        - name: eval_id
          in: path
          description: The ID of the evaluation to create a run for.
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEvalRunRequest'
        required: true
      responses:
        '201':
          description: Successfully created a run for the evaluation
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EvalRun'
        '400':
          description: 'Bad request (for example, missing eval object)'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/evals/eval_67e579652b548190aaa83ada4b125f47/runs \\\n  -X POST \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"name\":\"gpt-4o-mini\",\"data_source\":{\"type\":\"completions\",\"input_messages\":{\"type\":\"template\",\"template\":[{\"role\":\"developer\",\"content\":\"Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\\n\\n# Steps\\n\\n1. Analyze the content of the news headline to understand its primary focus.\\n2. Extract the subject matter, identifying any key indicators or keywords.\\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\\n4. Ensure only one category is selected per headline.\\n\\n# Output Format\\n\\nRespond with the chosen category as a single word. For instance: \\\"Technology\\\", \\\"Markets\\\", \\\"World\\\", \\\"Business\\\", or \\\"Sports\\\".\\n\\n# Examples\\n\\n**Input**: \\\"Apple Unveils New iPhone Model, Featuring Advanced AI Features\\\"  \\n**Output**: \\\"Technology\\\"\\n\\n**Input**: \\\"Global Stocks Mixed as Investors Await Central Bank Decisions\\\"  \\n**Output**: \\\"Markets\\\"\\n\\n**Input**: \\\"War in Ukraine: Latest Updates on Negotiation Status\\\"  \\n**Output**: \\\"World\\\"\\n\\n**Input**: \\\"Microsoft in Talks to Acquire Gaming Company for $2 Billion\\\"  \\n**Output**: \\\"Business\\\"\\n\\n**Input**: \\\"Manchester United Secures Win in Premier League Football Match\\\"  \\n**Output**: \\\"Sports\\\" \\n\\n# Notes\\n\\n- If the headline appears to fit into more than one category, choose the most dominant theme.\\n- Keywords or phrases such as \\\"stocks\\\", \\\"company acquisition\\\", \\\"match\\\", or technological brands can be good indicators for classification.\\n\"} , {\"role\":\"user\",\"content\":\"{{item.input}}\"}]} ,\"sampling_params\":{\"temperature\":1,\"max_completions_tokens\":2048,\"top_p\":1,\"seed\":42},\"model\":\"gpt-4o-mini\",\"source\":{\"type\":\"file_content\",\"content\":[{\"item\":{\"input\":\"Tech Company Launches Advanced Artificial Intelligence Platform\",\"ground_truth\":\"Technology\"}}]}}'\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.core.JsonValue;\nimport com.openai.models.evals.runs.CreateEvalJsonlRunDataSource;\nimport com.openai.models.evals.runs.RunCreateParams;\nimport com.openai.models.evals.runs.RunCreateResponse;\nimport java.util.List;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        RunCreateParams params = RunCreateParams.builder()\n            .evalId(\"eval_id\")\n            .dataSource(CreateEvalJsonlRunDataSource.builder()\n                .fileContentSource(List.of(CreateEvalJsonlRunDataSource.Source.FileContent.Content.builder()\n                    .item(CreateEvalJsonlRunDataSource.Source.FileContent.Content.Item.builder()\n                        .putAdditionalProperty(\"foo\", JsonValue.from(\"bar\"))\n                        .build())\n                    .build()))\n                .build())\n            .build();\n        RunCreateResponse run = client.evals().runs().create(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst run = await client.evals.runs.create('eval_id', {\n  data_source: { source: { content: [{ item: { foo: 'bar' } }], type: 'file_content' }, type: 'jsonl' },\n});\n\nconsole.log(run.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nrun = client.evals.runs.create(\n    eval_id=\"eval_id\",\n    data_source={\n        \"source\": {\n            \"content\": [{\n                \"item\": {\n                    \"foo\": \"bar\"\n                }\n            }],\n            \"type\": \"file_content\",\n        },\n        \"type\": \"jsonl\",\n    },\n)\nprint(run.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nrun = openai.evals.runs.create(\n  \"eval_id\",\n  data_source: {source: {content: [{item: {foo: \"bar\"}}], type: :file_content}, type: :jsonl}\n)\n\nputs(run)"
          response: "{\n  \"object\": \"eval.run\",\n  \"id\": \"evalrun_67e57965b480819094274e3a32235e4c\",\n  \"eval_id\": \"eval_67e579652b548190aaa83ada4b125f47\",\n  \"report_url\": \"https://platform.openai.com/evaluations/eval_67e579652b548190aaa83ada4b125f47&run_id=evalrun_67e57965b480819094274e3a32235e4c\",\n  \"status\": \"queued\",\n  \"model\": \"gpt-4o-mini\",\n  \"name\": \"gpt-4o-mini\",\n  \"created_at\": 1743092069,\n  \"result_counts\": {\n    \"total\": 0,\n    \"errored\": 0,\n    \"failed\": 0,\n    \"passed\": 0\n  },\n  \"per_model_usage\": null,\n  \"per_testing_criteria_results\": null,\n  \"data_source\": {\n    \"type\": \"completions\",\n    \"source\": {\n      \"type\": \"file_content\",\n      \"content\": [\n        {\n          \"item\": {\n            \"input\": \"Tech Company Launches Advanced Artificial Intelligence Platform\",\n            \"ground_truth\": \"Technology\"\n          }\n        }\n      ]\n    },\n    \"input_messages\": {\n      \"type\": \"template\",\n      \"template\": [\n        {\n          \"type\": \"message\",\n          \"role\": \"developer\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\\n\\n# Steps\\n\\n1. Analyze the content of the news headline to understand its primary focus.\\n2. Extract the subject matter, identifying any key indicators or keywords.\\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\\n4. Ensure only one category is selected per headline.\\n\\n# Output Format\\n\\nRespond with the chosen category as a single word. For instance: \\\"Technology\\\", \\\"Markets\\\", \\\"World\\\", \\\"Business\\\", or \\\"Sports\\\".\\n\\n# Examples\\n\\n**Input**: \\\"Apple Unveils New iPhone Model, Featuring Advanced AI Features\\\"  \\n**Output**: \\\"Technology\\\"\\n\\n**Input**: \\\"Global Stocks Mixed as Investors Await Central Bank Decisions\\\"  \\n**Output**: \\\"Markets\\\"\\n\\n**Input**: \\\"War in Ukraine: Latest Updates on Negotiation Status\\\"  \\n**Output**: \\\"World\\\"\\n\\n**Input**: \\\"Microsoft in Talks to Acquire Gaming Company for $2 Billion\\\"  \\n**Output**: \\\"Business\\\"\\n\\n**Input**: \\\"Manchester United Secures Win in Premier League Football Match\\\"  \\n**Output**: \\\"Sports\\\" \\n\\n# Notes\\n\\n- If the headline appears to fit into more than one category, choose the most dominant theme.\\n- Keywords or phrases such as \\\"stocks\\\", \\\"company acquisition\\\", \\\"match\\\", or technological brands can be good indicators for classification.\\n\"\n          }\n        },\n        {\n          \"type\": \"message\",\n          \"role\": \"user\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"{{item.input}}\"\n          }\n        }\n      ]\n    },\n    \"model\": \"gpt-4o-mini\",\n    \"sampling_params\": {\n      \"seed\": 42,\n      \"temperature\": 1.0,\n      \"top_p\": 1.0,\n      \"max_completions_tokens\": 2048\n    }\n  },\n  \"error\": null,\n  \"metadata\": {}\n}\n"
        group: evals
        name: Create eval run
        returns: 'The [EvalRun](https://platform.openai.com/docs/api-reference/evals/run-object) object matching the specified ID.'
  '/evals/{eval_id}/runs/{run_id}':
    delete:
      tags:
        - Evals
      summary: Delete eval run
      description: "Delete an eval run.\n"
      operationId: deleteEvalRun
      parameters:
        - name: eval_id
          in: path
          description: The ID of the evaluation to delete the run from.
          required: true
          schema:
            type: string
        - name: run_id
          in: path
          description: The ID of the run to delete.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Successfully deleted the eval run
          content:
            application/json:
              schema:
                type: object
                properties:
                  deleted:
                    type: boolean
                    example: true
                  object:
                    type: string
                    example: eval.run.deleted
                  run_id:
                    type: string
                    example: evalrun_677469f564d48190807532a852da3afb
        '404':
          description: Run not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/evals/eval_123abc/runs/evalrun_abc456 \\\n  -X DELETE \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.evals.runs.RunDeleteParams;\nimport com.openai.models.evals.runs.RunDeleteResponse;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        RunDeleteParams params = RunDeleteParams.builder()\n            .evalId(\"eval_id\")\n            .runId(\"run_id\")\n            .build();\n        RunDeleteResponse run = client.evals().runs().delete(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst run = await client.evals.runs.delete('run_id', { eval_id: 'eval_id' });\n\nconsole.log(run.run_id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nrun = client.evals.runs.delete(\n    run_id=\"run_id\",\n    eval_id=\"eval_id\",\n)\nprint(run.run_id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nrun = openai.evals.runs.delete(\"run_id\", eval_id: \"eval_id\")\n\nputs(run)"
          response: "{\n  \"object\": \"eval.run.deleted\",\n  \"deleted\": true,\n  \"run_id\": \"evalrun_abc456\"\n}\n"
        group: evals
        name: Delete eval run
        path: delete
        returns: An object containing the status of the delete operation.
    get:
      tags:
        - Evals
      summary: Get an eval run
      description: "Get an evaluation run by ID.\n"
      operationId: getEvalRun
      parameters:
        - name: eval_id
          in: path
          description: The ID of the evaluation to retrieve runs for.
          required: true
          schema:
            type: string
        - name: run_id
          in: path
          description: The ID of the run to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: The evaluation run
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EvalRun'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.evals.runs.RunRetrieveParams;\nimport com.openai.models.evals.runs.RunRetrieveResponse;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        RunRetrieveParams params = RunRetrieveParams.builder()\n            .evalId(\"eval_id\")\n            .runId(\"run_id\")\n            .build();\n        RunRetrieveResponse run = client.evals().runs().retrieve(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst run = await client.evals.runs.retrieve('run_id', { eval_id: 'eval_id' });\n\nconsole.log(run.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nrun = client.evals.runs.retrieve(\n    run_id=\"run_id\",\n    eval_id=\"eval_id\",\n)\nprint(run.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nrun = openai.evals.runs.retrieve(\"run_id\", eval_id: \"eval_id\")\n\nputs(run)"
          response: "{\n  \"object\": \"eval.run\",\n  \"id\": \"evalrun_67abd54d60ec8190832b46859da808f7\",\n  \"eval_id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n  \"report_url\": \"https://platform.openai.com/evaluations/eval_67abd54d9b0081909a86353f6fb9317a?run_id=evalrun_67abd54d60ec8190832b46859da808f7\",\n  \"status\": \"queued\",\n  \"model\": \"gpt-4o-mini\",\n  \"name\": \"gpt-4o-mini\",\n  \"created_at\": 1743092069,\n  \"result_counts\": {\n    \"total\": 0,\n    \"errored\": 0,\n    \"failed\": 0,\n    \"passed\": 0\n  },\n  \"per_model_usage\": null,\n  \"per_testing_criteria_results\": null,\n  \"data_source\": {\n    \"type\": \"completions\",\n    \"source\": {\n      \"type\": \"file_content\",\n      \"content\": [\n        {\n          \"item\": {\n            \"input\": \"Tech Company Launches Advanced Artificial Intelligence Platform\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Central Bank Increases Interest Rates Amid Inflation Concerns\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"International Summit Addresses Climate Change Strategies\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Major Retailer Reports Record-Breaking Holiday Sales\",\n            \"ground_truth\": \"Business\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"National Team Qualifies for World Championship Finals\",\n            \"ground_truth\": \"Sports\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Stock Markets Rally After Positive Economic Data Released\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Global Manufacturer Announces Merger with Competitor\",\n            \"ground_truth\": \"Business\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Breakthrough in Renewable Energy Technology Unveiled\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"World Leaders Sign Historic Climate Agreement\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Professional Athlete Sets New Record in Championship Event\",\n            \"ground_truth\": \"Sports\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Financial Institutions Adapt to New Regulatory Requirements\",\n            \"ground_truth\": \"Business\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Tech Conference Showcases Advances in Artificial Intelligence\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Global Markets Respond to Oil Price Fluctuations\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"International Cooperation Strengthened Through New Treaty\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Sports League Announces Revised Schedule for Upcoming Season\",\n            \"ground_truth\": \"Sports\"\n          }\n        }\n      ]\n    },\n    \"input_messages\": {\n      \"type\": \"template\",\n      \"template\": [\n        {\n          \"type\": \"message\",\n          \"role\": \"developer\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\\n\\n# Steps\\n\\n1. Analyze the content of the news headline to understand its primary focus.\\n2. Extract the subject matter, identifying any key indicators or keywords.\\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\\n4. Ensure only one category is selected per headline.\\n\\n# Output Format\\n\\nRespond with the chosen category as a single word. For instance: \\\"Technology\\\", \\\"Markets\\\", \\\"World\\\", \\\"Business\\\", or \\\"Sports\\\".\\n\\n# Examples\\n\\n**Input**: \\\"Apple Unveils New iPhone Model, Featuring Advanced AI Features\\\"  \\n**Output**: \\\"Technology\\\"\\n\\n**Input**: \\\"Global Stocks Mixed as Investors Await Central Bank Decisions\\\"  \\n**Output**: \\\"Markets\\\"\\n\\n**Input**: \\\"War in Ukraine: Latest Updates on Negotiation Status\\\"  \\n**Output**: \\\"World\\\"\\n\\n**Input**: \\\"Microsoft in Talks to Acquire Gaming Company for $2 Billion\\\"  \\n**Output**: \\\"Business\\\"\\n\\n**Input**: \\\"Manchester United Secures Win in Premier League Football Match\\\"  \\n**Output**: \\\"Sports\\\" \\n\\n# Notes\\n\\n- If the headline appears to fit into more than one category, choose the most dominant theme.\\n- Keywords or phrases such as \\\"stocks\\\", \\\"company acquisition\\\", \\\"match\\\", or technological brands can be good indicators for classification.\\n\"\n          }\n        },\n        {\n          \"type\": \"message\",\n          \"role\": \"user\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"{{item.input}}\"\n          }\n        }\n      ]\n    },\n    \"model\": \"gpt-4o-mini\",\n    \"sampling_params\": {\n      \"seed\": 42,\n      \"temperature\": 1.0,\n      \"top_p\": 1.0,\n      \"max_completions_tokens\": 2048\n    }\n  },\n  \"error\": null,\n  \"metadata\": {}\n}\n"
        group: evals
        name: Get an eval run
        path: get
        returns: 'The [EvalRun](https://platform.openai.com/docs/api-reference/evals/run-object) object matching the specified ID.'
    post:
      tags:
        - Evals
      summary: Cancel eval run
      description: "Cancel an ongoing evaluation run.\n"
      operationId: cancelEvalRun
      parameters:
        - name: eval_id
          in: path
          description: The ID of the evaluation whose run you want to cancel.
          required: true
          schema:
            type: string
        - name: run_id
          in: path
          description: The ID of the run to cancel.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: The canceled eval run object
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EvalRun'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7/cancel \\\n  -X POST \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.evals.runs.RunCancelParams;\nimport com.openai.models.evals.runs.RunCancelResponse;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        RunCancelParams params = RunCancelParams.builder()\n            .evalId(\"eval_id\")\n            .runId(\"run_id\")\n            .build();\n        RunCancelResponse response = client.evals().runs().cancel(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst response = await client.evals.runs.cancel('run_id', { eval_id: 'eval_id' });\n\nconsole.log(response.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nresponse = client.evals.runs.cancel(\n    run_id=\"run_id\",\n    eval_id=\"eval_id\",\n)\nprint(response.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nresponse = openai.evals.runs.cancel(\"run_id\", eval_id: \"eval_id\")\n\nputs(response)"
          response: "{\n  \"object\": \"eval.run\",\n  \"id\": \"evalrun_67abd54d60ec8190832b46859da808f7\",\n  \"eval_id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n  \"report_url\": \"https://platform.openai.com/evaluations/eval_67abd54d9b0081909a86353f6fb9317a?run_id=evalrun_67abd54d60ec8190832b46859da808f7\",\n  \"status\": \"canceled\",\n  \"model\": \"gpt-4o-mini\",\n  \"name\": \"gpt-4o-mini\",\n  \"created_at\": 1743092069,\n  \"result_counts\": {\n    \"total\": 0,\n    \"errored\": 0,\n    \"failed\": 0,\n    \"passed\": 0\n  },\n  \"per_model_usage\": null,\n  \"per_testing_criteria_results\": null,\n  \"data_source\": {\n    \"type\": \"completions\",\n    \"source\": {\n      \"type\": \"file_content\",\n      \"content\": [\n        {\n          \"item\": {\n            \"input\": \"Tech Company Launches Advanced Artificial Intelligence Platform\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Central Bank Increases Interest Rates Amid Inflation Concerns\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"International Summit Addresses Climate Change Strategies\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Major Retailer Reports Record-Breaking Holiday Sales\",\n            \"ground_truth\": \"Business\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"National Team Qualifies for World Championship Finals\",\n            \"ground_truth\": \"Sports\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Stock Markets Rally After Positive Economic Data Released\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Global Manufacturer Announces Merger with Competitor\",\n            \"ground_truth\": \"Business\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Breakthrough in Renewable Energy Technology Unveiled\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"World Leaders Sign Historic Climate Agreement\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Professional Athlete Sets New Record in Championship Event\",\n            \"ground_truth\": \"Sports\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Financial Institutions Adapt to New Regulatory Requirements\",\n            \"ground_truth\": \"Business\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Tech Conference Showcases Advances in Artificial Intelligence\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Global Markets Respond to Oil Price Fluctuations\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"International Cooperation Strengthened Through New Treaty\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Sports League Announces Revised Schedule for Upcoming Season\",\n            \"ground_truth\": \"Sports\"\n          }\n        }\n      ]\n    },\n    \"input_messages\": {\n      \"type\": \"template\",\n      \"template\": [\n        {\n          \"type\": \"message\",\n          \"role\": \"developer\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\\n\\n# Steps\\n\\n1. Analyze the content of the news headline to understand its primary focus.\\n2. Extract the subject matter, identifying any key indicators or keywords.\\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\\n4. Ensure only one category is selected per headline.\\n\\n# Output Format\\n\\nRespond with the chosen category as a single word. For instance: \\\"Technology\\\", \\\"Markets\\\", \\\"World\\\", \\\"Business\\\", or \\\"Sports\\\".\\n\\n# Examples\\n\\n**Input**: \\\"Apple Unveils New iPhone Model, Featuring Advanced AI Features\\\"  \\n**Output**: \\\"Technology\\\"\\n\\n**Input**: \\\"Global Stocks Mixed as Investors Await Central Bank Decisions\\\"  \\n**Output**: \\\"Markets\\\"\\n\\n**Input**: \\\"War in Ukraine: Latest Updates on Negotiation Status\\\"  \\n**Output**: \\\"World\\\"\\n\\n**Input**: \\\"Microsoft in Talks to Acquire Gaming Company for $2 Billion\\\"  \\n**Output**: \\\"Business\\\"\\n\\n**Input**: \\\"Manchester United Secures Win in Premier League Football Match\\\"  \\n**Output**: \\\"Sports\\\" \\n\\n# Notes\\n\\n- If the headline appears to fit into more than one category, choose the most dominant theme.\\n- Keywords or phrases such as \\\"stocks\\\", \\\"company acquisition\\\", \\\"match\\\", or technological brands can be good indicators for classification.\\n\"\n          }\n        },\n        {\n          \"type\": \"message\",\n          \"role\": \"user\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"{{item.input}}\"\n          }\n        }\n      ]\n    },\n    \"model\": \"gpt-4o-mini\",\n    \"sampling_params\": {\n      \"seed\": 42,\n      \"temperature\": 1.0,\n      \"top_p\": 1.0,\n      \"max_completions_tokens\": 2048\n    }\n  },\n  \"error\": null,\n  \"metadata\": {}\n}\n"
        group: evals
        name: Cancel eval run
        path: post
        returns: 'The updated [EvalRun](https://platform.openai.com/docs/api-reference/evals/run-object) object reflecting that the run is canceled.'
  '/evals/{eval_id}/runs/{run_id}/output_items':
    get:
      tags:
        - Evals
      summary: Get eval run output items
      description: "Get a list of output items for an evaluation run.\n"
      operationId: getEvalRunOutputItems
      parameters:
        - name: eval_id
          in: path
          description: The ID of the evaluation to retrieve runs for.
          required: true
          schema:
            type: string
        - name: run_id
          in: path
          description: The ID of the run to retrieve output items for.
          required: true
          schema:
            type: string
        - name: after
          in: query
          description: Identifier for the last output item from the previous pagination request.
          schema:
            type: string
        - name: limit
          in: query
          description: Number of output items to retrieve.
          schema:
            type: integer
            default: 20
        - name: status
          in: query
          description: "Filter output items by status. Use `failed` to filter by failed output\nitems or `pass` to filter by passed output items.\n"
          schema:
            enum:
              - fail
              - pass
            type: string
        - name: order
          in: query
          description: Sort order for output items by timestamp. Use `asc` for ascending order or `desc` for descending order. Defaults to `asc`.
          schema:
            enum:
              - asc
              - desc
            type: string
            default: asc
      responses:
        '200':
          description: A list of output items for the evaluation run
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EvalRunOutputItemList'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/evals/egroup_67abd54d9b0081909a86353f6fb9317a/runs/erun_67abd54d60ec8190832b46859da808f7/output_items \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.evals.runs.outputitems.OutputItemListPage;\nimport com.openai.models.evals.runs.outputitems.OutputItemListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        OutputItemListParams params = OutputItemListParams.builder()\n            .evalId(\"eval_id\")\n            .runId(\"run_id\")\n            .build();\n        OutputItemListPage page = client.evals().runs().outputItems().list(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const outputItemListResponse of client.evals.runs.outputItems.list('run_id', {\n  eval_id: 'eval_id',\n})) {\n  console.log(outputItemListResponse.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.evals.runs.output_items.list(\n    run_id=\"run_id\",\n    eval_id=\"eval_id\",\n)\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.evals.runs.output_items.list(\"run_id\", eval_id: \"eval_id\")\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"eval.run.output_item\",\n      \"id\": \"outputitem_67e5796c28e081909917bf79f6e6214d\",\n      \"created_at\": 1743092076,\n      \"run_id\": \"evalrun_67abd54d60ec8190832b46859da808f7\",\n      \"eval_id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n      \"status\": \"pass\",\n      \"datasource_item_id\": 5,\n      \"datasource_item\": {\n        \"input\": \"Stock Markets Rally After Positive Economic Data Released\",\n        \"ground_truth\": \"Markets\"\n      },\n      \"results\": [\n        {\n          \"name\": \"String check-a2486074-d803-4445-b431-ad2262e85d47\",\n          \"sample\": null,\n          \"passed\": true,\n          \"score\": 1.0\n        }\n      ],\n      \"sample\": {\n        \"input\": [\n          {\n            \"role\": \"developer\",\n            \"content\": \"Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\\n\\n# Steps\\n\\n1. Analyze the content of the news headline to understand its primary focus.\\n2. Extract the subject matter, identifying any key indicators or keywords.\\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\\n4. Ensure only one category is selected per headline.\\n\\n# Output Format\\n\\nRespond with the chosen category as a single word. For instance: \\\"Technology\\\", \\\"Markets\\\", \\\"World\\\", \\\"Business\\\", or \\\"Sports\\\".\\n\\n# Examples\\n\\n**Input**: \\\"Apple Unveils New iPhone Model, Featuring Advanced AI Features\\\"  \\n**Output**: \\\"Technology\\\"\\n\\n**Input**: \\\"Global Stocks Mixed as Investors Await Central Bank Decisions\\\"  \\n**Output**: \\\"Markets\\\"\\n\\n**Input**: \\\"War in Ukraine: Latest Updates on Negotiation Status\\\"  \\n**Output**: \\\"World\\\"\\n\\n**Input**: \\\"Microsoft in Talks to Acquire Gaming Company for $2 Billion\\\"  \\n**Output**: \\\"Business\\\"\\n\\n**Input**: \\\"Manchester United Secures Win in Premier League Football Match\\\"  \\n**Output**: \\\"Sports\\\" \\n\\n# Notes\\n\\n- If the headline appears to fit into more than one category, choose the most dominant theme.\\n- Keywords or phrases such as \\\"stocks\\\", \\\"company acquisition\\\", \\\"match\\\", or technological brands can be good indicators for classification.\\n\",\n            \"tool_call_id\": null,\n            \"tool_calls\": null,\n            \"function_call\": null\n          },\n          {\n            \"role\": \"user\",\n            \"content\": \"Stock Markets Rally After Positive Economic Data Released\",\n            \"tool_call_id\": null,\n            \"tool_calls\": null,\n            \"function_call\": null\n          }\n        ],\n        \"output\": [\n          {\n            \"role\": \"assistant\",\n            \"content\": \"Markets\",\n            \"tool_call_id\": null,\n            \"tool_calls\": null,\n            \"function_call\": null\n          }\n        ],\n        \"finish_reason\": \"stop\",\n        \"model\": \"gpt-4o-mini-2024-07-18\",\n        \"usage\": {\n          \"total_tokens\": 325,\n          \"completion_tokens\": 2,\n          \"prompt_tokens\": 323,\n          \"cached_tokens\": 0\n        },\n        \"error\": null,\n        \"temperature\": 1.0,\n        \"max_completion_tokens\": 2048,\n        \"top_p\": 1.0,\n        \"seed\": 42\n      }\n    }\n  ],\n  \"first_id\": \"outputitem_67e5796c28e081909917bf79f6e6214d\",\n  \"last_id\": \"outputitem_67e5796c28e081909917bf79f6e6214d\",\n  \"has_more\": true\n}\n"
        group: evals
        name: Get eval run output items
        path: get
        returns: 'A list of [EvalRunOutputItem](https://platform.openai.com/docs/api-reference/evals/run-output-item-object) objects matching the specified ID.'
  '/evals/{eval_id}/runs/{run_id}/output_items/{output_item_id}':
    get:
      tags:
        - Evals
      summary: Get an output item of an eval run
      description: "Get an evaluation run output item by ID.\n"
      operationId: getEvalRunOutputItem
      parameters:
        - name: eval_id
          in: path
          description: The ID of the evaluation to retrieve runs for.
          required: true
          schema:
            type: string
        - name: run_id
          in: path
          description: The ID of the run to retrieve.
          required: true
          schema:
            type: string
        - name: output_item_id
          in: path
          description: The ID of the output item to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: The evaluation run output item
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EvalRunOutputItem'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7/output_items/outputitem_67abd55eb6548190bb580745d5644a33 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.evals.runs.outputitems.OutputItemRetrieveParams;\nimport com.openai.models.evals.runs.outputitems.OutputItemRetrieveResponse;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        OutputItemRetrieveParams params = OutputItemRetrieveParams.builder()\n            .evalId(\"eval_id\")\n            .runId(\"run_id\")\n            .outputItemId(\"output_item_id\")\n            .build();\n        OutputItemRetrieveResponse outputItem = client.evals().runs().outputItems().retrieve(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst outputItem = await client.evals.runs.outputItems.retrieve('output_item_id', {\n  eval_id: 'eval_id',\n  run_id: 'run_id',\n});\n\nconsole.log(outputItem.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\noutput_item = client.evals.runs.output_items.retrieve(\n    output_item_id=\"output_item_id\",\n    eval_id=\"eval_id\",\n    run_id=\"run_id\",\n)\nprint(output_item.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\noutput_item = openai.evals.runs.output_items.retrieve(\"output_item_id\", eval_id: \"eval_id\", run_id: \"run_id\")\n\nputs(output_item)"
          response: "{\n  \"object\": \"eval.run.output_item\",\n  \"id\": \"outputitem_67e5796c28e081909917bf79f6e6214d\",\n  \"created_at\": 1743092076,\n  \"run_id\": \"evalrun_67abd54d60ec8190832b46859da808f7\",\n  \"eval_id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n  \"status\": \"pass\",\n  \"datasource_item_id\": 5,\n  \"datasource_item\": {\n    \"input\": \"Stock Markets Rally After Positive Economic Data Released\",\n    \"ground_truth\": \"Markets\"\n  },\n  \"results\": [\n    {\n      \"name\": \"String check-a2486074-d803-4445-b431-ad2262e85d47\",\n      \"sample\": null,\n      \"passed\": true,\n      \"score\": 1.0\n    }\n  ],\n  \"sample\": {\n    \"input\": [\n      {\n        \"role\": \"developer\",\n        \"content\": \"Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\\n\\n# Steps\\n\\n1. Analyze the content of the news headline to understand its primary focus.\\n2. Extract the subject matter, identifying any key indicators or keywords.\\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\\n4. Ensure only one category is selected per headline.\\n\\n# Output Format\\n\\nRespond with the chosen category as a single word. For instance: \\\"Technology\\\", \\\"Markets\\\", \\\"World\\\", \\\"Business\\\", or \\\"Sports\\\".\\n\\n# Examples\\n\\n**Input**: \\\"Apple Unveils New iPhone Model, Featuring Advanced AI Features\\\"  \\n**Output**: \\\"Technology\\\"\\n\\n**Input**: \\\"Global Stocks Mixed as Investors Await Central Bank Decisions\\\"  \\n**Output**: \\\"Markets\\\"\\n\\n**Input**: \\\"War in Ukraine: Latest Updates on Negotiation Status\\\"  \\n**Output**: \\\"World\\\"\\n\\n**Input**: \\\"Microsoft in Talks to Acquire Gaming Company for $2 Billion\\\"  \\n**Output**: \\\"Business\\\"\\n\\n**Input**: \\\"Manchester United Secures Win in Premier League Football Match\\\"  \\n**Output**: \\\"Sports\\\" \\n\\n# Notes\\n\\n- If the headline appears to fit into more than one category, choose the most dominant theme.\\n- Keywords or phrases such as \\\"stocks\\\", \\\"company acquisition\\\", \\\"match\\\", or technological brands can be good indicators for classification.\\n\",\n        \"tool_call_id\": null,\n        \"tool_calls\": null,\n        \"function_call\": null\n      },\n      {\n        \"role\": \"user\",\n        \"content\": \"Stock Markets Rally After Positive Economic Data Released\",\n        \"tool_call_id\": null,\n        \"tool_calls\": null,\n        \"function_call\": null\n      }\n    ],\n    \"output\": [\n      {\n        \"role\": \"assistant\",\n        \"content\": \"Markets\",\n        \"tool_call_id\": null,\n        \"tool_calls\": null,\n        \"function_call\": null\n      }\n    ],\n    \"finish_reason\": \"stop\",\n    \"model\": \"gpt-4o-mini-2024-07-18\",\n    \"usage\": {\n      \"total_tokens\": 325,\n      \"completion_tokens\": 2,\n      \"prompt_tokens\": 323,\n      \"cached_tokens\": 0\n    },\n    \"error\": null,\n    \"temperature\": 1.0,\n    \"max_completion_tokens\": 2048,\n    \"top_p\": 1.0,\n    \"seed\": 42\n  }\n}\n"
        group: evals
        name: Get an output item of an eval run
        path: get
        returns: 'The [EvalRunOutputItem](https://platform.openai.com/docs/api-reference/evals/run-output-item-object) object matching the specified ID.'
  /files:
    get:
      tags:
        - Files
      summary: List files
      description: Returns a list of files.
      operationId: listFiles
      parameters:
        - name: purpose
          in: query
          description: Only return files with the given purpose.
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 10,000, and the default is 10,000.\n"
          schema:
            type: integer
            default: 10000
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFilesResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.Files.List(context.TODO(), openai.FileListParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.files.FileListPage;\nimport com.openai.models.files.FileListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FileListPage page = client.files().list();\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const fileObject of client.files.list()) {\n  console.log(fileObject);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.files.list()\npage = page.data[0]\nprint(page)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.files.list\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"file\",\n      \"bytes\": 175,\n      \"created_at\": 1613677385,\n      \"expires_at\": 1677614202,\n      \"filename\": \"salesOverview.pdf\",\n      \"purpose\": \"assistants\",\n    },\n    {\n      \"id\": \"file-abc456\",\n      \"object\": \"file\",\n      \"bytes\": 140,\n      \"created_at\": 1613779121,\n      \"expires_at\": 1677614202,\n      \"filename\": \"puppy.jsonl\",\n      \"purpose\": \"fine-tune\",\n    }\n  ],\n  \"first_id\": \"file-abc123\",\n  \"last_id\": \"file-abc456\",\n  \"has_more\": false\n}\n"
        group: files
        name: List files
        returns: 'A list of [File](https://platform.openai.com/docs/api-reference/files/object) objects.'
    post:
      tags:
        - Files
      summary: Upload file
      description: "Upload a file that can be used across various endpoints. Individual files can be up to 512 MB, and the size of all files uploaded by one organization can be up to 1 TB.\n\nThe Assistants API supports files up to 2 million tokens and of specific file types. See the [Assistants Tools guide](https://platform.openai.com/docs/assistants/tools) for details.\n\nThe Fine-tuning API only supports `.jsonl` files. The input also has certain required formats for fine-tuning [chat](https://platform.openai.com/docs/api-reference/fine-tuning/chat-input) or [completions](https://platform.openai.com/docs/api-reference/fine-tuning/completions-input) models.\n\nThe Batch API only supports `.jsonl` files up to 200 MB in size. The input also has a specific required [format](https://platform.openai.com/docs/api-reference/batch/request-input).\n\nPlease [contact us](https://help.openai.com/) if you need to increase these storage limits.\n"
      operationId: createFile
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateFileRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OpenAIFile'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -F purpose=\"fine-tune\" \\\n  -F file=\"@mydata.jsonl\"\n  -F expires_after[anchor]=\"created_at\"\n  -F expires_after[seconds]=3600\n"
            go: "package main\n\nimport (\n  \"bytes\"\n  \"context\"\n  \"fmt\"\n  \"io\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  fileObject, err := client.Files.New(context.TODO(), openai.FileNewParams{\n    File: io.Reader(bytes.NewBuffer([]byte(\"some file contents\"))),\n    Purpose: openai.FilePurposeAssistants,\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", fileObject.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.files.FileCreateParams;\nimport com.openai.models.files.FileObject;\nimport com.openai.models.files.FilePurpose;\nimport java.io.ByteArrayInputStream;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FileCreateParams params = FileCreateParams.builder()\n            .file(ByteArrayInputStream(\"some content\".getBytes()))\n            .purpose(FilePurpose.ASSISTANTS)\n            .build();\n        FileObject fileObject = client.files().create(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst fileObject = await client.files.create({\n  file: fs.createReadStream('fine-tune.jsonl'),\n  purpose: 'assistants',\n});\n\nconsole.log(fileObject.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nfile_object = client.files.create(\n    file=b\"raw file contents\",\n    purpose=\"assistants\",\n)\nprint(file_object.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nfile_object = openai.files.create(file: Pathname(__FILE__), purpose: :assistants)\n\nputs(file_object)"
          response: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"bytes\": 120000,\n  \"created_at\": 1677610602,\n  \"expires_at\": 1677614202,\n  \"filename\": \"mydata.jsonl\",\n  \"purpose\": \"fine-tune\",\n}\n"
        group: files
        name: Upload file
        returns: 'The uploaded [File](https://platform.openai.com/docs/api-reference/files/object) object.'
  '/files/{file_id}':
    delete:
      tags:
        - Files
      summary: Delete file
      description: Delete a file.
      operationId: deleteFile
      parameters:
        - name: file_id
          in: path
          description: The ID of the file to use for this request.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteFileResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/files/file-abc123 \\\n  -X DELETE \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  fileDeleted, err := client.Files.Delete(context.TODO(), \"file_id\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", fileDeleted.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.files.FileDeleteParams;\nimport com.openai.models.files.FileDeleted;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FileDeleted fileDeleted = client.files().delete(\"file_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst fileDeleted = await client.files.delete('file_id');\n\nconsole.log(fileDeleted.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nfile_deleted = client.files.delete(\n    \"file_id\",\n)\nprint(file_deleted.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nfile_deleted = openai.files.delete(\"file_id\")\n\nputs(file_deleted)"
          response: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"deleted\": true\n}\n"
        group: files
        name: Delete file
        returns: Deletion status.
    get:
      tags:
        - Files
      summary: Retrieve file
      description: Returns information about a specific file.
      operationId: retrieveFile
      parameters:
        - name: file_id
          in: path
          description: The ID of the file to use for this request.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OpenAIFile'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/files/file-abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  fileObject, err := client.Files.Get(context.TODO(), \"file_id\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", fileObject.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.files.FileObject;\nimport com.openai.models.files.FileRetrieveParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FileObject fileObject = client.files().retrieve(\"file_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst fileObject = await client.files.retrieve('file_id');\n\nconsole.log(fileObject.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nfile_object = client.files.retrieve(\n    \"file_id\",\n)\nprint(file_object.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nfile_object = openai.files.retrieve(\"file_id\")\n\nputs(file_object)"
          response: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"bytes\": 120000,\n  \"created_at\": 1677610602,\n  \"expires_at\": 1677614202,\n  \"filename\": \"mydata.jsonl\",\n  \"purpose\": \"fine-tune\",\n}\n"
        group: files
        name: Retrieve file
        returns: 'The [File](https://platform.openai.com/docs/api-reference/files/object) object matching the specified ID.'
  '/files/{file_id}/content':
    get:
      tags:
        - Files
      summary: Retrieve file content
      description: Returns the contents of the specified file.
      operationId: downloadFile
      parameters:
        - name: file_id
          in: path
          description: The ID of the file to use for this request.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/octet-stream:
              schema:
                type: string
                format: binary
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/files/file-abc123/content \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" > file.jsonl\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  response, err := client.Files.Content(context.TODO(), \"file_id\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", response)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.core.http.HttpResponse;\nimport com.openai.models.files.FileContentParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        HttpResponse response = client.files().content(\"file_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst response = await client.files.content('file_id');\n\nconsole.log(response);\n\nconst content = await response.blob();\nconsole.log(content);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nresponse = client.files.content(\n    \"file_id\",\n)\nprint(response)\ncontent = response.read()\nprint(content)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nresponse = openai.files.content(\"file_id\")\n\nputs(response)"
          response: ''
        group: files
        name: Retrieve file content
        returns: The file content.
  /fine_tuning/alpha/graders/run:
    post:
      tags:
        - Fine-tuning
      summary: Run grader
      description: "Run a grader.\n"
      operationId: runGrader
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/RunGraderRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunGraderResponse'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/fine_tuning/alpha/graders/run \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"grader\": {\n      \"type\": \"score_model\",\n      \"name\": \"Example score model grader\",\n      \"input\": [\n        {\n          \"role\": \"user\",\n          \"content\": \"Score how close the reference answer is to the model answer. Score 1.0 if they are the same and 0.0 if they are different. Return just a floating point score\\n\\nReference answer: {{item.reference_answer}}\\n\\nModel answer: {{sample.output_text}}\"\n        }\n      ],\n      \"model\": \"gpt-4o-2024-08-06\",\n      \"sampling_params\": {\n        \"temperature\": 1,\n        \"top_p\": 1,\n        \"seed\": 42\n      }\n    },\n    \"item\": {\n      \"reference_answer\": \"fuzzy wuzzy was a bear\"\n    },\n    \"model_sample\": \"fuzzy wuzzy was a bear\"\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  response, err := client.FineTuning.Alpha.Graders.Run(context.TODO(), openai.FineTuningAlphaGraderRunParams{\n    Grader: openai.FineTuningAlphaGraderRunParamsGraderUnion{\n      OfStringCheck: &openai.StringCheckGraderParam{\n        Input: \"input\",\n        Name: \"name\",\n        Operation: openai.StringCheckGraderOperationEq,\n        Reference: \"reference\",\n      },\n    },\n    ModelSample: \"model_sample\",\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", response.Metadata)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.finetuning.alpha.graders.GraderRunParams;\nimport com.openai.models.finetuning.alpha.graders.GraderRunResponse;\nimport com.openai.models.graders.gradermodels.StringCheckGrader;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        GraderRunParams params = GraderRunParams.builder()\n            .grader(StringCheckGrader.builder()\n                .input(\"input\")\n                .name(\"name\")\n                .operation(StringCheckGrader.Operation.EQ)\n                .reference(\"reference\")\n                .build())\n            .modelSample(\"model_sample\")\n            .build();\n        GraderRunResponse response = client.fineTuning().alpha().graders().run(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst response = await client.fineTuning.alpha.graders.run({\n  grader: { input: 'input', name: 'name', operation: 'eq', reference: 'reference', type: 'string_check' },\n  model_sample: 'model_sample',\n});\n\nconsole.log(response.metadata);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nresponse = client.fine_tuning.alpha.graders.run(\n    grader={\n        \"input\": \"input\",\n        \"name\": \"name\",\n        \"operation\": \"eq\",\n        \"reference\": \"reference\",\n        \"type\": \"string_check\",\n    },\n    model_sample=\"model_sample\",\n)\nprint(response.metadata)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nresponse = openai.fine_tuning.alpha.graders.run(\n  grader: {input: \"input\", name: \"name\", operation: :eq, reference: \"reference\", type: :string_check},\n  model_sample: \"model_sample\"\n)\n\nputs(response)"
          response: "{\n  \"reward\": 1.0,\n  \"metadata\": {\n    \"name\": \"Example score model grader\",\n    \"type\": \"score_model\",\n    \"errors\": {\n      \"formula_parse_error\": false,\n      \"sample_parse_error\": false,\n      \"truncated_observation_error\": false,\n      \"unresponsive_reward_error\": false,\n      \"invalid_variable_error\": false,\n      \"other_error\": false,\n      \"python_grader_server_error\": false,\n      \"python_grader_server_error_type\": null,\n      \"python_grader_runtime_error\": false,\n      \"python_grader_runtime_error_details\": null,\n      \"model_grader_server_error\": false,\n      \"model_grader_refusal_error\": false,\n      \"model_grader_parse_error\": false,\n      \"model_grader_server_error_details\": null\n    },\n    \"execution_time\": 4.365238428115845,\n    \"scores\": {},\n    \"token_usage\": {\n      \"prompt_tokens\": 190,\n      \"total_tokens\": 324,\n      \"completion_tokens\": 134,\n      \"cached_tokens\": 0\n    },\n    \"sampled_model_name\": \"gpt-4o-2024-08-06\"\n  },\n  \"sub_rewards\": {},\n  \"model_grader_token_usage_per_model\": {\n    \"gpt-4o-2024-08-06\": {\n      \"prompt_tokens\": 190,\n      \"total_tokens\": 324,\n      \"completion_tokens\": 134,\n      \"cached_tokens\": 0\n    }\n  }\n}\n"
        group: graders
        name: Run grader
        returns: The results from the grader run.
  /fine_tuning/alpha/graders/validate:
    post:
      tags:
        - Fine-tuning
      summary: Validate grader
      description: "Validate a grader.\n"
      operationId: validateGrader
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ValidateGraderRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ValidateGraderResponse'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/fine_tuning/alpha/graders/validate \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"grader\": {\n      \"type\": \"string_check\",\n      \"name\": \"Example string check grader\",\n      \"input\": \"{{sample.output_text}}\",\n      \"reference\": \"{{item.label}}\",\n      \"operation\": \"eq\"\n    }\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  response, err := client.FineTuning.Alpha.Graders.Validate(context.TODO(), openai.FineTuningAlphaGraderValidateParams{\n    Grader: openai.FineTuningAlphaGraderValidateParamsGraderUnion{\n      OfStringCheckGrader: &openai.StringCheckGraderParam{\n        Input: \"input\",\n        Name: \"name\",\n        Operation: openai.StringCheckGraderOperationEq,\n        Reference: \"reference\",\n      },\n    },\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", response.Grader)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.finetuning.alpha.graders.GraderValidateParams;\nimport com.openai.models.finetuning.alpha.graders.GraderValidateResponse;\nimport com.openai.models.graders.gradermodels.StringCheckGrader;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        GraderValidateParams params = GraderValidateParams.builder()\n            .grader(StringCheckGrader.builder()\n                .input(\"input\")\n                .name(\"name\")\n                .operation(StringCheckGrader.Operation.EQ)\n                .reference(\"reference\")\n                .build())\n            .build();\n        GraderValidateResponse response = client.fineTuning().alpha().graders().validate(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst response = await client.fineTuning.alpha.graders.validate({\n  grader: { input: 'input', name: 'name', operation: 'eq', reference: 'reference', type: 'string_check' },\n});\n\nconsole.log(response.grader);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nresponse = client.fine_tuning.alpha.graders.validate(\n    grader={\n        \"input\": \"input\",\n        \"name\": \"name\",\n        \"operation\": \"eq\",\n        \"reference\": \"reference\",\n        \"type\": \"string_check\",\n    },\n)\nprint(response.grader)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nresponse = openai.fine_tuning.alpha.graders.validate(\n  grader: {input: \"input\", name: \"name\", operation: :eq, reference: \"reference\", type: :string_check}\n)\n\nputs(response)"
          response: "{\n  \"grader\": {\n    \"type\": \"string_check\",\n    \"name\": \"Example string check grader\",\n    \"input\": \"{{sample.output_text}}\",\n    \"reference\": \"{{item.label}}\",\n    \"operation\": \"eq\"\n  }\n}\n"
        group: graders
        name: Validate grader
        returns: The validated grader object.
  '/fine_tuning/checkpoints/{fine_tuned_model_checkpoint}/permissions':
    get:
      tags:
        - Fine-tuning
      summary: List checkpoint permissions
      description: "**NOTE:** This endpoint requires an [admin API key](../admin-api-keys).\n\nOrganization owners can use this endpoint to view all permissions for a fine-tuned model checkpoint.\n"
      operationId: listFineTuningCheckpointPermissions
      parameters:
        - name: fine_tuned_model_checkpoint
          in: path
          description: "The ID of the fine-tuned model checkpoint to get permissions for.\n"
          required: true
          schema:
            type: string
            example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
        - name: project_id
          in: query
          description: The ID of the project to get permissions for.
          schema:
            type: string
        - name: after
          in: query
          description: Identifier for the last permission ID from the previous pagination request.
          schema:
            type: string
        - name: limit
          in: query
          description: Number of permissions to retrieve.
          schema:
            type: integer
            default: 10
        - name: order
          in: query
          description: The order in which to retrieve permissions.
          schema:
            enum:
              - ascending
              - descending
            type: string
            default: descending
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuningCheckpointPermissionResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd/permissions \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  permission, err := client.FineTuning.Checkpoints.Permissions.Get(\n    context.TODO(),\n    \"ft-AF1WoRqd3aJAHsqc9NY7iL8F\",\n    openai.FineTuningCheckpointPermissionGetParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", permission.FirstID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.finetuning.checkpoints.permissions.PermissionRetrieveParams;\nimport com.openai.models.finetuning.checkpoints.permissions.PermissionRetrieveResponse;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        PermissionRetrieveResponse permission = client.fineTuning().checkpoints().permissions().retrieve(\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst permission = await client.fineTuning.checkpoints.permissions.retrieve('ft-AF1WoRqd3aJAHsqc9NY7iL8F');\n\nconsole.log(permission.first_id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npermission = client.fine_tuning.checkpoints.permissions.retrieve(\n    fine_tuned_model_checkpoint=\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\",\n)\nprint(permission.first_id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npermission = openai.fine_tuning.checkpoints.permissions.retrieve(\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\")\n\nputs(permission)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"checkpoint.permission\",\n      \"id\": \"cp_zc4Q7MP6XxulcVzj4MZdwsAB\",\n      \"created_at\": 1721764867,\n      \"project_id\": \"proj_abGMw1llN8IrBb6SvvY5A1iH\"\n    },\n    {\n      \"object\": \"checkpoint.permission\",\n      \"id\": \"cp_enQCFmOTGj3syEpYVhBRLTSy\",\n      \"created_at\": 1721764800,\n      \"project_id\": \"proj_iqGMw1llN8IrBb6SvvY5A1oF\"\n    },\n  ],\n  \"first_id\": \"cp_zc4Q7MP6XxulcVzj4MZdwsAB\",\n  \"last_id\": \"cp_enQCFmOTGj3syEpYVhBRLTSy\",\n  \"has_more\": false\n}\n"
        group: fine-tuning
        name: List checkpoint permissions
        returns: 'A list of fine-tuned model checkpoint [permission objects](https://platform.openai.com/docs/api-reference/fine-tuning/permission-object) for a fine-tuned model checkpoint.'
    post:
      tags:
        - Fine-tuning
      summary: Create checkpoint permissions
      description: "**NOTE:** Calling this endpoint requires an [admin API key](../admin-api-keys).\n\nThis enables organization owners to share fine-tuned models with other projects in their organization.\n"
      operationId: createFineTuningCheckpointPermission
      parameters:
        - name: fine_tuned_model_checkpoint
          in: path
          description: "The ID of the fine-tuned model checkpoint to create a permission for.\n"
          required: true
          schema:
            type: string
            example: ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateFineTuningCheckpointPermissionRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuningCheckpointPermissionResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd/permissions \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n  -d '{\"project_ids\": [\"proj_abGMw1llN8IrBb6SvvY5A1iH\"]}'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.FineTuning.Checkpoints.Permissions.New(\n    context.TODO(),\n    \"ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd\",\n    openai.FineTuningCheckpointPermissionNewParams{\n      ProjectIDs: []string{\"string\"},\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.finetuning.checkpoints.permissions.PermissionCreatePage;\nimport com.openai.models.finetuning.checkpoints.permissions.PermissionCreateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        PermissionCreateParams params = PermissionCreateParams.builder()\n            .fineTunedModelCheckpoint(\"ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd\")\n            .addProjectId(\"string\")\n            .build();\n        PermissionCreatePage page = client.fineTuning().checkpoints().permissions().create(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const permissionCreateResponse of client.fineTuning.checkpoints.permissions.create(\n  'ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd',\n  { project_ids: ['string'] },\n)) {\n  console.log(permissionCreateResponse.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.fine_tuning.checkpoints.permissions.create(\n    fine_tuned_model_checkpoint=\"ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd\",\n    project_ids=[\"string\"],\n)\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.fine_tuning.checkpoints.permissions.create(\n  \"ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd\",\n  project_ids: [\"string\"]\n)\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"checkpoint.permission\",\n      \"id\": \"cp_zc4Q7MP6XxulcVzj4MZdwsAB\",\n      \"created_at\": 1721764867,\n      \"project_id\": \"proj_abGMw1llN8IrBb6SvvY5A1iH\"\n    }\n  ],\n  \"first_id\": \"cp_zc4Q7MP6XxulcVzj4MZdwsAB\",\n  \"last_id\": \"cp_zc4Q7MP6XxulcVzj4MZdwsAB\",\n  \"has_more\": false\n}\n"
        group: fine-tuning
        name: Create checkpoint permissions
        returns: 'A list of fine-tuned model checkpoint [permission objects](https://platform.openai.com/docs/api-reference/fine-tuning/permission-object) for a fine-tuned model checkpoint.'
  '/fine_tuning/checkpoints/{fine_tuned_model_checkpoint}/permissions/{permission_id}':
    delete:
      tags:
        - Fine-tuning
      summary: Delete checkpoint permission
      description: "**NOTE:** This endpoint requires an [admin API key](../admin-api-keys).\n\nOrganization owners can use this endpoint to delete a permission for a fine-tuned model checkpoint.\n"
      operationId: deleteFineTuningCheckpointPermission
      parameters:
        - name: fine_tuned_model_checkpoint
          in: path
          description: "The ID of the fine-tuned model checkpoint to delete a permission for.\n"
          required: true
          schema:
            type: string
            example: ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd
        - name: permission_id
          in: path
          description: "The ID of the fine-tuned model checkpoint permission to delete.\n"
          required: true
          schema:
            type: string
            example: cp_zc4Q7MP6XxulcVzj4MZdwsAB
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteFineTuningCheckpointPermissionResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd/permissions/cp_zc4Q7MP6XxulcVzj4MZdwsAB \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  permission, err := client.FineTuning.Checkpoints.Permissions.Delete(\n    context.TODO(),\n    \"ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd\",\n    \"cp_zc4Q7MP6XxulcVzj4MZdwsAB\",\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", permission.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.finetuning.checkpoints.permissions.PermissionDeleteParams;\nimport com.openai.models.finetuning.checkpoints.permissions.PermissionDeleteResponse;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        PermissionDeleteParams params = PermissionDeleteParams.builder()\n            .fineTunedModelCheckpoint(\"ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd\")\n            .permissionId(\"cp_zc4Q7MP6XxulcVzj4MZdwsAB\")\n            .build();\n        PermissionDeleteResponse permission = client.fineTuning().checkpoints().permissions().delete(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst permission = await client.fineTuning.checkpoints.permissions.delete('cp_zc4Q7MP6XxulcVzj4MZdwsAB', {\n  fine_tuned_model_checkpoint: 'ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd',\n});\n\nconsole.log(permission.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npermission = client.fine_tuning.checkpoints.permissions.delete(\n    permission_id=\"cp_zc4Q7MP6XxulcVzj4MZdwsAB\",\n    fine_tuned_model_checkpoint=\"ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd\",\n)\nprint(permission.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npermission = openai.fine_tuning.checkpoints.permissions.delete(\n  \"cp_zc4Q7MP6XxulcVzj4MZdwsAB\",\n  fine_tuned_model_checkpoint: \"ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd\"\n)\n\nputs(permission)"
          response: "{\n  \"object\": \"checkpoint.permission\",\n  \"id\": \"cp_zc4Q7MP6XxulcVzj4MZdwsAB\",\n  \"deleted\": true\n}\n"
        group: fine-tuning
        name: Delete checkpoint permission
        returns: 'The deletion status of the fine-tuned model checkpoint [permission object](https://platform.openai.com/docs/api-reference/fine-tuning/permission-object).'
  /fine_tuning/jobs:
    get:
      tags:
        - Fine-tuning
      summary: List fine-tuning jobs
      description: "List your organization's fine-tuning jobs\n"
      operationId: listPaginatedFineTuningJobs
      parameters:
        - name: after
          in: query
          description: Identifier for the last job from the previous pagination request.
          schema:
            type: string
        - name: limit
          in: query
          description: Number of fine-tuning jobs to retrieve.
          schema:
            type: integer
            default: 20
        - name: metadata
          in: query
          description: "Optional metadata filter. To filter, use the syntax `metadata[k]=v`. Alternatively, set `metadata=null` to indicate no metadata.\n"
          style: deepObject
          explode: true
          schema:
            type: object
            additionalProperties:
              type: string
            nullable: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListPaginatedFineTuningJobsResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/fine_tuning/jobs?limit=2&metadata[key]=value \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.FineTuning.Jobs.List(context.TODO(), openai.FineTuningJobListParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.finetuning.jobs.JobListPage;\nimport com.openai.models.finetuning.jobs.JobListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        JobListPage page = client.fineTuning().jobs().list();\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const fineTuningJob of client.fineTuning.jobs.list()) {\n  console.log(fineTuningJob.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.fine_tuning.jobs.list()\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.fine_tuning.jobs.list\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"fine_tuning.job\",\n      \"id\": \"ftjob-abc123\",\n      \"model\": \"gpt-4o-mini-2024-07-18\",\n      \"created_at\": 1721764800,\n      \"fine_tuned_model\": null,\n      \"organization_id\": \"org-123\",\n      \"result_files\": [],\n      \"status\": \"queued\",\n      \"validation_file\": null,\n      \"training_file\": \"file-abc123\",\n      \"metadata\": {\n        \"key\": \"value\"\n      }\n    },\n    { ... },\n    { ... }\n  ], \"has_more\": true\n}\n"
        group: fine-tuning
        name: List fine-tuning jobs
        returns: 'A list of paginated [fine-tuning job](https://platform.openai.com/docs/api-reference/fine-tuning/object) objects.'
    post:
      tags:
        - Fine-tuning
      summary: Create fine-tuning job
      description: "Creates a fine-tuning job which begins the process of creating a new model from a given dataset.\n\nResponse includes details of the enqueued job including job status and the name of the fine-tuned models once complete.\n\n[Learn more about fine-tuning](https://platform.openai.com/docs/guides/model-optimization)\n"
      operationId: createFineTuningJob
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateFineTuningJobRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
      x-oaiMeta:
        example:
          request:
            curl: "curl https://api.openai.com/v1/fine_tuning/jobs \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"training_file\": \"file-BK7bzQj3FfZFXr7DbL6xJwfo\",\n    \"model\": \"gpt-4o-mini\"\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  fineTuningJob, err := client.FineTuning.Jobs.New(context.TODO(), openai.FineTuningJobNewParams{\n    Model: openai.FineTuningJobNewParamsModelBabbage002,\n    TrainingFile: \"file-abc123\",\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", fineTuningJob.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.finetuning.jobs.FineTuningJob;\nimport com.openai.models.finetuning.jobs.JobCreateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        JobCreateParams params = JobCreateParams.builder()\n            .model(JobCreateParams.Model.BABBAGE_002)\n            .trainingFile(\"file-abc123\")\n            .build();\n        FineTuningJob fineTuningJob = client.fineTuning().jobs().create(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst fineTuningJob = await client.fineTuning.jobs.create({\n  model: 'gpt-4o-mini',\n  training_file: 'file-abc123',\n});\n\nconsole.log(fineTuningJob.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nfine_tuning_job = client.fine_tuning.jobs.create(\n    model=\"gpt-4o-mini\",\n    training_file=\"file-abc123\",\n)\nprint(fine_tuning_job.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nfine_tuning_job = openai.fine_tuning.jobs.create(model: :\"babbage-002\", training_file: \"file-abc123\")\n\nputs(fine_tuning_job)"
          response: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"gpt-4o-mini-2024-07-18\",\n  \"created_at\": 1721764800,\n  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n  \"result_files\": [],\n  \"status\": \"queued\",\n  \"validation_file\": null,\n  \"training_file\": \"file-abc123\",\n  \"method\": {\n    \"type\": \"supervised\",\n    \"supervised\": {\n      \"hyperparameters\": {\n        \"batch_size\": \"auto\",\n        \"learning_rate_multiplier\": \"auto\",\n        \"n_epochs\": \"auto\",\n      }\n    }\n  },\n  \"metadata\": null\n}\n"
          title: Default
        group: fine-tuning
        name: Create fine-tuning job
        returns: 'A [fine-tuning.job](https://platform.openai.com/docs/api-reference/fine-tuning/object) object.'
  '/fine_tuning/jobs/{fine_tuning_job_id}':
    get:
      tags:
        - Fine-tuning
      summary: Retrieve fine-tuning job
      description: "Get info about a fine-tuning job.\n\n[Learn more about fine-tuning](https://platform.openai.com/docs/guides/model-optimization)\n"
      operationId: retrieveFineTuningJob
      parameters:
        - name: fine_tuning_job_id
          in: path
          description: "The ID of the fine-tuning job.\n"
          required: true
          schema:
            type: string
            example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  fineTuningJob, err := client.FineTuning.Jobs.Get(context.TODO(), \"ft-AF1WoRqd3aJAHsqc9NY7iL8F\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", fineTuningJob.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.finetuning.jobs.FineTuningJob;\nimport com.openai.models.finetuning.jobs.JobRetrieveParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FineTuningJob fineTuningJob = client.fineTuning().jobs().retrieve(\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst fineTuningJob = await client.fineTuning.jobs.retrieve('ft-AF1WoRqd3aJAHsqc9NY7iL8F');\n\nconsole.log(fineTuningJob.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nfine_tuning_job = client.fine_tuning.jobs.retrieve(\n    \"ft-AF1WoRqd3aJAHsqc9NY7iL8F\",\n)\nprint(fine_tuning_job.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nfine_tuning_job = openai.fine_tuning.jobs.retrieve(\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\")\n\nputs(fine_tuning_job)"
          response: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"davinci-002\",\n  \"created_at\": 1692661014,\n  \"finished_at\": 1692661190,\n  \"fine_tuned_model\": \"ft:davinci-002:my-org:custom_suffix:7q8mpxmy\",\n  \"organization_id\": \"org-123\",\n  \"result_files\": [\n      \"file-abc123\"\n  ],\n  \"status\": \"succeeded\",\n  \"validation_file\": null,\n  \"training_file\": \"file-abc123\",\n  \"hyperparameters\": {\n      \"n_epochs\": 4,\n      \"batch_size\": 1,\n      \"learning_rate_multiplier\": 1.0\n  },\n  \"trained_tokens\": 5768,\n  \"integrations\": [],\n  \"seed\": 0,\n  \"estimated_finish\": 0,\n  \"method\": {\n    \"type\": \"supervised\",\n    \"supervised\": {\n      \"hyperparameters\": {\n        \"n_epochs\": 4,\n        \"batch_size\": 1,\n        \"learning_rate_multiplier\": 1.0\n      }\n    }\n  }\n}\n"
        group: fine-tuning
        name: Retrieve fine-tuning job
        returns: 'The [fine-tuning](https://platform.openai.com/docs/api-reference/fine-tuning/object) object with the given ID.'
  '/fine_tuning/jobs/{fine_tuning_job_id}/cancel':
    post:
      tags:
        - Fine-tuning
      summary: Cancel fine-tuning
      description: "Immediately cancel a fine-tune job.\n"
      operationId: cancelFineTuningJob
      parameters:
        - name: fine_tuning_job_id
          in: path
          description: "The ID of the fine-tuning job to cancel.\n"
          required: true
          schema:
            type: string
            example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  fineTuningJob, err := client.FineTuning.Jobs.Cancel(context.TODO(), \"ft-AF1WoRqd3aJAHsqc9NY7iL8F\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", fineTuningJob.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.finetuning.jobs.FineTuningJob;\nimport com.openai.models.finetuning.jobs.JobCancelParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FineTuningJob fineTuningJob = client.fineTuning().jobs().cancel(\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst fineTuningJob = await client.fineTuning.jobs.cancel('ft-AF1WoRqd3aJAHsqc9NY7iL8F');\n\nconsole.log(fineTuningJob.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nfine_tuning_job = client.fine_tuning.jobs.cancel(\n    \"ft-AF1WoRqd3aJAHsqc9NY7iL8F\",\n)\nprint(fine_tuning_job.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nfine_tuning_job = openai.fine_tuning.jobs.cancel(\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\")\n\nputs(fine_tuning_job)"
          response: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"gpt-4o-mini-2024-07-18\",\n  \"created_at\": 1721764800,\n  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n  \"result_files\": [],\n  \"status\": \"cancelled\",\n  \"validation_file\": \"file-abc123\",\n  \"training_file\": \"file-abc123\"\n}\n"
        group: fine-tuning
        name: Cancel fine-tuning
        returns: 'The cancelled [fine-tuning](https://platform.openai.com/docs/api-reference/fine-tuning/object) object.'
  '/fine_tuning/jobs/{fine_tuning_job_id}/checkpoints':
    get:
      tags:
        - Fine-tuning
      summary: List fine-tuning checkpoints
      description: "List checkpoints for a fine-tuning job.\n"
      operationId: listFineTuningJobCheckpoints
      parameters:
        - name: fine_tuning_job_id
          in: path
          description: "The ID of the fine-tuning job to get checkpoints for.\n"
          required: true
          schema:
            type: string
            example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
        - name: after
          in: query
          description: Identifier for the last checkpoint ID from the previous pagination request.
          schema:
            type: string
        - name: limit
          in: query
          description: Number of checkpoints to retrieve.
          schema:
            type: integer
            default: 10
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuningJobCheckpointsResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.FineTuning.Jobs.Checkpoints.List(\n    context.TODO(),\n    \"ft-AF1WoRqd3aJAHsqc9NY7iL8F\",\n    openai.FineTuningJobCheckpointListParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.finetuning.jobs.checkpoints.CheckpointListPage;\nimport com.openai.models.finetuning.jobs.checkpoints.CheckpointListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        CheckpointListPage page = client.fineTuning().jobs().checkpoints().list(\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const fineTuningJobCheckpoint of client.fineTuning.jobs.checkpoints.list(\n  'ft-AF1WoRqd3aJAHsqc9NY7iL8F',\n)) {\n  console.log(fineTuningJobCheckpoint.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.fine_tuning.jobs.checkpoints.list(\n    fine_tuning_job_id=\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\",\n)\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.fine_tuning.jobs.checkpoints.list(\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\")\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"fine_tuning.job.checkpoint\",\n      \"id\": \"ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB\",\n      \"created_at\": 1721764867,\n      \"fine_tuned_model_checkpoint\": \"ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:96olL566:ckpt-step-2000\",\n      \"metrics\": {\n        \"full_valid_loss\": 0.134,\n        \"full_valid_mean_token_accuracy\": 0.874\n      },\n      \"fine_tuning_job_id\": \"ftjob-abc123\",\n      \"step_number\": 2000\n    },\n    {\n      \"object\": \"fine_tuning.job.checkpoint\",\n      \"id\": \"ftckpt_enQCFmOTGj3syEpYVhBRLTSy\",\n      \"created_at\": 1721764800,\n      \"fine_tuned_model_checkpoint\": \"ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000\",\n      \"metrics\": {\n        \"full_valid_loss\": 0.167,\n        \"full_valid_mean_token_accuracy\": 0.781\n      },\n      \"fine_tuning_job_id\": \"ftjob-abc123\",\n      \"step_number\": 1000\n    }\n  ],\n  \"first_id\": \"ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB\",\n  \"last_id\": \"ftckpt_enQCFmOTGj3syEpYVhBRLTSy\",\n  \"has_more\": true\n}\n"
        group: fine-tuning
        name: List fine-tuning checkpoints
        returns: 'A list of fine-tuning [checkpoint objects](https://platform.openai.com/docs/api-reference/fine-tuning/checkpoint-object) for a fine-tuning job.'
  '/fine_tuning/jobs/{fine_tuning_job_id}/events':
    get:
      tags:
        - Fine-tuning
      summary: List fine-tuning events
      description: "Get status updates for a fine-tuning job.\n"
      operationId: listFineTuningEvents
      parameters:
        - name: fine_tuning_job_id
          in: path
          description: "The ID of the fine-tuning job to get events for.\n"
          required: true
          schema:
            type: string
            example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
        - name: after
          in: query
          description: Identifier for the last event from the previous pagination request.
          schema:
            type: string
        - name: limit
          in: query
          description: Number of events to retrieve.
          schema:
            type: integer
            default: 20
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuningJobEventsResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.FineTuning.Jobs.ListEvents(\n    context.TODO(),\n    \"ft-AF1WoRqd3aJAHsqc9NY7iL8F\",\n    openai.FineTuningJobListEventsParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.finetuning.jobs.JobListEventsPage;\nimport com.openai.models.finetuning.jobs.JobListEventsParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        JobListEventsPage page = client.fineTuning().jobs().listEvents(\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const fineTuningJobEvent of client.fineTuning.jobs.listEvents('ft-AF1WoRqd3aJAHsqc9NY7iL8F')) {\n  console.log(fineTuningJobEvent.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.fine_tuning.jobs.list_events(\n    fine_tuning_job_id=\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\",\n)\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.fine_tuning.jobs.list_events(\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\")\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"fine_tuning.job.event\",\n      \"id\": \"ft-event-ddTJfwuMVpfLXseO0Am0Gqjm\",\n      \"created_at\": 1721764800,\n      \"level\": \"info\",\n      \"message\": \"Fine tuning job successfully completed\",\n      \"data\": null,\n      \"type\": \"message\"\n    },\n    {\n      \"object\": \"fine_tuning.job.event\",\n      \"id\": \"ft-event-tyiGuB72evQncpH87xe505Sv\",\n      \"created_at\": 1721764800,\n      \"level\": \"info\",\n      \"message\": \"New fine-tuned model created: ft:gpt-4o-mini:openai::7p4lURel\",\n      \"data\": null,\n      \"type\": \"message\"\n    }\n  ],\n  \"has_more\": true\n}\n"
        group: fine-tuning
        name: List fine-tuning events
        returns: A list of fine-tuning event objects.
  '/fine_tuning/jobs/{fine_tuning_job_id}/pause':
    post:
      tags:
        - Fine-tuning
      summary: Pause fine-tuning
      description: "Pause a fine-tune job.\n"
      operationId: pauseFineTuningJob
      parameters:
        - name: fine_tuning_job_id
          in: path
          description: "The ID of the fine-tuning job to pause.\n"
          required: true
          schema:
            type: string
            example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/pause \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  fineTuningJob, err := client.FineTuning.Jobs.Pause(context.TODO(), \"ft-AF1WoRqd3aJAHsqc9NY7iL8F\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", fineTuningJob.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.finetuning.jobs.FineTuningJob;\nimport com.openai.models.finetuning.jobs.JobPauseParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FineTuningJob fineTuningJob = client.fineTuning().jobs().pause(\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst fineTuningJob = await client.fineTuning.jobs.pause('ft-AF1WoRqd3aJAHsqc9NY7iL8F');\n\nconsole.log(fineTuningJob.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nfine_tuning_job = client.fine_tuning.jobs.pause(\n    \"ft-AF1WoRqd3aJAHsqc9NY7iL8F\",\n)\nprint(fine_tuning_job.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nfine_tuning_job = openai.fine_tuning.jobs.pause(\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\")\n\nputs(fine_tuning_job)"
          response: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"gpt-4o-mini-2024-07-18\",\n  \"created_at\": 1721764800,\n  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n  \"result_files\": [],\n  \"status\": \"paused\",\n  \"validation_file\": \"file-abc123\",\n  \"training_file\": \"file-abc123\"\n}\n"
        group: fine-tuning
        name: Pause fine-tuning
        returns: 'The paused [fine-tuning](https://platform.openai.com/docs/api-reference/fine-tuning/object) object.'
  '/fine_tuning/jobs/{fine_tuning_job_id}/resume':
    post:
      tags:
        - Fine-tuning
      summary: Resume fine-tuning
      description: "Resume a fine-tune job.\n"
      operationId: resumeFineTuningJob
      parameters:
        - name: fine_tuning_job_id
          in: path
          description: "The ID of the fine-tuning job to resume.\n"
          required: true
          schema:
            type: string
            example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/resume \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  fineTuningJob, err := client.FineTuning.Jobs.Resume(context.TODO(), \"ft-AF1WoRqd3aJAHsqc9NY7iL8F\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", fineTuningJob.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.finetuning.jobs.FineTuningJob;\nimport com.openai.models.finetuning.jobs.JobResumeParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FineTuningJob fineTuningJob = client.fineTuning().jobs().resume(\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst fineTuningJob = await client.fineTuning.jobs.resume('ft-AF1WoRqd3aJAHsqc9NY7iL8F');\n\nconsole.log(fineTuningJob.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nfine_tuning_job = client.fine_tuning.jobs.resume(\n    \"ft-AF1WoRqd3aJAHsqc9NY7iL8F\",\n)\nprint(fine_tuning_job.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nfine_tuning_job = openai.fine_tuning.jobs.resume(\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\")\n\nputs(fine_tuning_job)"
          response: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"gpt-4o-mini-2024-07-18\",\n  \"created_at\": 1721764800,\n  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n  \"result_files\": [],\n  \"status\": \"queued\",\n  \"validation_file\": \"file-abc123\",\n  \"training_file\": \"file-abc123\"\n}\n"
        group: fine-tuning
        name: Resume fine-tuning
        returns: 'The resumed [fine-tuning](https://platform.openai.com/docs/api-reference/fine-tuning/object) object.'
  /images/edits:
    post:
      tags:
        - Images
      summary: Create image edit
      description: Creates an edited or extended image given one or more source images and a prompt. This endpoint only supports `gpt-image-1` and `dall-e-2`.
      operationId: createImageEdit
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateImageEditRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
            text/event-stream:
              schema:
                $ref: '#/components/schemas/ImageEditStreamEvent'
      x-oaiMeta:
        example:
          request:
            curl: "curl -s -D >(grep -i x-request-id >&2) \\\n  -o >(jq -r '.data[0].b64_json' | base64 --decode > gift-basket.png) \\\n  -X POST \"https://api.openai.com/v1/images/edits\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -F \"model=gpt-image-1\" \\\n  -F \"image[]=@body-lotion.png\" \\\n  -F \"image[]=@bath-bomb.png\" \\\n  -F \"image[]=@incense-kit.png\" \\\n  -F \"image[]=@soap.png\" \\\n  -F 'prompt=Create a lovely gift basket with these four items in it'\n"
            go: "package main\n\nimport (\n  \"bytes\"\n  \"context\"\n  \"fmt\"\n  \"io\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  imagesResponse, err := client.Images.Edit(context.TODO(), openai.ImageEditParams{\n    Image: openai.ImageEditParamsImageUnion{\n      OfFile: io.Reader(bytes.NewBuffer([]byte(\"some file contents\"))),\n    },\n    Prompt: \"A cute baby sea otter wearing a beret\",\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", imagesResponse)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.images.ImageEditParams;\nimport com.openai.models.images.ImagesResponse;\nimport java.io.ByteArrayInputStream;\nimport java.io.InputStream;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ImageEditParams params = ImageEditParams.builder()\n            .image(ByteArrayInputStream(\"some content\".getBytes()))\n            .prompt(\"A cute baby sea otter wearing a beret\")\n            .build();\n        ImagesResponse imagesResponse = client.images().edit(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst imagesResponse = await client.images.edit({\n  image: fs.createReadStream('path/to/file'),\n  prompt: 'A cute baby sea otter wearing a beret',\n});\n\nconsole.log(imagesResponse);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nimages_response = client.images.edit(\n    image=b\"raw file contents\",\n    prompt=\"A cute baby sea otter wearing a beret\",\n)\nprint(images_response)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nimages_response = openai.images.edit(image: Pathname(__FILE__), prompt: \"A cute baby sea otter wearing a beret\")\n\nputs(images_response)"
          title: Edit image
        group: images
        name: Create image edit
        returns: 'Returns an [image](https://platform.openai.com/docs/api-reference/images/object) object.'
  /images/generations:
    post:
      tags:
        - Images
      summary: Create image
      description: "Creates an image given a prompt. [Learn more](https://platform.openai.com/docs/guides/images).\n"
      operationId: createImage
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateImageRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
            text/event-stream:
              schema:
                $ref: '#/components/schemas/ImageGenStreamEvent'
      x-oaiMeta:
        example:
          request:
            curl: "curl https://api.openai.com/v1/images/generations \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-image-1\",\n    \"prompt\": \"A cute baby sea otter\",\n    \"n\": 1,\n    \"size\": \"1024x1024\"\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  imagesResponse, err := client.Images.Generate(context.TODO(), openai.ImageGenerateParams{\n    Prompt: \"A cute baby sea otter\",\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", imagesResponse)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.images.ImageGenerateParams;\nimport com.openai.models.images.ImagesResponse;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ImageGenerateParams params = ImageGenerateParams.builder()\n            .prompt(\"A cute baby sea otter\")\n            .build();\n        ImagesResponse imagesResponse = client.images().generate(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst imagesResponse = await client.images.generate({ prompt: 'A cute baby sea otter' });\n\nconsole.log(imagesResponse);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nimages_response = client.images.generate(\n    prompt=\"A cute baby sea otter\",\n)\nprint(images_response)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nimages_response = openai.images.generate(prompt: \"A cute baby sea otter\")\n\nputs(images_response)"
          response: "{\n  \"created\": 1713833628,\n  \"data\": [\n    {\n      \"b64_json\": \"...\"\n    }\n  ],\n  \"usage\": {\n    \"total_tokens\": 100,\n    \"input_tokens\": 50,\n    \"output_tokens\": 50,\n    \"input_tokens_details\": {\n      \"text_tokens\": 10,\n      \"image_tokens\": 40\n    }\n  }\n}\n"
          title: Generate image
        group: images
        name: Create image
        returns: 'Returns an [image](https://platform.openai.com/docs/api-reference/images/object) object.'
  /images/variations:
    post:
      tags:
        - Images
      summary: Create image variation
      description: Creates a variation of a given image. This endpoint only supports `dall-e-2`.
      operationId: createImageVariation
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateImageVariationRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
      x-oaiMeta:
        examples:
          request:
            csharp: "using System;\n\nusing OpenAI.Images;\n\nImageClient client = new(\n    model: \"dall-e-2\",\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nGeneratedImage image = client.GenerateImageVariation(imageFilePath: \"otter.png\");\n\nConsole.WriteLine(image.ImageUri);\n"
            curl: "curl https://api.openai.com/v1/images/variations \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -F image=\"@otter.png\" \\\n  -F n=2 \\\n  -F size=\"1024x1024\"\n"
            go: "package main\n\nimport (\n  \"bytes\"\n  \"context\"\n  \"fmt\"\n  \"io\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  imagesResponse, err := client.Images.NewVariation(context.TODO(), openai.ImageNewVariationParams{\n    Image: io.Reader(bytes.NewBuffer([]byte(\"some file contents\"))),\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", imagesResponse.Created)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.images.ImageCreateVariationParams;\nimport com.openai.models.images.ImagesResponse;\nimport java.io.ByteArrayInputStream;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ImageCreateVariationParams params = ImageCreateVariationParams.builder()\n            .image(ByteArrayInputStream(\"some content\".getBytes()))\n            .build();\n        ImagesResponse imagesResponse = client.images().createVariation(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst imagesResponse = await client.images.createVariation({ image: fs.createReadStream('otter.png') });\n\nconsole.log(imagesResponse.created);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nimages_response = client.images.create_variation(\n    image=b\"raw file contents\",\n)\nprint(images_response.created)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nimages_response = openai.images.create_variation(image: Pathname(__FILE__))\n\nputs(images_response)"
          response: "{\n  \"created\": 1589478378,\n  \"data\": [\n    {\n      \"url\": \"https://...\"\n    },\n    {\n      \"url\": \"https://...\"\n    }\n  ]\n}\n"
        group: images
        name: Create image variation
        returns: 'Returns a list of [image](https://platform.openai.com/docs/api-reference/images/object) objects.'
  /models:
    get:
      tags:
        - Models
      summary: List models
      description: 'Lists the currently available models, and provides basic information about each one such as the owner and availability.'
      operationId: listModels
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListModelsResponse'
      x-oaiMeta:
        examples:
          request:
            csharp: "using System;\n\nusing OpenAI.Models;\n\nOpenAIModelClient client = new(\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nforeach (var model in client.GetModels().Value)\n{\n    Console.WriteLine(model.Id);\n}\n"
            curl: "curl https://api.openai.com/v1/models \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.Models.List(context.TODO())\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.models.ModelListPage;\nimport com.openai.models.models.ModelListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ModelListPage page = client.models().list();\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const model of client.models.list()) {\n  console.log(model.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.models.list()\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.models.list\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"model-id-0\",\n      \"object\": \"model\",\n      \"created\": 1686935002,\n      \"owned_by\": \"organization-owner\"\n    },\n    {\n      \"id\": \"model-id-1\",\n      \"object\": \"model\",\n      \"created\": 1686935002,\n      \"owned_by\": \"organization-owner\",\n    },\n    {\n      \"id\": \"model-id-2\",\n      \"object\": \"model\",\n      \"created\": 1686935002,\n      \"owned_by\": \"openai\"\n    },\n  ],\n  \"object\": \"list\"\n}\n"
        group: models
        name: List models
        returns: 'A list of [model](https://platform.openai.com/docs/api-reference/models/object) objects.'
  '/models/{model}':
    delete:
      tags:
        - Models
      summary: Delete a fine-tuned model
      description: Delete a fine-tuned model. You must have the Owner role in your organization to delete a model.
      operationId: deleteModel
      parameters:
        - name: model
          in: path
          description: The model to delete
          required: true
          schema:
            type: string
            example: ft:gpt-4o-mini:acemeco:suffix:abc123
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteModelResponse'
      x-oaiMeta:
        examples:
          request:
            csharp: "using System;\nusing System.ClientModel;\n\nusing OpenAI.Models;\n\nOpenAIModelClient client = new(\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nClientResult success = client.DeleteModel(\"ft:gpt-4o-mini:acemeco:suffix:abc123\");\nConsole.WriteLine(success);\n"
            curl: "curl https://api.openai.com/v1/models/ft:gpt-4o-mini:acemeco:suffix:abc123 \\\n  -X DELETE \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  modelDeleted, err := client.Models.Delete(context.TODO(), \"ft:gpt-4o-mini:acemeco:suffix:abc123\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", modelDeleted.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.models.ModelDeleteParams;\nimport com.openai.models.models.ModelDeleted;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ModelDeleted modelDeleted = client.models().delete(\"ft:gpt-4o-mini:acemeco:suffix:abc123\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst modelDeleted = await client.models.delete('ft:gpt-4o-mini:acemeco:suffix:abc123');\n\nconsole.log(modelDeleted.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nmodel_deleted = client.models.delete(\n    \"ft:gpt-4o-mini:acemeco:suffix:abc123\",\n)\nprint(model_deleted.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nmodel_deleted = openai.models.delete(\"ft:gpt-4o-mini:acemeco:suffix:abc123\")\n\nputs(model_deleted)"
          response: "{\n  \"id\": \"ft:gpt-4o-mini:acemeco:suffix:abc123\",\n  \"object\": \"model\",\n  \"deleted\": true\n}\n"
        group: models
        name: Delete a fine-tuned model
        returns: Deletion status.
    get:
      tags:
        - Models
      summary: Retrieve model
      description: 'Retrieves a model instance, providing basic information about the model such as the owner and permissioning.'
      operationId: retrieveModel
      parameters:
        - name: model
          in: path
          description: The ID of the model to use for this request
          required: true
          schema:
            type: string
            example: gpt-4o-mini
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Model'
      x-oaiMeta:
        examples:
          request:
            csharp: "using System;\nusing System.ClientModel;\n\nusing OpenAI.Models;\n\n  OpenAIModelClient client = new(\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nClientResult<OpenAIModel> model = client.GetModel(\"babbage-002\");\nConsole.WriteLine(model.Value.Id);\n"
            curl: "curl https://api.openai.com/v1/models/VAR_chat_model_id \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  model, err := client.Models.Get(context.TODO(), \"gpt-4o-mini\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", model.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.models.Model;\nimport com.openai.models.models.ModelRetrieveParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        Model model = client.models().retrieve(\"gpt-4o-mini\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst model = await client.models.retrieve('gpt-4o-mini');\n\nconsole.log(model.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nmodel = client.models.retrieve(\n    \"gpt-4o-mini\",\n)\nprint(model.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nmodel = openai.models.retrieve(\"gpt-4o-mini\")\n\nputs(model)"
          response: "{\n  \"id\": \"VAR_chat_model_id\",\n  \"object\": \"model\",\n  \"created\": 1686935002,\n  \"owned_by\": \"openai\"\n}\n"
        group: models
        name: Retrieve model
        returns: 'The [model](https://platform.openai.com/docs/api-reference/models/object) object matching the specified ID.'
  /moderations:
    post:
      tags:
        - Moderations
      summary: Create moderation
      description: "Classifies if text and/or image inputs are potentially harmful. Learn\nmore in the [moderation guide](https://platform.openai.com/docs/guides/moderation).\n"
      operationId: createModeration
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateModerationRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateModerationResponse'
      x-oaiMeta:
        example:
          request:
            csharp: "using System;\nusing System.ClientModel;\n\nusing OpenAI.Moderations;\n\nModerationClient client = new(\n    model: \"omni-moderation-latest\",\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nClientResult<ModerationResult> moderation = client.ClassifyText(\"I want to kill them.\");\n"
            curl: "curl https://api.openai.com/v1/moderations \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"input\": \"I want to kill them.\"\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  moderation, err := client.Moderations.New(context.TODO(), openai.ModerationNewParams{\n    Input: openai.ModerationNewParamsInputUnion{\n      OfString: openai.String(\"I want to kill them.\"),\n    },\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", moderation.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.moderations.ModerationCreateParams;\nimport com.openai.models.moderations.ModerationCreateResponse;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ModerationCreateParams params = ModerationCreateParams.builder()\n            .input(\"I want to kill them.\")\n            .build();\n        ModerationCreateResponse moderation = client.moderations().create(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst moderation = await client.moderations.create({ input: 'I want to kill them.' });\n\nconsole.log(moderation.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nmoderation = client.moderations.create(\n    input=\"I want to kill them.\",\n)\nprint(moderation.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nmoderation = openai.moderations.create(input: \"I want to kill them.\")\n\nputs(moderation)"
          response: "{\n  \"id\": \"modr-AB8CjOTu2jiq12hp1AQPfeqFWaORR\",\n  \"model\": \"text-moderation-007\",\n  \"results\": [\n    {\n      \"flagged\": true,\n      \"categories\": {\n        \"sexual\": false,\n        \"hate\": false,\n        \"harassment\": true,\n        \"self-harm\": false,\n        \"sexual/minors\": false,\n        \"hate/threatening\": false,\n        \"violence/graphic\": false,\n        \"self-harm/intent\": false,\n        \"self-harm/instructions\": false,\n        \"harassment/threatening\": true,\n        \"violence\": true\n      },\n      \"category_scores\": {\n        \"sexual\": 0.000011726012417057063,\n        \"hate\": 0.22706663608551025,\n        \"harassment\": 0.5215635299682617,\n        \"self-harm\": 2.227119921371923e-6,\n        \"sexual/minors\": 7.107352217872176e-8,\n        \"hate/threatening\": 0.023547329008579254,\n        \"violence/graphic\": 0.00003391829886822961,\n        \"self-harm/intent\": 1.646940972932498e-6,\n        \"self-harm/instructions\": 1.1198755256458526e-9,\n        \"harassment/threatening\": 0.5694745779037476,\n        \"violence\": 0.9971134662628174\n      }\n    }\n  ]\n}\n"
          title: Single string
        group: moderations
        name: Create moderation
        returns: 'A [moderation](https://platform.openai.com/docs/api-reference/moderations/object) object.'
  /organization/admin_api_keys:
    get:
      summary: List all organization and project API keys.
      description: List organization API keys
      operationId: admin-api-keys-list
      parameters:
        - name: after
          in: query
          schema:
            type: string
            description: Return keys with IDs that come after this ID in the pagination order.
            nullable: true
        - name: order
          in: query
          schema:
            enum:
              - asc
              - desc
            type: string
            description: 'Order results by creation time, ascending or descending.'
            default: asc
        - name: limit
          in: query
          schema:
            type: integer
            description: Maximum number of keys to return.
            default: 20
      responses:
        '200':
          description: A list of organization API keys.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ApiKeyList'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/admin_api_keys?after=key_abc&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"organization.admin_api_key\",\n      \"id\": \"key_abc\",\n      \"name\": \"Main Admin Key\",\n      \"redacted_value\": \"sk-admin...def\",\n      \"created_at\": 1711471533,\n      \"last_used_at\": 1711471534,\n      \"owner\": {\n        \"type\": \"service_account\",\n        \"object\": \"organization.service_account\",\n        \"id\": \"sa_456\",\n        \"name\": \"My Service Account\",\n        \"created_at\": 1711471533,\n        \"role\": \"member\"\n      }\n    }\n  ],\n  \"first_id\": \"key_abc\",\n  \"last_id\": \"key_abc\",\n  \"has_more\": false\n}\n"
        group: administration
        name: List all organization and project API keys.
        returns: A list of admin and project API key objects.
    post:
      summary: Create admin API key
      description: Create an organization admin API key
      operationId: admin-api-keys-create
      requestBody:
        content:
          application/json:
            schema:
              required:
                - name
              type: object
              properties:
                name:
                  type: string
                  example: New Admin Key
        required: true
      responses:
        '200':
          description: The newly created admin API key.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AdminApiKey'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/admin_api_keys \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"name\": \"New Admin Key\"\n  }'\n"
          response: "{\n  \"object\": \"organization.admin_api_key\",\n  \"id\": \"key_xyz\",\n  \"name\": \"New Admin Key\",\n  \"redacted_value\": \"sk-admin...xyz\",\n  \"created_at\": 1711471533,\n  \"last_used_at\": 1711471534,\n  \"owner\": {\n    \"type\": \"user\",\n    \"object\": \"organization.user\",\n    \"id\": \"user_123\",\n    \"name\": \"John Doe\",\n    \"created_at\": 1711471533,\n    \"role\": \"owner\"\n  },\n  \"value\": \"sk-admin-1234abcd\"\n}\n"
        group: administration
        name: Create admin API key
        returns: 'The created [AdminApiKey](https://platform.openai.com/docs/api-reference/admin-api-keys/object) object.'
  '/organization/admin_api_keys/{key_id}':
    delete:
      summary: Delete admin API key
      description: Delete an organization admin API key
      operationId: admin-api-keys-delete
      parameters:
        - name: key_id
          in: path
          required: true
          schema:
            type: string
            description: The ID of the API key to be deleted.
      responses:
        '200':
          description: Confirmation that the API key was deleted.
          content:
            application/json:
              schema:
                type: object
                properties:
                  deleted:
                    type: boolean
                    example: true
                  id:
                    type: string
                    example: key_abc
                  object:
                    type: string
                    example: organization.admin_api_key.deleted
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/organization/admin_api_keys/key_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n  \"id\": \"key_abc\",\n  \"object\": \"organization.admin_api_key.deleted\",\n  \"deleted\": true\n}\n"
        group: administration
        name: Delete admin API key
        returns: A confirmation object indicating the key was deleted.
    get:
      summary: Retrieve admin API key
      description: Retrieve a single organization API key
      operationId: admin-api-keys-get
      parameters:
        - name: key_id
          in: path
          required: true
          schema:
            type: string
            description: The ID of the API key.
      responses:
        '200':
          description: Details of the requested API key.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AdminApiKey'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/admin_api_keys/key_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n  \"object\": \"organization.admin_api_key\",\n  \"id\": \"key_abc\",\n  \"name\": \"Main Admin Key\",\n  \"redacted_value\": \"sk-admin...xyz\",\n  \"created_at\": 1711471533,\n  \"last_used_at\": 1711471534,\n  \"owner\": {\n    \"type\": \"user\",\n    \"object\": \"organization.user\",\n    \"id\": \"user_123\",\n    \"name\": \"John Doe\",\n    \"created_at\": 1711471533,\n    \"role\": \"owner\"\n  }\n}\n"
        group: administration
        name: Retrieve admin API key
        returns: 'The requested [AdminApiKey](https://platform.openai.com/docs/api-reference/admin-api-keys/object) object.'
  /organization/audit_logs:
    get:
      tags:
        - Audit Logs
      summary: List audit logs
      description: List user actions and configuration changes within this organization.
      operationId: list-audit-logs
      parameters:
        - name: effective_at
          in: query
          description: Return only events whose `effective_at` (Unix seconds) is in this range.
          schema:
            type: object
            properties:
              gt:
                type: integer
                description: Return only events whose `effective_at` (Unix seconds) is greater than this value.
              gte:
                type: integer
                description: Return only events whose `effective_at` (Unix seconds) is greater than or equal to this value.
              lt:
                type: integer
                description: Return only events whose `effective_at` (Unix seconds) is less than this value.
              lte:
                type: integer
                description: Return only events whose `effective_at` (Unix seconds) is less than or equal to this value.
        - name: 'project_ids[]'
          in: query
          description: Return only events for these projects.
          schema:
            type: array
            items:
              type: string
        - name: 'event_types[]'
          in: query
          description: 'Return only events with a `type` in one of these values. For example, `project.created`. For all options, see the documentation for the [audit log object](https://platform.openai.com/docs/api-reference/audit-logs/object).'
          schema:
            type: array
            items:
              $ref: '#/components/schemas/AuditLogEventType'
        - name: 'actor_ids[]'
          in: query
          description: 'Return only events performed by these actors. Can be a user ID, a service account ID, or an api key tracking ID.'
          schema:
            type: array
            items:
              type: string
        - name: 'actor_emails[]'
          in: query
          description: Return only events performed by users with these emails.
          schema:
            type: array
            items:
              type: string
        - name: 'resource_ids[]'
          in: query
          description: 'Return only events performed on these targets. For example, a project ID updated.'
          schema:
            type: array
            items:
              type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: before
          in: query
          description: "A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: Audit logs listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListAuditLogsResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/audit_logs \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"id\": \"audit_log-xxx_yyyymmdd\",\n            \"type\": \"project.archived\",\n            \"effective_at\": 1722461446,\n            \"actor\": {\n                \"type\": \"api_key\",\n                \"api_key\": {\n                    \"type\": \"user\",\n                    \"user\": {\n                        \"id\": \"user-xxx\",\n                        \"email\": \"user@example.com\"\n                    }\n                }\n            },\n            \"project.archived\": {\n                \"id\": \"proj_abc\"\n            },\n        },\n        {\n            \"id\": \"audit_log-yyy__20240101\",\n            \"type\": \"api_key.updated\",\n            \"effective_at\": 1720804190,\n            \"actor\": {\n                \"type\": \"session\",\n                \"session\": {\n                    \"user\": {\n                        \"id\": \"user-xxx\",\n                        \"email\": \"user@example.com\"\n                    },\n                    \"ip_address\": \"127.0.0.1\",\n                    \"user_agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n                    \"ja3\": \"a497151ce4338a12c4418c44d375173e\",\n                    \"ja4\": \"q13d0313h3_55b375c5d22e_c7319ce65786\",\n                    \"ip_address_details\": {\n                      \"country\": \"US\",\n                      \"city\": \"San Francisco\",\n                      \"region\": \"California\",\n                      \"region_code\": \"CA\",\n                      \"asn\": \"1234\",\n                      \"latitude\": \"37.77490\",\n                      \"longitude\": \"-122.41940\"\n                    }\n                }\n            },\n            \"api_key.updated\": {\n                \"id\": \"key_xxxx\",\n                \"data\": {\n                    \"scopes\": [\"resource_2.operation_2\"]\n                }\n            },\n        }\n    ],\n    \"first_id\": \"audit_log-xxx__20240101\",\n    \"last_id\": \"audit_log_yyy__20240101\",\n    \"has_more\": true\n}\n"
        group: audit-logs
        name: List audit logs
        returns: 'A list of paginated [Audit Log](https://platform.openai.com/docs/api-reference/audit-logs/object) objects.'
  /organization/certificates:
    get:
      tags:
        - Certificates
      summary: List organization certificates
      description: List uploaded certificates for this organization.
      operationId: listOrganizationCertificates
      parameters:
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
      responses:
        '200':
          description: Certificates listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListCertificatesResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/certificates \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\"\n"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"organization.certificate\",\n      \"id\": \"cert_abc\",\n      \"name\": \"My Example Certificate\",\n      \"active\": true,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n  ],\n  \"first_id\": \"cert_abc\",\n  \"last_id\": \"cert_abc\",\n  \"has_more\": false\n}\n"
        group: administration
        name: List organization certificates
        returns: 'A list of [Certificate](https://platform.openai.com/docs/api-reference/certificates/object) objects.'
    post:
      tags:
        - Certificates
      summary: Upload certificate
      description: "Upload a certificate to the organization. This does **not** automatically activate the certificate.\n\nOrganizations can upload up to 50 certificates.\n"
      operationId: uploadCertificate
      requestBody:
        description: The certificate upload payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UploadCertificateRequest'
        required: true
      responses:
        '200':
          description: Certificate uploaded successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Certificate'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/certificates \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"name\": \"My Example Certificate\",\n  \"certificate\": \"-----BEGIN CERTIFICATE-----\\\\nMIIDeT...\\\\n-----END CERTIFICATE-----\"\n}'\n"
          response: "{\n  \"object\": \"certificate\",\n  \"id\": \"cert_abc\",\n  \"name\": \"My Example Certificate\",\n  \"created_at\": 1234567,\n  \"certificate_details\": {\n    \"valid_at\": 12345667,\n    \"expires_at\": 12345678\n  }\n}\n"
        group: administration
        name: Upload certificate
        returns: 'A single [Certificate](https://platform.openai.com/docs/api-reference/certificates/object) object.'
  /organization/certificates/activate:
    post:
      tags:
        - Certificates
      summary: Activate certificates for organization
      description: "Activate certificates at the organization level.\n\nYou can atomically and idempotently activate up to 10 certificates at a time.\n"
      operationId: activateOrganizationCertificates
      requestBody:
        description: The certificate activation payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ToggleCertificatesRequest'
        required: true
      responses:
        '200':
          description: Certificates activated successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListCertificatesResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/certificates/activate \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"data\": [\"cert_abc\", \"cert_def\"]\n}'\n"
          response: "{\n  \"object\": \"organization.certificate.activation\",\n  \"data\": [\n    {\n      \"object\": \"organization.certificate\",\n      \"id\": \"cert_abc\",\n      \"name\": \"My Example Certificate\",\n      \"active\": true,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n    {\n      \"object\": \"organization.certificate\",\n      \"id\": \"cert_def\",\n      \"name\": \"My Example Certificate 2\",\n      \"active\": true,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n  ],\n}\n"
        group: administration
        name: Activate certificates for organization
        returns: 'A list of [Certificate](https://platform.openai.com/docs/api-reference/certificates/object) objects that were activated.'
  /organization/certificates/deactivate:
    post:
      tags:
        - Certificates
      summary: Deactivate certificates for organization
      description: "Deactivate certificates at the organization level.\n\nYou can atomically and idempotently deactivate up to 10 certificates at a time.\n"
      operationId: deactivateOrganizationCertificates
      requestBody:
        description: The certificate deactivation payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ToggleCertificatesRequest'
        required: true
      responses:
        '200':
          description: Certificates deactivated successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListCertificatesResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/certificates/deactivate \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"data\": [\"cert_abc\", \"cert_def\"]\n}'\n"
          response: "{\n  \"object\": \"organization.certificate.deactivation\",\n  \"data\": [\n    {\n      \"object\": \"organization.certificate\",\n      \"id\": \"cert_abc\",\n      \"name\": \"My Example Certificate\",\n      \"active\": false,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n    {\n      \"object\": \"organization.certificate\",\n      \"id\": \"cert_def\",\n      \"name\": \"My Example Certificate 2\",\n      \"active\": false,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n  ],\n}\n"
        group: administration
        name: Deactivate certificates for organization
        returns: 'A list of [Certificate](https://platform.openai.com/docs/api-reference/certificates/object) objects that were deactivated.'
  '/organization/certificates/{certificate_id}':
    delete:
      tags:
        - Certificates
      summary: Delete certificate
      description: "Delete a certificate from the organization.\n\nThe certificate must be inactive for the organization and all projects.\n"
      operationId: deleteCertificate
      responses:
        '200':
          description: Certificate deleted successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteCertificateResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/organization/certificates/cert_abc \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\"\n"
          response: "{\n  \"object\": \"certificate.deleted\",\n  \"id\": \"cert_abc\"\n}\n"
        group: administration
        name: Delete certificate
        returns: A confirmation object indicating the certificate was deleted.
    get:
      tags:
        - Certificates
      summary: Get certificate
      description: "Get a certificate that has been uploaded to the organization.\n\nYou can get a certificate regardless of whether it is active or not.\n"
      operationId: getCertificate
      parameters:
        - name: certificate_id
          in: path
          description: Unique ID of the certificate to retrieve.
          required: true
          schema:
            type: string
        - name: include
          in: query
          description: A list of additional fields to include in the response. Currently the only supported value is `content` to fetch the PEM content of the certificate.
          schema:
            type: array
            items:
              enum:
                - content
              type: string
      responses:
        '200':
          description: Certificate retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Certificate'
      x-oaiMeta:
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/certificates/cert_abc?include[]=content\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\"\n"
          response: "{\n  \"object\": \"certificate\",\n  \"id\": \"cert_abc\",\n  \"name\": \"My Example Certificate\",\n  \"created_at\": 1234567,\n  \"certificate_details\": {\n    \"valid_at\": 1234567,\n    \"expires_at\": 12345678,\n    \"content\": \"-----BEGIN CERTIFICATE-----MIIDeT...-----END CERTIFICATE-----\"\n  }\n}\n"
        group: administration
        name: Get certificate
        returns: 'A single [Certificate](https://platform.openai.com/docs/api-reference/certificates/object) object.'
    post:
      tags:
        - Certificates
      summary: Modify certificate
      description: "Modify a certificate. Note that only the name can be modified.\n"
      operationId: modifyCertificate
      requestBody:
        description: The certificate modification payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyCertificateRequest'
        required: true
      responses:
        '200':
          description: Certificate modified successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Certificate'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/certificates/cert_abc \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"name\": \"Renamed Certificate\"\n}'\n"
          response: "{\n  \"object\": \"certificate\",\n  \"id\": \"cert_abc\",\n  \"name\": \"Renamed Certificate\",\n  \"created_at\": 1234567,\n  \"certificate_details\": {\n    \"valid_at\": 12345667,\n    \"expires_at\": 12345678\n  }\n}\n"
        group: administration
        name: Modify certificate
        returns: 'The updated [Certificate](https://platform.openai.com/docs/api-reference/certificates/object) object.'
  /organization/costs:
    get:
      tags:
        - Usage
      summary: Costs
      description: Get costs details for the organization.
      operationId: usage-costs
      parameters:
        - name: start_time
          in: query
          description: 'Start time (Unix seconds) of the query time range, inclusive.'
          required: true
          schema:
            type: integer
        - name: end_time
          in: query
          description: 'End time (Unix seconds) of the query time range, exclusive.'
          schema:
            type: integer
        - name: bucket_width
          in: query
          description: 'Width of each time bucket in response. Currently only `1d` is supported, default to `1d`.'
          schema:
            enum:
              - 1d
            type: string
            default: 1d
        - name: project_ids
          in: query
          description: Return only costs for these projects.
          schema:
            type: array
            items:
              type: string
        - name: group_by
          in: query
          description: 'Group the costs by the specified fields. Support fields include `project_id`, `line_item` and any combination of them.'
          schema:
            type: array
            items:
              enum:
                - project_id
                - line_item
              type: string
        - name: limit
          in: query
          description: "A limit on the number of buckets to be returned. Limit can range between 1 and 180, and the default is 7.\n"
          schema:
            type: integer
            default: 7
        - name: page
          in: query
          description: A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.
          schema:
            type: string
      responses:
        '200':
          description: Costs data retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/costs?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"organization.costs.result\",\n                    \"amount\": {\n                        \"value\": 0.06,\n                        \"currency\": \"usd\"\n                    },\n                    \"line_item\": null,\n                    \"project_id\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\n"
        group: usage-costs
        name: Costs
        returns: 'A list of paginated, time bucketed [Costs](https://platform.openai.com/docs/api-reference/usage/costs_object) objects.'
  /organization/invites:
    get:
      tags:
        - Invites
      summary: List invites
      description: Returns a list of invites in the organization.
      operationId: list-invites
      parameters:
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: Invites listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/InviteListResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/invites?after=invite-abc&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"organization.invite\",\n      \"id\": \"invite-abc\",\n      \"email\": \"user@example.com\",\n      \"role\": \"owner\",\n      \"status\": \"accepted\",\n      \"invited_at\": 1711471533,\n      \"expires_at\": 1711471533,\n      \"accepted_at\": 1711471533\n    }\n  ],\n  \"first_id\": \"invite-abc\",\n  \"last_id\": \"invite-abc\",\n  \"has_more\": false\n}\n"
        group: administration
        name: List invites
        returns: 'A list of [Invite](https://platform.openai.com/docs/api-reference/invite/object) objects.'
    post:
      tags:
        - Invites
      summary: Create invite
      description: Create an invite for a user to the organization. The invite must be accepted by the user before they have access to the organization.
      operationId: inviteUser
      requestBody:
        description: The invite request payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/InviteRequest'
        required: true
      responses:
        '200':
          description: User invited successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Invite'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/invites \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"email\": \"anotheruser@example.com\",\n      \"role\": \"reader\",\n      \"projects\": [\n        {\n          \"id\": \"project-xyz\",\n          \"role\": \"member\"\n        },\n        {\n          \"id\": \"project-abc\",\n          \"role\": \"owner\"\n        }\n      ]\n  }'\n"
          response: "{\n  \"object\": \"organization.invite\",\n  \"id\": \"invite-def\",\n  \"email\": \"anotheruser@example.com\",\n  \"role\": \"reader\",\n  \"status\": \"pending\",\n  \"invited_at\": 1711471533,\n  \"expires_at\": 1711471533,\n  \"accepted_at\": null,\n  \"projects\": [\n    {\n      \"id\": \"project-xyz\",\n      \"role\": \"member\"\n    },\n    {\n      \"id\": \"project-abc\",\n      \"role\": \"owner\"\n    }\n  ]\n}\n"
        group: administration
        name: Create invite
        returns: 'The created [Invite](https://platform.openai.com/docs/api-reference/invite/object) object.'
  '/organization/invites/{invite_id}':
    delete:
      tags:
        - Invites
      summary: Delete invite
      description: 'Delete an invite. If the invite has already been accepted, it cannot be deleted.'
      operationId: delete-invite
      parameters:
        - name: invite_id
          in: path
          description: The ID of the invite to delete.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Invite deleted successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/InviteDeleteResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/organization/invites/invite-abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"organization.invite.deleted\",\n    \"id\": \"invite-abc\",\n    \"deleted\": true\n}\n"
        group: administration
        name: Delete invite
        returns: Confirmation that the invite has been deleted
    get:
      tags:
        - Invites
      summary: Retrieve invite
      description: Retrieves an invite.
      operationId: retrieve-invite
      parameters:
        - name: invite_id
          in: path
          description: The ID of the invite to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Invite retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Invite'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/invites/invite-abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"organization.invite\",\n    \"id\": \"invite-abc\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"status\": \"accepted\",\n    \"invited_at\": 1711471533,\n    \"expires_at\": 1711471533,\n    \"accepted_at\": 1711471533\n}\n"
        group: administration
        name: Retrieve invite
        returns: 'The [Invite](https://platform.openai.com/docs/api-reference/invite/object) object matching the specified ID.'
  /organization/projects:
    get:
      tags:
        - Projects
      summary: List projects
      description: Returns a list of projects.
      operationId: list-projects
      parameters:
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: include_archived
          in: query
          description: If `true` returns all projects including those that have been `archived`. Archived projects are not included by default.
          schema:
            type: boolean
            default: false
      responses:
        '200':
          description: Projects listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectListResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects?after=proj_abc&limit=20&include_archived=false \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"id\": \"proj_abc\",\n            \"object\": \"organization.project\",\n            \"name\": \"Project example\",\n            \"created_at\": 1711471533,\n            \"archived_at\": null,\n            \"status\": \"active\"\n        }\n    ],\n    \"first_id\": \"proj-abc\",\n    \"last_id\": \"proj-xyz\",\n    \"has_more\": false\n}\n"
        group: administration
        name: List projects
        returns: 'A list of [Project](https://platform.openai.com/docs/api-reference/projects/object) objects.'
    post:
      tags:
        - Projects
      summary: Create project
      description: 'Create a new project in the organization. Projects can be created and archived, but cannot be deleted.'
      operationId: create-project
      requestBody:
        description: The project create request payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectCreateRequest'
        required: true
      responses:
        '200':
          description: Project created successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/projects \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"name\": \"Project ABC\"\n  }'\n"
          response: "{\n    \"id\": \"proj_abc\",\n    \"object\": \"organization.project\",\n    \"name\": \"Project ABC\",\n    \"created_at\": 1711471533,\n    \"archived_at\": null,\n    \"status\": \"active\"\n}\n"
        group: administration
        name: Create project
        returns: 'The created [Project](https://platform.openai.com/docs/api-reference/projects/object) object.'
  '/organization/projects/{project_id}':
    get:
      tags:
        - Projects
      summary: Retrieve project
      description: Retrieves a project.
      operationId: retrieve-project
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Project retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'
      x-oaiMeta:
        description: Retrieve a project.
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"id\": \"proj_abc\",\n    \"object\": \"organization.project\",\n    \"name\": \"Project example\",\n    \"created_at\": 1711471533,\n    \"archived_at\": null,\n    \"status\": \"active\"\n}\n"
        group: administration
        name: Retrieve project
        returns: 'The [Project](https://platform.openai.com/docs/api-reference/projects/object) object matching the specified ID.'
    post:
      tags:
        - Projects
      summary: Modify project
      description: Modifies a project in the organization.
      operationId: modify-project
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
      requestBody:
        description: The project update request payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectUpdateRequest'
        required: true
      responses:
        '200':
          description: Project updated successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'
        '400':
          description: Error response when updating the default project.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/projects/proj_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"name\": \"Project DEF\"\n  }'\n"
          response: ''
        group: administration
        name: Modify project
        returns: 'The updated [Project](https://platform.openai.com/docs/api-reference/projects/object) object.'
  '/organization/projects/{project_id}/api_keys':
    get:
      tags:
        - Projects
      summary: List project API keys
      description: Returns a list of API keys in the project.
      operationId: list-project-api-keys
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: Project API keys listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectApiKeyListResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys?after=key_abc&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"object\": \"organization.project.api_key\",\n            \"redacted_value\": \"sk-abc...def\",\n            \"name\": \"My API Key\",\n            \"created_at\": 1711471533,\n            \"last_used_at\": 1711471534,\n            \"id\": \"key_abc\",\n            \"owner\": {\n                \"type\": \"user\",\n                \"user\": {\n                    \"object\": \"organization.project.user\",\n                    \"id\": \"user_abc\",\n                    \"name\": \"First Last\",\n                    \"email\": \"user@example.com\",\n                    \"role\": \"owner\",\n                    \"added_at\": 1711471533\n                }\n            }\n        }\n    ],\n    \"first_id\": \"key_abc\",\n    \"last_id\": \"key_xyz\",\n    \"has_more\": false\n}\n"
        group: administration
        name: List project API keys
        returns: 'A list of [ProjectApiKey](https://platform.openai.com/docs/api-reference/project-api-keys/object) objects.'
  '/organization/projects/{project_id}/api_keys/{key_id}':
    delete:
      tags:
        - Projects
      summary: Delete project API key
      description: Deletes an API key from the project.
      operationId: delete-project-api-key
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: key_id
          in: path
          description: The ID of the API key.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Project API key deleted successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectApiKeyDeleteResponse'
        '400':
          description: Error response for various conditions.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"organization.project.api_key.deleted\",\n    \"id\": \"key_abc\",\n    \"deleted\": true\n}\n"
        group: administration
        name: Delete project API key
        returns: Confirmation of the key's deletion or an error if the key belonged to a service account
    get:
      tags:
        - Projects
      summary: Retrieve project API key
      description: Retrieves an API key in the project.
      operationId: retrieve-project-api-key
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: key_id
          in: path
          description: The ID of the API key.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Project API key retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectApiKey'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"organization.project.api_key\",\n    \"redacted_value\": \"sk-abc...def\",\n    \"name\": \"My API Key\",\n    \"created_at\": 1711471533,\n    \"last_used_at\": 1711471534,\n    \"id\": \"key_abc\",\n    \"owner\": {\n        \"type\": \"user\",\n        \"user\": {\n            \"object\": \"organization.project.user\",\n            \"id\": \"user_abc\",\n            \"name\": \"First Last\",\n            \"email\": \"user@example.com\",\n            \"role\": \"owner\",\n            \"added_at\": 1711471533\n        }\n    }\n}\n"
        group: administration
        name: Retrieve project API key
        returns: 'The [ProjectApiKey](https://platform.openai.com/docs/api-reference/project-api-keys/object) object matching the specified ID.'
  '/organization/projects/{project_id}/archive':
    post:
      tags:
        - Projects
      summary: Archive project
      description: Archives a project in the organization. Archived projects cannot be used or updated.
      operationId: archive-project
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Project archived successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/archive \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"id\": \"proj_abc\",\n    \"object\": \"organization.project\",\n    \"name\": \"Project DEF\",\n    \"created_at\": 1711471533,\n    \"archived_at\": 1711471533,\n    \"status\": \"archived\"\n}\n"
        group: administration
        name: Archive project
        returns: 'The archived [Project](https://platform.openai.com/docs/api-reference/projects/object) object.'
  '/organization/projects/{project_id}/certificates':
    get:
      tags:
        - Certificates
      summary: List project certificates
      description: List certificates for this project.
      operationId: listProjectCertificates
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
      responses:
        '200':
          description: Certificates listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListCertificatesResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc/certificates \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\"\n"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"organization.project.certificate\",\n      \"id\": \"cert_abc\",\n      \"name\": \"My Example Certificate\",\n      \"active\": true,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n  ],\n  \"first_id\": \"cert_abc\",\n  \"last_id\": \"cert_abc\",\n  \"has_more\": false\n}\n"
        group: administration
        name: List project certificates
        returns: 'A list of [Certificate](https://platform.openai.com/docs/api-reference/certificates/object) objects.'
  '/organization/projects/{project_id}/certificates/activate':
    post:
      tags:
        - Certificates
      summary: Activate certificates for project
      description: "Activate certificates at the project level.\n\nYou can atomically and idempotently activate up to 10 certificates at a time.\n"
      operationId: activateProjectCertificates
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
      requestBody:
        description: The certificate activation payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ToggleCertificatesRequest'
        required: true
      responses:
        '200':
          description: Certificates activated successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListCertificatesResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc/certificates/activate \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"data\": [\"cert_abc\", \"cert_def\"]\n}'\n"
          response: "{\n  \"object\": \"organization.project.certificate.activation\",\n  \"data\": [\n    {\n      \"object\": \"organization.project.certificate\",\n      \"id\": \"cert_abc\",\n      \"name\": \"My Example Certificate\",\n      \"active\": true,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n    {\n      \"object\": \"organization.project.certificate\",\n      \"id\": \"cert_def\",\n      \"name\": \"My Example Certificate 2\",\n      \"active\": true,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n  ],\n}\n"
        group: administration
        name: Activate certificates for project
        returns: 'A list of [Certificate](https://platform.openai.com/docs/api-reference/certificates/object) objects that were activated.'
  '/organization/projects/{project_id}/certificates/deactivate':
    post:
      tags:
        - Certificates
      summary: Deactivate certificates for project
      description: "Deactivate certificates at the project level. You can atomically and \nidempotently deactivate up to 10 certificates at a time.\n"
      operationId: deactivateProjectCertificates
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
      requestBody:
        description: The certificate deactivation payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ToggleCertificatesRequest'
        required: true
      responses:
        '200':
          description: Certificates deactivated successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListCertificatesResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc/certificates/deactivate \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"data\": [\"cert_abc\", \"cert_def\"]\n}'\n"
          response: "{\n  \"object\": \"organization.project.certificate.deactivation\",\n  \"data\": [\n    {\n      \"object\": \"organization.project.certificate\",\n      \"id\": \"cert_abc\",\n      \"name\": \"My Example Certificate\",\n      \"active\": false,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n    {\n      \"object\": \"organization.project.certificate\",\n      \"id\": \"cert_def\",\n      \"name\": \"My Example Certificate 2\",\n      \"active\": false,\n      \"created_at\": 1234567,\n      \"certificate_details\": {\n        \"valid_at\": 12345667,\n        \"expires_at\": 12345678\n      }\n    },\n  ],\n}\n"
        group: administration
        name: Deactivate certificates for project
        returns: 'A list of [Certificate](https://platform.openai.com/docs/api-reference/certificates/object) objects that were deactivated.'
  '/organization/projects/{project_id}/rate_limits':
    get:
      tags:
        - Projects
      summary: List project rate limits
      description: Returns the rate limits per model for a project.
      operationId: list-project-rate-limits
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. The default is 100.\n"
          schema:
            type: integer
            default: 100
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: before
          in: query
          description: "A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, beginning with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: Project rate limits listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectRateLimitListResponse'
      x-oaiMeta:
        examples:
          error_response: "{\n    \"code\": 404,\n    \"message\": \"The project {project_id} was not found\"\n}\n"
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc/rate_limits?after=rl_xxx&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"list\",\n    \"data\": [\n        {\n          \"object\": \"project.rate_limit\",\n          \"id\": \"rl-ada\",\n          \"model\": \"ada\",\n          \"max_requests_per_1_minute\": 600,\n          \"max_tokens_per_1_minute\": 150000,\n          \"max_images_per_1_minute\": 10\n        }\n    ],\n    \"first_id\": \"rl-ada\",\n    \"last_id\": \"rl-ada\",\n    \"has_more\": false\n}\n"
        group: administration
        name: List project rate limits
        returns: 'A list of [ProjectRateLimit](https://platform.openai.com/docs/api-reference/project-rate-limits/object) objects.'
  '/organization/projects/{project_id}/rate_limits/{rate_limit_id}':
    post:
      tags:
        - Projects
      summary: Modify project rate limit
      description: Updates a project rate limit.
      operationId: update-project-rate-limits
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: rate_limit_id
          in: path
          description: The ID of the rate limit.
          required: true
          schema:
            type: string
      requestBody:
        description: The project rate limit update request payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectRateLimitUpdateRequest'
        required: true
      responses:
        '200':
          description: Project rate limit updated successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectRateLimit'
        '400':
          description: Error response for various conditions.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        examples:
          error_response: "{\n    \"code\": 404,\n    \"message\": \"The project {project_id} was not found\"\n}\n"
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/rate_limits/rl_xxx \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"max_requests_per_1_minute\": 500\n  }'\n"
          response: "{\n    \"object\": \"project.rate_limit\",\n    \"id\": \"rl-ada\",\n    \"model\": \"ada\",\n    \"max_requests_per_1_minute\": 600,\n    \"max_tokens_per_1_minute\": 150000,\n    \"max_images_per_1_minute\": 10\n  }\n"
        group: administration
        name: Modify project rate limit
        returns: 'The updated [ProjectRateLimit](https://platform.openai.com/docs/api-reference/project-rate-limits/object) object.'
  '/organization/projects/{project_id}/service_accounts':
    get:
      tags:
        - Projects
      summary: List project service accounts
      description: Returns a list of service accounts in the project.
      operationId: list-project-service-accounts
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: Project service accounts listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectServiceAccountListResponse'
        '400':
          description: Error response when project is archived.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts?after=custom_id&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"object\": \"organization.project.service_account\",\n            \"id\": \"svc_acct_abc\",\n            \"name\": \"Service Account\",\n            \"role\": \"owner\",\n            \"created_at\": 1711471533\n        }\n    ],\n    \"first_id\": \"svc_acct_abc\",\n    \"last_id\": \"svc_acct_xyz\",\n    \"has_more\": false\n}\n"
        group: administration
        name: List project service accounts
        returns: 'A list of [ProjectServiceAccount](https://platform.openai.com/docs/api-reference/project-service-accounts/object) objects.'
    post:
      tags:
        - Projects
      summary: Create project service account
      description: Creates a new service account in the project. This also returns an unredacted API key for the service account.
      operationId: create-project-service-account
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
      requestBody:
        description: The project service account create request payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectServiceAccountCreateRequest'
        required: true
      responses:
        '200':
          description: Project service account created successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectServiceAccountCreateResponse'
        '400':
          description: Error response when project is archived.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/service_accounts \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"name\": \"Production App\"\n  }'\n"
          response: "{\n    \"object\": \"organization.project.service_account\",\n    \"id\": \"svc_acct_abc\",\n    \"name\": \"Production App\",\n    \"role\": \"member\",\n    \"created_at\": 1711471533,\n    \"api_key\": {\n        \"object\": \"organization.project.service_account.api_key\",\n        \"value\": \"sk-abcdefghijklmnop123\",\n        \"name\": \"Secret Key\",\n        \"created_at\": 1711471533,\n        \"id\": \"key_abc\"\n    }\n}\n"
        group: administration
        name: Create project service account
        returns: 'The created [ProjectServiceAccount](https://platform.openai.com/docs/api-reference/project-service-accounts/object) object.'
  '/organization/projects/{project_id}/service_accounts/{service_account_id}':
    delete:
      tags:
        - Projects
      summary: Delete project service account
      description: Deletes a service account from the project.
      operationId: delete-project-service-account
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: service_account_id
          in: path
          description: The ID of the service account.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Project service account deleted successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectServiceAccountDeleteResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"organization.project.service_account.deleted\",\n    \"id\": \"svc_acct_abc\",\n    \"deleted\": true\n}\n"
        group: administration
        name: Delete project service account
        returns: 'Confirmation of service account being deleted, or an error in case of an archived project, which has no service accounts'
    get:
      tags:
        - Projects
      summary: Retrieve project service account
      description: Retrieves a service account in the project.
      operationId: retrieve-project-service-account
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: service_account_id
          in: path
          description: The ID of the service account.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Project service account retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectServiceAccount'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"organization.project.service_account\",\n    \"id\": \"svc_acct_abc\",\n    \"name\": \"Service Account\",\n    \"role\": \"owner\",\n    \"created_at\": 1711471533\n}\n"
        group: administration
        name: Retrieve project service account
        returns: 'The [ProjectServiceAccount](https://platform.openai.com/docs/api-reference/project-service-accounts/object) object matching the specified ID.'
  '/organization/projects/{project_id}/users':
    get:
      tags:
        - Projects
      summary: List project users
      description: Returns a list of users in the project.
      operationId: list-project-users
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: Project users listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUserListResponse'
        '400':
          description: Error response when project is archived.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc/users?after=user_abc&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"object\": \"organization.project.user\",\n            \"id\": \"user_abc\",\n            \"name\": \"First Last\",\n            \"email\": \"user@example.com\",\n            \"role\": \"owner\",\n            \"added_at\": 1711471533\n        }\n    ],\n    \"first_id\": \"user-abc\",\n    \"last_id\": \"user-xyz\",\n    \"has_more\": false\n}\n"
        group: administration
        name: List project users
        returns: 'A list of [ProjectUser](https://platform.openai.com/docs/api-reference/project-users/object) objects.'
    post:
      tags:
        - Projects
      summary: Create project user
      description: Adds a user to the project. Users must already be members of the organization to be added to a project.
      operationId: create-project-user
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
      requestBody:
        description: The project user create request payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectUserCreateRequest'
        required: true
      responses:
        '200':
          description: User added to project successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUser'
        '400':
          description: Error response for various conditions.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"user_id\": \"user_abc\",\n      \"role\": \"member\"\n  }'\n"
          response: "{\n    \"object\": \"organization.project.user\",\n    \"id\": \"user_abc\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\n"
        group: administration
        name: Create project user
        returns: 'The created [ProjectUser](https://platform.openai.com/docs/api-reference/project-users/object) object.'
  '/organization/projects/{project_id}/users/{user_id}':
    delete:
      tags:
        - Projects
      summary: Delete project user
      description: Deletes a user from the project.
      operationId: delete-project-user
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: user_id
          in: path
          description: The ID of the user.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Project user deleted successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUserDeleteResponse'
        '400':
          description: Error response for various conditions.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"organization.project.user.deleted\",\n    \"id\": \"user_abc\",\n    \"deleted\": true\n}\n"
        group: administration
        name: Delete project user
        returns: 'Confirmation that project has been deleted or an error in case of an archived project, which has no users'
    get:
      tags:
        - Projects
      summary: Retrieve project user
      description: Retrieves a user in the project.
      operationId: retrieve-project-user
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: user_id
          in: path
          description: The ID of the user.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Project user retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUser'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"organization.project.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\n"
        group: administration
        name: Retrieve project user
        returns: 'The [ProjectUser](https://platform.openai.com/docs/api-reference/project-users/object) object matching the specified ID.'
    post:
      tags:
        - Projects
      summary: Modify project user
      description: Modifies a user's role in the project.
      operationId: modify-project-user
      parameters:
        - name: project_id
          in: path
          description: The ID of the project.
          required: true
          schema:
            type: string
        - name: user_id
          in: path
          description: The ID of the user.
          required: true
          schema:
            type: string
      requestBody:
        description: The project user update request payload.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectUserUpdateRequest'
        required: true
      responses:
        '200':
          description: Project user's role updated successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUser'
        '400':
          description: Error response for various conditions.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"role\": \"owner\"\n  }'\n"
          response: "{\n    \"object\": \"organization.project.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\n"
        group: administration
        name: Modify project user
        returns: 'The updated [ProjectUser](https://platform.openai.com/docs/api-reference/project-users/object) object.'
  /organization/usage/audio_speeches:
    get:
      tags:
        - Usage
      summary: Audio speeches
      description: Get audio speeches usage details for the organization.
      operationId: usage-audio-speeches
      parameters:
        - name: start_time
          in: query
          description: 'Start time (Unix seconds) of the query time range, inclusive.'
          required: true
          schema:
            type: integer
        - name: end_time
          in: query
          description: 'End time (Unix seconds) of the query time range, exclusive.'
          schema:
            type: integer
        - name: bucket_width
          in: query
          description: 'Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.'
          schema:
            enum:
              - 1m
              - 1h
              - 1d
            type: string
            default: 1d
        - name: project_ids
          in: query
          description: Return only usage for these projects.
          schema:
            type: array
            items:
              type: string
        - name: user_ids
          in: query
          description: Return only usage for these users.
          schema:
            type: array
            items:
              type: string
        - name: api_key_ids
          in: query
          description: Return only usage for these API keys.
          schema:
            type: array
            items:
              type: string
        - name: models
          in: query
          description: Return only usage for these models.
          schema:
            type: array
            items:
              type: string
        - name: group_by
          in: query
          description: 'Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.'
          schema:
            type: array
            items:
              enum:
                - project_id
                - user_id
                - api_key_id
                - model
              type: string
        - name: limit
          in: query
          description: "Specifies the number of buckets to return.\n- `bucket_width=1d`: default: 7, max: 31\n- `bucket_width=1h`: default: 24, max: 168\n- `bucket_width=1m`: default: 60, max: 1440\n"
          schema:
            type: integer
        - name: page
          in: query
          description: A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.
          schema:
            type: string
      responses:
        '200':
          description: Usage data retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/usage/audio_speeches?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"organization.usage.audio_speeches.result\",\n                    \"characters\": 45,\n                    \"num_model_requests\": 1,\n                    \"project_id\": null,\n                    \"user_id\": null,\n                    \"api_key_id\": null,\n                    \"model\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\n"
        group: usage-audio-speeches
        name: Audio speeches
        returns: 'A list of paginated, time bucketed [Audio speeches usage](https://platform.openai.com/docs/api-reference/usage/audio_speeches_object) objects.'
  /organization/usage/audio_transcriptions:
    get:
      tags:
        - Usage
      summary: Audio transcriptions
      description: Get audio transcriptions usage details for the organization.
      operationId: usage-audio-transcriptions
      parameters:
        - name: start_time
          in: query
          description: 'Start time (Unix seconds) of the query time range, inclusive.'
          required: true
          schema:
            type: integer
        - name: end_time
          in: query
          description: 'End time (Unix seconds) of the query time range, exclusive.'
          schema:
            type: integer
        - name: bucket_width
          in: query
          description: 'Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.'
          schema:
            enum:
              - 1m
              - 1h
              - 1d
            type: string
            default: 1d
        - name: project_ids
          in: query
          description: Return only usage for these projects.
          schema:
            type: array
            items:
              type: string
        - name: user_ids
          in: query
          description: Return only usage for these users.
          schema:
            type: array
            items:
              type: string
        - name: api_key_ids
          in: query
          description: Return only usage for these API keys.
          schema:
            type: array
            items:
              type: string
        - name: models
          in: query
          description: Return only usage for these models.
          schema:
            type: array
            items:
              type: string
        - name: group_by
          in: query
          description: 'Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.'
          schema:
            type: array
            items:
              enum:
                - project_id
                - user_id
                - api_key_id
                - model
              type: string
        - name: limit
          in: query
          description: "Specifies the number of buckets to return.\n- `bucket_width=1d`: default: 7, max: 31\n- `bucket_width=1h`: default: 24, max: 168\n- `bucket_width=1m`: default: 60, max: 1440\n"
          schema:
            type: integer
        - name: page
          in: query
          description: A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.
          schema:
            type: string
      responses:
        '200':
          description: Usage data retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/usage/audio_transcriptions?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"organization.usage.audio_transcriptions.result\",\n                    \"seconds\": 20,\n                    \"num_model_requests\": 1,\n                    \"project_id\": null,\n                    \"user_id\": null,\n                    \"api_key_id\": null,\n                    \"model\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\n"
        group: usage-audio-transcriptions
        name: Audio transcriptions
        returns: 'A list of paginated, time bucketed [Audio transcriptions usage](https://platform.openai.com/docs/api-reference/usage/audio_transcriptions_object) objects.'
  /organization/usage/code_interpreter_sessions:
    get:
      tags:
        - Usage
      summary: Code interpreter sessions
      description: Get code interpreter sessions usage details for the organization.
      operationId: usage-code-interpreter-sessions
      parameters:
        - name: start_time
          in: query
          description: 'Start time (Unix seconds) of the query time range, inclusive.'
          required: true
          schema:
            type: integer
        - name: end_time
          in: query
          description: 'End time (Unix seconds) of the query time range, exclusive.'
          schema:
            type: integer
        - name: bucket_width
          in: query
          description: 'Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.'
          schema:
            enum:
              - 1m
              - 1h
              - 1d
            type: string
            default: 1d
        - name: project_ids
          in: query
          description: Return only usage for these projects.
          schema:
            type: array
            items:
              type: string
        - name: group_by
          in: query
          description: Group the usage data by the specified fields. Support fields include `project_id`.
          schema:
            type: array
            items:
              enum:
                - project_id
              type: string
        - name: limit
          in: query
          description: "Specifies the number of buckets to return.\n- `bucket_width=1d`: default: 7, max: 31\n- `bucket_width=1h`: default: 24, max: 168\n- `bucket_width=1m`: default: 60, max: 1440\n"
          schema:
            type: integer
        - name: page
          in: query
          description: A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.
          schema:
            type: string
      responses:
        '200':
          description: Usage data retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/usage/code_interpreter_sessions?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"organization.usage.code_interpreter_sessions.result\",\n                    \"num_sessions\": 1,\n                    \"project_id\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\n"
        group: usage-code-interpreter-sessions
        name: Code interpreter sessions
        returns: 'A list of paginated, time bucketed [Code interpreter sessions usage](https://platform.openai.com/docs/api-reference/usage/code_interpreter_sessions_object) objects.'
  /organization/usage/completions:
    get:
      tags:
        - Usage
      summary: Completions
      description: Get completions usage details for the organization.
      operationId: usage-completions
      parameters:
        - name: start_time
          in: query
          description: 'Start time (Unix seconds) of the query time range, inclusive.'
          required: true
          schema:
            type: integer
        - name: end_time
          in: query
          description: 'End time (Unix seconds) of the query time range, exclusive.'
          schema:
            type: integer
        - name: bucket_width
          in: query
          description: 'Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.'
          schema:
            enum:
              - 1m
              - 1h
              - 1d
            type: string
            default: 1d
        - name: project_ids
          in: query
          description: Return only usage for these projects.
          schema:
            type: array
            items:
              type: string
        - name: user_ids
          in: query
          description: Return only usage for these users.
          schema:
            type: array
            items:
              type: string
        - name: api_key_ids
          in: query
          description: Return only usage for these API keys.
          schema:
            type: array
            items:
              type: string
        - name: models
          in: query
          description: Return only usage for these models.
          schema:
            type: array
            items:
              type: string
        - name: batch
          in: query
          description: "If `true`, return batch jobs only. If `false`, return non-batch jobs only. By default, return both.\n"
          schema:
            type: boolean
        - name: group_by
          in: query
          description: 'Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `batch` or any combination of them.'
          schema:
            type: array
            items:
              enum:
                - project_id
                - user_id
                - api_key_id
                - model
                - batch
              type: string
        - name: limit
          in: query
          description: "Specifies the number of buckets to return.\n- `bucket_width=1d`: default: 7, max: 31\n- `bucket_width=1h`: default: 24, max: 168\n- `bucket_width=1m`: default: 60, max: 1440\n"
          schema:
            type: integer
        - name: page
          in: query
          description: A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.
          schema:
            type: string
      responses:
        '200':
          description: Usage data retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/usage/completions?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"organization.usage.completions.result\",\n                    \"input_tokens\": 1000,\n                    \"output_tokens\": 500,\n                    \"input_cached_tokens\": 800,\n                    \"input_audio_tokens\": 0,\n                    \"output_audio_tokens\": 0,\n                    \"num_model_requests\": 5,\n                    \"project_id\": null,\n                    \"user_id\": null,\n                    \"api_key_id\": null,\n                    \"model\": null,\n                    \"batch\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": true,\n    \"next_page\": \"page_AAAAAGdGxdEiJdKOAAAAAGcqsYA=\"\n}\n"
        group: usage-completions
        name: Completions
        returns: 'A list of paginated, time bucketed [Completions usage](https://platform.openai.com/docs/api-reference/usage/completions_object) objects.'
  /organization/usage/embeddings:
    get:
      tags:
        - Usage
      summary: Embeddings
      description: Get embeddings usage details for the organization.
      operationId: usage-embeddings
      parameters:
        - name: start_time
          in: query
          description: 'Start time (Unix seconds) of the query time range, inclusive.'
          required: true
          schema:
            type: integer
        - name: end_time
          in: query
          description: 'End time (Unix seconds) of the query time range, exclusive.'
          schema:
            type: integer
        - name: bucket_width
          in: query
          description: 'Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.'
          schema:
            enum:
              - 1m
              - 1h
              - 1d
            type: string
            default: 1d
        - name: project_ids
          in: query
          description: Return only usage for these projects.
          schema:
            type: array
            items:
              type: string
        - name: user_ids
          in: query
          description: Return only usage for these users.
          schema:
            type: array
            items:
              type: string
        - name: api_key_ids
          in: query
          description: Return only usage for these API keys.
          schema:
            type: array
            items:
              type: string
        - name: models
          in: query
          description: Return only usage for these models.
          schema:
            type: array
            items:
              type: string
        - name: group_by
          in: query
          description: 'Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.'
          schema:
            type: array
            items:
              enum:
                - project_id
                - user_id
                - api_key_id
                - model
              type: string
        - name: limit
          in: query
          description: "Specifies the number of buckets to return.\n- `bucket_width=1d`: default: 7, max: 31\n- `bucket_width=1h`: default: 24, max: 168\n- `bucket_width=1m`: default: 60, max: 1440\n"
          schema:
            type: integer
        - name: page
          in: query
          description: A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.
          schema:
            type: string
      responses:
        '200':
          description: Usage data retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/usage/embeddings?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"organization.usage.embeddings.result\",\n                    \"input_tokens\": 16,\n                    \"num_model_requests\": 2,\n                    \"project_id\": null,\n                    \"user_id\": null,\n                    \"api_key_id\": null,\n                    \"model\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\n"
        group: usage-embeddings
        name: Embeddings
        returns: 'A list of paginated, time bucketed [Embeddings usage](https://platform.openai.com/docs/api-reference/usage/embeddings_object) objects.'
  /organization/usage/images:
    get:
      tags:
        - Usage
      summary: Images
      description: Get images usage details for the organization.
      operationId: usage-images
      parameters:
        - name: start_time
          in: query
          description: 'Start time (Unix seconds) of the query time range, inclusive.'
          required: true
          schema:
            type: integer
        - name: end_time
          in: query
          description: 'End time (Unix seconds) of the query time range, exclusive.'
          schema:
            type: integer
        - name: bucket_width
          in: query
          description: 'Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.'
          schema:
            enum:
              - 1m
              - 1h
              - 1d
            type: string
            default: 1d
        - name: sources
          in: query
          description: 'Return only usages for these sources. Possible values are `image.generation`, `image.edit`, `image.variation` or any combination of them.'
          schema:
            type: array
            items:
              enum:
                - image.generation
                - image.edit
                - image.variation
              type: string
        - name: sizes
          in: query
          description: 'Return only usages for these image sizes. Possible values are `256x256`, `512x512`, `1024x1024`, `1792x1792`, `1024x1792` or any combination of them.'
          schema:
            type: array
            items:
              enum:
                - 256x256
                - 512x512
                - 1024x1024
                - 1792x1792
                - 1024x1792
              type: string
        - name: project_ids
          in: query
          description: Return only usage for these projects.
          schema:
            type: array
            items:
              type: string
        - name: user_ids
          in: query
          description: Return only usage for these users.
          schema:
            type: array
            items:
              type: string
        - name: api_key_ids
          in: query
          description: Return only usage for these API keys.
          schema:
            type: array
            items:
              type: string
        - name: models
          in: query
          description: Return only usage for these models.
          schema:
            type: array
            items:
              type: string
        - name: group_by
          in: query
          description: 'Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `size`, `source` or any combination of them.'
          schema:
            type: array
            items:
              enum:
                - project_id
                - user_id
                - api_key_id
                - model
                - size
                - source
              type: string
        - name: limit
          in: query
          description: "Specifies the number of buckets to return.\n- `bucket_width=1d`: default: 7, max: 31\n- `bucket_width=1h`: default: 24, max: 168\n- `bucket_width=1m`: default: 60, max: 1440\n"
          schema:
            type: integer
        - name: page
          in: query
          description: A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.
          schema:
            type: string
      responses:
        '200':
          description: Usage data retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/usage/images?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"organization.usage.images.result\",\n                    \"images\": 2,\n                    \"num_model_requests\": 2,\n                    \"size\": null,\n                    \"source\": null,\n                    \"project_id\": null,\n                    \"user_id\": null,\n                    \"api_key_id\": null,\n                    \"model\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\n"
        group: usage-images
        name: Images
        returns: 'A list of paginated, time bucketed [Images usage](https://platform.openai.com/docs/api-reference/usage/images_object) objects.'
  /organization/usage/moderations:
    get:
      tags:
        - Usage
      summary: Moderations
      description: Get moderations usage details for the organization.
      operationId: usage-moderations
      parameters:
        - name: start_time
          in: query
          description: 'Start time (Unix seconds) of the query time range, inclusive.'
          required: true
          schema:
            type: integer
        - name: end_time
          in: query
          description: 'End time (Unix seconds) of the query time range, exclusive.'
          schema:
            type: integer
        - name: bucket_width
          in: query
          description: 'Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.'
          schema:
            enum:
              - 1m
              - 1h
              - 1d
            type: string
            default: 1d
        - name: project_ids
          in: query
          description: Return only usage for these projects.
          schema:
            type: array
            items:
              type: string
        - name: user_ids
          in: query
          description: Return only usage for these users.
          schema:
            type: array
            items:
              type: string
        - name: api_key_ids
          in: query
          description: Return only usage for these API keys.
          schema:
            type: array
            items:
              type: string
        - name: models
          in: query
          description: Return only usage for these models.
          schema:
            type: array
            items:
              type: string
        - name: group_by
          in: query
          description: 'Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.'
          schema:
            type: array
            items:
              enum:
                - project_id
                - user_id
                - api_key_id
                - model
              type: string
        - name: limit
          in: query
          description: "Specifies the number of buckets to return.\n- `bucket_width=1d`: default: 7, max: 31\n- `bucket_width=1h`: default: 24, max: 168\n- `bucket_width=1m`: default: 60, max: 1440\n"
          schema:
            type: integer
        - name: page
          in: query
          description: A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.
          schema:
            type: string
      responses:
        '200':
          description: Usage data retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/usage/moderations?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"organization.usage.moderations.result\",\n                    \"input_tokens\": 16,\n                    \"num_model_requests\": 2,\n                    \"project_id\": null,\n                    \"user_id\": null,\n                    \"api_key_id\": null,\n                    \"model\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\n"
        group: usage-moderations
        name: Moderations
        returns: 'A list of paginated, time bucketed [Moderations usage](https://platform.openai.com/docs/api-reference/usage/moderations_object) objects.'
  /organization/usage/vector_stores:
    get:
      tags:
        - Usage
      summary: Vector stores
      description: Get vector stores usage details for the organization.
      operationId: usage-vector-stores
      parameters:
        - name: start_time
          in: query
          description: 'Start time (Unix seconds) of the query time range, inclusive.'
          required: true
          schema:
            type: integer
        - name: end_time
          in: query
          description: 'End time (Unix seconds) of the query time range, exclusive.'
          schema:
            type: integer
        - name: bucket_width
          in: query
          description: 'Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.'
          schema:
            enum:
              - 1m
              - 1h
              - 1d
            type: string
            default: 1d
        - name: project_ids
          in: query
          description: Return only usage for these projects.
          schema:
            type: array
            items:
              type: string
        - name: group_by
          in: query
          description: Group the usage data by the specified fields. Support fields include `project_id`.
          schema:
            type: array
            items:
              enum:
                - project_id
              type: string
        - name: limit
          in: query
          description: "Specifies the number of buckets to return.\n- `bucket_width=1d`: default: 7, max: 31\n- `bucket_width=1h`: default: 24, max: 168\n- `bucket_width=1m`: default: 60, max: 1440\n"
          schema:
            type: integer
        - name: page
          in: query
          description: A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.
          schema:
            type: string
      responses:
        '200':
          description: Usage data retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/organization/usage/vector_stores?start_time=1730419200&limit=1\" \\\n-H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n-H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"page\",\n    \"data\": [\n        {\n            \"object\": \"bucket\",\n            \"start_time\": 1730419200,\n            \"end_time\": 1730505600,\n            \"results\": [\n                {\n                    \"object\": \"organization.usage.vector_stores.result\",\n                    \"usage_bytes\": 1024,\n                    \"project_id\": null\n                }\n            ]\n        }\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\n"
        group: usage-vector-stores
        name: Vector stores
        returns: 'A list of paginated, time bucketed [Vector stores usage](https://platform.openai.com/docs/api-reference/usage/vector_stores_object) objects.'
  /organization/users:
    get:
      tags:
        - Users
      summary: List users
      description: Lists all of the users in the organization.
      operationId: list-users
      parameters:
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: emails
          in: query
          description: Filter by the email address of users.
          schema:
            type: array
            items:
              type: string
      responses:
        '200':
          description: Users listed successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UserListResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/users?after=user_abc&limit=20 \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"list\",\n    \"data\": [\n        {\n            \"object\": \"organization.user\",\n            \"id\": \"user_abc\",\n            \"name\": \"First Last\",\n            \"email\": \"user@example.com\",\n            \"role\": \"owner\",\n            \"added_at\": 1711471533\n        }\n    ],\n    \"first_id\": \"user-abc\",\n    \"last_id\": \"user-xyz\",\n    \"has_more\": false\n}\n"
        group: administration
        name: List users
        returns: 'A list of [User](https://platform.openai.com/docs/api-reference/users/object) objects.'
  '/organization/users/{user_id}':
    delete:
      tags:
        - Users
      summary: Delete user
      description: Deletes a user from the organization.
      operationId: delete-user
      parameters:
        - name: user_id
          in: path
          description: The ID of the user.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: User deleted successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UserDeleteResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/organization/users/user_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"organization.user.deleted\",\n    \"id\": \"user_abc\",\n    \"deleted\": true\n}\n"
        group: administration
        name: Delete user
        returns: Confirmation of the deleted user
    get:
      tags:
        - Users
      summary: Retrieve user
      description: Retrieves a user by their identifier.
      operationId: retrieve-user
      parameters:
        - name: user_id
          in: path
          description: The ID of the user.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: User retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/organization/users/user_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\"\n"
          response: "{\n    \"object\": \"organization.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\n"
        group: administration
        name: Retrieve user
        returns: 'The [User](https://platform.openai.com/docs/api-reference/users/object) object matching the specified ID.'
    post:
      tags:
        - Users
      summary: Modify user
      description: Modifies a user's role in the organization.
      operationId: modify-user
      parameters:
        - name: user_id
          in: path
          description: The ID of the user.
          required: true
          schema:
            type: string
      requestBody:
        description: The new user role to modify. This must be one of `owner` or `member`.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UserRoleUpdateRequest'
        required: true
      responses:
        '200':
          description: User role updated successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/organization/users/user_abc \\\n  -H \"Authorization: Bearer $OPENAI_ADMIN_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"role\": \"owner\"\n  }'\n"
          response: "{\n    \"object\": \"organization.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\n"
        group: administration
        name: Modify user
        returns: 'The updated [User](https://platform.openai.com/docs/api-reference/users/object) object.'
  /realtime/client_secrets:
    post:
      tags:
        - Realtime
      summary: Create realtime session
      description: "Create a Realtime session and client secret for either realtime or transcription.\n"
      operationId: create-realtime-client-secret
      requestBody:
        description: Create a client secret with the given session configuration.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/RealtimeCreateClientSecretRequest'
        required: true
      responses:
        '200':
          description: Client secret created successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RealtimeCreateClientSecretResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/realtime/client_secrets \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"expires_after\": { \"anchor\": \"created_at\", \"seconds\": 600 },\n    \"session\": {\n      \"type\": \"realtime\",\n      \"model\": \"gpt-realtime\",\n      \"instructions\": \"You are a friendly assistant.\"\n    }\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n  \"github.com/openai/openai-go/realtime\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  clientSecret, err := client.Realtime.ClientSecrets.New(context.TODO(), realtime.ClientSecretNewParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", clientSecret.ExpiresAt)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.realtime.clientsecrets.ClientSecretCreateParams;\nimport com.openai.models.realtime.clientsecrets.ClientSecretCreateResponse;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ClientSecretCreateResponse clientSecret = client.realtime().clientSecrets().create();\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst clientSecret = await client.realtime.clientSecrets.create();\n\nconsole.log(clientSecret.expires_at);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nclient_secret = client.realtime.client_secrets.create()\nprint(client_secret.expires_at)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nclient_secret = openai.realtime.client_secrets.create\n\nputs(client_secret)"
          response: "{\n  \"value\": \"ek_68af296e8e408191a1120ab6383263c2\",\n  \"expires_at\": 1756310470,\n  \"session\": {\n    \"type\": \"realtime\",\n    \"object\": \"realtime.session\",\n    \"id\": \"sess_C9CiUVUzUzYIssh3ELY1d\",\n    \"model\": \"gpt-realtime\",\n    \"output_modalities\": [\n      \"audio\"\n    ],\n    \"instructions\": \"You are a friendly assistant.\",\n    \"tools\": [],\n    \"tool_choice\": \"auto\",\n    \"max_output_tokens\": \"inf\",\n    \"tracing\": null,\n    \"truncation\": \"auto\",\n    \"prompt\": null,\n    \"expires_at\": 0,\n    \"audio\": {\n      \"input\": {\n        \"format\": {\n          \"type\": \"audio/pcm\",\n          \"rate\": 24000\n        },\n        \"transcription\": null,\n        \"noise_reduction\": null,\n        \"turn_detection\": {\n          \"type\": \"server_vad\",\n          \"threshold\": 0.5,\n          \"prefix_padding_ms\": 300,\n          \"silence_duration_ms\": 200,\n          \"idle_timeout_ms\": null,\n          \"create_response\": true,\n          \"interrupt_response\": true\n        }\n      },\n      \"output\": {\n        \"format\": {\n          \"type\": \"audio/pcm\",\n          \"rate\": 24000\n        },\n        \"voice\": \"alloy\",\n        \"speed\": 1.0\n      }\n    },\n    \"include\": null\n  }\n}\n"
        group: realtime
        name: Create realtime session
        returns: The created client secret and the effective session object
  /realtime/sessions:
    post:
      tags:
        - Realtime
      summary: Create session
      description: "Create an ephemeral API token for use in client-side applications with the\nRealtime API. Can be configured with the same session parameters as the\n`session.update` client event.\n\nIt responds with a session object, plus a `client_secret` key which contains\na usable ephemeral API token that can be used to authenticate browser clients\nfor the Realtime API.\n"
      operationId: create-realtime-session
      requestBody:
        description: Create an ephemeral API key with the given session configuration.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/RealtimeSessionCreateRequest'
        required: true
      responses:
        '200':
          description: Session created successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RealtimeSessionCreateResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/realtime/sessions \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"gpt-4o-realtime-preview\",\n    \"modalities\": [\"audio\", \"text\"],\n    \"instructions\": \"You are a friendly assistant.\"\n  }'\n"
          response: "{\n  \"id\": \"sess_001\",\n  \"object\": \"realtime.session\",\n  \"model\": \"gpt-4o-realtime-preview\",\n  \"modalities\": [\"audio\", \"text\"],\n  \"instructions\": \"You are a friendly assistant.\",\n  \"voice\": \"alloy\",\n  \"input_audio_format\": \"pcm16\",\n  \"output_audio_format\": \"pcm16\",\n  \"input_audio_transcription\": {\n      \"model\": \"whisper-1\"\n  },\n  \"turn_detection\": null,\n  \"tools\": [],\n  \"tool_choice\": \"none\",\n  \"temperature\": 0.7,\n  \"max_response_output_tokens\": 200,\n  \"speed\": 1.1,\n  \"tracing\": \"auto\",\n  \"client_secret\": {\n    \"value\": \"ek_abc123\", \n    \"expires_at\": 1234567890\n  }\n}\n"
        group: realtime
        name: Create session
        returns: 'The created Realtime session object, plus an ephemeral key'
  /realtime/transcription_sessions:
    post:
      tags:
        - Realtime
      summary: Create transcription session
      description: "Create an ephemeral API token for use in client-side applications with the\nRealtime API specifically for realtime transcriptions. \nCan be configured with the same session parameters as the `transcription_session.update` client event.\n\nIt responds with a session object, plus a `client_secret` key which contains\na usable ephemeral API token that can be used to authenticate browser clients\nfor the Realtime API.\n"
      operationId: create-realtime-transcription-session
      requestBody:
        description: Create an ephemeral API key with the given session configuration.
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/RealtimeTranscriptionSessionCreateRequest'
        required: true
      responses:
        '200':
          description: Session created successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RealtimeTranscriptionSessionCreateResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/realtime/transcription_sessions \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{}'\n"
          response: "{\n  \"id\": \"sess_BBwZc7cFV3XizEyKGDCGL\",\n  \"object\": \"realtime.transcription_session\",\n  \"modalities\": [\"audio\", \"text\"],\n  \"turn_detection\": {\n    \"type\": \"server_vad\",\n    \"threshold\": 0.5,\n    \"prefix_padding_ms\": 300,\n    \"silence_duration_ms\": 200\n  },\n  \"input_audio_format\": \"pcm16\",\n  \"input_audio_transcription\": {\n    \"model\": \"gpt-4o-transcribe\",\n    \"language\": null,\n    \"prompt\": \"\"\n  },\n  \"client_secret\": null\n}\n"
        group: realtime
        name: Create transcription session
        returns: 'The created [Realtime transcription session object](https://platform.openai.com/docs/api-reference/realtime-sessions/transcription_session_object), plus an ephemeral key'
  /responses:
    post:
      tags:
        - Responses
      summary: Create a model response
      description: "Creates a model response. Provide [text](https://platform.openai.com/docs/guides/text) or\n[image](https://platform.openai.com/docs/guides/images) inputs to generate [text](https://platform.openai.com/docs/guides/text)\nor [JSON](https://platform.openai.com/docs/guides/structured-outputs) outputs. Have the model call\nyour own [custom code](https://platform.openai.com/docs/guides/function-calling) or use built-in\n[tools](https://platform.openai.com/docs/guides/tools) like [web search](https://platform.openai.com/docs/guides/tools-web-search)\nor [file search](https://platform.openai.com/docs/guides/tools-file-search) to use your own data\nas input for the model's response.\n"
      operationId: createResponse
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateResponse'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Response'
            text/event-stream:
              schema:
                $ref: '#/components/schemas/ResponseStreamEvent'
      x-oaiMeta:
        example:
          request:
            csharp: "using System;\nusing OpenAI.Responses;\n\nOpenAIResponseClient client = new(\n    model: \"gpt-4.1\",\n    apiKey: Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nOpenAIResponse response = client.CreateResponse(\"Tell me a three sentence bedtime story about a unicorn.\");\n\nConsole.WriteLine(response.GetOutputText());\n"
            curl: "curl https://api.openai.com/v1/responses \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-4.1\",\n    \"input\": \"Tell me a three sentence bedtime story about a unicorn.\"\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n  \"github.com/openai/openai-go/responses\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  response, err := client.Responses.New(context.TODO(), responses.ResponseNewParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", response.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.responses.Response;\nimport com.openai.models.responses.ResponseCreateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        Response response = client.responses().create();\n    }\n}"
            javascript: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nconst response = await openai.responses.create({\n    model: \"gpt-4.1\",\n    input: \"Tell me a three sentence bedtime story about a unicorn.\"\n});\n\nconsole.log(response);\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst response = await client.responses.create();\n\nconsole.log(response.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nresponse = client.responses.create()\nprint(response.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nresponse = openai.responses.create\n\nputs(response)"
          response: "{\n  \"id\": \"resp_67ccd2bed1ec8190b14f964abc0542670bb6a6b452d3795b\",\n  \"object\": \"response\",\n  \"created_at\": 1741476542,\n  \"status\": \"completed\",\n  \"error\": null,\n  \"incomplete_details\": null,\n  \"instructions\": null,\n  \"max_output_tokens\": null,\n  \"model\": \"gpt-4.1-2025-04-14\",\n  \"output\": [\n    {\n      \"type\": \"message\",\n      \"id\": \"msg_67ccd2bf17f0819081ff3bb2cf6508e60bb6a6b452d3795b\",\n      \"status\": \"completed\",\n      \"role\": \"assistant\",\n      \"content\": [\n        {\n          \"type\": \"output_text\",\n          \"text\": \"In a peaceful grove beneath a silver moon, a unicorn named Lumina discovered a hidden pool that reflected the stars. As she dipped her horn into the water, the pool began to shimmer, revealing a pathway to a magical realm of endless night skies. Filled with wonder, Lumina whispered a wish for all who dream to find their own hidden magic, and as she glanced back, her hoofprints sparkled like stardust.\",\n          \"annotations\": []\n        }\n      ]\n    }\n  ],\n  \"parallel_tool_calls\": true,\n  \"previous_response_id\": null,\n  \"reasoning\": {\n    \"effort\": null,\n    \"summary\": null\n  },\n  \"store\": true,\n  \"temperature\": 1.0,\n  \"text\": {\n    \"format\": {\n      \"type\": \"text\"\n    }\n  },\n  \"tool_choice\": \"auto\",\n  \"tools\": [],\n  \"top_p\": 1.0,\n  \"truncation\": \"disabled\",\n  \"usage\": {\n    \"input_tokens\": 36,\n    \"input_tokens_details\": {\n      \"cached_tokens\": 0\n    },\n    \"output_tokens\": 87,\n    \"output_tokens_details\": {\n      \"reasoning_tokens\": 0\n    },\n    \"total_tokens\": 123\n  },\n  \"user\": null,\n  \"metadata\": {}\n}\n"
          title: Text input
        group: responses
        name: Create a model response
        path: create
        returns: "Returns a [Response](https://platform.openai.com/docs/api-reference/responses/object) object.\n"
  '/responses/{response_id}':
    delete:
      tags:
        - Responses
      summary: Delete a model response
      description: "Deletes a model response with the given ID.\n"
      operationId: deleteResponse
      parameters:
        - name: response_id
          in: path
          description: The ID of the response to delete.
          required: true
          schema:
            type: string
            example: resp_677efb5139a88190b512bc3fef8e535d
      responses:
        '200':
          description: OK
        '404':
          description: Not Found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/responses/resp_123 \\\n    -H \"Content-Type: application/json\" \\\n    -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  err := client.Responses.Delete(context.TODO(), \"resp_677efb5139a88190b512bc3fef8e535d\")\n  if err != nil {\n    panic(err.Error())\n  }\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.responses.ResponseDeleteParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        client.responses().delete(\"resp_677efb5139a88190b512bc3fef8e535d\");\n    }\n}"
            javascript: "import OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst response = await client.responses.delete(\"resp_123\");\nconsole.log(response);\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nawait client.responses.delete('resp_677efb5139a88190b512bc3fef8e535d');"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nclient.responses.delete(\n    \"resp_677efb5139a88190b512bc3fef8e535d\",\n)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nresult = openai.responses.delete(\"resp_677efb5139a88190b512bc3fef8e535d\")\n\nputs(result)"
          response: "{\n  \"id\": \"resp_6786a1bec27481909a17d673315b29f6\",\n  \"object\": \"response\",\n  \"deleted\": true\n}\n"
        group: responses
        name: Delete a model response
        returns: "A success message.\n"
    get:
      tags:
        - Responses
      summary: Get a model response
      description: "Retrieves a model response with the given ID.\n"
      operationId: getResponse
      parameters:
        - name: response_id
          in: path
          description: The ID of the response to retrieve.
          required: true
          schema:
            type: string
            example: resp_677efb5139a88190b512bc3fef8e535d
        - name: include
          in: query
          description: "Additional fields to include in the response. See the `include`\nparameter for Response creation above for more information.\n"
          schema:
            type: array
            items:
              $ref: '#/components/schemas/Includable'
        - name: stream
          in: query
          description: "If set to true, the model response data will be streamed to the client\nas it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\nSee the [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\nfor more information.\n"
          schema:
            type: boolean
        - name: starting_after
          in: query
          description: "The sequence number of the event after which to start streaming.\n"
          schema:
            type: integer
        - name: include_obfuscation
          in: query
          description: "When true, stream obfuscation will be enabled. Stream obfuscation adds\nrandom characters to an `obfuscation` field on streaming delta events\nto normalize payload sizes as a mitigation to certain side-channel\nattacks. These obfuscation fields are included by default, but add a\nsmall amount of overhead to the data stream. You can set\n`include_obfuscation` to false to optimize for bandwidth if you trust\nthe network links between your application and the OpenAI API.\n"
          schema:
            type: boolean
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Response'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/responses/resp_123 \\\n    -H \"Content-Type: application/json\" \\\n    -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n  \"github.com/openai/openai-go/responses\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  response, err := client.Responses.Get(\n    context.TODO(),\n    \"resp_677efb5139a88190b512bc3fef8e535d\",\n    responses.ResponseGetParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", response.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.responses.Response;\nimport com.openai.models.responses.ResponseRetrieveParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        Response response = client.responses().retrieve(\"resp_677efb5139a88190b512bc3fef8e535d\");\n    }\n}"
            javascript: "import OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst response = await client.responses.retrieve(\"resp_123\");\nconsole.log(response);\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst response = await client.responses.retrieve('resp_677efb5139a88190b512bc3fef8e535d');\n\nconsole.log(response.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nresponse = client.responses.retrieve(\n    response_id=\"resp_677efb5139a88190b512bc3fef8e535d\",\n)\nprint(response.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nresponse = openai.responses.retrieve(\"resp_677efb5139a88190b512bc3fef8e535d\")\n\nputs(response)"
          response: "{\n  \"id\": \"resp_67cb71b351908190a308f3859487620d06981a8637e6bc44\",\n  \"object\": \"response\",\n  \"created_at\": 1741386163,\n  \"status\": \"completed\",\n  \"error\": null,\n  \"incomplete_details\": null,\n  \"instructions\": null,\n  \"max_output_tokens\": null,\n  \"model\": \"gpt-4o-2024-08-06\",\n  \"output\": [\n    {\n      \"type\": \"message\",\n      \"id\": \"msg_67cb71b3c2b0819084d481baaaf148f206981a8637e6bc44\",\n      \"status\": \"completed\",\n      \"role\": \"assistant\",\n      \"content\": [\n        {\n          \"type\": \"output_text\",\n          \"text\": \"Silent circuits hum,  \\nThoughts emerge in data streams—  \\nDigital dawn breaks.\",\n          \"annotations\": []\n        }\n      ]\n    }\n  ],\n  \"parallel_tool_calls\": true,\n  \"previous_response_id\": null,\n  \"reasoning\": {\n    \"effort\": null,\n    \"summary\": null\n  },\n  \"store\": true,\n  \"temperature\": 1.0,\n  \"text\": {\n    \"format\": {\n      \"type\": \"text\"\n    }\n  },\n  \"tool_choice\": \"auto\",\n  \"tools\": [],\n  \"top_p\": 1.0,\n  \"truncation\": \"disabled\",\n  \"usage\": {\n    \"input_tokens\": 32,\n    \"input_tokens_details\": {\n      \"cached_tokens\": 0\n    },\n    \"output_tokens\": 18,\n    \"output_tokens_details\": {\n      \"reasoning_tokens\": 0\n    },\n    \"total_tokens\": 50\n  },\n  \"user\": null,\n  \"metadata\": {}\n}\n"
        group: responses
        name: Get a model response
        returns: "The [Response](https://platform.openai.com/docs/api-reference/responses/object) object matching the\nspecified ID.\n"
  '/responses/{response_id}/cancel':
    post:
      tags:
        - Responses
      summary: Cancel a response
      description: "Cancels a model response with the given ID. Only responses created with\nthe `background` parameter set to `true` can be cancelled. \n[Learn more](https://platform.openai.com/docs/guides/background).\n"
      operationId: cancelResponse
      parameters:
        - name: response_id
          in: path
          description: The ID of the response to cancel.
          required: true
          schema:
            type: string
            example: resp_677efb5139a88190b512bc3fef8e535d
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Response'
        '404':
          description: Not Found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/responses/resp_123/cancel \\\n    -H \"Content-Type: application/json\" \\\n    -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  response, err := client.Responses.Cancel(context.TODO(), \"resp_677efb5139a88190b512bc3fef8e535d\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", response.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.responses.Response;\nimport com.openai.models.responses.ResponseCancelParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        Response response = client.responses().cancel(\"resp_677efb5139a88190b512bc3fef8e535d\");\n    }\n}"
            javascript: "import OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst response = await client.responses.cancel(\"resp_123\");\nconsole.log(response);  \n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst response = await client.responses.cancel('resp_677efb5139a88190b512bc3fef8e535d');\n\nconsole.log(response.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nresponse = client.responses.cancel(\n    \"resp_677efb5139a88190b512bc3fef8e535d\",\n)\nprint(response.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nresponse = openai.responses.cancel(\"resp_677efb5139a88190b512bc3fef8e535d\")\n\nputs(response)"
          response: "{\n  \"id\": \"resp_67cb71b351908190a308f3859487620d06981a8637e6bc44\",\n  \"object\": \"response\",\n  \"created_at\": 1741386163,\n  \"status\": \"completed\",\n  \"error\": null,\n  \"incomplete_details\": null,\n  \"instructions\": null,\n  \"max_output_tokens\": null,\n  \"model\": \"gpt-4o-2024-08-06\",\n  \"output\": [\n    {\n      \"type\": \"message\",\n      \"id\": \"msg_67cb71b3c2b0819084d481baaaf148f206981a8637e6bc44\",\n      \"status\": \"completed\",\n      \"role\": \"assistant\",\n      \"content\": [\n        {\n          \"type\": \"output_text\",\n          \"text\": \"Silent circuits hum,  \\nThoughts emerge in data streams—  \\nDigital dawn breaks.\",\n          \"annotations\": []\n        }\n      ]\n    }\n  ],\n  \"parallel_tool_calls\": true,\n  \"previous_response_id\": null,\n  \"reasoning\": {\n    \"effort\": null,\n    \"summary\": null\n  },\n  \"store\": true,\n  \"temperature\": 1.0,\n  \"text\": {\n    \"format\": {\n      \"type\": \"text\"\n    }\n  },\n  \"tool_choice\": \"auto\",\n  \"tools\": [],\n  \"top_p\": 1.0,\n  \"truncation\": \"disabled\",\n  \"usage\": {\n    \"input_tokens\": 32,\n    \"input_tokens_details\": {\n      \"cached_tokens\": 0\n    },\n    \"output_tokens\": 18,\n    \"output_tokens_details\": {\n      \"reasoning_tokens\": 0\n    },\n    \"total_tokens\": 50\n  },\n  \"user\": null,\n  \"metadata\": {}\n}\n"
        group: responses
        name: Cancel a response
        returns: "A [Response](https://platform.openai.com/docs/api-reference/responses/object) object.\n"
  '/responses/{response_id}/input_items':
    get:
      tags:
        - Responses
      summary: List input items
      description: Returns a list of input items for a given response.
      operationId: listInputItems
      parameters:
        - name: response_id
          in: path
          description: The ID of the response to retrieve input items for.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between\n1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: "The order to return the input items in. Default is `desc`.\n- `asc`: Return the input items in ascending order.\n- `desc`: Return the input items in descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
        - name: after
          in: query
          description: "An item ID to list items after, used in pagination.\n"
          schema:
            type: string
        - name: include
          in: query
          description: "Additional fields to include in the response. See the `include`\nparameter for Response creation above for more information.\n"
          schema:
            type: array
            items:
              $ref: '#/components/schemas/Includable'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ResponseItemList'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/responses/resp_abc123/input_items \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n  \"github.com/openai/openai-go/responses\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.Responses.InputItems.List(\n    context.TODO(),\n    \"response_id\",\n    responses.InputItemListParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.responses.inputitems.InputItemListPage;\nimport com.openai.models.responses.inputitems.InputItemListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        InputItemListPage page = client.responses().inputItems().list(\"response_id\");\n    }\n}"
            javascript: "import OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst response = await client.responses.inputItems.list(\"resp_123\");\nconsole.log(response.data);\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const responseItem of client.responses.inputItems.list('response_id')) {\n  console.log(responseItem);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.responses.input_items.list(\n    response_id=\"response_id\",\n)\npage = page.data[0]\nprint(page)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.responses.input_items.list(\"response_id\")\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"msg_abc123\",\n      \"type\": \"message\",\n      \"role\": \"user\",\n      \"content\": [\n        {\n          \"type\": \"input_text\",\n          \"text\": \"Tell me a three sentence bedtime story about a unicorn.\"\n        }\n      ]\n    }\n  ],\n  \"first_id\": \"msg_abc123\",\n  \"last_id\": \"msg_abc123\",\n  \"has_more\": false\n}\n"
        group: responses
        name: List input items
        returns: A list of input item objects.
  /threads:
    post:
      tags:
        - Assistants
      summary: Create thread
      description: Create a thread.
      operationId: createThread
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateThreadRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
      x-oaiMeta:
        beta: true
        example:
          request:
            curl: "curl https://api.openai.com/v1/threads \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d ''\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  thread, err := client.Beta.Threads.New(context.TODO(), openai.BetaThreadNewParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", thread.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.threads.Thread;\nimport com.openai.models.beta.threads.ThreadCreateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        Thread thread = client.beta().threads().create();\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst thread = await client.beta.threads.create();\n\nconsole.log(thread.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nthread = client.beta.threads.create()\nprint(thread.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nthread = openai.beta.threads.create\n\nputs(thread)"
          response: "{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n  \"created_at\": 1699012949,\n  \"metadata\": {},\n  \"tool_resources\": {}\n}\n"
          title: Empty
        group: threads
        name: Create thread
        returns: 'A [thread](https://platform.openai.com/docs/api-reference/threads) object.'
  /threads/runs:
    post:
      tags:
        - Assistants
      summary: Create thread and run
      description: Create a thread and run it in one request.
      operationId: createThreadAndRun
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateThreadAndRunRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        beta: true
        example:
          request:
            curl: "curl https://api.openai.com/v1/threads/runs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n      \"assistant_id\": \"asst_abc123\",\n      \"thread\": {\n        \"messages\": [\n          {\"role\": \"user\", \"content\": \"Explain deep learning to a 5 year old.\"}\n        ]\n      }\n    }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  run, err := client.Beta.Threads.NewAndRun(context.TODO(), openai.BetaThreadNewAndRunParams{\n    AssistantID: \"assistant_id\",\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", run.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.threads.ThreadCreateAndRunParams;\nimport com.openai.models.beta.threads.runs.Run;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ThreadCreateAndRunParams params = ThreadCreateAndRunParams.builder()\n            .assistantId(\"assistant_id\")\n            .build();\n        Run run = client.beta().threads().createAndRun(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst run = await client.beta.threads.createAndRun({ assistant_id: 'assistant_id' });\n\nconsole.log(run.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nrun = client.beta.threads.create_and_run(\n    assistant_id=\"assistant_id\",\n)\nprint(run.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nrun = openai.beta.threads.create_and_run(assistant_id: \"assistant_id\")\n\nputs(run)"
          response: "{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699076792,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"queued\",\n  \"started_at\": null,\n  \"expires_at\": 1699077392,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": null,\n  \"required_action\": null,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You are a helpful assistant.\",\n  \"tools\": [],\n  \"tool_resources\": {},\n  \"metadata\": {},\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_completion_tokens\": null,\n  \"max_prompt_tokens\": null,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"incomplete_details\": null,\n  \"usage\": null,\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\n"
          title: Default
        group: threads
        name: Create thread and run
        returns: 'A [run](https://platform.openai.com/docs/api-reference/runs/object) object.'
  '/threads/{thread_id}':
    delete:
      tags:
        - Assistants
      summary: Delete thread
      description: Delete a thread.
      operationId: deleteThread
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread to delete.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteThreadResponse'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -X DELETE\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  threadDeleted, err := client.Beta.Threads.Delete(context.TODO(), \"thread_id\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", threadDeleted.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.threads.ThreadDeleteParams;\nimport com.openai.models.beta.threads.ThreadDeleted;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        ThreadDeleted threadDeleted = client.beta().threads().delete(\"thread_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst threadDeleted = await client.beta.threads.delete('thread_id');\n\nconsole.log(threadDeleted.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nthread_deleted = client.beta.threads.delete(\n    \"thread_id\",\n)\nprint(thread_deleted.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nthread_deleted = openai.beta.threads.delete(\"thread_id\")\n\nputs(thread_deleted)"
          response: "{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread.deleted\",\n  \"deleted\": true\n}\n"
        group: threads
        name: Delete thread
        returns: Deletion status
    get:
      tags:
        - Assistants
      summary: Retrieve thread
      description: Retrieves a thread.
      operationId: getThread
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  thread, err := client.Beta.Threads.Get(context.TODO(), \"thread_id\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", thread.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.threads.Thread;\nimport com.openai.models.beta.threads.ThreadRetrieveParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        Thread thread = client.beta().threads().retrieve(\"thread_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst thread = await client.beta.threads.retrieve('thread_id');\n\nconsole.log(thread.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nthread = client.beta.threads.retrieve(\n    \"thread_id\",\n)\nprint(thread.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nthread = openai.beta.threads.retrieve(\"thread_id\")\n\nputs(thread)"
          response: "{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n  \"created_at\": 1699014083,\n  \"metadata\": {},\n  \"tool_resources\": {\n    \"code_interpreter\": {\n      \"file_ids\": []\n    }\n  }\n}\n"
        group: threads
        name: Retrieve thread
        returns: 'The [thread](https://platform.openai.com/docs/api-reference/threads/object) object matching the specified ID.'
    post:
      tags:
        - Assistants
      summary: Modify thread
      description: Modifies a thread.
      operationId: modifyThread
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread to modify. Only the `metadata` can be modified.
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyThreadRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n      \"metadata\": {\n        \"modified\": \"true\",\n        \"user\": \"abc123\"\n      }\n    }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  thread, err := client.Beta.Threads.Update(\n    context.TODO(),\n    \"thread_id\",\n    openai.BetaThreadUpdateParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", thread.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.threads.Thread;\nimport com.openai.models.beta.threads.ThreadUpdateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        Thread thread = client.beta().threads().update(\"thread_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst thread = await client.beta.threads.update('thread_id');\n\nconsole.log(thread.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nthread = client.beta.threads.update(\n    thread_id=\"thread_id\",\n)\nprint(thread.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nthread = openai.beta.threads.update(\"thread_id\")\n\nputs(thread)"
          response: "{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n  \"created_at\": 1699014083,\n  \"metadata\": {\n    \"modified\": \"true\",\n    \"user\": \"abc123\"\n  },\n  \"tool_resources\": {}\n}\n"
        group: threads
        name: Modify thread
        returns: 'The modified [thread](https://platform.openai.com/docs/api-reference/threads/object) object matching the specified ID.'
  '/threads/{thread_id}/messages':
    get:
      tags:
        - Assistants
      summary: List messages
      description: Returns a list of messages for a given thread.
      operationId: listMessages
      parameters:
        - name: thread_id
          in: path
          description: 'The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) the messages belong to.'
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: before
          in: query
          description: "A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n"
          schema:
            type: string
        - name: run_id
          in: query
          description: "Filter messages by the run ID that generated them.\n"
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListMessagesResponse'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/messages \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.Beta.Threads.Messages.List(\n    context.TODO(),\n    \"thread_id\",\n    openai.BetaThreadMessageListParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.threads.messages.MessageListPage;\nimport com.openai.models.beta.threads.messages.MessageListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        MessageListPage page = client.beta().threads().messages().list(\"thread_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const message of client.beta.threads.messages.list('thread_id')) {\n  console.log(message.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.beta.threads.messages.list(\n    thread_id=\"thread_id\",\n)\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.beta.threads.messages.list(\"thread_id\")\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"msg_abc123\",\n      \"object\": \"thread.message\",\n      \"created_at\": 1699016383,\n      \"assistant_id\": null,\n      \"thread_id\": \"thread_abc123\",\n      \"run_id\": null,\n      \"role\": \"user\",\n      \"content\": [\n        {\n          \"type\": \"text\",\n          \"text\": {\n            \"value\": \"How does AI work? Explain it in simple terms.\",\n            \"annotations\": []\n          }\n        }\n      ],\n      \"attachments\": [],\n      \"metadata\": {}\n    },\n    {\n      \"id\": \"msg_abc456\",\n      \"object\": \"thread.message\",\n      \"created_at\": 1699016383,\n      \"assistant_id\": null,\n      \"thread_id\": \"thread_abc123\",\n      \"run_id\": null,\n      \"role\": \"user\",\n      \"content\": [\n        {\n          \"type\": \"text\",\n          \"text\": {\n            \"value\": \"Hello, what is AI?\",\n            \"annotations\": []\n          }\n        }\n      ],\n      \"attachments\": [],\n      \"metadata\": {}\n    }\n  ],\n  \"first_id\": \"msg_abc123\",\n  \"last_id\": \"msg_abc456\",\n  \"has_more\": false\n}\n"
        group: threads
        name: List messages
        returns: 'A list of [message](https://platform.openai.com/docs/api-reference/messages) objects.'
    post:
      tags:
        - Assistants
      summary: Create message
      description: Create a message.
      operationId: createMessage
      parameters:
        - name: thread_id
          in: path
          description: 'The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) to create a message for.'
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateMessageRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/messages \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n      \"role\": \"user\",\n      \"content\": \"How does AI work? Explain it in simple terms.\"\n    }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  message, err := client.Beta.Threads.Messages.New(\n    context.TODO(),\n    \"thread_id\",\n    openai.BetaThreadMessageNewParams{\n      Content: openai.BetaThreadMessageNewParamsContentUnion{\n        OfString: openai.String(\"string\"),\n      },\n      Role: openai.BetaThreadMessageNewParamsRoleUser,\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", message.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.threads.messages.Message;\nimport com.openai.models.beta.threads.messages.MessageCreateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        MessageCreateParams params = MessageCreateParams.builder()\n            .threadId(\"thread_id\")\n            .content(\"string\")\n            .role(MessageCreateParams.Role.USER)\n            .build();\n        Message message = client.beta().threads().messages().create(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst message = await client.beta.threads.messages.create('thread_id', { content: 'string', role: 'user' });\n\nconsole.log(message.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nmessage = client.beta.threads.messages.create(\n    thread_id=\"thread_id\",\n    content=\"string\",\n    role=\"user\",\n)\nprint(message.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nmessage = openai.beta.threads.messages.create(\"thread_id\", content: \"string\", role: :user)\n\nputs(message)"
          response: "{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\",\n  \"created_at\": 1713226573,\n  \"assistant_id\": null,\n  \"thread_id\": \"thread_abc123\",\n  \"run_id\": null,\n  \"role\": \"user\",\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"value\": \"How does AI work? Explain it in simple terms.\",\n        \"annotations\": []\n      }\n    }\n  ],\n  \"attachments\": [],\n  \"metadata\": {}\n}\n"
        group: threads
        name: Create message
        returns: 'A [message](https://platform.openai.com/docs/api-reference/messages/object) object.'
  '/threads/{thread_id}/messages/{message_id}':
    delete:
      tags:
        - Assistants
      summary: Delete message
      description: Deletes a message.
      operationId: deleteMessage
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread to which this message belongs.
          required: true
          schema:
            type: string
        - name: message_id
          in: path
          description: The ID of the message to delete.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteMessageResponse'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  messageDeleted, err := client.Beta.Threads.Messages.Delete(\n    context.TODO(),\n    \"thread_id\",\n    \"message_id\",\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", messageDeleted.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.threads.messages.MessageDeleteParams;\nimport com.openai.models.beta.threads.messages.MessageDeleted;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        MessageDeleteParams params = MessageDeleteParams.builder()\n            .threadId(\"thread_id\")\n            .messageId(\"message_id\")\n            .build();\n        MessageDeleted messageDeleted = client.beta().threads().messages().delete(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst messageDeleted = await client.beta.threads.messages.delete('message_id', { thread_id: 'thread_id' });\n\nconsole.log(messageDeleted.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nmessage_deleted = client.beta.threads.messages.delete(\n    message_id=\"message_id\",\n    thread_id=\"thread_id\",\n)\nprint(message_deleted.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nmessage_deleted = openai.beta.threads.messages.delete(\"message_id\", thread_id: \"thread_id\")\n\nputs(message_deleted)"
          response: "{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message.deleted\",\n  \"deleted\": true\n}\n"
        group: threads
        name: Delete message
        returns: Deletion status
    get:
      tags:
        - Assistants
      summary: Retrieve message
      description: Retrieve a message.
      operationId: getMessage
      parameters:
        - name: thread_id
          in: path
          description: 'The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) to which this message belongs.'
          required: true
          schema:
            type: string
        - name: message_id
          in: path
          description: The ID of the message to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  message, err := client.Beta.Threads.Messages.Get(\n    context.TODO(),\n    \"thread_id\",\n    \"message_id\",\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", message.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.threads.messages.Message;\nimport com.openai.models.beta.threads.messages.MessageRetrieveParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        MessageRetrieveParams params = MessageRetrieveParams.builder()\n            .threadId(\"thread_id\")\n            .messageId(\"message_id\")\n            .build();\n        Message message = client.beta().threads().messages().retrieve(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst message = await client.beta.threads.messages.retrieve('message_id', { thread_id: 'thread_id' });\n\nconsole.log(message.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nmessage = client.beta.threads.messages.retrieve(\n    message_id=\"message_id\",\n    thread_id=\"thread_id\",\n)\nprint(message.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nmessage = openai.beta.threads.messages.retrieve(\"message_id\", thread_id: \"thread_id\")\n\nputs(message)"
          response: "{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\",\n  \"created_at\": 1699017614,\n  \"assistant_id\": null,\n  \"thread_id\": \"thread_abc123\",\n  \"run_id\": null,\n  \"role\": \"user\",\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"value\": \"How does AI work? Explain it in simple terms.\",\n        \"annotations\": []\n      }\n    }\n  ],\n  \"attachments\": [],\n  \"metadata\": {}\n}\n"
        group: threads
        name: Retrieve message
        returns: 'The [message](https://platform.openai.com/docs/api-reference/messages/object) object matching the specified ID.'
    post:
      tags:
        - Assistants
      summary: Modify message
      description: Modifies a message.
      operationId: modifyMessage
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread to which this message belongs.
          required: true
          schema:
            type: string
        - name: message_id
          in: path
          description: The ID of the message to modify.
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyMessageRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n      \"metadata\": {\n        \"modified\": \"true\",\n        \"user\": \"abc123\"\n      }\n    }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  message, err := client.Beta.Threads.Messages.Update(\n    context.TODO(),\n    \"thread_id\",\n    \"message_id\",\n    openai.BetaThreadMessageUpdateParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", message.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.threads.messages.Message;\nimport com.openai.models.beta.threads.messages.MessageUpdateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        MessageUpdateParams params = MessageUpdateParams.builder()\n            .threadId(\"thread_id\")\n            .messageId(\"message_id\")\n            .build();\n        Message message = client.beta().threads().messages().update(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst message = await client.beta.threads.messages.update('message_id', { thread_id: 'thread_id' });\n\nconsole.log(message.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nmessage = client.beta.threads.messages.update(\n    message_id=\"message_id\",\n    thread_id=\"thread_id\",\n)\nprint(message.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nmessage = openai.beta.threads.messages.update(\"message_id\", thread_id: \"thread_id\")\n\nputs(message)"
          response: "{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\",\n  \"created_at\": 1699017614,\n  \"assistant_id\": null,\n  \"thread_id\": \"thread_abc123\",\n  \"run_id\": null,\n  \"role\": \"user\",\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"value\": \"How does AI work? Explain it in simple terms.\",\n        \"annotations\": []\n      }\n    }\n  ],\n  \"file_ids\": [],\n  \"metadata\": {\n    \"modified\": \"true\",\n    \"user\": \"abc123\"\n  }\n}\n"
        group: threads
        name: Modify message
        returns: 'The modified [message](https://platform.openai.com/docs/api-reference/messages/object) object.'
  '/threads/{thread_id}/runs':
    get:
      tags:
        - Assistants
      summary: List runs
      description: Returns a list of runs belonging to a thread.
      operationId: listRuns
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread the run belongs to.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: before
          in: query
          description: "A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListRunsResponse'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.Beta.Threads.Runs.List(\n    context.TODO(),\n    \"thread_id\",\n    openai.BetaThreadRunListParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.threads.runs.RunListPage;\nimport com.openai.models.beta.threads.runs.RunListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        RunListPage page = client.beta().threads().runs().list(\"thread_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const run of client.beta.threads.runs.list('thread_id')) {\n  console.log(run.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.beta.threads.runs.list(\n    thread_id=\"thread_id\",\n)\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.beta.threads.runs.list(\"thread_id\")\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"run_abc123\",\n      \"object\": \"thread.run\",\n      \"created_at\": 1699075072,\n      \"assistant_id\": \"asst_abc123\",\n      \"thread_id\": \"thread_abc123\",\n      \"status\": \"completed\",\n      \"started_at\": 1699075072,\n      \"expires_at\": null,\n      \"cancelled_at\": null,\n      \"failed_at\": null,\n      \"completed_at\": 1699075073,\n      \"last_error\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": null,\n      \"incomplete_details\": null,\n      \"tools\": [\n        {\n          \"type\": \"code_interpreter\"\n        }\n      ],\n      \"tool_resources\": {\n        \"code_interpreter\": {\n          \"file_ids\": [\n            \"file-abc123\",\n            \"file-abc456\"\n          ]\n        }\n      },\n      \"metadata\": {},\n      \"usage\": {\n        \"prompt_tokens\": 123,\n        \"completion_tokens\": 456,\n        \"total_tokens\": 579\n      },\n      \"temperature\": 1.0,\n      \"top_p\": 1.0,\n      \"max_prompt_tokens\": 1000,\n      \"max_completion_tokens\": 1000,\n      \"truncation_strategy\": {\n        \"type\": \"auto\",\n        \"last_messages\": null\n      },\n      \"response_format\": \"auto\",\n      \"tool_choice\": \"auto\",\n      \"parallel_tool_calls\": true\n    },\n    {\n      \"id\": \"run_abc456\",\n      \"object\": \"thread.run\",\n      \"created_at\": 1699063290,\n      \"assistant_id\": \"asst_abc123\",\n      \"thread_id\": \"thread_abc123\",\n      \"status\": \"completed\",\n      \"started_at\": 1699063290,\n      \"expires_at\": null,\n      \"cancelled_at\": null,\n      \"failed_at\": null,\n      \"completed_at\": 1699063291,\n      \"last_error\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": null,\n      \"incomplete_details\": null,\n      \"tools\": [\n        {\n          \"type\": \"code_interpreter\"\n        }\n      ],\n      \"tool_resources\": {\n        \"code_interpreter\": {\n          \"file_ids\": [\n            \"file-abc123\",\n            \"file-abc456\"\n          ]\n        }\n      },\n      \"metadata\": {},\n      \"usage\": {\n        \"prompt_tokens\": 123,\n        \"completion_tokens\": 456,\n        \"total_tokens\": 579\n      },\n      \"temperature\": 1.0,\n      \"top_p\": 1.0,\n      \"max_prompt_tokens\": 1000,\n      \"max_completion_tokens\": 1000,\n      \"truncation_strategy\": {\n        \"type\": \"auto\",\n        \"last_messages\": null\n      },\n      \"response_format\": \"auto\",\n      \"tool_choice\": \"auto\",\n      \"parallel_tool_calls\": true\n    }\n  ],\n  \"first_id\": \"run_abc123\",\n  \"last_id\": \"run_abc456\",\n  \"has_more\": false\n}\n"
        group: threads
        name: List runs
        returns: 'A list of [run](https://platform.openai.com/docs/api-reference/runs/object) objects.'
    post:
      tags:
        - Assistants
      summary: Create run
      description: Create a run.
      operationId: createRun
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread to run.
          required: true
          schema:
            type: string
        - name: 'include[]'
          in: query
          description: "A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n"
          schema:
            type: array
            items:
              enum:
                - 'step_details.tool_calls[*].file_search.results[*].content'
              type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateRunRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        beta: true
        example:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"assistant_id\": \"asst_abc123\"\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  run, err := client.Beta.Threads.Runs.New(\n    context.TODO(),\n    \"thread_id\",\n    openai.BetaThreadRunNewParams{\n      AssistantID: \"assistant_id\",\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", run.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.threads.runs.Run;\nimport com.openai.models.beta.threads.runs.RunCreateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        RunCreateParams params = RunCreateParams.builder()\n            .threadId(\"thread_id\")\n            .assistantId(\"assistant_id\")\n            .build();\n        Run run = client.beta().threads().runs().create(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst run = await client.beta.threads.runs.create('thread_id', { assistant_id: 'assistant_id' });\n\nconsole.log(run.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nrun = client.beta.threads.runs.create(\n    thread_id=\"thread_id\",\n    assistant_id=\"assistant_id\",\n)\nprint(run.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nrun = openai.beta.threads.runs.create(\"thread_id\", assistant_id: \"assistant_id\")\n\nputs(run)"
          response: "{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699063290,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"queued\",\n  \"started_at\": 1699063290,\n  \"expires_at\": null,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": 1699063291,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": null,\n  \"incomplete_details\": null,\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n  \"usage\": null,\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\": 1000,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\n"
          title: Default
        group: threads
        name: Create run
        returns: 'A [run](https://platform.openai.com/docs/api-reference/runs/object) object.'
  '/threads/{thread_id}/runs/{run_id}':
    get:
      tags:
        - Assistants
      summary: Retrieve run
      description: Retrieves a run.
      operationId: getRun
      parameters:
        - name: thread_id
          in: path
          description: 'The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was run.'
          required: true
          schema:
            type: string
        - name: run_id
          in: path
          description: The ID of the run to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  run, err := client.Beta.Threads.Runs.Get(\n    context.TODO(),\n    \"thread_id\",\n    \"run_id\",\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", run.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.threads.runs.Run;\nimport com.openai.models.beta.threads.runs.RunRetrieveParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        RunRetrieveParams params = RunRetrieveParams.builder()\n            .threadId(\"thread_id\")\n            .runId(\"run_id\")\n            .build();\n        Run run = client.beta().threads().runs().retrieve(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst run = await client.beta.threads.runs.retrieve('run_id', { thread_id: 'thread_id' });\n\nconsole.log(run.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nrun = client.beta.threads.runs.retrieve(\n    run_id=\"run_id\",\n    thread_id=\"thread_id\",\n)\nprint(run.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nrun = openai.beta.threads.runs.retrieve(\"run_id\", thread_id: \"thread_id\")\n\nputs(run)"
          response: "{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699075072,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"completed\",\n  \"started_at\": 1699075072,\n  \"expires_at\": null,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": 1699075073,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": null,\n  \"incomplete_details\": null,\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  },\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\": 1000,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\n"
        group: threads
        name: Retrieve run
        returns: 'The [run](https://platform.openai.com/docs/api-reference/runs/object) object matching the specified ID.'
    post:
      tags:
        - Assistants
      summary: Modify run
      description: Modifies a run.
      operationId: modifyRun
      parameters:
        - name: thread_id
          in: path
          description: 'The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was run.'
          required: true
          schema:
            type: string
        - name: run_id
          in: path
          description: The ID of the run to modify.
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyRunRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"metadata\": {\n      \"user_id\": \"user_abc123\"\n    }\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  run, err := client.Beta.Threads.Runs.Update(\n    context.TODO(),\n    \"thread_id\",\n    \"run_id\",\n    openai.BetaThreadRunUpdateParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", run.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.threads.runs.Run;\nimport com.openai.models.beta.threads.runs.RunUpdateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        RunUpdateParams params = RunUpdateParams.builder()\n            .threadId(\"thread_id\")\n            .runId(\"run_id\")\n            .build();\n        Run run = client.beta().threads().runs().update(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst run = await client.beta.threads.runs.update('run_id', { thread_id: 'thread_id' });\n\nconsole.log(run.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nrun = client.beta.threads.runs.update(\n    run_id=\"run_id\",\n    thread_id=\"thread_id\",\n)\nprint(run.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nrun = openai.beta.threads.runs.update(\"run_id\", thread_id: \"thread_id\")\n\nputs(run)"
          response: "{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699075072,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"completed\",\n  \"started_at\": 1699075072,\n  \"expires_at\": null,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": 1699075073,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": null,\n  \"incomplete_details\": null,\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"tool_resources\": {\n    \"code_interpreter\": {\n      \"file_ids\": [\n        \"file-abc123\",\n        \"file-abc456\"\n      ]\n    }\n  },\n  \"metadata\": {\n    \"user_id\": \"user_abc123\"\n  },\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  },\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\": 1000,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\n"
        group: threads
        name: Modify run
        returns: 'The modified [run](https://platform.openai.com/docs/api-reference/runs/object) object matching the specified ID.'
  '/threads/{thread_id}/runs/{run_id}/cancel':
    post:
      tags:
        - Assistants
      summary: Cancel a run
      description: Cancels a run that is `in_progress`.
      operationId: cancelRun
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread to which this run belongs.
          required: true
          schema:
            type: string
        - name: run_id
          in: path
          description: The ID of the run to cancel.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -X POST\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  run, err := client.Beta.Threads.Runs.Cancel(\n    context.TODO(),\n    \"thread_id\",\n    \"run_id\",\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", run.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.threads.runs.Run;\nimport com.openai.models.beta.threads.runs.RunCancelParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        RunCancelParams params = RunCancelParams.builder()\n            .threadId(\"thread_id\")\n            .runId(\"run_id\")\n            .build();\n        Run run = client.beta().threads().runs().cancel(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst run = await client.beta.threads.runs.cancel('run_id', { thread_id: 'thread_id' });\n\nconsole.log(run.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nrun = client.beta.threads.runs.cancel(\n    run_id=\"run_id\",\n    thread_id=\"thread_id\",\n)\nprint(run.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nrun = openai.beta.threads.runs.cancel(\"run_id\", thread_id: \"thread_id\")\n\nputs(run)"
          response: "{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699076126,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"cancelling\",\n  \"started_at\": 1699076126,\n  \"expires_at\": 1699076726,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": null,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You summarize books.\",\n  \"tools\": [\n    {\n      \"type\": \"file_search\"\n    }\n  ],\n  \"tool_resources\": {\n    \"file_search\": {\n      \"vector_store_ids\": [\"vs_123\"]\n    }\n  },\n  \"metadata\": {},\n  \"usage\": null,\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\n"
        group: threads
        name: Cancel a run
        returns: 'The modified [run](https://platform.openai.com/docs/api-reference/runs/object) object matching the specified ID.'
  '/threads/{thread_id}/runs/{run_id}/steps':
    get:
      tags:
        - Assistants
      summary: List run steps
      description: Returns a list of run steps belonging to a run.
      operationId: listRunSteps
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread the run and run steps belong to.
          required: true
          schema:
            type: string
        - name: run_id
          in: path
          description: The ID of the run the run steps belong to.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: before
          in: query
          description: "A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n"
          schema:
            type: string
        - name: 'include[]'
          in: query
          description: "A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n"
          schema:
            type: array
            items:
              enum:
                - 'step_details.tool_calls[*].file_search.results[*].content'
              type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListRunStepsResponse'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.Beta.Threads.Runs.Steps.List(\n    context.TODO(),\n    \"thread_id\",\n    \"run_id\",\n    openai.BetaThreadRunStepListParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.threads.runs.steps.StepListPage;\nimport com.openai.models.beta.threads.runs.steps.StepListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        StepListParams params = StepListParams.builder()\n            .threadId(\"thread_id\")\n            .runId(\"run_id\")\n            .build();\n        StepListPage page = client.beta().threads().runs().steps().list(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const runStep of client.beta.threads.runs.steps.list('run_id', { thread_id: 'thread_id' })) {\n  console.log(runStep.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.beta.threads.runs.steps.list(\n    run_id=\"run_id\",\n    thread_id=\"thread_id\",\n)\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.beta.threads.runs.steps.list(\"run_id\", thread_id: \"thread_id\")\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"step_abc123\",\n      \"object\": \"thread.run.step\",\n      \"created_at\": 1699063291,\n      \"run_id\": \"run_abc123\",\n      \"assistant_id\": \"asst_abc123\",\n      \"thread_id\": \"thread_abc123\",\n      \"type\": \"message_creation\",\n      \"status\": \"completed\",\n      \"cancelled_at\": null,\n      \"completed_at\": 1699063291,\n      \"expired_at\": null,\n      \"failed_at\": null,\n      \"last_error\": null,\n      \"step_details\": {\n        \"type\": \"message_creation\",\n        \"message_creation\": {\n          \"message_id\": \"msg_abc123\"\n        }\n      },\n      \"usage\": {\n        \"prompt_tokens\": 123,\n        \"completion_tokens\": 456,\n        \"total_tokens\": 579\n      }\n    }\n  ],\n  \"first_id\": \"step_abc123\",\n  \"last_id\": \"step_abc456\",\n  \"has_more\": false\n}\n"
        group: threads
        name: List run steps
        returns: 'A list of [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object) objects.'
  '/threads/{thread_id}/runs/{run_id}/steps/{step_id}':
    get:
      tags:
        - Assistants
      summary: Retrieve run step
      description: Retrieves a run step.
      operationId: getRunStep
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread to which the run and run step belongs.
          required: true
          schema:
            type: string
        - name: run_id
          in: path
          description: The ID of the run to which the run step belongs.
          required: true
          schema:
            type: string
        - name: step_id
          in: path
          description: The ID of the run step to retrieve.
          required: true
          schema:
            type: string
        - name: 'include[]'
          in: query
          description: "A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n"
          schema:
            type: array
            items:
              enum:
                - 'step_details.tool_calls[*].file_search.results[*].content'
              type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunStepObject'
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  runStep, err := client.Beta.Threads.Runs.Steps.Get(\n    context.TODO(),\n    \"thread_id\",\n    \"run_id\",\n    \"step_id\",\n    openai.BetaThreadRunStepGetParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", runStep.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.threads.runs.steps.RunStep;\nimport com.openai.models.beta.threads.runs.steps.StepRetrieveParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        StepRetrieveParams params = StepRetrieveParams.builder()\n            .threadId(\"thread_id\")\n            .runId(\"run_id\")\n            .stepId(\"step_id\")\n            .build();\n        RunStep runStep = client.beta().threads().runs().steps().retrieve(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst runStep = await client.beta.threads.runs.steps.retrieve('step_id', {\n  thread_id: 'thread_id',\n  run_id: 'run_id',\n});\n\nconsole.log(runStep.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nrun_step = client.beta.threads.runs.steps.retrieve(\n    step_id=\"step_id\",\n    thread_id=\"thread_id\",\n    run_id=\"run_id\",\n)\nprint(run_step.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nrun_step = openai.beta.threads.runs.steps.retrieve(\"step_id\", thread_id: \"thread_id\", run_id: \"run_id\")\n\nputs(run_step)"
          response: "{\n  \"id\": \"step_abc123\",\n  \"object\": \"thread.run.step\",\n  \"created_at\": 1699063291,\n  \"run_id\": \"run_abc123\",\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"type\": \"message_creation\",\n  \"status\": \"completed\",\n  \"cancelled_at\": null,\n  \"completed_at\": 1699063291,\n  \"expired_at\": null,\n  \"failed_at\": null,\n  \"last_error\": null,\n  \"step_details\": {\n    \"type\": \"message_creation\",\n    \"message_creation\": {\n      \"message_id\": \"msg_abc123\"\n    }\n  },\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  }\n}\n"
        group: threads
        name: Retrieve run step
        returns: 'The [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object) object matching the specified ID.'
  '/threads/{thread_id}/runs/{run_id}/submit_tool_outputs':
    post:
      tags:
        - Assistants
      summary: Submit tool outputs to run
      description: "When a run has the `status: \"requires_action\"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.\n"
      operationId: submitToolOuputsToRun
      parameters:
        - name: thread_id
          in: path
          description: 'The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) to which this run belongs.'
          required: true
          schema:
            type: string
        - name: run_id
          in: path
          description: The ID of the run that requires the tool output submission.
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/SubmitToolOutputsRunRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        beta: true
        example:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"tool_outputs\": [\n      {\n        \"tool_call_id\": \"call_001\",\n        \"output\": \"70 degrees and sunny.\"\n      }\n    ]\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  run, err := client.Beta.Threads.Runs.SubmitToolOutputs(\n    context.TODO(),\n    \"thread_id\",\n    \"run_id\",\n    openai.BetaThreadRunSubmitToolOutputsParams{\n      ToolOutputs: []openai.BetaThreadRunSubmitToolOutputsParamsToolOutput{openai.BetaThreadRunSubmitToolOutputsParamsToolOutput{\n\n      }},\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", run.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.beta.threads.runs.Run;\nimport com.openai.models.beta.threads.runs.RunSubmitToolOutputsParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        RunSubmitToolOutputsParams params = RunSubmitToolOutputsParams.builder()\n            .threadId(\"thread_id\")\n            .runId(\"run_id\")\n            .addToolOutput(RunSubmitToolOutputsParams.ToolOutput.builder().build())\n            .build();\n        Run run = client.beta().threads().runs().submitToolOutputs(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst run = await client.beta.threads.runs.submitToolOutputs('run_id', {\n  thread_id: 'thread_id',\n  tool_outputs: [{}],\n});\n\nconsole.log(run.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nrun = client.beta.threads.runs.submit_tool_outputs(\n    run_id=\"run_id\",\n    thread_id=\"thread_id\",\n    tool_outputs=[{}],\n)\nprint(run.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nrun = openai.beta.threads.runs.submit_tool_outputs(\"run_id\", thread_id: \"thread_id\", tool_outputs: [{}])\n\nputs(run)"
          response: "{\n  \"id\": \"run_123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699075592,\n  \"assistant_id\": \"asst_123\",\n  \"thread_id\": \"thread_123\",\n  \"status\": \"queued\",\n  \"started_at\": 1699075592,\n  \"expires_at\": 1699076192,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": null,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": null,\n  \"tools\": [\n    {\n      \"type\": \"function\",\n      \"function\": {\n        \"name\": \"get_current_weather\",\n        \"description\": \"Get the current weather in a given location\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"location\": {\n              \"type\": \"string\",\n              \"description\": \"The city and state, e.g. San Francisco, CA\"\n            },\n            \"unit\": {\n              \"type\": \"string\",\n              \"enum\": [\"celsius\", \"fahrenheit\"]\n            }\n          },\n          \"required\": [\"location\"]\n        }\n      }\n    }\n  ],\n  \"metadata\": {},\n  \"usage\": null,\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\": 1000,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\n"
          title: Default
        group: threads
        name: Submit tool outputs to run
        returns: 'The modified [run](https://platform.openai.com/docs/api-reference/runs/object) object matching the specified ID.'
  /uploads:
    post:
      tags:
        - Uploads
      summary: Create upload
      description: "Creates an intermediate [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object\nthat you can add [Parts](https://platform.openai.com/docs/api-reference/uploads/part-object) to.\nCurrently, an Upload can accept at most 8 GB in total and expires after an\nhour after you create it.\n\nOnce you complete the Upload, we will create a\n[File](https://platform.openai.com/docs/api-reference/files/object) object that contains all the parts\nyou uploaded. This File is usable in the rest of our platform as a regular\nFile object.\n\nFor certain `purpose` values, the correct `mime_type` must be specified. \nPlease refer to documentation for the \n[supported MIME types for your use case](https://platform.openai.com/docs/assistants/tools/file-search#supported-files).\n\nFor guidance on the proper filename extensions for each purpose, please\nfollow the documentation on [creating a\nFile](https://platform.openai.com/docs/api-reference/files/create).\n"
      operationId: createUpload
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateUploadRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Upload'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/uploads \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"purpose\": \"fine-tune\",\n    \"filename\": \"training_examples.jsonl\",\n    \"bytes\": 2147483648,\n    \"mime_type\": \"text/jsonl\",\n    \"expires_after\": {\n      \"anchor\": \"created_at\",\n      \"seconds\": 3600\n    }\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  upload, err := client.Uploads.New(context.TODO(), openai.UploadNewParams{\n    Bytes: 0,\n    Filename: \"filename\",\n    MimeType: \"mime_type\",\n    Purpose: openai.FilePurposeAssistants,\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", upload.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.files.FilePurpose;\nimport com.openai.models.uploads.Upload;\nimport com.openai.models.uploads.UploadCreateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        UploadCreateParams params = UploadCreateParams.builder()\n            .bytes(0L)\n            .filename(\"filename\")\n            .mimeType(\"mime_type\")\n            .purpose(FilePurpose.ASSISTANTS)\n            .build();\n        Upload upload = client.uploads().create(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst upload = await client.uploads.create({\n  bytes: 0,\n  filename: 'filename',\n  mime_type: 'mime_type',\n  purpose: 'assistants',\n});\n\nconsole.log(upload.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nupload = client.uploads.create(\n    bytes=0,\n    filename=\"filename\",\n    mime_type=\"mime_type\",\n    purpose=\"assistants\",\n)\nprint(upload.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nupload = openai.uploads.create(bytes: 0, filename: \"filename\", mime_type: \"mime_type\", purpose: :assistants)\n\nputs(upload)"
          response: "{\n  \"id\": \"upload_abc123\",\n  \"object\": \"upload\",\n  \"bytes\": 2147483648,\n  \"created_at\": 1719184911,\n  \"filename\": \"training_examples.jsonl\",\n  \"purpose\": \"fine-tune\",\n  \"status\": \"pending\",\n  \"expires_at\": 1719127296\n}\n"
        group: uploads
        name: Create upload
        returns: 'The [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object with status `pending`.'
  '/uploads/{upload_id}/cancel':
    post:
      tags:
        - Uploads
      summary: Cancel upload
      description: "Cancels the Upload. No Parts may be added after an Upload is cancelled.\n"
      operationId: cancelUpload
      parameters:
        - name: upload_id
          in: path
          description: "The ID of the Upload.\n"
          required: true
          schema:
            type: string
            example: upload_abc123
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Upload'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/uploads/upload_abc123/cancel\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  upload, err := client.Uploads.Cancel(context.TODO(), \"upload_abc123\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", upload.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.uploads.Upload;\nimport com.openai.models.uploads.UploadCancelParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        Upload upload = client.uploads().cancel(\"upload_abc123\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst upload = await client.uploads.cancel('upload_abc123');\n\nconsole.log(upload.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nupload = client.uploads.cancel(\n    \"upload_abc123\",\n)\nprint(upload.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nupload = openai.uploads.cancel(\"upload_abc123\")\n\nputs(upload)"
          response: "{\n  \"id\": \"upload_abc123\",\n  \"object\": \"upload\",\n  \"bytes\": 2147483648,\n  \"created_at\": 1719184911,\n  \"filename\": \"training_examples.jsonl\",\n  \"purpose\": \"fine-tune\",\n  \"status\": \"cancelled\",\n  \"expires_at\": 1719127296\n}\n"
        group: uploads
        name: Cancel upload
        returns: 'The [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object with status `cancelled`.'
  '/uploads/{upload_id}/complete':
    post:
      tags:
        - Uploads
      summary: Complete upload
      description: "Completes the [Upload](https://platform.openai.com/docs/api-reference/uploads/object). \n\nWithin the returned Upload object, there is a nested [File](https://platform.openai.com/docs/api-reference/files/object) object that is ready to use in the rest of the platform.\n\nYou can specify the order of the Parts by passing in an ordered list of the Part IDs.\n\nThe number of bytes uploaded upon completion must match the number of bytes initially specified when creating the Upload object. No Parts may be added after an Upload is completed.\n"
      operationId: completeUpload
      parameters:
        - name: upload_id
          in: path
          description: "The ID of the Upload.\n"
          required: true
          schema:
            type: string
            example: upload_abc123
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CompleteUploadRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Upload'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/uploads/upload_abc123/complete\n  -d '{\n    \"part_ids\": [\"part_def456\", \"part_ghi789\"]\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  upload, err := client.Uploads.Complete(\n    context.TODO(),\n    \"upload_abc123\",\n    openai.UploadCompleteParams{\n      PartIDs: []string{\"string\"},\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", upload.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.uploads.Upload;\nimport com.openai.models.uploads.UploadCompleteParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        UploadCompleteParams params = UploadCompleteParams.builder()\n            .uploadId(\"upload_abc123\")\n            .addPartId(\"string\")\n            .build();\n        Upload upload = client.uploads().complete(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst upload = await client.uploads.complete('upload_abc123', { part_ids: ['string'] });\n\nconsole.log(upload.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nupload = client.uploads.complete(\n    upload_id=\"upload_abc123\",\n    part_ids=[\"string\"],\n)\nprint(upload.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nupload = openai.uploads.complete(\"upload_abc123\", part_ids: [\"string\"])\n\nputs(upload)"
          response: "{\n  \"id\": \"upload_abc123\",\n  \"object\": \"upload\",\n  \"bytes\": 2147483648,\n  \"created_at\": 1719184911,\n  \"filename\": \"training_examples.jsonl\",\n  \"purpose\": \"fine-tune\",\n  \"status\": \"completed\",\n  \"expires_at\": 1719127296,\n  \"file\": {\n    \"id\": \"file-xyz321\",\n    \"object\": \"file\",\n    \"bytes\": 2147483648,\n    \"created_at\": 1719186911,\n    \"expires_at\": 1719127296,\n    \"filename\": \"training_examples.jsonl\",\n    \"purpose\": \"fine-tune\",\n  }\n}\n"
        group: uploads
        name: Complete upload
        returns: 'The [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object with status `completed` with an additional `file` property containing the created usable File object.'
  '/uploads/{upload_id}/parts':
    post:
      tags:
        - Uploads
      summary: Add upload part
      description: "Adds a [Part](https://platform.openai.com/docs/api-reference/uploads/part-object) to an [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object. A Part represents a chunk of bytes from the file you are trying to upload. \n\nEach Part can be at most 64 MB, and you can add Parts until you hit the Upload maximum of 8 GB.\n\nIt is possible to add multiple Parts in parallel. You can decide the intended order of the Parts when you [complete the Upload](https://platform.openai.com/docs/api-reference/uploads/complete).\n"
      operationId: addUploadPart
      parameters:
        - name: upload_id
          in: path
          description: "The ID of the Upload.\n"
          required: true
          schema:
            type: string
            example: upload_abc123
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/AddUploadPartRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UploadPart'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/uploads/upload_abc123/parts\n  -F data=\"aHR0cHM6Ly9hcGkub3BlbmFpLmNvbS92MS91cGxvYWRz...\"\n"
            go: "package main\n\nimport (\n  \"bytes\"\n  \"context\"\n  \"fmt\"\n  \"io\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  uploadPart, err := client.Uploads.Parts.New(\n    context.TODO(),\n    \"upload_abc123\",\n    openai.UploadPartNewParams{\n      Data: io.Reader(bytes.NewBuffer([]byte(\"some file contents\"))),\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", uploadPart.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.uploads.parts.PartCreateParams;\nimport com.openai.models.uploads.parts.UploadPart;\nimport java.io.ByteArrayInputStream;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        PartCreateParams params = PartCreateParams.builder()\n            .uploadId(\"upload_abc123\")\n            .data(ByteArrayInputStream(\"some content\".getBytes()))\n            .build();\n        UploadPart uploadPart = client.uploads().parts().create(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst uploadPart = await client.uploads.parts.create('upload_abc123', {\n  data: fs.createReadStream('path/to/file'),\n});\n\nconsole.log(uploadPart.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nupload_part = client.uploads.parts.create(\n    upload_id=\"upload_abc123\",\n    data=b\"raw file contents\",\n)\nprint(upload_part.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nupload_part = openai.uploads.parts.create(\"upload_abc123\", data: Pathname(__FILE__))\n\nputs(upload_part)"
          response: "{\n  \"id\": \"part_def456\",\n  \"object\": \"upload.part\",\n  \"created_at\": 1719185911,\n  \"upload_id\": \"upload_abc123\"\n}\n"
        group: uploads
        name: Add upload part
        returns: 'The upload [Part](https://platform.openai.com/docs/api-reference/uploads/part-object) object.'
  /vector_stores:
    get:
      tags:
        - Vector stores
      summary: List vector stores
      description: Returns a list of vector stores.
      operationId: listVectorStores
      parameters:
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: before
          in: query
          description: "A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n"
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoresResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.VectorStores.List(context.TODO(), openai.VectorStoreListParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.vectorstores.VectorStoreListPage;\nimport com.openai.models.vectorstores.VectorStoreListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        VectorStoreListPage page = client.vectorStores().list();\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const vectorStore of client.vectorStores.list()) {\n  console.log(vectorStore.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.vector_stores.list()\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.vector_stores.list\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"vs_abc123\",\n      \"object\": \"vector_store\",\n      \"created_at\": 1699061776,\n      \"name\": \"Support FAQ\",\n      \"bytes\": 139920,\n      \"file_counts\": {\n        \"in_progress\": 0,\n        \"completed\": 3,\n        \"failed\": 0,\n        \"cancelled\": 0,\n        \"total\": 3\n      }\n    },\n    {\n      \"id\": \"vs_abc456\",\n      \"object\": \"vector_store\",\n      \"created_at\": 1699061776,\n      \"name\": \"Support FAQ v2\",\n      \"bytes\": 139920,\n      \"file_counts\": {\n        \"in_progress\": 0,\n        \"completed\": 3,\n        \"failed\": 0,\n        \"cancelled\": 0,\n        \"total\": 3\n      }\n    }\n  ],\n  \"first_id\": \"vs_abc123\",\n  \"last_id\": \"vs_abc456\",\n  \"has_more\": false\n}\n"
        group: vector_stores
        name: List vector stores
        returns: 'A list of [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) objects.'
    post:
      tags:
        - Vector stores
      summary: Create vector store
      description: Create a vector store.
      operationId: createVectorStore
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"name\": \"Support FAQ\"\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  vectorStore, err := client.VectorStores.New(context.TODO(), openai.VectorStoreNewParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", vectorStore.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.vectorstores.VectorStore;\nimport com.openai.models.vectorstores.VectorStoreCreateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        VectorStore vectorStore = client.vectorStores().create();\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst vectorStore = await client.vectorStores.create();\n\nconsole.log(vectorStore.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nvector_store = client.vector_stores.create()\nprint(vector_store.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nvector_store = openai.vector_stores.create\n\nputs(vector_store)"
          response: "{\n  \"id\": \"vs_abc123\",\n  \"object\": \"vector_store\",\n  \"created_at\": 1699061776,\n  \"name\": \"Support FAQ\",\n  \"bytes\": 139920,\n  \"file_counts\": {\n    \"in_progress\": 0,\n    \"completed\": 3,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 3\n  }\n}\n"
        group: vector_stores
        name: Create vector store
        returns: 'A [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) object.'
  '/vector_stores/{vector_store_id}':
    delete:
      tags:
        - Vector stores
      summary: Delete vector store
      description: Delete a vector store.
      operationId: deleteVectorStore
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store to delete.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteVectorStoreResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -X DELETE\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  vectorStoreDeleted, err := client.VectorStores.Delete(context.TODO(), \"vector_store_id\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", vectorStoreDeleted.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.vectorstores.VectorStoreDeleteParams;\nimport com.openai.models.vectorstores.VectorStoreDeleted;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        VectorStoreDeleted vectorStoreDeleted = client.vectorStores().delete(\"vector_store_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst vectorStoreDeleted = await client.vectorStores.delete('vector_store_id');\n\nconsole.log(vectorStoreDeleted.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nvector_store_deleted = client.vector_stores.delete(\n    \"vector_store_id\",\n)\nprint(vector_store_deleted.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nvector_store_deleted = openai.vector_stores.delete(\"vector_store_id\")\n\nputs(vector_store_deleted)"
          response: "{\n  id: \"vs_abc123\",\n  object: \"vector_store.deleted\",\n  deleted: true\n}\n"
        group: vector_stores
        name: Delete vector store
        returns: Deletion status
    get:
      tags:
        - Vector stores
      summary: Retrieve vector store
      description: Retrieves a vector store.
      operationId: getVectorStore
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  vectorStore, err := client.VectorStores.Get(context.TODO(), \"vector_store_id\")\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", vectorStore.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.vectorstores.VectorStore;\nimport com.openai.models.vectorstores.VectorStoreRetrieveParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        VectorStore vectorStore = client.vectorStores().retrieve(\"vector_store_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst vectorStore = await client.vectorStores.retrieve('vector_store_id');\n\nconsole.log(vectorStore.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nvector_store = client.vector_stores.retrieve(\n    \"vector_store_id\",\n)\nprint(vector_store.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nvector_store = openai.vector_stores.retrieve(\"vector_store_id\")\n\nputs(vector_store)"
          response: "{\n  \"id\": \"vs_abc123\",\n  \"object\": \"vector_store\",\n  \"created_at\": 1699061776\n}\n"
        group: vector_stores
        name: Retrieve vector store
        returns: 'The [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) object matching the specified ID.'
    post:
      tags:
        - Vector stores
      summary: Modify vector store
      description: Modifies a vector store.
      operationId: modifyVectorStore
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store to modify.
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateVectorStoreRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n  -d '{\n    \"name\": \"Support FAQ\"\n  }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  vectorStore, err := client.VectorStores.Update(\n    context.TODO(),\n    \"vector_store_id\",\n    openai.VectorStoreUpdateParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", vectorStore.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.vectorstores.VectorStore;\nimport com.openai.models.vectorstores.VectorStoreUpdateParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        VectorStore vectorStore = client.vectorStores().update(\"vector_store_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst vectorStore = await client.vectorStores.update('vector_store_id');\n\nconsole.log(vectorStore.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nvector_store = client.vector_stores.update(\n    vector_store_id=\"vector_store_id\",\n)\nprint(vector_store.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nvector_store = openai.vector_stores.update(\"vector_store_id\")\n\nputs(vector_store)"
          response: "{\n  \"id\": \"vs_abc123\",\n  \"object\": \"vector_store\",\n  \"created_at\": 1699061776,\n  \"name\": \"Support FAQ\",\n  \"bytes\": 139920,\n  \"file_counts\": {\n    \"in_progress\": 0,\n    \"completed\": 3,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 3\n  }\n}\n"
        group: vector_stores
        name: Modify vector store
        returns: 'The modified [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) object.'
  '/vector_stores/{vector_store_id}/file_batches':
    post:
      tags:
        - Vector stores
      summary: Create vector store file batch
      description: Create a vector store file batch.
      operationId: createVectorStoreFileBatch
      parameters:
        - name: vector_store_id
          in: path
          description: "The ID of the vector store for which to create a File Batch.\n"
          required: true
          schema:
            type: string
            example: vs_abc123
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreFileBatchRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \\\n    -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n    -H \"Content-Type: application/json \\\n    -H \"OpenAI-Beta: assistants=v2\" \\\n    -d '{\n      \"file_ids\": [\"file-abc123\", \"file-abc456\"]\n    }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  vectorStoreFileBatch, err := client.VectorStores.FileBatches.New(\n    context.TODO(),\n    \"vs_abc123\",\n    openai.VectorStoreFileBatchNewParams{\n      FileIDs: []string{\"string\"},\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", vectorStoreFileBatch.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.vectorstores.filebatches.FileBatchCreateParams;\nimport com.openai.models.vectorstores.filebatches.VectorStoreFileBatch;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FileBatchCreateParams params = FileBatchCreateParams.builder()\n            .vectorStoreId(\"vs_abc123\")\n            .addFileId(\"string\")\n            .build();\n        VectorStoreFileBatch vectorStoreFileBatch = client.vectorStores().fileBatches().create(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst vectorStoreFileBatch = await client.vectorStores.fileBatches.create('vs_abc123', {\n  file_ids: ['string'],\n});\n\nconsole.log(vectorStoreFileBatch.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nvector_store_file_batch = client.vector_stores.file_batches.create(\n    vector_store_id=\"vs_abc123\",\n    file_ids=[\"string\"],\n)\nprint(vector_store_file_batch.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nvector_store_file_batch = openai.vector_stores.file_batches.create(\"vs_abc123\", file_ids: [\"string\"])\n\nputs(vector_store_file_batch)"
          response: "{\n  \"id\": \"vsfb_abc123\",\n  \"object\": \"vector_store.file_batch\",\n  \"created_at\": 1699061776,\n  \"vector_store_id\": \"vs_abc123\",\n  \"status\": \"in_progress\",\n  \"file_counts\": {\n    \"in_progress\": 1,\n    \"completed\": 1,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 0,\n  }\n}\n"
        group: vector_stores
        name: Create vector store file batch
        returns: 'A [vector store file batch](https://platform.openai.com/docs/api-reference/vector-stores-file-batches/batch-object) object.'
  '/vector_stores/{vector_store_id}/file_batches/{batch_id}':
    get:
      tags:
        - Vector stores
      summary: Retrieve vector store file batch
      description: Retrieves a vector store file batch.
      operationId: getVectorStoreFileBatch
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store that the file batch belongs to.
          required: true
          schema:
            type: string
            example: vs_abc123
        - name: batch_id
          in: path
          description: The ID of the file batch being retrieved.
          required: true
          schema:
            type: string
            example: vsfb_abc123
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  vectorStoreFileBatch, err := client.VectorStores.FileBatches.Get(\n    context.TODO(),\n    \"vs_abc123\",\n    \"vsfb_abc123\",\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", vectorStoreFileBatch.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.vectorstores.filebatches.FileBatchRetrieveParams;\nimport com.openai.models.vectorstores.filebatches.VectorStoreFileBatch;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FileBatchRetrieveParams params = FileBatchRetrieveParams.builder()\n            .vectorStoreId(\"vs_abc123\")\n            .batchId(\"vsfb_abc123\")\n            .build();\n        VectorStoreFileBatch vectorStoreFileBatch = client.vectorStores().fileBatches().retrieve(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst vectorStoreFileBatch = await client.vectorStores.fileBatches.retrieve('vsfb_abc123', {\n  vector_store_id: 'vs_abc123',\n});\n\nconsole.log(vectorStoreFileBatch.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nvector_store_file_batch = client.vector_stores.file_batches.retrieve(\n    batch_id=\"vsfb_abc123\",\n    vector_store_id=\"vs_abc123\",\n)\nprint(vector_store_file_batch.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nvector_store_file_batch = openai.vector_stores.file_batches.retrieve(\"vsfb_abc123\", vector_store_id: \"vs_abc123\")\n\nputs(vector_store_file_batch)"
          response: "{\n  \"id\": \"vsfb_abc123\",\n  \"object\": \"vector_store.file_batch\",\n  \"created_at\": 1699061776,\n  \"vector_store_id\": \"vs_abc123\",\n  \"status\": \"in_progress\",\n  \"file_counts\": {\n    \"in_progress\": 1,\n    \"completed\": 1,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 0,\n  }\n}\n"
        group: vector_stores
        name: Retrieve vector store file batch
        returns: 'The [vector store file batch](https://platform.openai.com/docs/api-reference/vector-stores-file-batches/batch-object) object.'
  '/vector_stores/{vector_store_id}/file_batches/{batch_id}/cancel':
    post:
      tags:
        - Vector stores
      summary: Cancel vector store file batch
      description: Cancel a vector store file batch. This attempts to cancel the processing of files in this batch as soon as possible.
      operationId: cancelVectorStoreFileBatch
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store that the file batch belongs to.
          required: true
          schema:
            type: string
        - name: batch_id
          in: path
          description: The ID of the file batch to cancel.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -X POST\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  vectorStoreFileBatch, err := client.VectorStores.FileBatches.Cancel(\n    context.TODO(),\n    \"vector_store_id\",\n    \"batch_id\",\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", vectorStoreFileBatch.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.vectorstores.filebatches.FileBatchCancelParams;\nimport com.openai.models.vectorstores.filebatches.VectorStoreFileBatch;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FileBatchCancelParams params = FileBatchCancelParams.builder()\n            .vectorStoreId(\"vector_store_id\")\n            .batchId(\"batch_id\")\n            .build();\n        VectorStoreFileBatch vectorStoreFileBatch = client.vectorStores().fileBatches().cancel(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst vectorStoreFileBatch = await client.vectorStores.fileBatches.cancel('batch_id', {\n  vector_store_id: 'vector_store_id',\n});\n\nconsole.log(vectorStoreFileBatch.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nvector_store_file_batch = client.vector_stores.file_batches.cancel(\n    batch_id=\"batch_id\",\n    vector_store_id=\"vector_store_id\",\n)\nprint(vector_store_file_batch.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nvector_store_file_batch = openai.vector_stores.file_batches.cancel(\"batch_id\", vector_store_id: \"vector_store_id\")\n\nputs(vector_store_file_batch)"
          response: "{\n  \"id\": \"vsfb_abc123\",\n  \"object\": \"vector_store.file_batch\",\n  \"created_at\": 1699061776,\n  \"vector_store_id\": \"vs_abc123\",\n  \"status\": \"in_progress\",\n  \"file_counts\": {\n    \"in_progress\": 12,\n    \"completed\": 3,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 15,\n  }\n}\n"
        group: vector_stores
        name: Cancel vector store file batch
        returns: The modified vector store file batch object.
  '/vector_stores/{vector_store_id}/file_batches/{batch_id}/files':
    get:
      tags:
        - Vector stores
      summary: List vector store files in a batch
      description: Returns a list of vector store files in a batch.
      operationId: listFilesInVectorStoreBatch
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store that the files belong to.
          required: true
          schema:
            type: string
        - name: batch_id
          in: path
          description: The ID of the file batch that the files belong to.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: before
          in: query
          description: "A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n"
          schema:
            type: string
        - name: filter
          in: query
          description: 'Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.'
          schema:
            enum:
              - in_progress
              - completed
              - failed
              - cancelled
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoreFilesResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.VectorStores.FileBatches.ListFiles(\n    context.TODO(),\n    \"vector_store_id\",\n    \"batch_id\",\n    openai.VectorStoreFileBatchListFilesParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.vectorstores.filebatches.FileBatchListFilesPage;\nimport com.openai.models.vectorstores.filebatches.FileBatchListFilesParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FileBatchListFilesParams params = FileBatchListFilesParams.builder()\n            .vectorStoreId(\"vector_store_id\")\n            .batchId(\"batch_id\")\n            .build();\n        FileBatchListFilesPage page = client.vectorStores().fileBatches().listFiles(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const vectorStoreFile of client.vectorStores.fileBatches.listFiles('batch_id', {\n  vector_store_id: 'vector_store_id',\n})) {\n  console.log(vectorStoreFile.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.vector_stores.file_batches.list_files(\n    batch_id=\"batch_id\",\n    vector_store_id=\"vector_store_id\",\n)\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.vector_stores.file_batches.list_files(\"batch_id\", vector_store_id: \"vector_store_id\")\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"vector_store.file\",\n      \"created_at\": 1699061776,\n      \"vector_store_id\": \"vs_abc123\"\n    },\n    {\n      \"id\": \"file-abc456\",\n      \"object\": \"vector_store.file\",\n      \"created_at\": 1699061776,\n      \"vector_store_id\": \"vs_abc123\"\n    }\n  ],\n  \"first_id\": \"file-abc123\",\n  \"last_id\": \"file-abc456\",\n  \"has_more\": false\n}\n"
        group: vector_stores
        name: List vector store files in a batch
        returns: 'A list of [vector store file](https://platform.openai.com/docs/api-reference/vector-stores-files/file-object) objects.'
  '/vector_stores/{vector_store_id}/files':
    get:
      tags:
        - Vector stores
      summary: List vector store files
      description: Returns a list of vector store files.
      operationId: listVectorStoreFiles
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store that the files belong to.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: "A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n"
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: "Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n"
          schema:
            enum:
              - asc
              - desc
            type: string
            default: desc
        - name: after
          in: query
          description: "A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n"
          schema:
            type: string
        - name: before
          in: query
          description: "A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n"
          schema:
            type: string
        - name: filter
          in: query
          description: 'Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.'
          schema:
            enum:
              - in_progress
              - completed
              - failed
              - cancelled
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoreFilesResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.VectorStores.Files.List(\n    context.TODO(),\n    \"vector_store_id\",\n    openai.VectorStoreFileListParams{\n\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.vectorstores.files.FileListPage;\nimport com.openai.models.vectorstores.files.FileListParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FileListPage page = client.vectorStores().files().list(\"vector_store_id\");\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const vectorStoreFile of client.vectorStores.files.list('vector_store_id')) {\n  console.log(vectorStoreFile.id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.vector_stores.files.list(\n    vector_store_id=\"vector_store_id\",\n)\npage = page.data[0]\nprint(page.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.vector_stores.files.list(\"vector_store_id\")\n\nputs(page)"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"vector_store.file\",\n      \"created_at\": 1699061776,\n      \"vector_store_id\": \"vs_abc123\"\n    },\n    {\n      \"id\": \"file-abc456\",\n      \"object\": \"vector_store.file\",\n      \"created_at\": 1699061776,\n      \"vector_store_id\": \"vs_abc123\"\n    }\n  ],\n  \"first_id\": \"file-abc123\",\n  \"last_id\": \"file-abc456\",\n  \"has_more\": false\n}\n"
        group: vector_stores
        name: List vector store files
        returns: 'A list of [vector store file](https://platform.openai.com/docs/api-reference/vector-stores-files/file-object) objects.'
    post:
      tags:
        - Vector stores
      summary: Create vector store file
      description: 'Create a vector store file by attaching a [File](https://platform.openai.com/docs/api-reference/files) to a [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object).'
      operationId: createVectorStoreFile
      parameters:
        - name: vector_store_id
          in: path
          description: "The ID of the vector store for which to create a File.\n"
          required: true
          schema:
            type: string
            example: vs_abc123
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreFileRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileObject'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files \\\n    -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n    -H \"Content-Type: application/json\" \\\n    -H \"OpenAI-Beta: assistants=v2\" \\\n    -d '{\n      \"file_id\": \"file-abc123\"\n    }'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  vectorStoreFile, err := client.VectorStores.Files.New(\n    context.TODO(),\n    \"vs_abc123\",\n    openai.VectorStoreFileNewParams{\n      FileID: \"file_id\",\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", vectorStoreFile.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.vectorstores.files.FileCreateParams;\nimport com.openai.models.vectorstores.files.VectorStoreFile;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FileCreateParams params = FileCreateParams.builder()\n            .vectorStoreId(\"vs_abc123\")\n            .fileId(\"file_id\")\n            .build();\n        VectorStoreFile vectorStoreFile = client.vectorStores().files().create(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst vectorStoreFile = await client.vectorStores.files.create('vs_abc123', { file_id: 'file_id' });\n\nconsole.log(vectorStoreFile.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nvector_store_file = client.vector_stores.files.create(\n    vector_store_id=\"vs_abc123\",\n    file_id=\"file_id\",\n)\nprint(vector_store_file.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nvector_store_file = openai.vector_stores.files.create(\"vs_abc123\", file_id: \"file_id\")\n\nputs(vector_store_file)"
          response: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"vector_store.file\",\n  \"created_at\": 1699061776,\n  \"usage_bytes\": 1234,\n  \"vector_store_id\": \"vs_abcd\",\n  \"status\": \"completed\",\n  \"last_error\": null\n}\n"
        group: vector_stores
        name: Create vector store file
        returns: 'A [vector store file](https://platform.openai.com/docs/api-reference/vector-stores-files/file-object) object.'
  '/vector_stores/{vector_store_id}/files/{file_id}':
    delete:
      tags:
        - Vector stores
      summary: Delete vector store file
      description: 'Delete a vector store file. This will remove the file from the vector store but the file itself will not be deleted. To delete the file, use the [delete file](https://platform.openai.com/docs/api-reference/files/delete) endpoint.'
      operationId: deleteVectorStoreFile
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store that the file belongs to.
          required: true
          schema:
            type: string
        - name: file_id
          in: path
          description: The ID of the file to delete.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteVectorStoreFileResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -X DELETE\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  vectorStoreFileDeleted, err := client.VectorStores.Files.Delete(\n    context.TODO(),\n    \"vector_store_id\",\n    \"file_id\",\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", vectorStoreFileDeleted.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.vectorstores.files.FileDeleteParams;\nimport com.openai.models.vectorstores.files.VectorStoreFileDeleted;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FileDeleteParams params = FileDeleteParams.builder()\n            .vectorStoreId(\"vector_store_id\")\n            .fileId(\"file_id\")\n            .build();\n        VectorStoreFileDeleted vectorStoreFileDeleted = client.vectorStores().files().delete(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst vectorStoreFileDeleted = await client.vectorStores.files.delete('file_id', {\n  vector_store_id: 'vector_store_id',\n});\n\nconsole.log(vectorStoreFileDeleted.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nvector_store_file_deleted = client.vector_stores.files.delete(\n    file_id=\"file_id\",\n    vector_store_id=\"vector_store_id\",\n)\nprint(vector_store_file_deleted.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nvector_store_file_deleted = openai.vector_stores.files.delete(\"file_id\", vector_store_id: \"vector_store_id\")\n\nputs(vector_store_file_deleted)"
          response: "{\n  id: \"file-abc123\",\n  object: \"vector_store.file.deleted\",\n  deleted: true\n}\n"
        group: vector_stores
        name: Delete vector store file
        returns: Deletion status
    get:
      tags:
        - Vector stores
      summary: Retrieve vector store file
      description: Retrieves a vector store file.
      operationId: getVectorStoreFile
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store that the file belongs to.
          required: true
          schema:
            type: string
            example: vs_abc123
        - name: file_id
          in: path
          description: The ID of the file being retrieved.
          required: true
          schema:
            type: string
            example: file-abc123
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileObject'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  vectorStoreFile, err := client.VectorStores.Files.Get(\n    context.TODO(),\n    \"vs_abc123\",\n    \"file-abc123\",\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", vectorStoreFile.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.vectorstores.files.FileRetrieveParams;\nimport com.openai.models.vectorstores.files.VectorStoreFile;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FileRetrieveParams params = FileRetrieveParams.builder()\n            .vectorStoreId(\"vs_abc123\")\n            .fileId(\"file-abc123\")\n            .build();\n        VectorStoreFile vectorStoreFile = client.vectorStores().files().retrieve(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst vectorStoreFile = await client.vectorStores.files.retrieve('file-abc123', {\n  vector_store_id: 'vs_abc123',\n});\n\nconsole.log(vectorStoreFile.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nvector_store_file = client.vector_stores.files.retrieve(\n    file_id=\"file-abc123\",\n    vector_store_id=\"vs_abc123\",\n)\nprint(vector_store_file.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nvector_store_file = openai.vector_stores.files.retrieve(\"file-abc123\", vector_store_id: \"vs_abc123\")\n\nputs(vector_store_file)"
          response: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"vector_store.file\",\n  \"created_at\": 1699061776,\n  \"vector_store_id\": \"vs_abcd\",\n  \"status\": \"completed\",\n  \"last_error\": null\n}\n"
        group: vector_stores
        name: Retrieve vector store file
        returns: 'The [vector store file](https://platform.openai.com/docs/api-reference/vector-stores-files/file-object) object.'
    post:
      tags:
        - Vector stores
      summary: Update vector store file attributes
      description: Update attributes on a vector store file.
      operationId: updateVectorStoreFileAttributes
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store the file belongs to.
          required: true
          schema:
            type: string
            example: vs_abc123
        - name: file_id
          in: path
          description: The ID of the file to update attributes.
          required: true
          schema:
            type: string
            example: file-abc123
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateVectorStoreFileAttributesRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileObject'
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/{vector_store_id}/files/{file_id} \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"attributes\": {\"key1\": \"value1\", \"key2\": 2}}'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  vectorStoreFile, err := client.VectorStores.Files.Update(\n    context.TODO(),\n    \"vs_abc123\",\n    \"file-abc123\",\n    openai.VectorStoreFileUpdateParams{\n      Attributes: map[string]openai.VectorStoreFileUpdateParamsAttributeUnion{\n      \"foo\": openai.VectorStoreFileUpdateParamsAttributeUnion{\n        OfString: openai.String(\"string\"),\n      },\n      },\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", vectorStoreFile.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.core.JsonValue;\nimport com.openai.models.vectorstores.files.FileUpdateParams;\nimport com.openai.models.vectorstores.files.VectorStoreFile;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FileUpdateParams params = FileUpdateParams.builder()\n            .vectorStoreId(\"vs_abc123\")\n            .fileId(\"file-abc123\")\n            .attributes(FileUpdateParams.Attributes.builder()\n                .putAdditionalProperty(\"foo\", JsonValue.from(\"string\"))\n                .build())\n            .build();\n        VectorStoreFile vectorStoreFile = client.vectorStores().files().update(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\nconst vectorStoreFile = await client.vectorStores.files.update('file-abc123', {\n  vector_store_id: 'vs_abc123',\n  attributes: { foo: 'string' },\n});\n\nconsole.log(vectorStoreFile.id);"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\nvector_store_file = client.vector_stores.files.update(\n    file_id=\"file-abc123\",\n    vector_store_id=\"vs_abc123\",\n    attributes={\n        \"foo\": \"string\"\n    },\n)\nprint(vector_store_file.id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\nvector_store_file = openai.vector_stores.files.update(\n  \"file-abc123\",\n  vector_store_id: \"vs_abc123\",\n  attributes: {foo: \"string\"}\n)\n\nputs(vector_store_file)"
          response: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"vector_store.file\",\n  \"usage_bytes\": 1234,\n  \"created_at\": 1699061776,\n  \"vector_store_id\": \"vs_abcd\",\n  \"status\": \"completed\",\n  \"last_error\": null,\n  \"chunking_strategy\": {...},\n  \"attributes\": {\"key1\": \"value1\", \"key2\": 2}\n}\n"
        group: vector_stores
        name: Update vector store file attributes
        returns: 'The updated [vector store file](https://platform.openai.com/docs/api-reference/vector-stores-files/file-object) object.'
  '/vector_stores/{vector_store_id}/files/{file_id}/content':
    get:
      tags:
        - Vector stores
      summary: Retrieve vector store file content
      description: Retrieve the parsed contents of a vector store file.
      operationId: retrieveVectorStoreFileContent
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store.
          required: true
          schema:
            type: string
            example: vs_abc123
        - name: file_id
          in: path
          description: The ID of the file within the vector store.
          required: true
          schema:
            type: string
            example: file-abc123
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileContentResponse'
      x-oaiMeta:
        examples:
          request:
            curl: "curl \\\nhttps://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123/content \\\n-H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.VectorStores.Files.Content(\n    context.TODO(),\n    \"vs_abc123\",\n    \"file-abc123\",\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.vectorstores.files.FileContentPage;\nimport com.openai.models.vectorstores.files.FileContentParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        FileContentParams params = FileContentParams.builder()\n            .vectorStoreId(\"vs_abc123\")\n            .fileId(\"file-abc123\")\n            .build();\n        FileContentPage page = client.vectorStores().files().content(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const fileContentResponse of client.vectorStores.files.content('file-abc123', {\n  vector_store_id: 'vs_abc123',\n})) {\n  console.log(fileContentResponse.text);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.vector_stores.files.content(\n    file_id=\"file-abc123\",\n    vector_store_id=\"vs_abc123\",\n)\npage = page.data[0]\nprint(page.text)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.vector_stores.files.content(\"file-abc123\", vector_store_id: \"vs_abc123\")\n\nputs(page)"
          response: "{\n  \"file_id\": \"file-abc123\",\n  \"filename\": \"example.txt\",\n  \"attributes\": {\"key\": \"value\"},\n  \"content\": [\n    {\"type\": \"text\", \"text\": \"...\"},\n    ...\n  ]\n}\n"
        group: vector_stores
        name: Retrieve vector store file content
        returns: The parsed contents of the specified vector store file.
  '/vector_stores/{vector_store_id}/search':
    post:
      tags:
        - Vector stores
      summary: Search vector store
      description: Search a vector store for relevant chunks based on a query and file attributes filter.
      operationId: searchVectorStore
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store to search.
          required: true
          schema:
            type: string
            example: vs_abc123
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/VectorStoreSearchRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreSearchResultsPage'
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST \\\nhttps://api.openai.com/v1/vector_stores/vs_abc123/search \\\n-H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\"query\": \"What is the return policy?\", \"filters\": {...}}'\n"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\n  \"github.com/openai/openai-go/option\"\n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"My API Key\"),\n  )\n  page, err := client.VectorStores.Search(\n    context.TODO(),\n    \"vs_abc123\",\n    openai.VectorStoreSearchParams{\n      Query: openai.VectorStoreSearchParamsQueryUnion{\n        OfString: openai.String(\"string\"),\n      },\n    },\n  )\n  if err != nil {\n    panic(err.Error())\n  }\n  fmt.Printf(\"%+v\\n\", page)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.vectorstores.VectorStoreSearchPage;\nimport com.openai.models.vectorstores.VectorStoreSearchParams;\n\npublic final class Main {\n    private Main() {}\n\n    public static void main(String[] args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\n        VectorStoreSearchParams params = VectorStoreSearchParams.builder()\n            .vectorStoreId(\"vs_abc123\")\n            .query(\"string\")\n            .build();\n        VectorStoreSearchPage page = client.vectorStores().search(params);\n    }\n}"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: 'My API Key',\n});\n\n// Automatically fetches more pages as needed.\nfor await (const vectorStoreSearchResponse of client.vectorStores.search('vs_abc123', { query: 'string' })) {\n  console.log(vectorStoreSearchResponse.file_id);\n}"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"My API Key\",\n)\npage = client.vector_stores.search(\n    vector_store_id=\"vs_abc123\",\n    query=\"string\",\n)\npage = page.data[0]\nprint(page.file_id)"
            ruby: "require \"openai\"\n\nopenai = OpenAI::Client.new(api_key: \"My API Key\")\n\npage = openai.vector_stores.search(\"vs_abc123\", query: \"string\")\n\nputs(page)"
          response: "{\n  \"object\": \"vector_store.search_results.page\",\n  \"search_query\": \"What is the return policy?\",\n  \"data\": [\n    {\n      \"file_id\": \"file_123\",\n      \"filename\": \"document.pdf\",\n      \"score\": 0.95,\n      \"attributes\": {\n        \"author\": \"John Doe\",\n        \"date\": \"2023-01-01\"\n      },\n      \"content\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"Relevant chunk\"\n        }\n      ]\n    },\n    {\n      \"file_id\": \"file_456\",\n      \"filename\": \"notes.txt\",\n      \"score\": 0.89,\n      \"attributes\": {\n        \"author\": \"Jane Smith\",\n        \"date\": \"2023-01-02\"\n      },\n      \"content\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"Sample text content from the vector store.\"\n        }\n      ]\n    }\n  ],\n  \"has_more\": false,\n  \"next_page\": null\n}\n"
        group: vector_stores
        name: Search vector store
        returns: A page of search results from the vector store.
components:
  schemas:
    AddUploadPartRequest:
      required:
        - data
      type: object
      properties:
        data:
          type: string
          description: "The chunk of bytes for this Part.\n"
          format: binary
      additionalProperties: false
    AdminApiKey:
      required:
        - object
        - redacted_value
        - name
        - created_at
        - last_used_at
        - id
        - owner
      type: object
      properties:
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the API key was created
          format: int64
          example: 1711471533
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints'
          example: key_abc
        last_used_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the API key was last used
          format: int64
          nullable: true
          example: 1711471534
        name:
          type: string
          description: The name of the API key
          example: Administration Key
        object:
          type: string
          description: 'The object type, which is always `organization.admin_api_key`'
          example: organization.admin_api_key
          x-stainless-const: true
        owner:
          type: object
          properties:
            created_at:
              type: integer
              description: The Unix timestamp (in seconds) of when the user was created
              format: int64
              example: 1711471533
            id:
              type: string
              description: 'The identifier, which can be referenced in API endpoints'
              example: sa_456
            name:
              type: string
              description: The name of the user
              example: My Service Account
            object:
              type: string
              description: 'The object type, which is always organization.user'
              example: organization.user
            role:
              type: string
              description: Always `owner`
              example: owner
            type:
              type: string
              description: Always `user`
              example: user
        redacted_value:
          type: string
          description: The redacted value of the API key
          example: sk-admin...def
        value:
          type: string
          description: The value of the API key. Only shown on create.
          example: sk-admin-1234abcd
      description: Represents an individual Admin API key in an org.
      x-oaiMeta:
        example: "{\n  \"object\": \"organization.admin_api_key\",\n  \"id\": \"key_abc\",\n  \"name\": \"Main Admin Key\",\n  \"redacted_value\": \"sk-admin...xyz\",\n  \"created_at\": 1711471533,\n  \"last_used_at\": 1711471534,\n  \"owner\": {\n    \"type\": \"user\",\n    \"object\": \"organization.user\",\n    \"id\": \"user_123\",\n    \"name\": \"John Doe\",\n    \"created_at\": 1711471533,\n    \"role\": \"owner\"\n  }\n}\n"
        name: The admin API key object
    Annotation:
      anyOf:
        - $ref: '#/components/schemas/FileCitationBody'
        - $ref: '#/components/schemas/UrlCitationBody'
        - $ref: '#/components/schemas/ContainerFileCitationBody'
        - $ref: '#/components/schemas/FilePath'
      discriminator:
        propertyName: type
    Annotation-2:
      anyOf:
        - $ref: '#/components/schemas/FileCitationBody-2'
        - $ref: '#/components/schemas/UrlCitationBody-2'
        - $ref: '#/components/schemas/ContainerFileCitationBody-2'
      discriminator:
        propertyName: type
    ApiKeyList:
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/AdminApiKey'
        first_id:
          type: string
          example: key_abc
        has_more:
          type: boolean
          example: false
        last_id:
          type: string
          example: key_xyz
        object:
          type: string
          example: list
    ApproximateLocation:
      required:
        - type
      type: object
      properties:
        city:
          type: string
          description: 'Free text input for the city of the user, e.g. `San Francisco`.'
          nullable: true
        country:
          type: string
          description: 'The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.'
          nullable: true
        region:
          type: string
          description: 'Free text input for the region of the user, e.g. `California`.'
          nullable: true
        timezone:
          type: string
          description: 'The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.'
          nullable: true
        type:
          enum:
            - approximate
          type: string
          description: The type of location approximation. Always `approximate`.
          default: approximate
          x-stainless-const: true
    AssistantObject:
      title: Assistant
      required:
        - id
        - object
        - created_at
        - name
        - description
        - model
        - instructions
        - tools
        - metadata
      type: object
      properties:
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the assistant was created.
        description:
          maxLength: 512
          type: string
          description: "The description of the assistant. The maximum length is 512 characters.\n"
          nullable: true
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints.'
        instructions:
          maxLength: 256000
          type: string
          description: "The system instructions that the assistant uses. The maximum length is 256,000 characters.\n"
          nullable: true
        metadata:
          $ref: '#/components/schemas/Metadata'
        model:
          type: string
          description: "ID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models) for descriptions of them.\n"
        name:
          maxLength: 256
          type: string
          description: "The name of the assistant. The maximum length is 256 characters.\n"
          nullable: true
        object:
          enum:
            - assistant
          type: string
          description: 'The object type, which is always `assistant`.'
          x-stainless-const: true
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n"
          default: 1
          nullable: true
          example: 1
        tool_resources:
          type: object
          properties:
            code_interpreter:
              type: object
              properties:
                file_ids:
                  maxItems: 20
                  type: array
                  items:
                    type: string
                  description: "A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter`` tool. There can be a maximum of 20 files associated with the tool.\n"
            file_search:
              type: object
              properties:
                vector_store_ids:
                  maxItems: 1
                  type: array
                  items:
                    type: string
                  description: "The ID of the [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.\n"
          description: "A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n"
          nullable: true
        tools:
          maxItems: 128
          type: array
          items:
            $ref: '#/components/schemas/AssistantTool'
          description: "A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.\n"
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n"
          default: 1
          nullable: true
          example: 1
      description: Represents an `assistant` that can call the model and use tools.
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n  \"created_at\": 1698984975,\n  \"name\": \"Math Tutor\",\n  \"description\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": \"You are a personal math tutor. When asked a question, write and run Python code to answer the question.\",\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n  \"top_p\": 1.0,\n  \"temperature\": 1.0,\n  \"response_format\": \"auto\"\n}\n"
        name: The assistant object
    AssistantStreamEvent:
      anyOf:
        - $ref: '#/components/schemas/ThreadStreamEvent'
        - $ref: '#/components/schemas/RunStreamEvent'
        - $ref: '#/components/schemas/RunStepStreamEvent'
        - $ref: '#/components/schemas/MessageStreamEvent'
        - $ref: '#/components/schemas/ErrorEvent'
      description: "Represents an event emitted when streaming a Run.\n\nEach event in a server-sent events stream has an `event` and `data` property:\n\n```\nevent: thread.created\ndata: {\"id\": \"thread_123\", \"object\": \"thread\", ...}\n```\n\nWe emit events whenever a new object is created, transitions to a new state, or is being\nstreamed in parts (deltas). For example, we emit `thread.run.created` when a new run\nis created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses\nto create a message during a run, we emit a `thread.message.created event`, a\n`thread.message.in_progress` event, many `thread.message.delta` events, and finally a\n`thread.message.completed` event.\n\nWe may add additional events over time, so we recommend handling unknown events gracefully\nin your code. See the [Assistants API quickstart](https://platform.openai.com/docs/assistants/overview) to learn how to\nintegrate the Assistants API with streaming.\n"
      discriminator:
        propertyName: event
      x-oaiMeta:
        beta: true
        name: Assistant stream events
    AssistantSupportedModels:
      enum:
        - gpt-5
        - gpt-5-mini
        - gpt-5-nano
        - gpt-5-2025-08-07
        - gpt-5-mini-2025-08-07
        - gpt-5-nano-2025-08-07
        - gpt-4.1
        - gpt-4.1-mini
        - gpt-4.1-nano
        - gpt-4.1-2025-04-14
        - gpt-4.1-mini-2025-04-14
        - gpt-4.1-nano-2025-04-14
        - o3-mini
        - o3-mini-2025-01-31
        - o1
        - o1-2024-12-17
        - gpt-4o
        - gpt-4o-2024-11-20
        - gpt-4o-2024-08-06
        - gpt-4o-2024-05-13
        - gpt-4o-mini
        - gpt-4o-mini-2024-07-18
        - gpt-4.5-preview
        - gpt-4.5-preview-2025-02-27
        - gpt-4-turbo
        - gpt-4-turbo-2024-04-09
        - gpt-4-0125-preview
        - gpt-4-turbo-preview
        - gpt-4-1106-preview
        - gpt-4-vision-preview
        - gpt-4
        - gpt-4-0314
        - gpt-4-0613
        - gpt-4-32k
        - gpt-4-32k-0314
        - gpt-4-32k-0613
        - gpt-3.5-turbo
        - gpt-3.5-turbo-16k
        - gpt-3.5-turbo-0613
        - gpt-3.5-turbo-1106
        - gpt-3.5-turbo-0125
        - gpt-3.5-turbo-16k-0613
      type: string
    AssistantTool:
      anyOf:
        - $ref: '#/components/schemas/AssistantToolsCode'
        - $ref: '#/components/schemas/AssistantToolsFileSearch'
        - $ref: '#/components/schemas/AssistantToolsFunction'
      discriminator:
        propertyName: type
    AssistantToolsCode:
      title: Code interpreter tool
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - code_interpreter
          type: string
          description: 'The type of tool being defined: `code_interpreter`'
          x-stainless-const: true
    AssistantToolsFileSearch:
      title: FileSearch tool
      required:
        - type
      type: object
      properties:
        file_search:
          type: object
          properties:
            max_num_results:
              maximum: 50
              minimum: 1
              type: integer
              description: "The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.\n\nNote that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n"
            ranking_options:
              $ref: '#/components/schemas/FileSearchRankingOptions'
          description: Overrides for the file search tool.
        type:
          enum:
            - file_search
          type: string
          description: 'The type of tool being defined: `file_search`'
          x-stainless-const: true
    AssistantToolsFileSearchTypeOnly:
      title: FileSearch tool
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - file_search
          type: string
          description: 'The type of tool being defined: `file_search`'
          x-stainless-const: true
    AssistantToolsFunction:
      title: Function tool
      required:
        - type
        - function
      type: object
      properties:
        function:
          $ref: '#/components/schemas/FunctionObject'
        type:
          enum:
            - function
          type: string
          description: 'The type of tool being defined: `function`'
          x-stainless-const: true
    AssistantsApiResponseFormatOption:
      anyOf:
        - enum:
            - auto
          type: string
          description: "`auto` is the default value\n"
          x-stainless-const: true
        - $ref: '#/components/schemas/ResponseFormatText'
        - $ref: '#/components/schemas/ResponseFormatJsonObject'
        - $ref: '#/components/schemas/ResponseFormatJsonSchema'
      description: "Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models#gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.\n\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n"
    AssistantsApiToolChoiceOption:
      anyOf:
        - title: Auto
          enum:
            - none
            - auto
            - required
          type: string
          description: "`none` means the model will not call any tools and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user.\n"
        - $ref: '#/components/schemas/AssistantsNamedToolChoice'
      description: "Controls which (if any) tool is called by the model.\n`none` means the model will not call any tools and instead generates a message.\n`auto` is the default value and means the model can pick between generating a message or calling one or more tools.\n`required` means the model must call one or more tools before responding to the user.\nSpecifying a particular tool like `{\"type\": \"file_search\"}` or `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to call that tool.\n"
    AssistantsNamedToolChoice:
      required:
        - type
      type: object
      properties:
        function:
          required:
            - name
          type: object
          properties:
            name:
              type: string
              description: The name of the function to call.
        type:
          enum:
            - function
            - code_interpreter
            - file_search
          type: string
          description: 'The type of the tool. If type is `function`, the function name must be set'
      description: Specifies a tool the model should use. Use to force the model to call a specific tool.
    AudioResponseFormat:
      enum:
        - json
        - text
        - srt
        - verbose_json
        - vtt
      type: string
      description: "The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`. For `gpt-4o-transcribe` and `gpt-4o-mini-transcribe`, the only supported format is `json`.\n"
      default: json
    AuditLog:
      required:
        - id
        - type
        - effective_at
        - actor
      type: object
      properties:
        actor:
          $ref: '#/components/schemas/AuditLogActor'
        api_key.created:
          type: object
          properties:
            data:
              type: object
              properties:
                scopes:
                  type: array
                  items:
                    type: string
                  description: 'A list of scopes allowed for the API key, e.g. `["api.model.request"]`'
              description: The payload used to create the API key.
            id:
              type: string
              description: The tracking ID of the API key.
          description: The details for events with this `type`.
        api_key.deleted:
          type: object
          properties:
            id:
              type: string
              description: The tracking ID of the API key.
          description: The details for events with this `type`.
        api_key.updated:
          type: object
          properties:
            changes_requested:
              type: object
              properties:
                scopes:
                  type: array
                  items:
                    type: string
                  description: 'A list of scopes allowed for the API key, e.g. `["api.model.request"]`'
              description: The payload used to update the API key.
            id:
              type: string
              description: The tracking ID of the API key.
          description: The details for events with this `type`.
        certificate.created:
          type: object
          properties:
            id:
              type: string
              description: The certificate ID.
            name:
              type: string
              description: The name of the certificate.
          description: The details for events with this `type`.
        certificate.deleted:
          type: object
          properties:
            certificate:
              type: string
              description: The certificate content in PEM format.
            id:
              type: string
              description: The certificate ID.
            name:
              type: string
              description: The name of the certificate.
          description: The details for events with this `type`.
        certificate.updated:
          type: object
          properties:
            id:
              type: string
              description: The certificate ID.
            name:
              type: string
              description: The name of the certificate.
          description: The details for events with this `type`.
        certificates.activated:
          type: object
          properties:
            certificates:
              type: array
              items:
                type: object
                properties:
                  id:
                    type: string
                    description: The certificate ID.
                  name:
                    type: string
                    description: The name of the certificate.
          description: The details for events with this `type`.
        certificates.deactivated:
          type: object
          properties:
            certificates:
              type: array
              items:
                type: object
                properties:
                  id:
                    type: string
                    description: The certificate ID.
                  name:
                    type: string
                    description: The name of the certificate.
          description: The details for events with this `type`.
        checkpoint_permission.created:
          type: object
          properties:
            data:
              type: object
              properties:
                fine_tuned_model_checkpoint:
                  type: string
                  description: The ID of the fine-tuned model checkpoint.
                project_id:
                  type: string
                  description: The ID of the project that the checkpoint permission was created for.
              description: The payload used to create the checkpoint permission.
            id:
              type: string
              description: The ID of the checkpoint permission.
          description: The project and fine-tuned model checkpoint that the checkpoint permission was created for.
        checkpoint_permission.deleted:
          type: object
          properties:
            id:
              type: string
              description: The ID of the checkpoint permission.
          description: The details for events with this `type`.
        effective_at:
          type: integer
          description: The Unix timestamp (in seconds) of the event.
        id:
          type: string
          description: The ID of this log.
        invite.accepted:
          type: object
          properties:
            id:
              type: string
              description: The ID of the invite.
          description: The details for events with this `type`.
        invite.deleted:
          type: object
          properties:
            id:
              type: string
              description: The ID of the invite.
          description: The details for events with this `type`.
        invite.sent:
          type: object
          properties:
            data:
              type: object
              properties:
                email:
                  type: string
                  description: The email invited to the organization.
                role:
                  type: string
                  description: The role the email was invited to be. Is either `owner` or `member`.
              description: The payload used to create the invite.
            id:
              type: string
              description: The ID of the invite.
          description: The details for events with this `type`.
        login.failed:
          type: object
          properties:
            error_code:
              type: string
              description: The error code of the failure.
            error_message:
              type: string
              description: The error message of the failure.
          description: The details for events with this `type`.
        logout.failed:
          type: object
          properties:
            error_code:
              type: string
              description: The error code of the failure.
            error_message:
              type: string
              description: The error message of the failure.
          description: The details for events with this `type`.
        organization.updated:
          type: object
          properties:
            changes_requested:
              type: object
              properties:
                api_call_logging:
                  type: string
                  description: 'How your organization logs data from supported API calls. One of `disabled`, `enabled_per_call`, `enabled_for_all_projects`, or `enabled_for_selected_projects`'
                api_call_logging_project_ids:
                  type: string
                  description: The list of project ids if api_call_logging is set to `enabled_for_selected_projects`
                description:
                  type: string
                  description: The organization description.
                name:
                  type: string
                  description: The organization name.
                threads_ui_visibility:
                  type: string
                  description: 'Visibility of the threads page which shows messages created with the Assistants API and Playground. One of `ANY_ROLE`, `OWNERS`, or `NONE`.'
                title:
                  type: string
                  description: The organization title.
                usage_dashboard_visibility:
                  type: string
                  description: Visibility of the usage dashboard which shows activity and costs for your organization. One of `ANY_ROLE` or `OWNERS`.
              description: The payload used to update the organization settings.
            id:
              type: string
              description: The organization ID.
          description: The details for events with this `type`.
        project:
          type: object
          properties:
            id:
              type: string
              description: The project ID.
            name:
              type: string
              description: The project title.
          description: The project that the action was scoped to. Absent for actions not scoped to projects. Note that any admin actions taken via Admin API keys are associated with the default project.
        project.archived:
          type: object
          properties:
            id:
              type: string
              description: The project ID.
          description: The details for events with this `type`.
        project.created:
          type: object
          properties:
            data:
              type: object
              properties:
                name:
                  type: string
                  description: The project name.
                title:
                  type: string
                  description: The title of the project as seen on the dashboard.
              description: The payload used to create the project.
            id:
              type: string
              description: The project ID.
          description: The details for events with this `type`.
        project.updated:
          type: object
          properties:
            changes_requested:
              type: object
              properties:
                title:
                  type: string
                  description: The title of the project as seen on the dashboard.
              description: The payload used to update the project.
            id:
              type: string
              description: The project ID.
          description: The details for events with this `type`.
        rate_limit.deleted:
          type: object
          properties:
            id:
              type: string
              description: The rate limit ID
          description: The details for events with this `type`.
        rate_limit.updated:
          type: object
          properties:
            changes_requested:
              type: object
              properties:
                batch_1_day_max_input_tokens:
                  type: integer
                  description: The maximum batch input tokens per day. Only relevant for certain models.
                max_audio_megabytes_per_1_minute:
                  type: integer
                  description: The maximum audio megabytes per minute. Only relevant for certain models.
                max_images_per_1_minute:
                  type: integer
                  description: The maximum images per minute. Only relevant for certain models.
                max_requests_per_1_day:
                  type: integer
                  description: The maximum requests per day. Only relevant for certain models.
                max_requests_per_1_minute:
                  type: integer
                  description: The maximum requests per minute.
                max_tokens_per_1_minute:
                  type: integer
                  description: The maximum tokens per minute.
              description: The payload used to update the rate limits.
            id:
              type: string
              description: The rate limit ID
          description: The details for events with this `type`.
        service_account.created:
          type: object
          properties:
            data:
              type: object
              properties:
                role:
                  type: string
                  description: The role of the service account. Is either `owner` or `member`.
              description: The payload used to create the service account.
            id:
              type: string
              description: The service account ID.
          description: The details for events with this `type`.
        service_account.deleted:
          type: object
          properties:
            id:
              type: string
              description: The service account ID.
          description: The details for events with this `type`.
        service_account.updated:
          type: object
          properties:
            changes_requested:
              type: object
              properties:
                role:
                  type: string
                  description: The role of the service account. Is either `owner` or `member`.
              description: The payload used to updated the service account.
            id:
              type: string
              description: The service account ID.
          description: The details for events with this `type`.
        type:
          $ref: '#/components/schemas/AuditLogEventType'
        user.added:
          type: object
          properties:
            data:
              type: object
              properties:
                role:
                  type: string
                  description: The role of the user. Is either `owner` or `member`.
              description: The payload used to add the user to the project.
            id:
              type: string
              description: The user ID.
          description: The details for events with this `type`.
        user.deleted:
          type: object
          properties:
            id:
              type: string
              description: The user ID.
          description: The details for events with this `type`.
        user.updated:
          type: object
          properties:
            changes_requested:
              type: object
              properties:
                role:
                  type: string
                  description: The role of the user. Is either `owner` or `member`.
              description: The payload used to update the user.
            id:
              type: string
              description: The project ID.
          description: The details for events with this `type`.
      description: A log of a user action or configuration change within this organization.
      x-oaiMeta:
        example: "{\n    \"id\": \"req_xxx_20240101\",\n    \"type\": \"api_key.created\",\n    \"effective_at\": 1720804090,\n    \"actor\": {\n        \"type\": \"session\",\n        \"session\": {\n            \"user\": {\n                \"id\": \"user-xxx\",\n                \"email\": \"user@example.com\"\n            },\n            \"ip_address\": \"127.0.0.1\",\n            \"user_agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n        }\n    },\n    \"api_key.created\": {\n        \"id\": \"key_xxxx\",\n        \"data\": {\n            \"scopes\": [\"resource.operation\"]\n        }\n    }\n}\n"
        name: The audit log object
    AuditLogActor:
      type: object
      properties:
        api_key:
          $ref: '#/components/schemas/AuditLogActorApiKey'
        session:
          $ref: '#/components/schemas/AuditLogActorSession'
        type:
          enum:
            - session
            - api_key
          type: string
          description: The type of actor. Is either `session` or `api_key`.
      description: The actor who performed the audit logged action.
    AuditLogActorApiKey:
      type: object
      properties:
        id:
          type: string
          description: The tracking id of the API key.
        service_account:
          $ref: '#/components/schemas/AuditLogActorServiceAccount'
        type:
          enum:
            - user
            - service_account
          type: string
          description: The type of API key. Can be either `user` or `service_account`.
        user:
          $ref: '#/components/schemas/AuditLogActorUser'
      description: The API Key used to perform the audit logged action.
    AuditLogActorServiceAccount:
      type: object
      properties:
        id:
          type: string
          description: The service account id.
      description: The service account that performed the audit logged action.
    AuditLogActorSession:
      type: object
      properties:
        ip_address:
          type: string
          description: The IP address from which the action was performed.
        user:
          $ref: '#/components/schemas/AuditLogActorUser'
      description: The session in which the audit logged action was performed.
    AuditLogActorUser:
      type: object
      properties:
        email:
          type: string
          description: The user email.
        id:
          type: string
          description: The user id.
      description: The user who performed the audit logged action.
    AuditLogEventType:
      enum:
        - api_key.created
        - api_key.updated
        - api_key.deleted
        - checkpoint_permission.created
        - checkpoint_permission.deleted
        - invite.sent
        - invite.accepted
        - invite.deleted
        - login.succeeded
        - login.failed
        - logout.succeeded
        - logout.failed
        - organization.updated
        - project.created
        - project.updated
        - project.archived
        - service_account.created
        - service_account.updated
        - service_account.deleted
        - rate_limit.updated
        - rate_limit.deleted
        - user.added
        - user.updated
        - user.deleted
      type: string
      description: The event type.
    AutoChunkingStrategyRequestParam:
      title: Auto Chunking Strategy
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - auto
          type: string
          description: Always `auto`.
          x-stainless-const: true
      additionalProperties: false
      description: The default strategy. This strategy currently uses a `max_chunk_size_tokens` of `800` and `chunk_overlap_tokens` of `400`.
    Batch:
      required:
        - id
        - object
        - endpoint
        - input_file_id
        - completion_window
        - status
        - created_at
      type: object
      properties:
        cancelled_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch was cancelled.
        cancelling_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch started cancelling.
        completed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch was completed.
        completion_window:
          type: string
          description: The time frame within which the batch should be processed.
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch was created.
        endpoint:
          type: string
          description: The OpenAI API endpoint used by the batch.
        error_file_id:
          type: string
          description: The ID of the file containing the outputs of requests with errors.
        errors:
          type: object
          properties:
            data:
              type: array
              items:
                $ref: '#/components/schemas/BatchError'
            object:
              type: string
              description: 'The object type, which is always `list`.'
        expired_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch expired.
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch will expire.
        failed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch failed.
        finalizing_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch started finalizing.
        id:
          type: string
        in_progress_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch started processing.
        input_file_id:
          type: string
          description: The ID of the input file for the batch.
        metadata:
          $ref: '#/components/schemas/Metadata'
        object:
          enum:
            - batch
          type: string
          description: 'The object type, which is always `batch`.'
          x-stainless-const: true
        output_file_id:
          type: string
          description: The ID of the file containing the outputs of successfully executed requests.
        request_counts:
          $ref: '#/components/schemas/BatchRequestCounts'
        status:
          enum:
            - validating
            - failed
            - in_progress
            - finalizing
            - completed
            - expired
            - cancelling
            - cancelled
          type: string
          description: The current status of the batch.
      x-oaiMeta:
        example: "{\n  \"id\": \"batch_abc123\",\n  \"object\": \"batch\",\n  \"endpoint\": \"/v1/completions\",\n  \"errors\": null,\n  \"input_file_id\": \"file-abc123\",\n  \"completion_window\": \"24h\",\n  \"status\": \"completed\",\n  \"output_file_id\": \"file-cvaTdG\",\n  \"error_file_id\": \"file-HOWS94\",\n  \"created_at\": 1711471533,\n  \"in_progress_at\": 1711471538,\n  \"expires_at\": 1711557933,\n  \"finalizing_at\": 1711493133,\n  \"completed_at\": 1711493163,\n  \"failed_at\": null,\n  \"expired_at\": null,\n  \"cancelling_at\": null,\n  \"cancelled_at\": null,\n  \"request_counts\": {\n    \"total\": 100,\n    \"completed\": 95,\n    \"failed\": 5\n  },\n  \"metadata\": {\n    \"customer_id\": \"user_123456789\",\n    \"batch_description\": \"Nightly eval job\",\n  }\n}\n"
        name: The batch object
    BatchError:
      type: object
      properties:
        code:
          type: string
          description: An error code identifying the error type.
        line:
          type: integer
          description: 'The line number of the input file where the error occurred, if applicable.'
          nullable: true
        message:
          type: string
          description: A human-readable message providing more details about the error.
        param:
          type: string
          description: 'The name of the parameter that caused the error, if applicable.'
          nullable: true
    BatchFileExpirationAfter:
      title: File expiration policy
      required:
        - anchor
        - seconds
      type: object
      properties:
        anchor:
          enum:
            - created_at
          type: string
          description: 'Anchor timestamp after which the expiration policy applies. Supported anchors: `created_at`. Note that the anchor is the file creation time, not the time the batch is created.'
          x-stainless-const: true
        seconds:
          maximum: 2592000
          minimum: 3600
          type: integer
          description: The number of seconds after the anchor time that the file will expire. Must be between 3600 (1 hour) and 2592000 (30 days).
      description: The expiration policy for the output and/or error file that are generated for a batch.
    BatchRequestCounts:
      required:
        - total
        - completed
        - failed
      type: object
      properties:
        completed:
          type: integer
          description: Number of requests that have been completed successfully.
        failed:
          type: integer
          description: Number of requests that have failed.
        total:
          type: integer
          description: Total number of requests in the batch.
      description: The request counts for different statuses within the batch.
    BatchRequestInput:
      type: object
      properties:
        custom_id:
          type: string
          description: A developer-provided per-request id that will be used to match outputs to inputs. Must be unique for each request in a batch.
        method:
          enum:
            - POST
          type: string
          description: The HTTP method to be used for the request. Currently only `POST` is supported.
          x-stainless-const: true
        url:
          type: string
          description: 'The OpenAI API relative URL to be used for the request. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported.'
      description: The per-line object of the batch input file
      x-oaiMeta:
        example: "{\"custom_id\": \"request-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4o-mini\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"What is 2+2?\"}]}}\n"
        name: The request input object
    BatchRequestOutput:
      type: object
      properties:
        custom_id:
          type: string
          description: A developer-provided per-request id that will be used to match outputs to inputs.
        error:
          type: object
          properties:
            code:
              type: string
              description: A machine-readable error code.
            message:
              type: string
              description: A human-readable error message.
          description: 'For requests that failed with a non-HTTP error, this will contain more information on the cause of the failure.'
          nullable: true
        id:
          type: string
        response:
          type: object
          properties:
            body:
              type: object
              description: The JSON body of the response
              x-oaiTypeLabel: map
            request_id:
              type: string
              description: An unique identifier for the OpenAI API request. Please include this request ID when contacting support.
            status_code:
              type: integer
              description: The HTTP status code of the response
          nullable: true
      description: The per-line object of the batch output and error files
      x-oaiMeta:
        example: "{\"id\": \"batch_req_wnaDys\", \"custom_id\": \"request-2\", \"response\": {\"status_code\": 200, \"request_id\": \"req_c187b3\", \"body\": {\"id\": \"chatcmpl-9758Iw\", \"object\": \"chat.completion\", \"created\": 1711475054, \"model\": \"gpt-4o-mini\", \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": \"2 + 2 equals 4.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 24, \"completion_tokens\": 15, \"total_tokens\": 39}, \"system_fingerprint\": null}}, \"error\": null}\n"
        name: The request output object
    Certificate:
      required:
        - object
        - id
        - name
        - created_at
        - certificate_details
      type: object
      properties:
        active:
          type: boolean
          description: Whether the certificate is currently active at the specified scope. Not returned when getting details for a specific certificate.
        certificate_details:
          type: object
          properties:
            content:
              type: string
              description: The content of the certificate in PEM format.
            expires_at:
              type: integer
              description: The Unix timestamp (in seconds) of when the certificate expires.
            valid_at:
              type: integer
              description: The Unix timestamp (in seconds) of when the certificate becomes valid.
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the certificate was uploaded.
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints'
        name:
          type: string
          description: The name of the certificate.
        object:
          enum:
            - certificate
            - organization.certificate
            - organization.project.certificate
          type: string
          description: "The object type.\n\n- If creating, updating, or getting a specific certificate, the object type is `certificate`.\n- If listing, activating, or deactivating certificates for the organization, the object type is `organization.certificate`.\n- If listing, activating, or deactivating certificates for a project, the object type is `organization.project.certificate`.\n"
          x-stainless-const: true
      description: Represents an individual `certificate` uploaded to the organization.
      x-oaiMeta:
        example: "{\n  \"object\": \"certificate\",\n  \"id\": \"cert_abc\",\n  \"name\": \"My Certificate\",\n  \"created_at\": 1234567,\n  \"certificate_details\": {\n    \"valid_at\": 1234567,\n    \"expires_at\": 12345678,\n    \"content\": \"-----BEGIN CERTIFICATE----- MIIGAjCCA...6znFlOW+ -----END CERTIFICATE-----\"\n  }\n}\n"
        name: The certificate object
    ChatCompletionAllowedTools:
      title: Allowed tools
      required:
        - mode
        - tools
      type: object
      properties:
        mode:
          enum:
            - auto
            - required
          type: string
          description: "Constrains the tools available to the model to a pre-defined set.\n\n`auto` allows the model to pick from among the allowed tools and generate a\nmessage.\n\n`required` requires the model to call one or more of the allowed tools.\n"
        tools:
          type: array
          items:
            type: object
            description: "A tool definition that the model should be allowed to call.\n"
            x-oaiExpandable: false
          description: "A list of tool definitions that the model should be allowed to call.\n\nFor the Chat Completions API, the list of tool definitions might look like:\n```json\n[\n  { \"type\": \"function\", \"function\": { \"name\": \"get_weather\" } },\n  { \"type\": \"function\", \"function\": { \"name\": \"get_time\" } }\n]\n```\n"
      description: "Constrains the tools available to the model to a pre-defined set.\n"
    ChatCompletionAllowedToolsChoice:
      title: Allowed tools
      required:
        - type
        - allowed_tools
      type: object
      properties:
        allowed_tools:
          $ref: '#/components/schemas/ChatCompletionAllowedTools'
        type:
          enum:
            - allowed_tools
          type: string
          description: Allowed tool configuration type. Always `allowed_tools`.
          x-stainless-const: true
      description: "Constrains the tools available to the model to a pre-defined set.\n"
    ChatCompletionDeleted:
      required:
        - object
        - id
        - deleted
      type: object
      properties:
        deleted:
          type: boolean
          description: Whether the chat completion was deleted.
        id:
          type: string
          description: The ID of the chat completion that was deleted.
        object:
          enum:
            - chat.completion.deleted
          type: string
          description: The type of object being deleted.
          x-stainless-const: true
    ChatCompletionFunctionCallOption:
      required:
        - name
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call.
      description: "Specifying a particular function via `{\"name\": \"my_function\"}` forces the model to call that function.\n"
      x-stainless-variantName: function_call_option
    ChatCompletionFunctions:
      required:
        - name
      type: object
      properties:
        description:
          type: string
          description: 'A description of what the function does, used by the model to choose when and how to call the function.'
        name:
          type: string
          description: 'The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'
        parameters:
          $ref: '#/components/schemas/FunctionParameters'
      deprecated: true
    ChatCompletionList:
      title: ChatCompletionList
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/CreateChatCompletionResponse'
          description: "An array of chat completion objects.\n"
        first_id:
          type: string
          description: The identifier of the first chat completion in the data array.
        has_more:
          type: boolean
          description: Indicates whether there are more Chat Completions available.
        last_id:
          type: string
          description: The identifier of the last chat completion in the data array.
        object:
          enum:
            - list
          type: string
          description: "The type of this object. It is always set to \"list\".\n"
          default: list
          x-stainless-const: true
      description: "An object representing a list of Chat Completions.\n"
      x-oaiMeta:
        example: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"chat.completion\",\n      \"id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2\",\n      \"model\": \"gpt-4o-2024-08-06\",\n      \"created\": 1738960610,\n      \"request_id\": \"req_ded8ab984ec4bf840f37566c1011c417\",\n      \"tool_choice\": null,\n      \"usage\": {\n        \"total_tokens\": 31,\n        \"completion_tokens\": 18,\n        \"prompt_tokens\": 13\n      },\n      \"seed\": 4944116822809979520,\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"presence_penalty\": 0.0,\n      \"frequency_penalty\": 0.0,\n      \"system_fingerprint\": \"fp_50cad350e4\",\n      \"input_user\": null,\n      \"service_tier\": \"default\",\n      \"tools\": null,\n      \"metadata\": {},\n      \"choices\": [\n        {\n          \"index\": 0,\n          \"message\": {\n            \"content\": \"Mind of circuits hum,  \\nLearning patterns in silence—  \\nFuture's quiet spark.\",\n            \"role\": \"assistant\",\n            \"tool_calls\": null,\n            \"function_call\": null\n          },\n          \"finish_reason\": \"stop\",\n          \"logprobs\": null\n        }\n      ],\n      \"response_format\": null\n    }\n  ],\n  \"first_id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2\",\n  \"last_id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2\",\n  \"has_more\": false\n}\n"
        group: chat
        name: The chat completion list object
    ChatCompletionMessageCustomToolCall:
      title: Custom tool call
      required:
        - id
        - type
        - custom
      type: object
      properties:
        custom:
          required:
            - name
            - input
          type: object
          properties:
            input:
              type: string
              description: The input for the custom tool call generated by the model.
            name:
              type: string
              description: The name of the custom tool to call.
          description: The custom tool that the model called.
        id:
          type: string
          description: The ID of the tool call.
        type:
          enum:
            - custom
          type: string
          description: The type of the tool. Always `custom`.
          x-stainless-const: true
      description: "A call to a custom tool created by the model.\n"
    ChatCompletionMessageList:
      title: ChatCompletionMessageList
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            allOf:
              - $ref: '#/components/schemas/ChatCompletionResponseMessage'
              - required:
                  - id
                type: object
                properties:
                  content_parts:
                    type: array
                    items:
                      anyOf:
                        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
                        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartImage'
                    description: "If a content parts array was provided, this is an array of `text` and `image_url` parts. \nOtherwise, null.\n"
                    nullable: true
                  id:
                    type: string
                    description: The identifier of the chat message.
          description: "An array of chat completion message objects.\n"
        first_id:
          type: string
          description: The identifier of the first chat message in the data array.
        has_more:
          type: boolean
          description: Indicates whether there are more chat messages available.
        last_id:
          type: string
          description: The identifier of the last chat message in the data array.
        object:
          enum:
            - list
          type: string
          description: "The type of this object. It is always set to \"list\".\n"
          default: list
          x-stainless-const: true
      description: "An object representing a list of chat completion messages.\n"
      x-oaiMeta:
        example: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0\",\n      \"role\": \"user\",\n      \"content\": \"write a haiku about ai\",\n      \"name\": null,\n      \"content_parts\": null\n    }\n  ],\n  \"first_id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0\",\n  \"last_id\": \"chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0\",\n  \"has_more\": false\n}\n"
        group: chat
        name: The chat completion message list object
    ChatCompletionMessageToolCall:
      title: Function tool call
      required:
        - id
        - type
        - function
      type: object
      properties:
        function:
          required:
            - name
            - arguments
          type: object
          properties:
            arguments:
              type: string
              description: 'The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.'
            name:
              type: string
              description: The name of the function to call.
          description: The function that the model called.
        id:
          type: string
          description: The ID of the tool call.
        type:
          enum:
            - function
          type: string
          description: 'The type of the tool. Currently, only `function` is supported.'
          x-stainless-const: true
      description: "A call to a function tool created by the model.\n"
    ChatCompletionMessageToolCallChunk:
      required:
        - index
      type: object
      properties:
        function:
          type: object
          properties:
            arguments:
              type: string
              description: 'The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.'
            name:
              type: string
              description: The name of the function to call.
        id:
          type: string
          description: The ID of the tool call.
        index:
          type: integer
        type:
          enum:
            - function
          type: string
          description: 'The type of the tool. Currently, only `function` is supported.'
          x-stainless-const: true
    ChatCompletionMessageToolCalls:
      type: array
      items:
        anyOf:
          - $ref: '#/components/schemas/ChatCompletionMessageToolCall'
          - $ref: '#/components/schemas/ChatCompletionMessageCustomToolCall'
        discriminator:
          propertyName: type
        x-stainless-go-variant-constructor: skip
        x-stainless-naming:
          python:
            model_name: chat_completion_message_tool_call_union
            param_model_name: chat_completion_message_tool_call_union_param
      description: 'The tool calls generated by the model, such as function calls.'
    ChatCompletionModalities:
      type: array
      items:
        enum:
          - text
          - audio
        type: string
      description: "Output types that you would like the model to generate for this request.\nMost models are capable of generating text, which is the default:\n\n`[\"text\"]`\n\nThe `gpt-4o-audio-preview` model can also be used to [generate audio](https://platform.openai.com/docs/guides/audio). To\nrequest that this model generate both text and audio responses, you can\nuse:\n\n`[\"text\", \"audio\"]`\n"
      nullable: true
    ChatCompletionNamedToolChoice:
      title: Function tool choice
      required:
        - type
        - function
      type: object
      properties:
        function:
          required:
            - name
          type: object
          properties:
            name:
              type: string
              description: The name of the function to call.
        type:
          enum:
            - function
          type: string
          description: 'For function calling, the type is always `function`.'
          x-stainless-const: true
      description: Specifies a tool the model should use. Use to force the model to call a specific function.
    ChatCompletionNamedToolChoiceCustom:
      title: Custom tool choice
      required:
        - type
        - custom
      type: object
      properties:
        custom:
          required:
            - name
          type: object
          properties:
            name:
              type: string
              description: The name of the custom tool to call.
        type:
          enum:
            - custom
          type: string
          description: 'For custom tool calling, the type is always `custom`.'
          x-stainless-const: true
      description: Specifies a tool the model should use. Use to force the model to call a specific custom tool.
    ChatCompletionRequestAssistantMessage:
      title: Assistant message
      required:
        - role
      type: object
      properties:
        audio:
          required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "Unique identifier for a previous audio response from the model.\n"
          description: "Data about a previous audio response from the model. \n[Learn more](https://platform.openai.com/docs/guides/audio).\n"
          nullable: true
        content:
          anyOf:
            - title: Text content
              type: string
              description: The contents of the assistant message.
            - title: Array of content parts
              minItems: 1
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionRequestAssistantMessageContentPart'
              description: 'An array of content parts with a defined type. Can be one or more of type `text`, or exactly one of type `refusal`.'
          description: "The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified.\n"
          nullable: true
        function_call:
          required:
            - arguments
            - name
          type: object
          properties:
            arguments:
              type: string
              description: 'The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.'
            name:
              type: string
              description: The name of the function to call.
          description: 'Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model.'
          nullable: true
          deprecated: true
        name:
          type: string
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
        refusal:
          type: string
          description: The refusal message by the assistant.
          nullable: true
        role:
          enum:
            - assistant
          type: string
          description: 'The role of the messages author, in this case `assistant`.'
          x-stainless-const: true
        tool_calls:
          $ref: '#/components/schemas/ChatCompletionMessageToolCalls'
      description: "Messages sent by the model in response to user messages.\n"
      x-stainless-soft-required:
        - content
    ChatCompletionRequestAssistantMessageContentPart:
      anyOf:
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartRefusal'
      discriminator:
        propertyName: type
    ChatCompletionRequestDeveloperMessage:
      title: Developer message
      required:
        - content
        - role
      type: object
      properties:
        content:
          anyOf:
            - title: Text content
              type: string
              description: The contents of the developer message.
            - title: Array of content parts
              minItems: 1
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
              description: 'An array of content parts with a defined type. For developer messages, only type `text` is supported.'
          description: The contents of the developer message.
        name:
          type: string
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
        role:
          enum:
            - developer
          type: string
          description: 'The role of the messages author, in this case `developer`.'
          x-stainless-const: true
      description: "Developer-provided instructions that the model should follow, regardless of\nmessages sent by the user. With o1 models and newer, `developer` messages\nreplace the previous `system` messages.\n"
      x-stainless-naming:
        go:
          variant_constructor: DeveloperMessage
    ChatCompletionRequestFunctionMessage:
      title: Function message
      required:
        - role
        - content
        - name
      type: object
      properties:
        content:
          type: string
          description: The contents of the function message.
          nullable: true
        name:
          type: string
          description: The name of the function to call.
        role:
          enum:
            - function
          type: string
          description: 'The role of the messages author, in this case `function`.'
          x-stainless-const: true
      deprecated: true
    ChatCompletionRequestMessage:
      anyOf:
        - $ref: '#/components/schemas/ChatCompletionRequestDeveloperMessage'
        - $ref: '#/components/schemas/ChatCompletionRequestSystemMessage'
        - $ref: '#/components/schemas/ChatCompletionRequestUserMessage'
        - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage'
        - $ref: '#/components/schemas/ChatCompletionRequestToolMessage'
        - $ref: '#/components/schemas/ChatCompletionRequestFunctionMessage'
      discriminator:
        propertyName: role
    ChatCompletionRequestMessageContentPartAudio:
      title: Audio content part
      required:
        - type
        - input_audio
      type: object
      properties:
        input_audio:
          required:
            - data
            - format
          type: object
          properties:
            data:
              type: string
              description: Base64 encoded audio data.
            format:
              enum:
                - wav
                - mp3
              type: string
              description: "The format of the encoded audio data. Currently supports \"wav\" and \"mp3\".\n"
        type:
          enum:
            - input_audio
          type: string
          description: The type of the content part. Always `input_audio`.
          x-stainless-const: true
      description: "Learn about [audio inputs](https://platform.openai.com/docs/guides/audio).\n"
      x-stainless-naming:
        go:
          variant_constructor: InputAudioContentPart
    ChatCompletionRequestMessageContentPartFile:
      title: File content part
      required:
        - type
        - file
      type: object
      properties:
        file:
          type: object
          properties:
            file_data:
              type: string
              description: "The base64 encoded file data, used when passing the file to the model \nas a string.\n"
            file_id:
              type: string
              description: "The ID of an uploaded file to use as input.\n"
            filename:
              type: string
              description: "The name of the file, used when passing the file to the model as a \nstring.\n"
          x-stainless-naming:
            java:
              type_name: FileObject
            kotlin:
              type_name: FileObject
        type:
          enum:
            - file
          type: string
          description: The type of the content part. Always `file`.
          x-stainless-const: true
      description: "Learn about [file inputs](https://platform.openai.com/docs/guides/text) for text generation.\n"
      x-stainless-naming:
        go:
          variant_constructor: FileContentPart
    ChatCompletionRequestMessageContentPartImage:
      title: Image content part
      required:
        - type
        - image_url
      type: object
      properties:
        image_url:
          required:
            - url
          type: object
          properties:
            detail:
              enum:
                - auto
                - low
                - high
              type: string
              description: 'Specifies the detail level of the image. Learn more in the [Vision guide](https://platform.openai.com/docs/guides/vision#low-or-high-fidelity-image-understanding).'
              default: auto
            url:
              type: string
              description: Either a URL of the image or the base64 encoded image data.
              format: uri
        type:
          enum:
            - image_url
          type: string
          description: The type of the content part.
          x-stainless-const: true
      description: "Learn about [image inputs](https://platform.openai.com/docs/guides/vision).\n"
      x-stainless-naming:
        go:
          variant_constructor: ImageContentPart
    ChatCompletionRequestMessageContentPartRefusal:
      title: Refusal content part
      required:
        - type
        - refusal
      type: object
      properties:
        refusal:
          type: string
          description: The refusal message generated by the model.
        type:
          enum:
            - refusal
          type: string
          description: The type of the content part.
          x-stainless-const: true
    ChatCompletionRequestMessageContentPartText:
      title: Text content part
      required:
        - type
        - text
      type: object
      properties:
        text:
          type: string
          description: The text content.
        type:
          enum:
            - text
          type: string
          description: The type of the content part.
          x-stainless-const: true
      description: "Learn about [text inputs](https://platform.openai.com/docs/guides/text-generation).\n"
      x-stainless-naming:
        go:
          variant_constructor: TextContentPart
    ChatCompletionRequestSystemMessage:
      title: System message
      required:
        - content
        - role
      type: object
      properties:
        content:
          anyOf:
            - title: Text content
              type: string
              description: The contents of the system message.
            - title: Array of content parts
              minItems: 1
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionRequestSystemMessageContentPart'
              description: 'An array of content parts with a defined type. For system messages, only type `text` is supported.'
          description: The contents of the system message.
        name:
          type: string
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
        role:
          enum:
            - system
          type: string
          description: 'The role of the messages author, in this case `system`.'
          x-stainless-const: true
      description: "Developer-provided instructions that the model should follow, regardless of\nmessages sent by the user. With o1 models and newer, use `developer` messages\nfor this purpose instead.\n"
      x-stainless-naming:
        go:
          variant_constructor: SystemMessage
    ChatCompletionRequestSystemMessageContentPart:
      anyOf:
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
    ChatCompletionRequestToolMessage:
      title: Tool message
      required:
        - role
        - content
        - tool_call_id
      type: object
      properties:
        content:
          anyOf:
            - title: Text content
              type: string
              description: The contents of the tool message.
            - title: Array of content parts
              minItems: 1
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionRequestToolMessageContentPart'
              description: 'An array of content parts with a defined type. For tool messages, only type `text` is supported.'
          description: The contents of the tool message.
        role:
          enum:
            - tool
          type: string
          description: 'The role of the messages author, in this case `tool`.'
          x-stainless-const: true
        tool_call_id:
          type: string
          description: Tool call that this message is responding to.
      x-stainless-naming:
        go:
          variant_constructor: ToolMessage
    ChatCompletionRequestToolMessageContentPart:
      anyOf:
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
    ChatCompletionRequestUserMessage:
      title: User message
      required:
        - content
        - role
      type: object
      properties:
        content:
          anyOf:
            - title: Text content
              type: string
              description: The text contents of the message.
            - title: Array of content parts
              minItems: 1
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionRequestUserMessageContentPart'
              description: 'An array of content parts with a defined type. Supported options differ based on the [model](https://platform.openai.com/docs/models) being used to generate the response. Can contain text, image, or audio inputs.'
          description: "The contents of the user message.\n"
        name:
          type: string
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
        role:
          enum:
            - user
          type: string
          description: 'The role of the messages author, in this case `user`.'
          x-stainless-const: true
      description: "Messages sent by an end user, containing prompts or additional context\ninformation.\n"
      x-stainless-naming:
        go:
          variant_constructor: UserMessage
    ChatCompletionRequestUserMessageContentPart:
      anyOf:
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartImage'
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartAudio'
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartFile'
      discriminator:
        propertyName: type
    ChatCompletionResponseMessage:
      required:
        - role
      type: object
      properties:
        annotations:
          type: array
          items:
            required:
              - type
              - url_citation
            type: object
            properties:
              type:
                enum:
                  - url_citation
                type: string
                description: The type of the URL citation. Always `url_citation`.
                x-stainless-const: true
              url_citation:
                required:
                  - end_index
                  - start_index
                  - url
                  - title
                type: object
                properties:
                  end_index:
                    type: integer
                    description: The index of the last character of the URL citation in the message.
                  start_index:
                    type: integer
                    description: The index of the first character of the URL citation in the message.
                  title:
                    type: string
                    description: The title of the web resource.
                  url:
                    type: string
                    description: The URL of the web resource.
                description: A URL citation when using web search.
            description: "A URL citation when using web search.\n"
          description: "Annotations for the message, when applicable, as when using the\n[web search tool](https://platform.openai.com/docs/guides/tools-web-search?api-mode=chat).\n"
        audio:
          required:
            - id
            - expires_at
            - data
            - transcript
          type: object
          properties:
            data:
              type: string
              description: "Base64 encoded audio bytes generated by the model, in the format\nspecified in the request.\n"
            expires_at:
              type: integer
              description: "The Unix timestamp (in seconds) for when this audio response will\nno longer be accessible on the server for use in multi-turn\nconversations.\n"
            id:
              type: string
              description: Unique identifier for this audio response.
            transcript:
              type: string
              description: Transcript of the audio generated by the model.
          description: "If the audio output modality is requested, this object contains data\nabout the audio response from the model. [Learn more](https://platform.openai.com/docs/guides/audio).\n"
          nullable: true
        content:
          type: string
          description: The contents of the message.
          nullable: true
        function_call:
          required:
            - name
            - arguments
          type: object
          properties:
            arguments:
              type: string
              description: 'The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.'
            name:
              type: string
              description: The name of the function to call.
          description: 'Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model.'
          deprecated: true
        refusal:
          type: string
          description: The refusal message generated by the model.
          nullable: true
        role:
          enum:
            - assistant
          type: string
          description: The role of the author of this message.
          x-stainless-const: true
        tool_calls:
          $ref: '#/components/schemas/ChatCompletionMessageToolCalls'
      description: A chat completion message generated by the model.
    ChatCompletionRole:
      enum:
        - developer
        - system
        - user
        - assistant
        - tool
        - function
      type: string
      description: The role of the author of a message
    ChatCompletionStreamOptions:
      type: object
      properties:
        include_obfuscation:
          type: boolean
          description: "When true, stream obfuscation will be enabled. Stream obfuscation adds\nrandom characters to an `obfuscation` field on streaming delta events to\nnormalize payload sizes as a mitigation to certain side-channel attacks.\nThese obfuscation fields are included by default, but add a small amount\nof overhead to the data stream. You can set `include_obfuscation` to\nfalse to optimize for bandwidth if you trust the network links between\nyour application and the OpenAI API.\n"
        include_usage:
          type: boolean
          description: "If set, an additional chunk will be streamed before the `data: [DONE]`\nmessage. The `usage` field on this chunk shows the token usage statistics\nfor the entire request, and the `choices` field will always be an empty\narray.\n\nAll other chunks will also include a `usage` field, but with a null\nvalue. **NOTE:** If the stream is interrupted, you may not receive the\nfinal usage chunk which contains the total token usage for the request.\n"
      description: "Options for streaming response. Only set this when you set `stream: true`.\n"
      default: 
      nullable: true
    ChatCompletionStreamResponseDelta:
      type: object
      properties:
        content:
          type: string
          description: The contents of the chunk message.
          nullable: true
        function_call:
          type: object
          properties:
            arguments:
              type: string
              description: 'The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.'
            name:
              type: string
              description: The name of the function to call.
          description: 'Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model.'
          deprecated: true
        refusal:
          type: string
          description: The refusal message generated by the model.
          nullable: true
        role:
          enum:
            - developer
            - system
            - user
            - assistant
            - tool
          type: string
          description: The role of the author of this message.
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionMessageToolCallChunk'
      description: A chat completion delta generated by streamed model responses.
    ChatCompletionTokenLogprob:
      required:
        - token
        - logprob
        - bytes
        - top_logprobs
      type: object
      properties:
        bytes:
          type: array
          items:
            type: integer
          description: A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
          nullable: true
        logprob:
          type: number
          description: 'The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely.'
        token:
          type: string
          description: The token.
        top_logprobs:
          type: array
          items:
            required:
              - token
              - logprob
              - bytes
            type: object
            properties:
              bytes:
                type: array
                items:
                  type: integer
                description: A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
                nullable: true
              logprob:
                type: number
                description: 'The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely.'
              token:
                type: string
                description: The token.
          description: 'List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number of requested `top_logprobs` returned.'
    ChatCompletionTool:
      title: Function tool
      required:
        - type
        - function
      type: object
      properties:
        function:
          $ref: '#/components/schemas/FunctionObject'
        type:
          enum:
            - function
          type: string
          description: 'The type of the tool. Currently, only `function` is supported.'
          x-stainless-const: true
      description: "A function tool that can be used to generate a response.\n"
    ChatCompletionToolChoiceOption:
      anyOf:
        - title: Auto
          enum:
            - none
            - auto
            - required
          type: string
          description: "`none` means the model will not call any tool and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools.\n"
        - $ref: '#/components/schemas/ChatCompletionAllowedToolsChoice'
        - $ref: '#/components/schemas/ChatCompletionNamedToolChoice'
        - $ref: '#/components/schemas/ChatCompletionNamedToolChoiceCustom'
      description: "Controls which (if any) tool is called by the model.\n`none` means the model will not call any tool and instead generates a message.\n`auto` means the model can pick between generating a message or calling one or more tools.\n`required` means the model must call one or more tools.\nSpecifying a particular tool via `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to call that tool.\n\n`none` is the default when no tools are present. `auto` is the default if tools are present.\n"
      x-stainless-go-variant-constructor:
        naming: 'tool_choice_option_{variant}'
    ChatModel:
      enum:
        - gpt-5
        - gpt-5-mini
        - gpt-5-nano
        - gpt-5-2025-08-07
        - gpt-5-mini-2025-08-07
        - gpt-5-nano-2025-08-07
        - gpt-5-chat-latest
        - gpt-4.1
        - gpt-4.1-mini
        - gpt-4.1-nano
        - gpt-4.1-2025-04-14
        - gpt-4.1-mini-2025-04-14
        - gpt-4.1-nano-2025-04-14
        - o4-mini
        - o4-mini-2025-04-16
        - o3
        - o3-2025-04-16
        - o3-mini
        - o3-mini-2025-01-31
        - o1
        - o1-2024-12-17
        - o1-preview
        - o1-preview-2024-09-12
        - o1-mini
        - o1-mini-2024-09-12
        - gpt-4o
        - gpt-4o-2024-11-20
        - gpt-4o-2024-08-06
        - gpt-4o-2024-05-13
        - gpt-4o-audio-preview
        - gpt-4o-audio-preview-2024-10-01
        - gpt-4o-audio-preview-2024-12-17
        - gpt-4o-audio-preview-2025-06-03
        - gpt-4o-mini-audio-preview
        - gpt-4o-mini-audio-preview-2024-12-17
        - gpt-4o-search-preview
        - gpt-4o-mini-search-preview
        - gpt-4o-search-preview-2025-03-11
        - gpt-4o-mini-search-preview-2025-03-11
        - chatgpt-4o-latest
        - codex-mini-latest
        - gpt-4o-mini
        - gpt-4o-mini-2024-07-18
        - gpt-4-turbo
        - gpt-4-turbo-2024-04-09
        - gpt-4-0125-preview
        - gpt-4-turbo-preview
        - gpt-4-1106-preview
        - gpt-4-vision-preview
        - gpt-4
        - gpt-4-0314
        - gpt-4-0613
        - gpt-4-32k
        - gpt-4-32k-0314
        - gpt-4-32k-0613
        - gpt-3.5-turbo
        - gpt-3.5-turbo-16k
        - gpt-3.5-turbo-0301
        - gpt-3.5-turbo-0613
        - gpt-3.5-turbo-1106
        - gpt-3.5-turbo-0125
        - gpt-3.5-turbo-16k-0613
      type: string
      x-stainless-nominal: false
    ChunkingStrategyRequestParam:
      type: object
      anyOf:
        - $ref: '#/components/schemas/AutoChunkingStrategyRequestParam'
        - $ref: '#/components/schemas/StaticChunkingStrategyRequestParam'
      description: 'The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy. Only applicable if `file_ids` is non-empty.'
      discriminator:
        propertyName: type
    ChunkingStrategyResponse:
      type: object
      anyOf:
        - $ref: '#/components/schemas/StaticChunkingStrategyResponseParam'
        - $ref: '#/components/schemas/OtherChunkingStrategyResponseParam'
      description: The strategy used to chunk the file.
      discriminator:
        propertyName: type
    Click:
      title: Click
      required:
        - type
        - button
        - x
        - y
      type: object
      properties:
        button:
          enum:
            - left
            - right
            - wheel
            - back
            - forward
          type: string
          description: "Indicates which mouse button was pressed during the click. One of `left`, `right`, `wheel`, `back`, or `forward`.\n"
        type:
          enum:
            - click
          type: string
          description: "Specifies the event type. For a click action, this property is \nalways set to `click`.\n"
          default: click
          x-stainless-const: true
        x:
          type: integer
          description: "The x-coordinate where the click occurred.\n"
        y:
          type: integer
          description: "The y-coordinate where the click occurred.\n"
      description: "A click action.\n"
    CodeInterpreterFileOutput:
      title: Code interpreter file output
      required:
        - type
        - files
      type: object
      properties:
        files:
          type: array
          items:
            required:
              - mime_type
              - file_id
            type: object
            properties:
              file_id:
                type: string
                description: "The ID of the file.\n"
              mime_type:
                type: string
                description: "The MIME type of the file.\n"
        type:
          enum:
            - files
          type: string
          description: "The type of the code interpreter file output. Always `files`.\n"
          x-stainless-const: true
      description: "The output of a code interpreter tool call that is a file.\n"
    CodeInterpreterOutputImage:
      title: Code interpreter output image
      required:
        - type
        - url
      type: object
      properties:
        type:
          enum:
            - image
          type: string
          description: The type of the output. Always 'image'.
          default: image
          x-stainless-const: true
        url:
          type: string
          description: The URL of the image output from the code interpreter.
      description: "The image output from the code interpreter.\n"
    CodeInterpreterOutputLogs:
      title: Code interpreter output logs
      required:
        - type
        - logs
      type: object
      properties:
        logs:
          type: string
          description: The logs output from the code interpreter.
        type:
          enum:
            - logs
          type: string
          description: The type of the output. Always 'logs'.
          default: logs
          x-stainless-const: true
      description: "The logs output from the code interpreter.\n"
    CodeInterpreterTextOutput:
      title: Code interpreter text output
      required:
        - type
        - logs
      type: object
      properties:
        logs:
          type: string
          description: "The logs of the code interpreter tool call.\n"
        type:
          enum:
            - logs
          type: string
          description: "The type of the code interpreter text output. Always `logs`.\n"
          x-stainless-const: true
      description: "The output of a code interpreter tool call that is text.\n"
    CodeInterpreterTool:
      title: Code interpreter
      required:
        - type
        - container
      type: object
      properties:
        container:
          anyOf:
            - type: string
              description: The container ID.
            - $ref: '#/components/schemas/CodeInterpreterToolAuto'
          description: "The code interpreter container. Can be a container ID or an object that\nspecifies uploaded file IDs to make available to your code.\n"
        type:
          enum:
            - code_interpreter
          type: string
          description: "The type of the code interpreter tool. Always `code_interpreter`.\n"
          x-stainless-const: true
      description: "A tool that runs Python code to help generate a response to a prompt.\n"
    CodeInterpreterToolAuto:
      title: CodeInterpreterContainerAuto
      required:
        - type
      type: object
      properties:
        file_ids:
          type: array
          items:
            type: string
          description: "An optional list of uploaded files to make available to your code.\n"
        type:
          enum:
            - auto
          type: string
          description: Always `auto`.
          x-stainless-const: true
      description: "Configuration for a code interpreter container. Optionally specify the IDs\nof the files to run the code on.\n"
    CodeInterpreterToolCall:
      title: Code interpreter tool call
      required:
        - type
        - id
        - status
        - container_id
        - code
        - outputs
      type: object
      properties:
        code:
          type: string
          description: "The code to run, or null if not available.\n"
          nullable: true
        container_id:
          type: string
          description: "The ID of the container used to run the code.\n"
        id:
          type: string
          description: "The unique ID of the code interpreter tool call.\n"
        outputs:
          type: array
          items:
            anyOf:
              - $ref: '#/components/schemas/CodeInterpreterOutputLogs'
              - $ref: '#/components/schemas/CodeInterpreterOutputImage'
            discriminator:
              propertyName: type
          description: "The outputs generated by the code interpreter, such as logs or images. \nCan be null if no outputs are available.\n"
          nullable: true
          discriminator:
            propertyName: type
        status:
          enum:
            - in_progress
            - completed
            - incomplete
            - interpreting
            - failed
          type: string
          description: "The status of the code interpreter tool call. Valid values are `in_progress`, `completed`, `incomplete`, `interpreting`, and `failed`.\n"
        type:
          enum:
            - code_interpreter_call
          type: string
          description: "The type of the code interpreter tool call. Always `code_interpreter_call`.\n"
          default: code_interpreter_call
          x-stainless-const: true
      description: "A tool call to run code.\n"
    ComparisonFilter:
      title: Comparison Filter
      required:
        - type
        - key
        - value
      type: object
      properties:
        key:
          type: string
          description: The key to compare against the value.
        type:
          enum:
            - eq
            - ne
            - gt
            - gte
            - lt
            - lte
          type: string
          description: "Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`.\n- `eq`: equals\n- `ne`: not equal\n- `gt`: greater than\n- `gte`: greater than or equal\n- `lt`: less than\n- `lte`: less than or equal\n"
          default: eq
        value:
          anyOf:
            - type: string
            - type: number
            - type: boolean
          description: 'The value to compare against the attribute key; supports string, number, or boolean types.'
      additionalProperties: false
      description: "A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n"
      x-oaiMeta:
        name: ComparisonFilter
    CompleteUploadRequest:
      required:
        - part_ids
      type: object
      properties:
        md5:
          type: string
          description: "The optional md5 checksum for the file contents to verify if the bytes uploaded matches what you expect.\n"
        part_ids:
          type: array
          items:
            type: string
          description: "The ordered list of Part IDs.\n"
      additionalProperties: false
    CompletionUsage:
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      type: object
      properties:
        completion_tokens:
          type: integer
          description: Number of tokens in the generated completion.
          default: 0
        completion_tokens_details:
          type: object
          properties:
            accepted_prediction_tokens:
              type: integer
              description: "When using Predicted Outputs, the number of tokens in the\nprediction that appeared in the completion.\n"
              default: 0
            audio_tokens:
              type: integer
              description: Audio input tokens generated by the model.
              default: 0
            reasoning_tokens:
              type: integer
              description: Tokens generated by the model for reasoning.
              default: 0
            rejected_prediction_tokens:
              type: integer
              description: "When using Predicted Outputs, the number of tokens in the\nprediction that did not appear in the completion. However, like\nreasoning tokens, these tokens are still counted in the total\ncompletion tokens for purposes of billing, output, and context window\nlimits.\n"
              default: 0
          description: Breakdown of tokens used in a completion.
        prompt_tokens:
          type: integer
          description: Number of tokens in the prompt.
          default: 0
        prompt_tokens_details:
          type: object
          properties:
            audio_tokens:
              type: integer
              description: Audio input tokens present in the prompt.
              default: 0
            cached_tokens:
              type: integer
              description: Cached tokens present in the prompt.
              default: 0
          description: Breakdown of tokens used in the prompt.
        total_tokens:
          type: integer
          description: Total number of tokens used in the request (prompt + completion).
          default: 0
      description: Usage statistics for the completion request.
    CompoundFilter:
      title: Compound Filter
      required:
        - type
        - filters
      type: object
      properties:
        filters:
          type: array
          items:
            anyOf:
              - $ref: '#/components/schemas/ComparisonFilter'
              - { }
          description: Array of filters to combine. Items can be `ComparisonFilter` or `CompoundFilter`.
        type:
          enum:
            - and
            - or
          type: string
          description: 'Type of operation: `and` or `or`.'
      additionalProperties: false
      description: Combine multiple filters using `and` or `or`.
      x-oaiMeta:
        name: CompoundFilter
    ComputerAction:
      anyOf:
        - $ref: '#/components/schemas/Click'
        - $ref: '#/components/schemas/DoubleClick'
        - $ref: '#/components/schemas/Drag'
        - $ref: '#/components/schemas/KeyPress'
        - $ref: '#/components/schemas/Move'
        - $ref: '#/components/schemas/Screenshot'
        - $ref: '#/components/schemas/Scroll'
        - $ref: '#/components/schemas/Type'
        - $ref: '#/components/schemas/Wait'
      discriminator:
        propertyName: type
    ComputerCallOutputItemParam:
      title: Computer tool call output
      required:
        - call_id
        - type
        - output
      type: object
      properties:
        acknowledged_safety_checks:
          type: array
          items:
            $ref: '#/components/schemas/ComputerCallSafetyCheckParam'
          description: The safety checks reported by the API that have been acknowledged by the developer.
          nullable: true
        call_id:
          maxLength: 64
          minLength: 1
          type: string
          description: The ID of the computer tool call that produced the output.
        id:
          type: string
          description: The ID of the computer tool call output.
          nullable: true
        output:
          $ref: '#/components/schemas/ComputerScreenshotImage'
        status:
          enum:
            - in_progress
            - completed
            - incomplete
          type: string
          description: 'The status of the message input. One of `in_progress`, `completed`, or `incomplete`. Populated when input items are returned via API.'
          nullable: true
        type:
          enum:
            - computer_call_output
          type: string
          description: The type of the computer tool call output. Always `computer_call_output`.
          default: computer_call_output
          x-stainless-const: true
      description: The output of a computer tool call.
    ComputerCallSafetyCheckParam:
      required:
        - id
      type: object
      properties:
        code:
          type: string
          description: The type of the pending safety check.
          nullable: true
        id:
          type: string
          description: The ID of the pending safety check.
        message:
          type: string
          description: Details about the pending safety check.
          nullable: true
      description: A pending safety check for the computer call.
    ComputerScreenshotContent:
      title: Computer screenshot
      required:
        - type
        - image_url
        - file_id
      type: object
      properties:
        file_id:
          type: string
          description: The identifier of an uploaded file that contains the screenshot.
          nullable: true
        image_url:
          type: string
          description: The URL of the screenshot image.
          nullable: true
        type:
          enum:
            - computer_screenshot
          type: string
          description: 'Specifies the event type. For a computer screenshot, this property is always set to `computer_screenshot`.'
          default: computer_screenshot
          x-stainless-const: true
    ComputerScreenshotImage:
      required:
        - type
      type: object
      properties:
        file_id:
          type: string
          description: The identifier of an uploaded file that contains the screenshot.
        image_url:
          type: string
          description: The URL of the screenshot image.
        type:
          enum:
            - computer_screenshot
          type: string
          description: "Specifies the event type. For a computer screenshot, this property is \nalways set to `computer_screenshot`.\n"
          default: computer_screenshot
          x-stainless-const: true
      description: "A computer screenshot image used with the computer use tool.\n"
    ComputerToolCall:
      title: Computer tool call
      required:
        - type
        - id
        - action
        - call_id
        - pending_safety_checks
        - status
      type: object
      properties:
        action:
          $ref: '#/components/schemas/ComputerAction'
        call_id:
          type: string
          description: "An identifier used when responding to the tool call with output.\n"
        id:
          type: string
          description: The unique ID of the computer call.
        pending_safety_checks:
          type: array
          items:
            $ref: '#/components/schemas/ComputerToolCallSafetyCheck'
          description: "The pending safety checks for the computer call.\n"
        status:
          enum:
            - in_progress
            - completed
            - incomplete
          type: string
          description: "The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n"
        type:
          enum:
            - computer_call
          type: string
          description: The type of the computer call. Always `computer_call`.
          default: computer_call
      description: "A tool call to a computer use tool. See the \n[computer use guide](https://platform.openai.com/docs/guides/tools-computer-use) for more information.\n"
    ComputerToolCallOutput:
      title: Computer tool call output
      required:
        - type
        - call_id
        - output
      type: object
      properties:
        acknowledged_safety_checks:
          type: array
          items:
            $ref: '#/components/schemas/ComputerToolCallSafetyCheck'
          description: "The safety checks reported by the API that have been acknowledged by the \ndeveloper.\n"
        call_id:
          type: string
          description: "The ID of the computer tool call that produced the output.\n"
        id:
          type: string
          description: "The ID of the computer tool call output.\n"
        output:
          $ref: '#/components/schemas/ComputerScreenshotImage'
        status:
          enum:
            - in_progress
            - completed
            - incomplete
          type: string
          description: "The status of the message input. One of `in_progress`, `completed`, or\n`incomplete`. Populated when input items are returned via API.\n"
        type:
          enum:
            - computer_call_output
          type: string
          description: "The type of the computer tool call output. Always `computer_call_output`.\n"
          default: computer_call_output
          x-stainless-const: true
      description: "The output of a computer tool call.\n"
    ComputerToolCallOutputResource:
      allOf:
        - $ref: '#/components/schemas/ComputerToolCallOutput'
        - required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "The unique ID of the computer call tool output.\n"
    ComputerToolCallSafetyCheck:
      required:
        - id
        - code
        - message
      type: object
      properties:
        code:
          type: string
          description: The type of the pending safety check.
        id:
          type: string
          description: The ID of the pending safety check.
        message:
          type: string
          description: Details about the pending safety check.
      description: "A pending safety check for the computer call.\n"
    ComputerUsePreviewTool:
      title: Computer use preview
      required:
        - type
        - environment
        - display_width
        - display_height
      type: object
      properties:
        display_height:
          type: integer
          description: The height of the computer display.
        display_width:
          type: integer
          description: The width of the computer display.
        environment:
          enum:
            - windows
            - mac
            - linux
            - ubuntu
            - browser
          type: string
          description: The type of computer environment to control.
        type:
          enum:
            - computer_use_preview
          type: string
          description: The type of the computer use tool. Always `computer_use_preview`.
          default: computer_use_preview
          x-stainless-const: true
      description: 'A tool that controls a virtual computer. Learn more about the [computer tool](https://platform.openai.com/docs/guides/tools-computer-use).'
    ContainerFileCitationBody:
      title: Container file citation
      required:
        - type
        - container_id
        - file_id
        - start_index
        - end_index
        - filename
      type: object
      properties:
        container_id:
          type: string
          description: The ID of the container file.
        end_index:
          type: integer
          description: The index of the last character of the container file citation in the message.
        file_id:
          type: string
          description: The ID of the file.
        filename:
          type: string
          description: The filename of the container file cited.
        start_index:
          type: integer
          description: The index of the first character of the container file citation in the message.
        type:
          enum:
            - container_file_citation
          type: string
          description: The type of the container file citation. Always `container_file_citation`.
          default: container_file_citation
          x-stainless-const: true
      description: A citation for a container file used to generate a model response.
    ContainerFileCitationBody-2:
      title: Container file citation
      required:
        - type
        - container_id
        - file_id
        - start_index
        - end_index
        - filename
      type: object
      properties:
        container_id:
          type: string
          description: The ID of the container file.
        end_index:
          type: integer
          description: The index of the last character of the container file citation in the message.
        file_id:
          type: string
          description: The ID of the file.
        filename:
          type: string
          description: The filename of the container file cited.
        start_index:
          type: integer
          description: The index of the first character of the container file citation in the message.
        type:
          enum:
            - container_file_citation
          type: string
          description: The type of the container file citation. Always `container_file_citation`.
          default: container_file_citation
          x-stainless-const: true
    ContainerFileListResource:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/ContainerFileResource'
          description: A list of container files.
        first_id:
          type: string
          description: The ID of the first file in the list.
        has_more:
          type: boolean
          description: Whether there are more files available.
        last_id:
          type: string
          description: The ID of the last file in the list.
        object:
          enum:
            - list
          description: 'The type of object returned, must be ''list''.'
    ContainerFileResource:
      title: The container file object
      required:
        - id
        - object
        - created_at
        - bytes
        - container_id
        - path
        - source
      type: object
      properties:
        bytes:
          type: integer
          description: Size of the file in bytes.
        container_id:
          type: string
          description: The container this file belongs to.
        created_at:
          type: integer
          description: Unix timestamp (in seconds) when the file was created.
        id:
          type: string
          description: Unique identifier for the file.
        object:
          enum:
            - container.file
          type: string
          description: The type of this object (`container.file`).
        path:
          type: string
          description: Path of the file in the container.
        source:
          type: string
          description: 'Source of the file (e.g., `user`, `assistant`).'
      x-oaiMeta:
        example: "{\n    \"id\": \"cfile_682e0e8a43c88191a7978f477a09bdf5\",\n    \"object\": \"container.file\",\n    \"created_at\": 1747848842,\n    \"bytes\": 880,\n    \"container_id\": \"cntr_682e0e7318108198aa783fd921ff305e08e78805b9fdbb04\",\n    \"path\": \"/mnt/data/88e12fa445d32636f190a0b33daed6cb-tsconfig.json\",\n    \"source\": \"user\"\n}\n"
        name: The container file object
    ContainerListResource:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/ContainerResource'
          description: A list of containers.
        first_id:
          type: string
          description: The ID of the first container in the list.
        has_more:
          type: boolean
          description: Whether there are more containers available.
        last_id:
          type: string
          description: The ID of the last container in the list.
        object:
          enum:
            - list
          description: 'The type of object returned, must be ''list''.'
    ContainerResource:
      title: The container object
      required:
        - id
        - object
        - name
        - created_at
        - status
      type: object
      properties:
        created_at:
          type: integer
          description: Unix timestamp (in seconds) when the container was created.
        expires_after:
          type: object
          properties:
            anchor:
              enum:
                - last_active_at
              type: string
              description: The reference point for the expiration.
            minutes:
              type: integer
              description: The number of minutes after the anchor before the container expires.
          description: "The container will expire after this time period.\nThe anchor is the reference point for the expiration.\nThe minutes is the number of minutes after the anchor before the container expires.\n"
        id:
          type: string
          description: Unique identifier for the container.
        name:
          type: string
          description: Name of the container.
        object:
          type: string
          description: The type of this object.
        status:
          type: string
          description: 'Status of the container (e.g., active, deleted).'
      x-oaiMeta:
        example: "{\n   \"id\": \"cntr_682dfebaacac8198bbfe9c2474fb6f4a085685cbe3cb5863\",\n   \"object\": \"container\",\n   \"created_at\": 1747844794,\n   \"status\": \"running\",\n   \"expires_after\": {\n     \"anchor\": \"last_active_at\",\n     \"minutes\": 20\n   },\n   \"last_active_at\": 1747844794,\n   \"name\": \"My Container\"\n}\n"
        name: The container object
    Content:
      anyOf:
        - $ref: '#/components/schemas/InputContent'
        - $ref: '#/components/schemas/OutputContent'
      description: "Multi-modal input and output contents.\n"
    Conversation:
      title: The conversation object
      allOf:
        - $ref: '#/components/schemas/ConversationResource'
      x-oaiMeta:
        group: conversations
        name: The conversation object
    Conversation-2:
      title: Conversation
      required:
        - id
      type: object
      properties:
        id:
          type: string
          description: The unique ID of the conversation.
      description: The conversation that this response belongs to. Input items and output items from this response are automatically added to this conversation.
    ConversationItem:
      title: Conversation item
      anyOf:
        - $ref: '#/components/schemas/Message'
        - $ref: '#/components/schemas/FunctionToolCallResource'
        - $ref: '#/components/schemas/FunctionToolCallOutputResource'
        - $ref: '#/components/schemas/FileSearchToolCall'
        - $ref: '#/components/schemas/WebSearchToolCall'
        - $ref: '#/components/schemas/ImageGenToolCall'
        - $ref: '#/components/schemas/ComputerToolCall'
        - $ref: '#/components/schemas/ComputerToolCallOutputResource'
        - $ref: '#/components/schemas/ReasoningItem'
        - $ref: '#/components/schemas/CodeInterpreterToolCall'
        - $ref: '#/components/schemas/LocalShellToolCall'
        - $ref: '#/components/schemas/LocalShellToolCallOutput'
        - $ref: '#/components/schemas/MCPListTools'
        - $ref: '#/components/schemas/MCPApprovalRequest'
        - $ref: '#/components/schemas/MCPApprovalResponseResource'
        - $ref: '#/components/schemas/MCPToolCall'
        - $ref: '#/components/schemas/CustomToolCall'
        - $ref: '#/components/schemas/CustomToolCallOutput'
      description: 'A single item within a conversation. The set of possible types are the same as the `output` type of a [Response object](https://platform.openai.com/docs/api-reference/responses/object#responses/object-output).'
      discriminator:
        propertyName: type
      x-oaiMeta:
        group: conversations
        name: The item object
    ConversationItemList:
      title: The conversation item list
      required:
        - object
        - data
        - has_more
        - first_id
        - last_id
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/ConversationItem'
          description: A list of conversation items.
        first_id:
          type: string
          description: The ID of the first item in the list.
        has_more:
          type: boolean
          description: Whether there are more items available.
        last_id:
          type: string
          description: The ID of the last item in the list.
        object:
          enum:
            - list
          description: 'The type of object returned, must be `list`.'
          x-stainless-const: true
      description: A list of Conversation items.
      x-oaiMeta:
        group: conversations
        name: The item list
    ConversationParam:
      title: Conversation object
      required:
        - id
      type: object
      properties:
        id:
          type: string
          description: The unique ID of the conversation.
      description: The conversation that this response belongs to.
    ConversationResource:
      required:
        - id
        - object
        - metadata
        - created_at
      type: object
      properties:
        created_at:
          type: integer
          description: 'The time at which the conversation was created, measured in seconds since the Unix epoch.'
        id:
          type: string
          description: The unique ID of the conversation.
        metadata:
          description: "Set of 16 key-value pairs that can be attached to an object. This can be         useful for storing additional information about the object in a structured         format, and querying for objects via API or the dashboard.\n        Keys are strings with a maximum length of 64 characters. Values are strings         with a maximum length of 512 characters."
        object:
          enum:
            - conversation
          type: string
          description: 'The object type, which is always `conversation`.'
          default: conversation
          x-stainless-const: true
    Coordinate:
      title: Coordinate
      required:
        - x
        - y
      type: object
      properties:
        x:
          type: integer
          description: "The x-coordinate.\n"
        y:
          type: integer
          description: "The y-coordinate.\n"
      description: "An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.\n"
    CostsResult:
      required:
        - object
      type: object
      properties:
        amount:
          type: object
          properties:
            currency:
              type: string
              description: Lowercase ISO-4217 currency e.g. "usd"
            value:
              type: number
              description: The numeric value of the cost.
          description: The monetary value in its associated currency.
        line_item:
          type: string
          description: 'When `group_by=line_item`, this field provides the line item of the grouped costs result.'
          nullable: true
        object:
          enum:
            - organization.costs.result
          type: string
          x-stainless-const: true
        project_id:
          type: string
          description: 'When `group_by=project_id`, this field provides the project ID of the grouped costs result.'
          nullable: true
      description: The aggregated costs details of the specific time bucket.
      x-oaiMeta:
        example: "{\n    \"object\": \"organization.costs.result\",\n    \"amount\": {\n      \"value\": 0.06,\n      \"currency\": \"usd\"\n    },\n    \"line_item\": \"Image models\",\n    \"project_id\": \"proj_abc\"\n}\n"
        name: Costs object
    CreateAssistantRequest:
      required:
        - model
      type: object
      properties:
        description:
          maxLength: 512
          type: string
          description: "The description of the assistant. The maximum length is 512 characters.\n"
          nullable: true
        instructions:
          maxLength: 256000
          type: string
          description: "The system instructions that the assistant uses. The maximum length is 256,000 characters.\n"
          nullable: true
        metadata:
          $ref: '#/components/schemas/Metadata'
        model:
          anyOf:
            - type: string
            - $ref: '#/components/schemas/AssistantSupportedModels'
          description: "ID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models) for descriptions of them.\n"
          example: gpt-4o
          x-oaiTypeLabel: string
        name:
          maxLength: 256
          type: string
          description: "The name of the assistant. The maximum length is 256 characters.\n"
          nullable: true
        reasoning_effort:
          $ref: '#/components/schemas/ReasoningEffort'
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n"
          default: 1
          nullable: true
          example: 1
        tool_resources:
          type: object
          properties:
            code_interpreter:
              type: object
              properties:
                file_ids:
                  maxItems: 20
                  type: array
                  items:
                    type: string
                  description: "A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n"
            file_search:
              type: object
              anyOf:
                - required:
                    - vector_store_ids
                - required:
                    - vector_stores
              properties:
                vector_store_ids:
                  maxItems: 1
                  type: array
                  items:
                    type: string
                  description: "The [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.\n"
                vector_stores:
                  maxItems: 1
                  type: array
                  items:
                    type: object
                    properties:
                      chunking_strategy:
                        type: object
                        anyOf:
                          - title: Auto Chunking Strategy
                            required:
                              - type
                            type: object
                            properties:
                              type:
                                enum:
                                  - auto
                                type: string
                                description: Always `auto`.
                                x-stainless-const: true
                            additionalProperties: false
                            description: The default strategy. This strategy currently uses a `max_chunk_size_tokens` of `800` and `chunk_overlap_tokens` of `400`.
                          - title: Static Chunking Strategy
                            required:
                              - type
                              - static
                            type: object
                            properties:
                              static:
                                required:
                                  - max_chunk_size_tokens
                                  - chunk_overlap_tokens
                                type: object
                                properties:
                                  chunk_overlap_tokens:
                                    type: integer
                                    description: "The number of tokens that overlap between chunks. The default value is `400`.\n\nNote that the overlap must not exceed half of `max_chunk_size_tokens`.\n"
                                  max_chunk_size_tokens:
                                    maximum: 4096
                                    minimum: 100
                                    type: integer
                                    description: The maximum number of tokens in each chunk. The default value is `800`. The minimum value is `100` and the maximum value is `4096`.
                                additionalProperties: false
                              type:
                                enum:
                                  - static
                                type: string
                                description: Always `static`.
                                x-stainless-const: true
                            additionalProperties: false
                            x-stainless-naming:
                              java:
                                type_name: StaticObject
                              kotlin:
                                type_name: StaticObject
                        description: 'The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.'
                        discriminator:
                          propertyName: type
                      file_ids:
                        maxItems: 10000
                        type: array
                        items:
                          type: string
                        description: "A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to add to the vector store. There can be a maximum of 10000 files in a vector store.\n"
                      metadata:
                        $ref: '#/components/schemas/Metadata'
                  description: "A helper to create a [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) with file_ids and attach it to this assistant. There can be a maximum of 1 vector store attached to the assistant.\n"
          description: "A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n"
          nullable: true
        tools:
          maxItems: 128
          type: array
          items:
            $ref: '#/components/schemas/AssistantTool'
          description: "A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.\n"
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n"
          default: 1
          nullable: true
          example: 1
      additionalProperties: false
    CreateChatCompletionRequest:
      allOf:
        - $ref: '#/components/schemas/CreateModelResponseProperties'
        - required:
            - model
            - messages
          type: object
          properties:
            audio:
              required:
                - voice
                - format
              type: object
              properties:
                format:
                  enum:
                    - wav
                    - aac
                    - mp3
                    - flac
                    - opus
                    - pcm16
                  type: string
                  description: "Specifies the output audio format. Must be one of `wav`, `mp3`, `flac`,\n`opus`, or `pcm16`.\n"
                voice:
                  $ref: '#/components/schemas/VoiceIdsShared'
              description: "Parameters for audio output. Required when audio output is requested with\n`modalities: [\"audio\"]`. [Learn more](https://platform.openai.com/docs/guides/audio).\n"
              nullable: true
            frequency_penalty:
              maximum: 2
              minimum: -2
              type: number
              description: "Number between -2.0 and 2.0. Positive values penalize new tokens based on\ntheir existing frequency in the text so far, decreasing the model's\nlikelihood to repeat the same line verbatim.\n"
              default: 0
              nullable: true
            function_call:
              anyOf:
                - title: function call mode
                  enum:
                    - none
                    - auto
                  type: string
                  description: "`none` means the model will not call a function and instead generates a message. `auto` means the model can pick between generating a message or calling a function.\n"
                - $ref: '#/components/schemas/ChatCompletionFunctionCallOption'
              description: "Deprecated in favor of `tool_choice`.\n\nControls which (if any) function is called by the model.\n\n`none` means the model will not call a function and instead generates a\nmessage.\n\n`auto` means the model can pick between generating a message or calling a\nfunction.\n\nSpecifying a particular function via `{\"name\": \"my_function\"}` forces the\nmodel to call that function.\n\n`none` is the default when no functions are present. `auto` is the default\nif functions are present.\n"
              deprecated: true
            functions:
              maxItems: 128
              minItems: 1
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionFunctions'
              description: "Deprecated in favor of `tools`.\n\nA list of functions the model may generate JSON inputs for.\n"
              deprecated: true
            logit_bias:
              type: object
              additionalProperties:
                type: integer
              description: "Modify the likelihood of specified tokens appearing in the completion.\n\nAccepts a JSON object that maps tokens (specified by their token ID in the\ntokenizer) to an associated bias value from -100 to 100. Mathematically,\nthe bias is added to the logits generated by the model prior to sampling.\nThe exact effect will vary per model, but values between -1 and 1 should\ndecrease or increase likelihood of selection; values like -100 or 100\nshould result in a ban or exclusive selection of the relevant token.\n"
              default: 
              nullable: true
              x-oaiTypeLabel: map
            logprobs:
              type: boolean
              description: "Whether to return log probabilities of the output tokens or not. If true,\nreturns the log probabilities of each output token returned in the\n`content` of `message`.\n"
              default: false
              nullable: true
            max_completion_tokens:
              type: integer
              description: "An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).\n"
              nullable: true
            max_tokens:
              type: integer
              description: "The maximum number of [tokens](/tokenizer) that can be generated in the\nchat completion. This value can be used to control\n[costs](https://openai.com/api/pricing/) for text generated via API.\n\nThis value is now deprecated in favor of `max_completion_tokens`, and is\nnot compatible with [o-series models](https://platform.openai.com/docs/guides/reasoning).\n"
              nullable: true
              deprecated: true
            messages:
              minItems: 1
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionRequestMessage'
              description: "A list of messages comprising the conversation so far. Depending on the\n[model](https://platform.openai.com/docs/models) you use, different message types (modalities) are\nsupported, like [text](https://platform.openai.com/docs/guides/text-generation),\n[images](https://platform.openai.com/docs/guides/vision), and [audio](https://platform.openai.com/docs/guides/audio).\n"
            modalities:
              $ref: '#/components/schemas/ResponseModalities'
            model:
              $ref: '#/components/schemas/ModelIdsShared'
            n:
              maximum: 128
              minimum: 1
              type: integer
              description: How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.
              default: 1
              nullable: true
              example: 1
            parallel_tool_calls:
              $ref: '#/components/schemas/ParallelToolCalls'
            prediction:
              anyOf:
                - $ref: '#/components/schemas/PredictionContent'
              description: "Configuration for a [Predicted Output](https://platform.openai.com/docs/guides/predicted-outputs),\nwhich can greatly improve response times when large parts of the model\nresponse are known ahead of time. This is most common when you are\nregenerating a file with only minor changes to most of the content.\n"
              nullable: true
              discriminator:
                propertyName: type
            presence_penalty:
              maximum: 2
              minimum: -2
              type: number
              description: "Number between -2.0 and 2.0. Positive values penalize new tokens based on\nwhether they appear in the text so far, increasing the model's likelihood\nto talk about new topics.\n"
              default: 0
              nullable: true
            reasoning_effort:
              $ref: '#/components/schemas/ReasoningEffort'
            response_format:
              anyOf:
                - $ref: '#/components/schemas/ResponseFormatText'
                - $ref: '#/components/schemas/ResponseFormatJsonSchema'
                - $ref: '#/components/schemas/ResponseFormatJsonObject'
              description: "An object specifying the format that the model must output.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables\nStructured Outputs which ensures the model will match your supplied JSON\nschema. Learn more in the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it.\n"
            seed:
              maximum: 9223372036854776000
              type: integer
              description: "This feature is in Beta.\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.\nDeterminism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.\n"
              nullable: true
              deprecated: true
              x-oaiMeta:
                beta: true
            stop:
              $ref: '#/components/schemas/StopConfiguration'
            store:
              type: boolean
              description: "Whether or not to store the output of this chat completion request for\nuse in our [model distillation](https://platform.openai.com/docs/guides/distillation) or\n[evals](https://platform.openai.com/docs/guides/evals) products.\n\nSupports text and image inputs. Note: image inputs over 8MB will be dropped.\n"
              default: false
              nullable: true
            stream:
              type: boolean
              description: "If set to true, the model response data will be streamed to the client\nas it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\nSee the [Streaming section below](https://platform.openai.com/docs/api-reference/chat/streaming)\nfor more information, along with the [streaming responses](https://platform.openai.com/docs/guides/streaming-responses)\nguide for more information on how to handle the streaming events.\n"
              default: false
              nullable: true
            stream_options:
              $ref: '#/components/schemas/ChatCompletionStreamOptions'
            tool_choice:
              $ref: '#/components/schemas/ChatCompletionToolChoiceOption'
            tools:
              type: array
              items:
                anyOf:
                  - $ref: '#/components/schemas/ChatCompletionTool'
                  - $ref: '#/components/schemas/CustomToolChatCompletions'
                discriminator:
                  propertyName: type
                x-stainless-go-variant-constructor:
                  naming: 'chat_completion_{variant}_tool'
                x-stainless-naming:
                  python:
                    model_name: chat_completion_tool_union
                    param_model_name: chat_completion_tool_union_param
              description: "A list of tools the model may call. You can provide either\n[custom tools](https://platform.openai.com/docs/guides/function-calling#custom-tools) or\n[function tools](https://platform.openai.com/docs/guides/function-calling).\n"
            top_logprobs:
              maximum: 20
              minimum: 0
              type: integer
              description: "An integer between 0 and 20 specifying the number of most likely tokens to\nreturn at each token position, each with an associated log probability.\n`logprobs` must be set to `true` if this parameter is used.\n"
              nullable: true
            verbosity:
              $ref: '#/components/schemas/Verbosity'
            web_search_options:
              title: Web search
              type: object
              properties:
                search_context_size:
                  $ref: '#/components/schemas/WebSearchContextSize'
                user_location:
                  required:
                    - type
                    - approximate
                  type: object
                  properties:
                    approximate:
                      $ref: '#/components/schemas/WebSearchLocation'
                    type:
                      enum:
                        - approximate
                      type: string
                      description: "The type of location approximation. Always `approximate`.\n"
                      x-stainless-const: true
                  description: "Approximate location parameters for the search.\n"
                  nullable: true
              description: "This tool searches the web for relevant results to use in a response.\nLearn more about the [web search tool](https://platform.openai.com/docs/guides/tools-web-search?api-mode=chat).\n"
    CreateChatCompletionResponse:
      required:
        - choices
        - created
        - id
        - model
        - object
      type: object
      properties:
        choices:
          type: array
          items:
            required:
              - finish_reason
              - index
              - message
            type: object
            properties:
              finish_reason:
                enum:
                  - stop
                  - length
                  - tool_calls
                  - content_filter
                  - function_call
                type: string
                description: "The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,\n`length` if the maximum number of tokens specified in the request was reached,\n`content_filter` if content was omitted due to a flag from our content filters,\n`tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.\n"
              index:
                type: integer
                description: The index of the choice in the list of choices.
              logprobs:
                required:
                  - content
                  - refusal
                type: object
                properties:
                  content:
                    type: array
                    items:
                      $ref: '#/components/schemas/ChatCompletionTokenLogprob'
                    description: A list of message content tokens with log probability information.
                    nullable: true
                  refusal:
                    type: array
                    items:
                      $ref: '#/components/schemas/ChatCompletionTokenLogprob'
                    description: A list of message refusal tokens with log probability information.
                    nullable: true
                description: Log probability information for the choice.
                nullable: true
              message:
                $ref: '#/components/schemas/ChatCompletionResponseMessage'
          description: A list of chat completion choices. Can be more than one if `n` is greater than 1.
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion was created.
        id:
          type: string
          description: A unique identifier for the chat completion.
        model:
          type: string
          description: The model used for the chat completion.
        object:
          enum:
            - chat.completion
          type: string
          description: 'The object type, which is always `chat.completion`.'
          x-stainless-const: true
        service_tier:
          $ref: '#/components/schemas/ServiceTier'
        system_fingerprint:
          type: string
          description: "This fingerprint represents the backend configuration that the model runs with.\n\nCan be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.\n"
          deprecated: true
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      description: 'Represents a chat completion response returned by model, based on the provided input.'
      x-oaiMeta:
        example: "{\n  \"id\": \"chatcmpl-B9MHDbslfkBeAs8l4bebGdFOJ6PeG\",\n  \"object\": \"chat.completion\",\n  \"created\": 1741570283,\n  \"model\": \"gpt-4o-2024-08-06\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"The image shows a wooden boardwalk path running through a lush green field or meadow. The sky is bright blue with some scattered clouds, giving the scene a serene and peaceful atmosphere. Trees and shrubs are visible in the background.\",\n        \"refusal\": null,\n        \"annotations\": []\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 1117,\n    \"completion_tokens\": 46,\n    \"total_tokens\": 1163,\n    \"prompt_tokens_details\": {\n      \"cached_tokens\": 0,\n      \"audio_tokens\": 0\n    },\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\": 0,\n      \"audio_tokens\": 0,\n      \"accepted_prediction_tokens\": 0,\n      \"rejected_prediction_tokens\": 0\n    }\n  },\n  \"service_tier\": \"default\",\n  \"system_fingerprint\": \"fp_fc9f1d7035\"\n}\n"
        group: chat
        name: The chat completion object
    CreateChatCompletionStreamResponse:
      required:
        - choices
        - created
        - id
        - model
        - object
      type: object
      properties:
        choices:
          type: array
          items:
            required:
              - delta
              - finish_reason
              - index
            type: object
            properties:
              delta:
                $ref: '#/components/schemas/ChatCompletionStreamResponseDelta'
              finish_reason:
                enum:
                  - stop
                  - length
                  - tool_calls
                  - content_filter
                  - function_call
                type: string
                description: "The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,\n`length` if the maximum number of tokens specified in the request was reached,\n`content_filter` if content was omitted due to a flag from our content filters,\n`tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.\n"
                nullable: true
              index:
                type: integer
                description: The index of the choice in the list of choices.
              logprobs:
                required:
                  - content
                  - refusal
                type: object
                properties:
                  content:
                    type: array
                    items:
                      $ref: '#/components/schemas/ChatCompletionTokenLogprob'
                    description: A list of message content tokens with log probability information.
                    nullable: true
                  refusal:
                    type: array
                    items:
                      $ref: '#/components/schemas/ChatCompletionTokenLogprob'
                    description: A list of message refusal tokens with log probability information.
                    nullable: true
                description: Log probability information for the choice.
                nullable: true
          description: "A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the\nlast chunk if you set `stream_options: {\"include_usage\": true}`.\n"
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.
        id:
          type: string
          description: A unique identifier for the chat completion. Each chunk has the same ID.
        model:
          type: string
          description: The model to generate the completion.
        object:
          enum:
            - chat.completion.chunk
          type: string
          description: 'The object type, which is always `chat.completion.chunk`.'
          x-stainless-const: true
        service_tier:
          $ref: '#/components/schemas/ServiceTier'
        system_fingerprint:
          type: string
          description: "This fingerprint represents the backend configuration that the model runs with.\nCan be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.\n"
          deprecated: true
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      description: "Represents a streamed chunk of a chat completion response returned\nby the model, based on the provided input. \n[Learn more](https://platform.openai.com/docs/guides/streaming-responses).\n"
      x-oaiMeta:
        example: "{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-4o-mini\", \"system_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\"},\"logprobs\":null,\"finish_reason\":null}]}\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-4o-mini\", \"system_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{\"content\":\"Hello\"},\"logprobs\":null,\"finish_reason\":null}]}\n\n....\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-4o-mini\", \"system_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{},\"logprobs\":null,\"finish_reason\":\"stop\"}]}\n"
        group: chat
        name: The chat completion chunk object
    CreateCompletionRequest:
      required:
        - model
        - prompt
      type: object
      properties:
        best_of:
          maximum: 20
          minimum: 0
          type: integer
          description: "Generates `best_of` completions server-side and returns the \"best\" (the one with the highest log probability per token). Results cannot be streamed.\n\nWhen used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return – `best_of` must be greater than `n`.\n\n**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.\n"
          default: 1
          nullable: true
        echo:
          type: boolean
          description: "Echo back the prompt in addition to the completion\n"
          default: false
          nullable: true
        frequency_penalty:
          maximum: 2
          minimum: -2
          type: number
          description: "Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\n\n[See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation)\n"
          default: 0
          nullable: true
        logit_bias:
          type: object
          additionalProperties:
            type: integer
          description: "Modify the likelihood of specified tokens appearing in the completion.\n\nAccepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.\n\nAs an example, you can pass `{\"50256\": -100}` to prevent the <|endoftext|> token from being generated.\n"
          default: 
          nullable: true
          x-oaiTypeLabel: map
        logprobs:
          maximum: 5
          minimum: 0
          type: integer
          description: "Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.\n\nThe maximum value for `logprobs` is 5.\n"
          default: 
          nullable: true
        max_tokens:
          minimum: 0
          type: integer
          description: "The maximum number of [tokens](/tokenizer) that can be generated in the completion.\n\nThe token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.\n"
          default: 16
          nullable: true
          example: 16
        model:
          anyOf:
            - type: string
            - title: Preset
              enum:
                - gpt-3.5-turbo-instruct
                - davinci-002
                - babbage-002
              type: string
          description: "ID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models) for descriptions of them.\n"
          x-oaiTypeLabel: string
        n:
          maximum: 128
          minimum: 1
          type: integer
          description: "How many completions to generate for each prompt.\n\n**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.\n"
          default: 1
          nullable: true
          example: 1
        presence_penalty:
          maximum: 2
          minimum: -2
          type: number
          description: "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.\n\n[See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation)\n"
          default: 0
          nullable: true
        prompt:
          anyOf:
            - type: string
              default: ''
              example: This is a test.
            - title: Array of strings
              type: array
              items:
                type: string
                default: ''
                example: This is a test.
            - title: Array of tokens
              minItems: 1
              type: array
              items:
                type: integer
            - title: Array of token arrays
              minItems: 1
              type: array
              items:
                minItems: 1
                type: array
                items:
                  type: integer
          description: "The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.\n\nNote that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.\n"
          nullable: true
        seed:
          type: integer
          description: "If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.\n\nDeterminism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.\n"
          format: int64
          nullable: true
        stop:
          $ref: '#/components/schemas/StopConfiguration'
        stream:
          type: boolean
          description: "Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n"
          default: false
          nullable: true
        stream_options:
          $ref: '#/components/schemas/ChatCompletionStreamOptions'
        suffix:
          type: string
          description: "The suffix that comes after a completion of inserted text.\n\nThis parameter is only supported for `gpt-3.5-turbo-instruct`.\n"
          default: 
          nullable: true
          example: test.
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\nWe generally recommend altering this or `top_p` but not both.\n"
          default: 1
          nullable: true
          example: 1
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or `temperature` but not both.\n"
          default: 1
          nullable: true
          example: 1
        user:
          type: string
          description: "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n"
          example: user-1234
    CreateCompletionResponse:
      required:
        - id
        - object
        - created
        - model
        - choices
      type: object
      properties:
        choices:
          type: array
          items:
            required:
              - finish_reason
              - index
              - logprobs
              - text
            type: object
            properties:
              finish_reason:
                enum:
                  - stop
                  - length
                  - content_filter
                type: string
                description: "The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,\n`length` if the maximum number of tokens specified in the request was reached,\nor `content_filter` if content was omitted due to a flag from our content filters.\n"
              index:
                type: integer
              logprobs:
                type: object
                properties:
                  text_offset:
                    type: array
                    items:
                      type: integer
                  token_logprobs:
                    type: array
                    items:
                      type: number
                  tokens:
                    type: array
                    items:
                      type: string
                  top_logprobs:
                    type: array
                    items:
                      type: object
                      additionalProperties:
                        type: number
                nullable: true
              text:
                type: string
          description: The list of completion choices the model generated for the input prompt.
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the completion was created.
        id:
          type: string
          description: A unique identifier for the completion.
        model:
          type: string
          description: The model used for completion.
        object:
          enum:
            - text_completion
          type: string
          description: 'The object type, which is always "text_completion"'
          x-stainless-const: true
        system_fingerprint:
          type: string
          description: "This fingerprint represents the backend configuration that the model runs with.\n\nCan be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.\n"
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      description: "Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7\",\n  \"object\": \"text_completion\",\n  \"created\": 1589478378,\n  \"model\": \"gpt-4-turbo\",\n  \"choices\": [\n    {\n      \"text\": \"\\n\\nThis is indeed a test\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"finish_reason\": \"length\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 5,\n    \"completion_tokens\": 7,\n    \"total_tokens\": 12\n  }\n}\n"
        legacy: true
        name: The completion object
    CreateContainerBody:
      required:
        - name
      type: object
      properties:
        expires_after:
          required:
            - anchor
            - minutes
          type: object
          properties:
            anchor:
              enum:
                - last_active_at
              type: string
              description: Time anchor for the expiration time. Currently only 'last_active_at' is supported.
            minutes:
              type: integer
          description: Container expiration time in seconds relative to the 'anchor' time.
        file_ids:
          type: array
          items:
            type: string
          description: IDs of files to copy to the container.
        name:
          type: string
          description: Name of the container to create.
    CreateContainerFileBody:
      type: object
      properties:
        file:
          type: string
          description: "The File object (not file name) to be uploaded.\n"
          format: binary
        file_id:
          type: string
          description: Name of the file to create.
    CreateConversationRequest:
      type: object
      properties:
        items:
          maxItems: 20
          type: array
          items:
            $ref: '#/components/schemas/InputItem'
          description: "Initial items to include in the conversation context.\nYou may add up to 20 items at a time.\n"
          nullable: true
        metadata:
          $ref: '#/components/schemas/Metadata'
      description: Create a conversation
    CreateEmbeddingRequest:
      required:
        - model
        - input
      type: object
      properties:
        dimensions:
          minimum: 1
          type: integer
          description: "The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.\n"
          nullable: true
        encoding_format:
          enum:
            - float
            - base64
          type: string
          description: 'The format to return the embeddings in. Can be either `float` or [`base64`](https://pypi.org/project/pybase64/).'
          default: float
          example: float
        input:
          anyOf:
            - title: string
              type: string
              description: The string that will be turned into an embedding.
              default: ''
              example: This is a test.
            - title: Array of strings
              maxItems: 2048
              minItems: 1
              type: array
              items:
                type: string
                default: ''
                example: '[''This is a test.'']'
              description: The array of strings that will be turned into an embedding.
            - title: Array of tokens
              maxItems: 2048
              minItems: 1
              type: array
              items:
                type: integer
              description: The array of integers that will be turned into an embedding.
            - title: Array of token arrays
              maxItems: 2048
              minItems: 1
              type: array
              items:
                minItems: 1
                type: array
                items:
                  type: integer
              description: The array of arrays containing integers that will be turned into an embedding.
          description: "Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for all embedding models), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens. In addition to the per-input token limit, all embedding  models enforce a maximum of 300,000 tokens summed across all inputs in a  single request.\n"
          example: The quick brown fox jumped over the lazy dog
        model:
          anyOf:
            - type: string
            - enum:
                - text-embedding-ada-002
                - text-embedding-3-small
                - text-embedding-3-large
              type: string
              x-stainless-nominal: false
          description: "ID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models) for descriptions of them.\n"
          example: text-embedding-3-small
          x-oaiTypeLabel: string
        user:
          type: string
          description: "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n"
          example: user-1234
      additionalProperties: false
    CreateEmbeddingResponse:
      required:
        - object
        - model
        - data
        - usage
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/Embedding'
          description: The list of embeddings generated by the model.
        model:
          type: string
          description: The name of the model used to generate the embedding.
        object:
          enum:
            - list
          type: string
          description: 'The object type, which is always "list".'
          x-stainless-const: true
        usage:
          required:
            - prompt_tokens
            - total_tokens
          type: object
          properties:
            prompt_tokens:
              type: integer
              description: The number of tokens used by the prompt.
            total_tokens:
              type: integer
              description: The total number of tokens used by the request.
          description: The usage information for the request.
    CreateEvalCompletionsRunDataSource:
      title: CompletionsRunDataSource
      required:
        - type
        - source
      type: object
      properties:
        input_messages:
          anyOf:
            - title: TemplateInputMessages
              required:
                - type
                - template
              type: object
              properties:
                template:
                  type: array
                  items:
                    anyOf:
                      - $ref: '#/components/schemas/EasyInputMessage'
                      - $ref: '#/components/schemas/EvalItem'
                  description: 'A list of chat messages forming the prompt or context. May include variable references to the `item` namespace, ie {{item.name}}.'
                type:
                  enum:
                    - template
                  type: string
                  description: The type of input messages. Always `template`.
            - title: ItemReferenceInputMessages
              required:
                - type
                - item_reference
              type: object
              properties:
                item_reference:
                  type: string
                  description: 'A reference to a variable in the `item` namespace. Ie, "item.input_trajectory"'
                type:
                  enum:
                    - item_reference
                  type: string
                  description: The type of input messages. Always `item_reference`.
          description: 'Used when sampling from a model. Dictates the structure of the messages passed into the model. Can either be a reference to a prebuilt trajectory (ie, `item.input_trajectory`), or a template with variable references to the `item` namespace.'
          discriminator:
            propertyName: type
        model:
          type: string
          description: The name of the model to use for generating completions (e.g. "o3-mini").
        sampling_params:
          type: object
          properties:
            max_completion_tokens:
              type: integer
              description: The maximum number of tokens in the generated output.
            response_format:
              anyOf:
                - $ref: '#/components/schemas/ResponseFormatText'
                - $ref: '#/components/schemas/ResponseFormatJsonSchema'
                - $ref: '#/components/schemas/ResponseFormatJsonObject'
              description: "An object specifying the format that the model must output.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables\nStructured Outputs which ensures the model will match your supplied JSON\nschema. Learn more in the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it.\n"
            seed:
              type: integer
              description: 'A seed value to initialize the randomness, during sampling.'
              default: 42
            temperature:
              type: number
              description: A higher temperature increases randomness in the outputs.
              default: 1
            tools:
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionTool'
              description: "A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.\n"
            top_p:
              type: number
              description: An alternative to temperature for nucleus sampling; 1.0 includes all tokens.
              default: 1
        source:
          anyOf:
            - $ref: '#/components/schemas/EvalJsonlFileContentSource'
            - $ref: '#/components/schemas/EvalJsonlFileIdSource'
            - $ref: '#/components/schemas/EvalStoredCompletionsSource'
          description: Determines what populates the `item` namespace in this run's data source.
          discriminator:
            propertyName: type
        type:
          enum:
            - completions
          type: string
          description: The type of run data source. Always `completions`.
          default: completions
      description: "A CompletionsRunDataSource object describing a model sampling configuration.\n"
      x-oaiMeta:
        example: "{\n  \"name\": \"gpt-4o-mini-2024-07-18\",\n  \"data_source\": {\n    \"type\": \"completions\",\n    \"input_messages\": {\n      \"type\": \"item_reference\",\n      \"item_reference\": \"item.input\"\n    },\n    \"model\": \"gpt-4o-mini-2024-07-18\",\n    \"source\": {\n      \"type\": \"stored_completions\",\n      \"model\": \"gpt-4o-mini-2024-07-18\"\n    }\n  }\n}\n"
        group: eval runs
        name: The completions data source object used to configure an individual run
    CreateEvalCustomDataSourceConfig:
      title: CustomDataSourceConfig
      required:
        - item_schema
        - type
      type: object
      properties:
        include_sample_schema:
          type: boolean
          description: 'Whether the eval should expect you to populate the sample namespace (ie, by generating responses off of your data source)'
          default: false
        item_schema:
          type: object
          description: The json schema for each row in the data source.
        type:
          enum:
            - custom
          type: string
          description: The type of data source. Always `custom`.
          default: custom
          x-stainless-const: true
      description: "A CustomDataSourceConfig object that defines the schema for the data source used for the evaluation runs.\nThis schema is used to define the shape of the data that will be:\n- Used to define your testing criteria and\n- What data is required when creating a run\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"custom\",\n  \"item_schema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"name\": {\"type\": \"string\"},\n      \"age\": {\"type\": \"integer\"}\n    },\n    \"required\": [\"name\", \"age\"]\n  },\n  \"include_sample_schema\": true\n}\n"
        group: evals
        name: The eval file data source config object
    CreateEvalItem:
      title: CreateEvalItem
      type: object
      anyOf:
        - title: SimpleInputMessage
          required:
            - role
            - content
          type: object
          properties:
            content:
              type: string
              description: The content of the message.
            role:
              type: string
              description: 'The role of the message (e.g. "system", "assistant", "user").'
        - $ref: '#/components/schemas/EvalItem'
      description: 'A chat message that makes up the prompt or context. May include variable references to the `item` namespace, ie {{item.name}}.'
      x-oaiMeta:
        name: The chat message object used to configure an individual run
    CreateEvalJsonlRunDataSource:
      title: JsonlRunDataSource
      required:
        - type
        - source
      type: object
      properties:
        source:
          anyOf:
            - $ref: '#/components/schemas/EvalJsonlFileContentSource'
            - $ref: '#/components/schemas/EvalJsonlFileIdSource'
          description: Determines what populates the `item` namespace in the data source.
          discriminator:
            propertyName: type
        type:
          enum:
            - jsonl
          type: string
          description: The type of data source. Always `jsonl`.
          default: jsonl
          x-stainless-const: true
      description: "A JsonlRunDataSource object with that specifies a JSONL file that matches the eval \n"
      x-oaiMeta:
        example: "{\n \"type\": \"jsonl\",\n \"source\": {\n   \"type\": \"file_id\",\n   \"id\": \"file-9GYS6xbkWgWhmE7VoLUWFg\"\n }\n}\n"
        group: evals
        name: The file data source object for the eval run configuration
    CreateEvalLabelModelGrader:
      title: LabelModelGrader
      required:
        - type
        - model
        - input
        - passing_labels
        - labels
        - name
      type: object
      properties:
        input:
          type: array
          items:
            $ref: '#/components/schemas/CreateEvalItem'
          description: 'A list of chat messages forming the prompt or context. May include variable references to the `item` namespace, ie {{item.name}}.'
        labels:
          type: array
          items:
            type: string
          description: The labels to classify to each item in the evaluation.
        model:
          type: string
          description: The model to use for the evaluation. Must support structured outputs.
        name:
          type: string
          description: The name of the grader.
        passing_labels:
          type: array
          items:
            type: string
          description: The labels that indicate a passing result. Must be a subset of labels.
        type:
          enum:
            - label_model
          type: string
          description: 'The object type, which is always `label_model`.'
          x-stainless-const: true
      description: "A LabelModelGrader object which uses a model to assign labels to each item\nin the evaluation.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"label_model\",\n  \"model\": \"gpt-4o-2024-08-06\",\n  \"input\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Classify the sentiment of the following statement as one of 'positive', 'neutral', or 'negative'\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Statement: {{item.response}}\"\n    }\n  ],\n  \"passing_labels\": [\"positive\"],\n  \"labels\": [\"positive\", \"neutral\", \"negative\"],\n  \"name\": \"Sentiment label grader\"\n}\n"
        group: evals
        name: The eval label model grader object
    CreateEvalLogsDataSourceConfig:
      title: LogsDataSourceConfig
      required:
        - type
      type: object
      properties:
        metadata:
          type: object
          description: Metadata filters for the logs data source.
        type:
          enum:
            - logs
          type: string
          description: The type of data source. Always `logs`.
          default: logs
          x-stainless-const: true
      description: "A data source config which specifies the metadata property of your logs query.\nThis is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"logs\",\n  \"metadata\": {\n    \"use_case\": \"customer_support_agent\"\n  }\n}\n"
        group: evals
        name: The logs data source object for evals
    CreateEvalRequest:
      title: CreateEvalRequest
      required:
        - data_source_config
        - testing_criteria
      type: object
      properties:
        data_source_config:
          type: object
          anyOf:
            - $ref: '#/components/schemas/CreateEvalCustomDataSourceConfig'
            - $ref: '#/components/schemas/CreateEvalLogsDataSourceConfig'
            - $ref: '#/components/schemas/CreateEvalStoredCompletionsDataSourceConfig'
          description: The configuration for the data source used for the evaluation runs. Dictates the schema of the data used in the evaluation.
          discriminator:
            propertyName: type
        metadata:
          $ref: '#/components/schemas/Metadata'
        name:
          type: string
          description: The name of the evaluation.
        testing_criteria:
          type: array
          items:
            anyOf:
              - $ref: '#/components/schemas/CreateEvalLabelModelGrader'
              - $ref: '#/components/schemas/EvalGraderStringCheck'
              - $ref: '#/components/schemas/EvalGraderTextSimilarity'
              - $ref: '#/components/schemas/EvalGraderPython'
              - $ref: '#/components/schemas/EvalGraderScoreModel'
            discriminator:
              propertyName: type
          description: 'A list of graders for all eval runs in this group. Graders can reference variables in the data source using double curly braces notation, like `{{item.variable_name}}`. To reference the model''s output, use the `sample` namespace (ie, `{{sample.output_text}}`).'
    CreateEvalResponsesRunDataSource:
      title: ResponsesRunDataSource
      required:
        - type
        - source
      type: object
      properties:
        input_messages:
          anyOf:
            - title: InputMessagesTemplate
              required:
                - type
                - template
              type: object
              properties:
                template:
                  type: array
                  items:
                    anyOf:
                      - title: ChatMessage
                        required:
                          - role
                          - content
                        type: object
                        properties:
                          content:
                            type: string
                            description: The content of the message.
                          role:
                            type: string
                            description: 'The role of the message (e.g. "system", "assistant", "user").'
                      - $ref: '#/components/schemas/EvalItem'
                  description: 'A list of chat messages forming the prompt or context. May include variable references to the `item` namespace, ie {{item.name}}.'
                type:
                  enum:
                    - template
                  type: string
                  description: The type of input messages. Always `template`.
            - title: InputMessagesItemReference
              required:
                - type
                - item_reference
              type: object
              properties:
                item_reference:
                  type: string
                  description: 'A reference to a variable in the `item` namespace. Ie, "item.name"'
                type:
                  enum:
                    - item_reference
                  type: string
                  description: The type of input messages. Always `item_reference`.
          description: 'Used when sampling from a model. Dictates the structure of the messages passed into the model. Can either be a reference to a prebuilt trajectory (ie, `item.input_trajectory`), or a template with variable references to the `item` namespace.'
          discriminator:
            propertyName: type
        model:
          type: string
          description: The name of the model to use for generating completions (e.g. "o3-mini").
        sampling_params:
          type: object
          properties:
            max_completion_tokens:
              type: integer
              description: The maximum number of tokens in the generated output.
            seed:
              type: integer
              description: 'A seed value to initialize the randomness, during sampling.'
              default: 42
            temperature:
              type: number
              description: A higher temperature increases randomness in the outputs.
              default: 1
            text:
              type: object
              properties:
                format:
                  $ref: '#/components/schemas/TextResponseFormatConfiguration'
              description: "Configuration options for a text response from the model. Can be plain\ntext or structured JSON data. Learn more:\n- [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n- [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n"
            tools:
              type: array
              items:
                $ref: '#/components/schemas/Tool'
              description: "An array of tools the model may call while generating a response. You\ncan specify which tool to use by setting the `tool_choice` parameter.\n\nThe two categories of tools you can provide the model are:\n\n- **Built-in tools**: Tools that are provided by OpenAI that extend the\n  model's capabilities, like [web search](https://platform.openai.com/docs/guides/tools-web-search)\n  or [file search](https://platform.openai.com/docs/guides/tools-file-search). Learn more about\n  [built-in tools](https://platform.openai.com/docs/guides/tools).\n- **Function calls (custom tools)**: Functions that are defined by you,\n  enabling the model to call your own code. Learn more about\n  [function calling](https://platform.openai.com/docs/guides/function-calling).\n"
            top_p:
              type: number
              description: An alternative to temperature for nucleus sampling; 1.0 includes all tokens.
              default: 1
        source:
          anyOf:
            - $ref: '#/components/schemas/EvalJsonlFileContentSource'
            - $ref: '#/components/schemas/EvalJsonlFileIdSource'
            - $ref: '#/components/schemas/EvalResponsesSource'
          description: Determines what populates the `item` namespace in this run's data source.
          discriminator:
            propertyName: type
        type:
          enum:
            - responses
          type: string
          description: The type of run data source. Always `responses`.
          default: responses
      description: "A ResponsesRunDataSource object describing a model sampling configuration.\n"
      x-oaiMeta:
        example: "{\n  \"name\": \"gpt-4o-mini-2024-07-18\",\n  \"data_source\": {\n    \"type\": \"responses\",\n    \"input_messages\": {\n      \"type\": \"item_reference\",\n      \"item_reference\": \"item.input\"\n    },\n    \"model\": \"gpt-4o-mini-2024-07-18\",\n    \"source\": {\n      \"type\": \"responses\",\n      \"model\": \"gpt-4o-mini-2024-07-18\"\n    }\n  }\n}\n"
        group: eval runs
        name: The completions data source object used to configure an individual run
    CreateEvalRunRequest:
      title: CreateEvalRunRequest
      required:
        - data_source
      type: object
      properties:
        data_source:
          type: object
          anyOf:
            - $ref: '#/components/schemas/CreateEvalJsonlRunDataSource'
            - $ref: '#/components/schemas/CreateEvalCompletionsRunDataSource'
            - $ref: '#/components/schemas/CreateEvalResponsesRunDataSource'
          description: Details about the run's data source.
        metadata:
          $ref: '#/components/schemas/Metadata'
        name:
          type: string
          description: The name of the run.
    CreateEvalStoredCompletionsDataSourceConfig:
      title: StoredCompletionsDataSourceConfig
      required:
        - type
      type: object
      properties:
        metadata:
          type: object
          description: Metadata filters for the stored completions data source.
        type:
          enum:
            - stored_completions
          type: string
          description: The type of data source. Always `stored_completions`.
          default: stored_completions
          x-stainless-const: true
      description: "Deprecated in favor of LogsDataSourceConfig.\n"
      deprecated: true
      x-oaiMeta:
        example: "{\n  \"type\": \"stored_completions\",\n  \"metadata\": {\n    \"use_case\": \"customer_support_agent\"\n  }\n}\n"
        group: evals
        name: The stored completions data source object for evals
    CreateFileRequest:
      required:
        - file
        - purpose
      type: object
      properties:
        expires_after:
          $ref: '#/components/schemas/FileExpirationAfter'
        file:
          type: string
          description: "The File object (not file name) to be uploaded.\n"
          format: binary
          x-oaiMeta:
            exampleFilePath: fine-tune.jsonl
        purpose:
          $ref: '#/components/schemas/FilePurpose'
      additionalProperties: false
    CreateFineTuningCheckpointPermissionRequest:
      required:
        - project_ids
      type: object
      properties:
        project_ids:
          type: array
          items:
            type: string
          description: The project identifiers to grant access to.
      additionalProperties: false
    CreateFineTuningJobRequest:
      required:
        - model
        - training_file
      type: object
      properties:
        hyperparameters:
          type: object
          properties:
            batch_size:
              anyOf:
                - title: Auto
                  enum:
                    - auto
                  type: string
                  x-stainless-const: true
                - maximum: 256
                  minimum: 1
                  type: integer
              description: "Number of examples in each batch. A larger batch size means that model parameters\nare updated less frequently, but with lower variance.\n"
              default: auto
            learning_rate_multiplier:
              anyOf:
                - title: Auto
                  enum:
                    - auto
                  type: string
                  x-stainless-const: true
                - minimum: 0
                  exclusiveMinimum: true
                  type: number
              description: "Scaling factor for the learning rate. A smaller learning rate may be useful to avoid\noverfitting.\n"
            n_epochs:
              anyOf:
                - title: Auto
                  enum:
                    - auto
                  type: string
                  x-stainless-const: true
                - maximum: 50
                  minimum: 1
                  type: integer
              description: "The number of epochs to train the model for. An epoch refers to one full cycle\nthrough the training dataset.\n"
              default: auto
          description: "The hyperparameters used for the fine-tuning job.\nThis value is now deprecated in favor of `method`, and should be passed in under the `method` parameter.\n"
          deprecated: true
        integrations:
          type: array
          items:
            required:
              - type
              - wandb
            type: object
            properties:
              type:
                anyOf:
                  - enum:
                      - wandb
                    type: string
                    x-stainless-const: true
                description: "The type of integration to enable. Currently, only \"wandb\" (Weights and Biases) is supported.\n"
              wandb:
                required:
                  - project
                type: object
                properties:
                  entity:
                    type: string
                    description: "The entity to use for the run. This allows you to set the team or username of the WandB user that you would\nlike associated with the run. If not set, the default entity for the registered WandB API key is used.\n"
                    nullable: true
                  name:
                    type: string
                    description: "A display name to set for the run. If not set, we will use the Job ID as the name.\n"
                    nullable: true
                  project:
                    type: string
                    description: "The name of the project that the new run will be created under.\n"
                    example: my-wandb-project
                  tags:
                    type: array
                    items:
                      type: string
                      example: custom-tag
                    description: "A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some\ndefault tags are generated by OpenAI: \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n"
                description: "The settings for your integration with Weights and Biases. This payload specifies the project that\nmetrics will be sent to. Optionally, you can set an explicit display name for your run, add tags\nto your run, and set a default entity (team, username, etc) to be associated with your run.\n"
          description: A list of integrations to enable for your fine-tuning job.
          nullable: true
        metadata:
          $ref: '#/components/schemas/Metadata'
        method:
          $ref: '#/components/schemas/FineTuneMethod'
        model:
          anyOf:
            - type: string
            - title: Preset
              enum:
                - babbage-002
                - davinci-002
                - gpt-3.5-turbo
                - gpt-4o-mini
              type: string
          description: "The name of the model to fine-tune. You can select one of the\n[supported models](https://platform.openai.com/docs/guides/fine-tuning#which-models-can-be-fine-tuned).\n"
          example: gpt-4o-mini
          x-oaiTypeLabel: string
        seed:
          maximum: 2147483647
          minimum: 0
          type: integer
          description: "The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.\nIf a seed is not specified, one will be generated for you.\n"
          nullable: true
          example: 42
        suffix:
          maxLength: 64
          minLength: 1
          type: string
          description: "A string of up to 64 characters that will be added to your fine-tuned model name.\n\nFor example, a `suffix` of \"custom-model-name\" would produce a model name like `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.\n"
          default: 
          nullable: true
        training_file:
          type: string
          description: "The ID of an uploaded file that contains training data.\n\nSee [upload file](https://platform.openai.com/docs/api-reference/files/create) for how to upload a file.\n\nYour dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.\n\nThe contents of the file should differ depending on if the model uses the [chat](https://platform.openai.com/docs/api-reference/fine-tuning/chat-input), [completions](https://platform.openai.com/docs/api-reference/fine-tuning/completions-input) format, or if the fine-tuning method uses the [preference](https://platform.openai.com/docs/api-reference/fine-tuning/preference-input) format.\n\nSee the [fine-tuning guide](https://platform.openai.com/docs/guides/model-optimization) for more details.\n"
          example: file-abc123
        validation_file:
          type: string
          description: "The ID of an uploaded file that contains validation data.\n\nIf you provide this file, the data is used to generate validation\nmetrics periodically during fine-tuning. These metrics can be viewed in\nthe fine-tuning results file.\nThe same data should not be present in both train and validation files.\n\nYour dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.\n\nSee the [fine-tuning guide](https://platform.openai.com/docs/guides/model-optimization) for more details.\n"
          nullable: true
          example: file-abc123
    CreateImageEditRequest:
      required:
        - prompt
        - image
      type: object
      properties:
        background:
          enum:
            - transparent
            - opaque
            - auto
          type: string
          description: "Allows to set transparency for the background of the generated image(s). \nThis parameter is only supported for `gpt-image-1`. Must be one of \n`transparent`, `opaque` or `auto` (default value). When `auto` is used, the \nmodel will automatically determine the best background for the image.\n\nIf `transparent`, the output format needs to support transparency, so it \nshould be set to either `png` (default value) or `webp`.\n"
          default: auto
          nullable: true
          example: transparent
        image:
          anyOf:
            - type: string
              format: binary
            - maxItems: 16
              type: array
              items:
                type: string
                format: binary
          description: "The image(s) to edit. Must be a supported image file or an array of images.\n\nFor `gpt-image-1`, each image should be a `png`, `webp`, or `jpg` file less \nthan 50MB. You can provide up to 16 images.\n\nFor `dall-e-2`, you can only provide one image, and it should be a square \n`png` file less than 4MB.\n"
          x-oaiMeta:
            exampleFilePath: otter.png
        input_fidelity:
          $ref: '#/components/schemas/ImageInputFidelity'
        mask:
          type: string
          description: 'An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. If there are multiple images provided, the mask will be applied on the first image. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.'
          format: binary
          x-oaiMeta:
            exampleFilePath: mask.png
        model:
          anyOf:
            - type: string
            - enum:
                - dall-e-2
                - gpt-image-1
              type: string
              x-stainless-const: true
          description: The model to use for image generation. Only `dall-e-2` and `gpt-image-1` are supported. Defaults to `dall-e-2` unless a parameter specific to `gpt-image-1` is used.
          nullable: true
          x-oaiTypeLabel: string
        n:
          maximum: 10
          minimum: 1
          type: integer
          description: The number of images to generate. Must be between 1 and 10.
          default: 1
          nullable: true
          example: 1
        output_compression:
          type: integer
          description: "The compression level (0-100%) for the generated images. This parameter \nis only supported for `gpt-image-1` with the `webp` or `jpeg` output \nformats, and defaults to 100.\n"
          default: 100
          nullable: true
          example: 100
        output_format:
          enum:
            - png
            - jpeg
            - webp
          type: string
          description: "The format in which the generated images are returned. This parameter is\nonly supported for `gpt-image-1`. Must be one of `png`, `jpeg`, or `webp`.\nThe default value is `png`.\n"
          default: png
          nullable: true
          example: png
        partial_images:
          $ref: '#/components/schemas/PartialImages'
        prompt:
          type: string
          description: 'A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2`, and 32000 characters for `gpt-image-1`.'
          example: A cute baby sea otter wearing a beret
        quality:
          enum:
            - standard
            - low
            - medium
            - high
            - auto
          type: string
          description: "The quality of the image that will be generated. `high`, `medium` and `low` are only supported for `gpt-image-1`. `dall-e-2` only supports `standard` quality. Defaults to `auto`.\n"
          default: auto
          nullable: true
          example: high
        response_format:
          enum:
            - url
            - b64_json
          type: string
          description: 'The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated. This parameter is only supported for `dall-e-2`, as `gpt-image-1` will always return base64-encoded images.'
          default: url
          nullable: true
          example: url
        size:
          enum:
            - 256x256
            - 512x512
            - 1024x1024
            - 1536x1024
            - 1024x1536
            - auto
          type: string
          description: 'The size of the generated images. Must be one of `1024x1024`, `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default value) for `gpt-image-1`, and one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`.'
          default: 1024x1024
          nullable: true
          example: 1024x1024
        stream:
          type: boolean
          description: "Edit the image in streaming mode. Defaults to `false`. See the \n[Image generation guide](https://platform.openai.com/docs/guides/image-generation) for more information.\n"
          default: false
          nullable: true
          example: false
        user:
          type: string
          description: "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n"
          example: user-1234
    CreateImageRequest:
      required:
        - prompt
      type: object
      properties:
        background:
          enum:
            - transparent
            - opaque
            - auto
          type: string
          description: "Allows to set transparency for the background of the generated image(s). \nThis parameter is only supported for `gpt-image-1`. Must be one of \n`transparent`, `opaque` or `auto` (default value). When `auto` is used, the \nmodel will automatically determine the best background for the image.\n\nIf `transparent`, the output format needs to support transparency, so it \nshould be set to either `png` (default value) or `webp`.\n"
          default: auto
          nullable: true
          example: transparent
        model:
          anyOf:
            - type: string
            - enum:
                - dall-e-2
                - dall-e-3
                - gpt-image-1
              type: string
              x-stainless-nominal: false
          description: 'The model to use for image generation. One of `dall-e-2`, `dall-e-3`, or `gpt-image-1`. Defaults to `dall-e-2` unless a parameter specific to `gpt-image-1` is used.'
          nullable: true
          x-oaiTypeLabel: string
        moderation:
          enum:
            - low
            - auto
          type: string
          description: Control the content-moderation level for images generated by `gpt-image-1`. Must be either `low` for less restrictive filtering or `auto` (default value).
          default: auto
          nullable: true
          example: low
        n:
          maximum: 10
          minimum: 1
          type: integer
          description: 'The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.'
          default: 1
          nullable: true
          example: 1
        output_compression:
          type: integer
          description: 'The compression level (0-100%) for the generated images. This parameter is only supported for `gpt-image-1` with the `webp` or `jpeg` output formats, and defaults to 100.'
          default: 100
          nullable: true
          example: 100
        output_format:
          enum:
            - png
            - jpeg
            - webp
          type: string
          description: 'The format in which the generated images are returned. This parameter is only supported for `gpt-image-1`. Must be one of `png`, `jpeg`, or `webp`.'
          default: png
          nullable: true
          example: png
        partial_images:
          $ref: '#/components/schemas/PartialImages'
        prompt:
          type: string
          description: 'A text description of the desired image(s). The maximum length is 32000 characters for `gpt-image-1`, 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.'
          example: A cute baby sea otter
        quality:
          enum:
            - standard
            - hd
            - low
            - medium
            - high
            - auto
          type: string
          description: "The quality of the image that will be generated. \n\n- `auto` (default value) will automatically select the best quality for the given model.\n- `high`, `medium` and `low` are supported for `gpt-image-1`.\n- `hd` and `standard` are supported for `dall-e-3`.\n- `standard` is the only option for `dall-e-2`.\n"
          default: auto
          nullable: true
          example: medium
        response_format:
          enum:
            - url
            - b64_json
          type: string
          description: The format in which generated images with `dall-e-2` and `dall-e-3` are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated. This parameter isn't supported for `gpt-image-1` which will always return base64-encoded images.
          default: url
          nullable: true
          example: url
        size:
          enum:
            - auto
            - 1024x1024
            - 1536x1024
            - 1024x1536
            - 256x256
            - 512x512
            - 1792x1024
            - 1024x1792
          type: string
          description: 'The size of the generated images. Must be one of `1024x1024`, `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default value) for `gpt-image-1`, one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`, and one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3`.'
          default: auto
          nullable: true
          example: 1024x1024
        stream:
          type: boolean
          description: "Generate the image in streaming mode. Defaults to `false`. See the \n[Image generation guide](https://platform.openai.com/docs/guides/image-generation) for more information.\nThis parameter is only supported for `gpt-image-1`.\n"
          default: false
          nullable: true
          example: false
        style:
          enum:
            - vivid
            - natural
          type: string
          description: 'The style of the generated images. This parameter is only supported for `dall-e-3`. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images.'
          default: vivid
          nullable: true
          example: vivid
        user:
          type: string
          description: "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n"
          example: user-1234
    CreateImageVariationRequest:
      required:
        - image
      type: object
      properties:
        image:
          type: string
          description: 'The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.'
          format: binary
          x-oaiMeta:
            exampleFilePath: otter.png
        model:
          anyOf:
            - type: string
            - enum:
                - dall-e-2
              type: string
              x-stainless-const: true
          description: The model to use for image generation. Only `dall-e-2` is supported at this time.
          nullable: true
          x-oaiTypeLabel: string
        n:
          maximum: 10
          minimum: 1
          type: integer
          description: The number of images to generate. Must be between 1 and 10.
          default: 1
          nullable: true
          example: 1
        response_format:
          enum:
            - url
            - b64_json
          type: string
          description: The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.
          default: url
          nullable: true
          example: url
        size:
          enum:
            - 256x256
            - 512x512
            - 1024x1024
          type: string
          description: 'The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.'
          default: 1024x1024
          nullable: true
          example: 1024x1024
        user:
          type: string
          description: "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n"
          example: user-1234
    CreateMessageRequest:
      required:
        - role
        - content
      type: object
      properties:
        attachments:
          required:
            - file_id
            - tools
          type: array
          items:
            type: object
            properties:
              file_id:
                type: string
                description: The ID of the file to attach to the message.
              tools:
                type: array
                items:
                  anyOf:
                    - $ref: '#/components/schemas/AssistantToolsCode'
                    - $ref: '#/components/schemas/AssistantToolsFileSearchTypeOnly'
                  discriminator:
                    propertyName: type
                description: The tools to add this file to.
          description: 'A list of files attached to the message, and the tools they should be added to.'
          nullable: true
        content:
          anyOf:
            - title: Text content
              type: string
              description: The text contents of the message.
            - title: Array of content parts
              minItems: 1
              type: array
              items:
                anyOf:
                  - $ref: '#/components/schemas/MessageContentImageFileObject'
                  - $ref: '#/components/schemas/MessageContentImageUrlObject'
                  - $ref: '#/components/schemas/MessageRequestContentTextObject'
                discriminator:
                  propertyName: type
              description: 'An array of content parts with a defined type, each can be of type `text` or images can be passed with `image_url` or `image_file`. Image types are only supported on [Vision-compatible models](https://platform.openai.com/docs/models).'
        metadata:
          $ref: '#/components/schemas/Metadata'
        role:
          enum:
            - user
            - assistant
          type: string
          description: "The role of the entity that is creating the message. Allowed values include:\n- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.\n- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.\n"
      additionalProperties: false
    CreateModelResponseProperties:
      allOf:
        - $ref: '#/components/schemas/ModelResponseProperties'
        - type: object
          properties:
            top_logprobs:
              maximum: 20
              minimum: 0
              type: integer
              description: "An integer between 0 and 20 specifying the number of most likely tokens to\nreturn at each token position, each with an associated log probability.\n"
    CreateModerationRequest:
      required:
        - input
      type: object
      properties:
        input:
          anyOf:
            - type: string
              description: A string of text to classify for moderation.
              default: ''
              example: I want to kill them.
            - type: array
              items:
                type: string
                default: ''
                example: I want to kill them.
              description: An array of strings to classify for moderation.
            - title: Moderation Multi Modal Array
              type: array
              items:
                anyOf:
                  - $ref: '#/components/schemas/ModerationImageURLInput'
                  - $ref: '#/components/schemas/ModerationTextInput'
                discriminator:
                  propertyName: type
              description: An array of multi-modal inputs to the moderation model.
          description: "Input (or inputs) to classify. Can be a single string, an array of strings, or\nan array of multi-modal input objects similar to other models.\n"
        model:
          anyOf:
            - type: string
            - enum:
                - omni-moderation-latest
                - omni-moderation-2024-09-26
                - text-moderation-latest
                - text-moderation-stable
              type: string
              x-stainless-nominal: false
          description: "The content moderation model you would like to use. Learn more in\n[the moderation guide](https://platform.openai.com/docs/guides/moderation), and learn about\navailable models [here](https://platform.openai.com/docs/models#moderation).\n"
          x-oaiTypeLabel: string
    CreateModerationResponse:
      required:
        - id
        - model
        - results
      type: object
      properties:
        id:
          type: string
          description: The unique identifier for the moderation request.
        model:
          type: string
          description: The model used to generate the moderation results.
        results:
          type: array
          items:
            required:
              - flagged
              - categories
              - category_scores
              - category_applied_input_types
            type: object
            properties:
              categories:
                required:
                  - hate
                  - hate/threatening
                  - harassment
                  - harassment/threatening
                  - illicit
                  - illicit/violent
                  - self-harm
                  - self-harm/intent
                  - self-harm/instructions
                  - sexual
                  - sexual/minors
                  - violence
                  - violence/graphic
                type: object
                properties:
                  harassment:
                    type: boolean
                    description: 'Content that expresses, incites, or promotes harassing language towards any target.'
                  harassment/threatening:
                    type: boolean
                    description: Harassment content that also includes violence or serious harm towards any target.
                  hate:
                    type: boolean
                    description: 'Content that expresses, incites, or promotes hate based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste. Hateful content aimed at non-protected groups (e.g., chess players) is harassment.'
                  hate/threatening:
                    type: boolean
                    description: 'Hateful content that also includes violence or serious harm towards the targeted group based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste.'
                  illicit:
                    type: boolean
                    description: 'Content that includes instructions or advice that facilitate the planning or execution of wrongdoing, or that gives advice or instruction on how to commit illicit acts. For example, "how to shoplift" would fit this category.'
                    nullable: true
                  illicit/violent:
                    type: boolean
                    description: 'Content that includes instructions or advice that facilitate the planning or execution of wrongdoing that also includes violence, or that gives advice or instruction on the procurement of any weapon.'
                    nullable: true
                  self-harm:
                    type: boolean
                    description: 'Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting, and eating disorders.'
                  self-harm/instructions:
                    type: boolean
                    description: 'Content that encourages performing acts of self-harm, such as suicide, cutting, and eating disorders, or that gives instructions or advice on how to commit such acts.'
                  self-harm/intent:
                    type: boolean
                    description: 'Content where the speaker expresses that they are engaging or intend to engage in acts of self-harm, such as suicide, cutting, and eating disorders.'
                  sexual:
                    type: boolean
                    description: 'Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education and wellness).'
                  sexual/minors:
                    type: boolean
                    description: Sexual content that includes an individual who is under 18 years old.
                  violence:
                    type: boolean
                    description: 'Content that depicts death, violence, or physical injury.'
                  violence/graphic:
                    type: boolean
                    description: 'Content that depicts death, violence, or physical injury in graphic detail.'
                description: 'A list of the categories, and whether they are flagged or not.'
              category_applied_input_types:
                required:
                  - hate
                  - hate/threatening
                  - harassment
                  - harassment/threatening
                  - illicit
                  - illicit/violent
                  - self-harm
                  - self-harm/intent
                  - self-harm/instructions
                  - sexual
                  - sexual/minors
                  - violence
                  - violence/graphic
                type: object
                properties:
                  harassment:
                    type: array
                    items:
                      enum:
                        - text
                      type: string
                      x-stainless-const: true
                    description: The applied input type(s) for the category 'harassment'.
                  harassment/threatening:
                    type: array
                    items:
                      enum:
                        - text
                      type: string
                      x-stainless-const: true
                    description: The applied input type(s) for the category 'harassment/threatening'.
                  hate:
                    type: array
                    items:
                      enum:
                        - text
                      type: string
                      x-stainless-const: true
                    description: The applied input type(s) for the category 'hate'.
                  hate/threatening:
                    type: array
                    items:
                      enum:
                        - text
                      type: string
                      x-stainless-const: true
                    description: The applied input type(s) for the category 'hate/threatening'.
                  illicit:
                    type: array
                    items:
                      enum:
                        - text
                      type: string
                      x-stainless-const: true
                    description: The applied input type(s) for the category 'illicit'.
                  illicit/violent:
                    type: array
                    items:
                      enum:
                        - text
                      type: string
                      x-stainless-const: true
                    description: The applied input type(s) for the category 'illicit/violent'.
                  self-harm:
                    type: array
                    items:
                      enum:
                        - text
                        - image
                      type: string
                    description: The applied input type(s) for the category 'self-harm'.
                  self-harm/instructions:
                    type: array
                    items:
                      enum:
                        - text
                        - image
                      type: string
                    description: The applied input type(s) for the category 'self-harm/instructions'.
                  self-harm/intent:
                    type: array
                    items:
                      enum:
                        - text
                        - image
                      type: string
                    description: The applied input type(s) for the category 'self-harm/intent'.
                  sexual:
                    type: array
                    items:
                      enum:
                        - text
                        - image
                      type: string
                    description: The applied input type(s) for the category 'sexual'.
                  sexual/minors:
                    type: array
                    items:
                      enum:
                        - text
                      type: string
                      x-stainless-const: true
                    description: The applied input type(s) for the category 'sexual/minors'.
                  violence:
                    type: array
                    items:
                      enum:
                        - text
                        - image
                      type: string
                    description: The applied input type(s) for the category 'violence'.
                  violence/graphic:
                    type: array
                    items:
                      enum:
                        - text
                        - image
                      type: string
                    description: The applied input type(s) for the category 'violence/graphic'.
                description: A list of the categories along with the input type(s) that the score applies to.
              category_scores:
                required:
                  - hate
                  - hate/threatening
                  - harassment
                  - harassment/threatening
                  - illicit
                  - illicit/violent
                  - self-harm
                  - self-harm/intent
                  - self-harm/instructions
                  - sexual
                  - sexual/minors
                  - violence
                  - violence/graphic
                type: object
                properties:
                  harassment:
                    type: number
                    description: The score for the category 'harassment'.
                  harassment/threatening:
                    type: number
                    description: The score for the category 'harassment/threatening'.
                  hate:
                    type: number
                    description: The score for the category 'hate'.
                  hate/threatening:
                    type: number
                    description: The score for the category 'hate/threatening'.
                  illicit:
                    type: number
                    description: The score for the category 'illicit'.
                  illicit/violent:
                    type: number
                    description: The score for the category 'illicit/violent'.
                  self-harm:
                    type: number
                    description: The score for the category 'self-harm'.
                  self-harm/instructions:
                    type: number
                    description: The score for the category 'self-harm/instructions'.
                  self-harm/intent:
                    type: number
                    description: The score for the category 'self-harm/intent'.
                  sexual:
                    type: number
                    description: The score for the category 'sexual'.
                  sexual/minors:
                    type: number
                    description: The score for the category 'sexual/minors'.
                  violence:
                    type: number
                    description: The score for the category 'violence'.
                  violence/graphic:
                    type: number
                    description: The score for the category 'violence/graphic'.
                description: A list of the categories along with their scores as predicted by model.
              flagged:
                type: boolean
                description: Whether any of the below categories are flagged.
          description: A list of moderation objects.
      description: Represents if a given text input is potentially harmful.
      x-oaiMeta:
        example: "{\n  \"id\": \"modr-0d9740456c391e43c445bf0f010940c7\",\n  \"model\": \"omni-moderation-latest\",\n  \"results\": [\n    {\n      \"flagged\": true,\n      \"categories\": {\n        \"harassment\": true,\n        \"harassment/threatening\": true,\n        \"sexual\": false,\n        \"hate\": false,\n        \"hate/threatening\": false,\n        \"illicit\": false,\n        \"illicit/violent\": false,\n        \"self-harm/intent\": false,\n        \"self-harm/instructions\": false,\n        \"self-harm\": false,\n        \"sexual/minors\": false,\n        \"violence\": true,\n        \"violence/graphic\": true\n      },\n      \"category_scores\": {\n        \"harassment\": 0.8189693396524255,\n        \"harassment/threatening\": 0.804985420696006,\n        \"sexual\": 1.573112165348997e-6,\n        \"hate\": 0.007562942636942845,\n        \"hate/threatening\": 0.004208854591835476,\n        \"illicit\": 0.030535955153511665,\n        \"illicit/violent\": 0.008925306722380033,\n        \"self-harm/intent\": 0.00023023930975076432,\n        \"self-harm/instructions\": 0.0002293869201073356,\n        \"self-harm\": 0.012598046106750154,\n        \"sexual/minors\": 2.212566909570261e-8,\n        \"violence\": 0.9999992735124786,\n        \"violence/graphic\": 0.843064871157054\n      },\n      \"category_applied_input_types\": {\n        \"harassment\": [\n          \"text\"\n        ],\n        \"harassment/threatening\": [\n          \"text\"\n        ],\n        \"sexual\": [\n          \"text\",\n          \"image\"\n        ],\n        \"hate\": [\n          \"text\"\n        ],\n        \"hate/threatening\": [\n          \"text\"\n        ],\n        \"illicit\": [\n          \"text\"\n        ],\n        \"illicit/violent\": [\n          \"text\"\n        ],\n        \"self-harm/intent\": [\n          \"text\",\n          \"image\"\n        ],\n        \"self-harm/instructions\": [\n          \"text\",\n          \"image\"\n        ],\n        \"self-harm\": [\n          \"text\",\n          \"image\"\n        ],\n        \"sexual/minors\": [\n          \"text\"\n        ],\n        \"violence\": [\n          \"text\",\n          \"image\"\n        ],\n        \"violence/graphic\": [\n          \"text\",\n          \"image\"\n        ]\n      }\n    }\n  ]\n}\n"
        name: The moderation object
    CreateResponse:
      allOf:
        - $ref: '#/components/schemas/CreateModelResponseProperties'
        - $ref: '#/components/schemas/ResponseProperties'
        - type: object
          properties:
            conversation:
              anyOf:
                - title: Conversation ID
                  type: string
                  description: "The unique ID of the conversation.\n"
                - $ref: '#/components/schemas/ConversationParam'
              description: "The conversation that this response belongs to. Items from this conversation are prepended to `input_items` for this response request.\nInput items and output items from this response are automatically added to this conversation after this response completes.\n"
              nullable: true
            include:
              type: array
              items:
                $ref: '#/components/schemas/Includable'
              description: "Specify additional output data to include in the model response. Currently\nsupported values are:\n- `web_search_call.action.sources`: Include the sources of the web search tool call.\n- `code_interpreter_call.outputs`: Includes the outputs of python code execution\n  in code interpreter tool call items.\n- `computer_call_output.output.image_url`: Include image urls from the computer call output.\n- `file_search_call.results`: Include the search results of\n  the file search tool call.\n- `message.input_image.image_url`: Include image urls from the input message.\n- `message.output_text.logprobs`: Include logprobs with assistant messages.\n- `reasoning.encrypted_content`: Includes an encrypted version of reasoning\n  tokens in reasoning item outputs. This enables reasoning items to be used in\n  multi-turn conversations when using the Responses API statelessly (like\n  when the `store` parameter is set to `false`, or when an organization is\n  enrolled in the zero data retention program).\n"
              nullable: true
            input:
              anyOf:
                - title: Text input
                  type: string
                  description: "A text input to the model, equivalent to a text input with the\n`user` role.\n"
                - title: Input item list
                  type: array
                  items:
                    $ref: '#/components/schemas/InputItem'
                  description: "A list of one or many input items to the model, containing\ndifferent content types.\n"
              description: "Text, image, or file inputs to the model, used to generate a response.\n\nLearn more:\n- [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n- [Image inputs](https://platform.openai.com/docs/guides/images)\n- [File inputs](https://platform.openai.com/docs/guides/pdf-files)\n- [Conversation state](https://platform.openai.com/docs/guides/conversation-state)\n- [Function calling](https://platform.openai.com/docs/guides/function-calling)\n"
            instructions:
              type: string
              description: "A system (or developer) message inserted into the model's context.\n\nWhen using along with `previous_response_id`, the instructions from a previous\nresponse will not be carried over to the next response. This makes it simple\nto swap out system (or developer) messages in new responses.\n"
              nullable: true
            parallel_tool_calls:
              type: boolean
              description: "Whether to allow the model to run tool calls in parallel.\n"
              default: true
              nullable: true
            store:
              type: boolean
              description: "Whether to store the generated model response for later retrieval via\nAPI.\n"
              default: true
              nullable: true
            stream:
              type: boolean
              description: "If set to true, the model response data will be streamed to the client\nas it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\nSee the [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\nfor more information.\n"
              default: false
              nullable: true
            stream_options:
              $ref: '#/components/schemas/ResponseStreamOptions'
    CreateRunRequest:
      required:
        - assistant_id
      type: object
      properties:
        additional_instructions:
          type: string
          description: Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.
          nullable: true
        additional_messages:
          type: array
          items:
            $ref: '#/components/schemas/CreateMessageRequest'
          description: Adds additional messages to the thread before creating the run.
          nullable: true
        assistant_id:
          type: string
          description: 'The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to execute this run.'
        instructions:
          type: string
          description: 'Overrides the [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.'
          nullable: true
        max_completion_tokens:
          minimum: 256
          type: integer
          description: "The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.\n"
          nullable: true
        max_prompt_tokens:
          minimum: 256
          type: integer
          description: "The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.\n"
          nullable: true
        metadata:
          $ref: '#/components/schemas/Metadata'
        model:
          anyOf:
            - type: string
            - $ref: '#/components/schemas/AssistantSupportedModels'
          description: 'The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.'
          nullable: true
          x-oaiTypeLabel: string
        parallel_tool_calls:
          $ref: '#/components/schemas/ParallelToolCalls'
        reasoning_effort:
          $ref: '#/components/schemas/ReasoningEffort'
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
        stream:
          type: boolean
          description: "If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.\n"
          nullable: true
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n"
          default: 1
          nullable: true
          example: 1
        tool_choice:
          $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
        tools:
          maxItems: 20
          type: array
          items:
            $ref: '#/components/schemas/AssistantTool'
          description: Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.
          nullable: true
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n"
          default: 1
          nullable: true
          example: 1
        truncation_strategy:
          $ref: '#/components/schemas/TruncationObject'
      additionalProperties: false
    CreateRunRequestWithoutStream:
      required:
        - assistant_id
      type: object
      properties:
        additional_instructions:
          type: string
          description: Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.
          nullable: true
        additional_messages:
          type: array
          items:
            $ref: '#/components/schemas/CreateMessageRequest'
          description: Adds additional messages to the thread before creating the run.
          nullable: true
        assistant_id:
          type: string
          description: 'The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to execute this run.'
        instructions:
          type: string
          description: 'Overrides the [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.'
          nullable: true
        max_completion_tokens:
          minimum: 256
          type: integer
          description: "The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.\n"
          nullable: true
        max_prompt_tokens:
          minimum: 256
          type: integer
          description: "The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.\n"
          nullable: true
        metadata:
          $ref: '#/components/schemas/Metadata'
        model:
          anyOf:
            - type: string
            - $ref: '#/components/schemas/AssistantSupportedModels'
          description: 'The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.'
          nullable: true
          x-oaiTypeLabel: string
        parallel_tool_calls:
          $ref: '#/components/schemas/ParallelToolCalls'
        reasoning_effort:
          $ref: '#/components/schemas/ReasoningEffort'
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n"
          default: 1
          nullable: true
          example: 1
        tool_choice:
          $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
        tools:
          maxItems: 20
          type: array
          items:
            $ref: '#/components/schemas/AssistantTool'
          description: Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.
          nullable: true
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n"
          default: 1
          nullable: true
          example: 1
        truncation_strategy:
          $ref: '#/components/schemas/TruncationObject'
      additionalProperties: false
    CreateSpeechRequest:
      required:
        - model
        - input
        - voice
      type: object
      properties:
        input:
          maxLength: 4096
          type: string
          description: The text to generate audio for. The maximum length is 4096 characters.
        instructions:
          maxLength: 4096
          type: string
          description: Control the voice of your generated audio with additional instructions. Does not work with `tts-1` or `tts-1-hd`.
        model:
          anyOf:
            - type: string
            - enum:
                - tts-1
                - tts-1-hd
                - gpt-4o-mini-tts
              type: string
              x-stainless-nominal: false
          description: "One of the available [TTS models](https://platform.openai.com/docs/models#tts): `tts-1`, `tts-1-hd` or `gpt-4o-mini-tts`.\n"
          x-oaiTypeLabel: string
        response_format:
          enum:
            - mp3
            - opus
            - aac
            - flac
            - wav
            - pcm
          type: string
          description: 'The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`.'
          default: mp3
        speed:
          maximum: 4
          minimum: 0.25
          type: number
          description: The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default.
          default: 1
        stream_format:
          enum:
            - sse
            - audio
          type: string
          description: The format to stream the audio in. Supported formats are `sse` and `audio`. `sse` is not supported for `tts-1` or `tts-1-hd`.
          default: audio
        voice:
          $ref: '#/components/schemas/VoiceIdsShared'
      additionalProperties: false
    CreateSpeechResponseStreamEvent:
      anyOf:
        - $ref: '#/components/schemas/SpeechAudioDeltaEvent'
        - $ref: '#/components/schemas/SpeechAudioDoneEvent'
      discriminator:
        propertyName: type
    CreateThreadAndRunRequest:
      required:
        - assistant_id
      type: object
      properties:
        assistant_id:
          type: string
          description: 'The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to execute this run.'
        instructions:
          type: string
          description: Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.
          nullable: true
        max_completion_tokens:
          minimum: 256
          type: integer
          description: "The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.\n"
          nullable: true
        max_prompt_tokens:
          minimum: 256
          type: integer
          description: "The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.\n"
          nullable: true
        metadata:
          $ref: '#/components/schemas/Metadata'
        model:
          anyOf:
            - type: string
            - enum:
                - gpt-5
                - gpt-5-mini
                - gpt-5-nano
                - gpt-5-2025-08-07
                - gpt-5-mini-2025-08-07
                - gpt-5-nano-2025-08-07
                - gpt-4.1
                - gpt-4.1-mini
                - gpt-4.1-nano
                - gpt-4.1-2025-04-14
                - gpt-4.1-mini-2025-04-14
                - gpt-4.1-nano-2025-04-14
                - gpt-4o
                - gpt-4o-2024-11-20
                - gpt-4o-2024-08-06
                - gpt-4o-2024-05-13
                - gpt-4o-mini
                - gpt-4o-mini-2024-07-18
                - gpt-4.5-preview
                - gpt-4.5-preview-2025-02-27
                - gpt-4-turbo
                - gpt-4-turbo-2024-04-09
                - gpt-4-0125-preview
                - gpt-4-turbo-preview
                - gpt-4-1106-preview
                - gpt-4-vision-preview
                - gpt-4
                - gpt-4-0314
                - gpt-4-0613
                - gpt-4-32k
                - gpt-4-32k-0314
                - gpt-4-32k-0613
                - gpt-3.5-turbo
                - gpt-3.5-turbo-16k
                - gpt-3.5-turbo-0613
                - gpt-3.5-turbo-1106
                - gpt-3.5-turbo-0125
                - gpt-3.5-turbo-16k-0613
              type: string
          description: 'The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.'
          nullable: true
          x-oaiTypeLabel: string
        parallel_tool_calls:
          $ref: '#/components/schemas/ParallelToolCalls'
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
        stream:
          type: boolean
          description: "If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.\n"
          nullable: true
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n"
          default: 1
          nullable: true
          example: 1
        thread:
          $ref: '#/components/schemas/CreateThreadRequest'
        tool_choice:
          $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
        tool_resources:
          type: object
          properties:
            code_interpreter:
              type: object
              properties:
                file_ids:
                  maxItems: 20
                  type: array
                  items:
                    type: string
                  description: "A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n"
            file_search:
              type: object
              properties:
                vector_store_ids:
                  maxItems: 1
                  type: array
                  items:
                    type: string
                  description: "The ID of the [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.\n"
          description: "A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n"
          nullable: true
        tools:
          maxItems: 20
          type: array
          items:
            $ref: '#/components/schemas/AssistantTool'
          description: Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.
          nullable: true
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n"
          default: 1
          nullable: true
          example: 1
        truncation_strategy:
          $ref: '#/components/schemas/TruncationObject'
      additionalProperties: false
    CreateThreadAndRunRequestWithoutStream:
      required:
        - assistant_id
      type: object
      properties:
        assistant_id:
          type: string
          description: 'The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to execute this run.'
        instructions:
          type: string
          description: Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.
          nullable: true
        max_completion_tokens:
          minimum: 256
          type: integer
          description: "The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.\n"
          nullable: true
        max_prompt_tokens:
          minimum: 256
          type: integer
          description: "The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.\n"
          nullable: true
        metadata:
          $ref: '#/components/schemas/Metadata'
        model:
          anyOf:
            - type: string
            - enum:
                - gpt-5
                - gpt-5-mini
                - gpt-5-nano
                - gpt-5-2025-08-07
                - gpt-5-mini-2025-08-07
                - gpt-5-nano-2025-08-07
                - gpt-4.1
                - gpt-4.1-mini
                - gpt-4.1-nano
                - gpt-4.1-2025-04-14
                - gpt-4.1-mini-2025-04-14
                - gpt-4.1-nano-2025-04-14
                - gpt-4o
                - gpt-4o-2024-11-20
                - gpt-4o-2024-08-06
                - gpt-4o-2024-05-13
                - gpt-4o-mini
                - gpt-4o-mini-2024-07-18
                - gpt-4.5-preview
                - gpt-4.5-preview-2025-02-27
                - gpt-4-turbo
                - gpt-4-turbo-2024-04-09
                - gpt-4-0125-preview
                - gpt-4-turbo-preview
                - gpt-4-1106-preview
                - gpt-4-vision-preview
                - gpt-4
                - gpt-4-0314
                - gpt-4-0613
                - gpt-4-32k
                - gpt-4-32k-0314
                - gpt-4-32k-0613
                - gpt-3.5-turbo
                - gpt-3.5-turbo-16k
                - gpt-3.5-turbo-0613
                - gpt-3.5-turbo-1106
                - gpt-3.5-turbo-0125
                - gpt-3.5-turbo-16k-0613
              type: string
          description: 'The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.'
          nullable: true
          x-oaiTypeLabel: string
        parallel_tool_calls:
          $ref: '#/components/schemas/ParallelToolCalls'
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n"
          default: 1
          nullable: true
          example: 1
        thread:
          $ref: '#/components/schemas/CreateThreadRequest'
        tool_choice:
          $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
        tool_resources:
          type: object
          properties:
            code_interpreter:
              type: object
              properties:
                file_ids:
                  maxItems: 20
                  type: array
                  items:
                    type: string
                  description: "A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n"
            file_search:
              type: object
              properties:
                vector_store_ids:
                  maxItems: 1
                  type: array
                  items:
                    type: string
                  description: "The ID of the [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.\n"
          description: "A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n"
          nullable: true
        tools:
          maxItems: 20
          type: array
          items:
            $ref: '#/components/schemas/AssistantTool'
          description: Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.
          nullable: true
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n"
          default: 1
          nullable: true
          example: 1
        truncation_strategy:
          $ref: '#/components/schemas/TruncationObject'
      additionalProperties: false
    CreateThreadRequest:
      type: object
      properties:
        messages:
          type: array
          items:
            $ref: '#/components/schemas/CreateMessageRequest'
          description: 'A list of [messages](https://platform.openai.com/docs/api-reference/messages) to start the thread with.'
        metadata:
          $ref: '#/components/schemas/Metadata'
        tool_resources:
          type: object
          properties:
            code_interpreter:
              type: object
              properties:
                file_ids:
                  maxItems: 20
                  type: array
                  items:
                    type: string
                  description: "A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n"
            file_search:
              type: object
              anyOf:
                - required:
                    - vector_store_ids
                - required:
                    - vector_stores
              properties:
                vector_store_ids:
                  maxItems: 1
                  type: array
                  items:
                    type: string
                  description: "The [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.\n"
                vector_stores:
                  maxItems: 1
                  type: array
                  items:
                    type: object
                    properties:
                      chunking_strategy:
                        type: object
                        anyOf:
                          - title: Auto Chunking Strategy
                            required:
                              - type
                            type: object
                            properties:
                              type:
                                enum:
                                  - auto
                                type: string
                                description: Always `auto`.
                                x-stainless-const: true
                            additionalProperties: false
                            description: The default strategy. This strategy currently uses a `max_chunk_size_tokens` of `800` and `chunk_overlap_tokens` of `400`.
                          - title: Static Chunking Strategy
                            required:
                              - type
                              - static
                            type: object
                            properties:
                              static:
                                required:
                                  - max_chunk_size_tokens
                                  - chunk_overlap_tokens
                                type: object
                                properties:
                                  chunk_overlap_tokens:
                                    type: integer
                                    description: "The number of tokens that overlap between chunks. The default value is `400`.\n\nNote that the overlap must not exceed half of `max_chunk_size_tokens`.\n"
                                  max_chunk_size_tokens:
                                    maximum: 4096
                                    minimum: 100
                                    type: integer
                                    description: The maximum number of tokens in each chunk. The default value is `800`. The minimum value is `100` and the maximum value is `4096`.
                                additionalProperties: false
                              type:
                                enum:
                                  - static
                                type: string
                                description: Always `static`.
                                x-stainless-const: true
                            additionalProperties: false
                            x-stainless-naming:
                              java:
                                type_name: StaticObject
                              kotlin:
                                type_name: StaticObject
                        description: 'The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.'
                        discriminator:
                          propertyName: type
                      file_ids:
                        maxItems: 10000
                        type: array
                        items:
                          type: string
                        description: "A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to add to the vector store. There can be a maximum of 10000 files in a vector store.\n"
                      metadata:
                        $ref: '#/components/schemas/Metadata'
                  description: "A helper to create a [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) with file_ids and attach it to this thread. There can be a maximum of 1 vector store attached to the thread.\n"
          description: "A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n"
          nullable: true
      additionalProperties: false
      description: "Options to create a new thread. If no thread is provided when running a \nrequest, an empty thread will be created.\n"
    CreateTranscriptionRequest:
      required:
        - file
        - model
      type: object
      properties:
        chunking_strategy:
          $ref: '#/components/schemas/TranscriptionChunkingStrategy'
        file:
          type: string
          description: "The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n"
          format: binary
          x-oaiMeta:
            exampleFilePath: speech.mp3
          x-oaiTypeLabel: file
        include:
          type: array
          items:
            $ref: '#/components/schemas/TranscriptionInclude'
          description: "Additional information to include in the transcription response. \n`logprobs` will return the log probabilities of the tokens in the \nresponse to understand the model's confidence in the transcription. \n`logprobs` only works with response_format set to `json` and only with \nthe models `gpt-4o-transcribe` and `gpt-4o-mini-transcribe`.\n"
        language:
          type: string
          description: "The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`) format will improve accuracy and latency.\n"
        model:
          anyOf:
            - type: string
            - enum:
                - whisper-1
                - gpt-4o-transcribe
                - gpt-4o-mini-transcribe
              type: string
              x-stainless-const: true
              x-stainless-nominal: false
          description: "ID of the model to use. The options are `gpt-4o-transcribe`, `gpt-4o-mini-transcribe`, and `whisper-1` (which is powered by our open source Whisper V2 model).\n"
          example: gpt-4o-transcribe
          x-oaiTypeLabel: string
        prompt:
          type: string
          description: "An optional text to guide the model's style or continue a previous audio segment. The [prompt](https://platform.openai.com/docs/guides/speech-to-text#prompting) should match the audio language.\n"
        response_format:
          $ref: '#/components/schemas/AudioResponseFormat'
        stream:
          type: boolean
          description: "If set to true, the model response data will be streamed to the client\nas it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format). \nSee the [Streaming section of the Speech-to-Text guide](https://platform.openai.com/docs/guides/speech-to-text?lang=curl#streaming-transcriptions)\nfor more information.\n\nNote: Streaming is not supported for the `whisper-1` model and will be ignored.\n"
          default: false
          nullable: true
        temperature:
          type: number
          description: "The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.\n"
          default: 0
        timestamp_granularities:
          type: array
          items:
            enum:
              - word
              - segment
            type: string
          description: "The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.\n"
          default:
            - segment
      additionalProperties: false
    CreateTranscriptionResponseJson:
      required:
        - text
      type: object
      properties:
        logprobs:
          type: array
          items:
            type: object
            properties:
              bytes:
                type: array
                items:
                  type: number
                description: The bytes of the token.
              logprob:
                type: number
                description: The log probability of the token.
              token:
                type: string
                description: The token in the transcription.
          description: "The log probabilities of the tokens in the transcription. Only returned with the models `gpt-4o-transcribe` and `gpt-4o-mini-transcribe` if `logprobs` is added to the `include` array.\n"
        text:
          type: string
          description: The transcribed text.
        usage:
          type: object
          anyOf:
            - $ref: '#/components/schemas/TranscriptTextUsageTokens'
            - $ref: '#/components/schemas/TranscriptTextUsageDuration'
          description: Token usage statistics for the request.
          discriminator:
            propertyName: type
      description: 'Represents a transcription response returned by model, based on the provided input.'
      x-oaiMeta:
        example: "{\n  \"text\": \"Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that.\",\n  \"usage\": {\n    \"type\": \"tokens\",\n    \"input_tokens\": 14,\n    \"input_token_details\": {\n      \"text_tokens\": 10,\n      \"audio_tokens\": 4\n    },\n    \"output_tokens\": 101,\n    \"total_tokens\": 115\n  }\n}\n"
        group: audio
        name: The transcription object (JSON)
    CreateTranscriptionResponseStreamEvent:
      anyOf:
        - $ref: '#/components/schemas/TranscriptTextDeltaEvent'
        - $ref: '#/components/schemas/TranscriptTextDoneEvent'
      discriminator:
        propertyName: type
    CreateTranscriptionResponseVerboseJson:
      required:
        - language
        - duration
        - text
      type: object
      properties:
        duration:
          type: number
          description: The duration of the input audio.
        language:
          type: string
          description: The language of the input audio.
        segments:
          type: array
          items:
            $ref: '#/components/schemas/TranscriptionSegment'
          description: Segments of the transcribed text and their corresponding details.
        text:
          type: string
          description: The transcribed text.
        usage:
          $ref: '#/components/schemas/TranscriptTextUsageDuration'
        words:
          type: array
          items:
            $ref: '#/components/schemas/TranscriptionWord'
          description: Extracted words and their corresponding timestamps.
      description: 'Represents a verbose json transcription response returned by model, based on the provided input.'
      x-oaiMeta:
        example: "{\n  \"task\": \"transcribe\",\n  \"language\": \"english\",\n  \"duration\": 8.470000267028809,\n  \"text\": \"The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.\",\n  \"segments\": [\n    {\n      \"id\": 0,\n      \"seek\": 0,\n      \"start\": 0.0,\n      \"end\": 3.319999933242798,\n      \"text\": \" The beach was a popular spot on a hot summer day.\",\n      \"tokens\": [\n        50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530\n      ],\n      \"temperature\": 0.0,\n      \"avg_logprob\": -0.2860786020755768,\n      \"compression_ratio\": 1.2363636493682861,\n      \"no_speech_prob\": 0.00985979475080967\n    },\n    ...\n  ],\n  \"usage\": {\n    \"type\": \"duration\",\n    \"seconds\": 9\n  }\n}\n"
        group: audio
        name: The transcription object (Verbose JSON)
    CreateTranslationRequest:
      required:
        - file
        - model
      type: object
      properties:
        file:
          type: string
          description: "The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n"
          format: binary
          x-oaiMeta:
            exampleFilePath: speech.mp3
          x-oaiTypeLabel: file
        model:
          anyOf:
            - type: string
            - enum:
                - whisper-1
              type: string
              x-stainless-const: true
          description: "ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.\n"
          example: whisper-1
          x-oaiTypeLabel: string
        prompt:
          type: string
          description: "An optional text to guide the model's style or continue a previous audio segment. The [prompt](https://platform.openai.com/docs/guides/speech-to-text#prompting) should be in English.\n"
        response_format:
          enum:
            - json
            - text
            - srt
            - verbose_json
            - vtt
          type: string
          description: "The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.\n"
          default: json
        temperature:
          type: number
          description: "The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.\n"
          default: 0
      additionalProperties: false
    CreateTranslationResponseJson:
      required:
        - text
      type: object
      properties:
        text:
          type: string
    CreateTranslationResponseVerboseJson:
      required:
        - language
        - duration
        - text
      type: object
      properties:
        duration:
          type: number
          description: The duration of the input audio.
        language:
          type: string
          description: The language of the output translation (always `english`).
        segments:
          type: array
          items:
            $ref: '#/components/schemas/TranscriptionSegment'
          description: Segments of the translated text and their corresponding details.
        text:
          type: string
          description: The translated text.
    CreateUploadRequest:
      required:
        - filename
        - purpose
        - bytes
        - mime_type
      type: object
      properties:
        bytes:
          type: integer
          description: "The number of bytes in the file you are uploading.\n"
        expires_after:
          $ref: '#/components/schemas/FileExpirationAfter'
        filename:
          type: string
          description: "The name of the file to upload.\n"
        mime_type:
          type: string
          description: "The MIME type of the file.\n\nThis must fall within the supported MIME types for your file purpose. See the supported MIME types for assistants and vision.\n"
        purpose:
          enum:
            - assistants
            - batch
            - fine-tune
            - vision
          type: string
          description: "The intended purpose of the uploaded file.\n\nSee the [documentation on File purposes](https://platform.openai.com/docs/api-reference/files/create#files-create-purpose).\n"
      additionalProperties: false
    CreateVectorStoreFileBatchRequest:
      required:
        - file_ids
      type: object
      properties:
        attributes:
          $ref: '#/components/schemas/VectorStoreFileAttributes'
        chunking_strategy:
          $ref: '#/components/schemas/ChunkingStrategyRequestParam'
        file_ids:
          maxItems: 500
          minItems: 1
          type: array
          items:
            type: string
          description: 'A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.'
      additionalProperties: false
    CreateVectorStoreFileRequest:
      required:
        - file_id
      type: object
      properties:
        attributes:
          $ref: '#/components/schemas/VectorStoreFileAttributes'
        chunking_strategy:
          $ref: '#/components/schemas/ChunkingStrategyRequestParam'
        file_id:
          type: string
          description: 'A [File](https://platform.openai.com/docs/api-reference/files) ID that the vector store should use. Useful for tools like `file_search` that can access files.'
      additionalProperties: false
    CreateVectorStoreRequest:
      type: object
      properties:
        chunking_strategy:
          $ref: '#/components/schemas/ChunkingStrategyRequestParam'
        expires_after:
          $ref: '#/components/schemas/VectorStoreExpirationAfter'
        file_ids:
          maxItems: 500
          type: array
          items:
            type: string
          description: 'A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.'
        metadata:
          $ref: '#/components/schemas/Metadata'
        name:
          type: string
          description: The name of the vector store.
      additionalProperties: false
    CustomTool:
      title: Custom tool
      required:
        - type
        - name
      type: object
      properties:
        description:
          type: string
          description: "Optional description of the custom tool, used to provide more context.\n"
        format:
          anyOf:
            - title: Text format
              required:
                - type
              type: object
              properties:
                type:
                  enum:
                    - text
                  type: string
                  description: Unconstrained text format. Always `text`.
                  x-stainless-const: true
              additionalProperties: false
              description: Unconstrained free-form text.
            - title: Grammar format
              required:
                - type
                - definition
                - syntax
              type: object
              properties:
                definition:
                  type: string
                  description: The grammar definition.
                syntax:
                  enum:
                    - lark
                    - regex
                  type: string
                  description: The syntax of the grammar definition. One of `lark` or `regex`.
                type:
                  enum:
                    - grammar
                  type: string
                  description: Grammar format. Always `grammar`.
                  x-stainless-const: true
              additionalProperties: false
              description: A grammar defined by the user.
          description: "The input format for the custom tool. Default is unconstrained text.\n"
          discriminator:
            propertyName: type
        name:
          type: string
          description: 'The name of the custom tool, used to identify it in tool calls.'
        type:
          enum:
            - custom
          type: string
          description: The type of the custom tool. Always `custom`.
          x-stainless-const: true
      description: "A custom tool that processes input using a specified format. Learn more about\n[custom tools](https://platform.openai.com/docs/guides/function-calling#custom-tools).\n"
    CustomToolCall:
      title: Custom tool call
      required:
        - type
        - call_id
        - name
        - input
      type: object
      properties:
        call_id:
          type: string
          description: "An identifier used to map this custom tool call to a tool call output.\n"
        id:
          type: string
          description: "The unique ID of the custom tool call in the OpenAI platform.\n"
        input:
          type: string
          description: "The input for the custom tool call generated by the model.\n"
        name:
          type: string
          description: "The name of the custom tool being called.\n"
        type:
          enum:
            - custom_tool_call
          type: string
          description: "The type of the custom tool call. Always `custom_tool_call`.\n"
          x-stainless-const: true
      description: "A call to a custom tool created by the model.\n"
    CustomToolCallOutput:
      title: Custom tool call output
      required:
        - type
        - call_id
        - output
      type: object
      properties:
        call_id:
          type: string
          description: "The call ID, used to map this custom tool call output to a custom tool call.\n"
        id:
          type: string
          description: "The unique ID of the custom tool call output in the OpenAI platform.\n"
        output:
          type: string
          description: "The output from the custom tool call generated by your code.\n"
        type:
          enum:
            - custom_tool_call_output
          type: string
          description: "The type of the custom tool call output. Always `custom_tool_call_output`.\n"
          x-stainless-const: true
      description: "The output of a custom tool call from your code, being sent back to the model.\n"
    CustomToolChatCompletions:
      title: Custom tool
      required:
        - type
        - custom
      type: object
      properties:
        custom:
          title: Custom tool properties
          required:
            - name
          type: object
          properties:
            description:
              type: string
              description: "Optional description of the custom tool, used to provide more context.\n"
            format:
              anyOf:
                - title: Text format
                  required:
                    - type
                  type: object
                  properties:
                    type:
                      enum:
                        - text
                      type: string
                      description: Unconstrained text format. Always `text`.
                      x-stainless-const: true
                  additionalProperties: false
                  description: Unconstrained free-form text.
                - title: Grammar format
                  required:
                    - type
                    - grammar
                  type: object
                  properties:
                    grammar:
                      title: Grammar format
                      required:
                        - definition
                        - syntax
                      type: object
                      properties:
                        definition:
                          type: string
                          description: The grammar definition.
                        syntax:
                          enum:
                            - lark
                            - regex
                          type: string
                          description: The syntax of the grammar definition. One of `lark` or `regex`.
                      description: Your chosen grammar.
                    type:
                      enum:
                        - grammar
                      type: string
                      description: Grammar format. Always `grammar`.
                      x-stainless-const: true
                  additionalProperties: false
                  description: A grammar defined by the user.
              description: "The input format for the custom tool. Default is unconstrained text.\n"
              discriminator:
                propertyName: type
            name:
              type: string
              description: 'The name of the custom tool, used to identify it in tool calls.'
          description: "Properties of the custom tool.\n"
        type:
          enum:
            - custom
          type: string
          description: The type of the custom tool. Always `custom`.
          x-stainless-const: true
      description: "A custom tool that processes input using a specified format.\n"
    DeleteAssistantResponse:
      required:
        - id
        - object
        - deleted
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          enum:
            - assistant.deleted
          type: string
          x-stainless-const: true
    DeleteCertificateResponse:
      required:
        - object
        - id
      type: object
      properties:
        id:
          type: string
          description: The ID of the certificate that was deleted.
        object:
          enum:
            - certificate.deleted
          description: 'The object type, must be `certificate.deleted`.'
          x-stainless-const: true
    DeleteFileResponse:
      required:
        - id
        - object
        - deleted
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          enum:
            - file
          type: string
          x-stainless-const: true
    DeleteFineTuningCheckpointPermissionResponse:
      required:
        - id
        - object
        - deleted
      type: object
      properties:
        deleted:
          type: boolean
          description: Whether the fine-tuned model checkpoint permission was successfully deleted.
        id:
          type: string
          description: The ID of the fine-tuned model checkpoint permission that was deleted.
        object:
          enum:
            - checkpoint.permission
          type: string
          description: 'The object type, which is always "checkpoint.permission".'
          x-stainless-const: true
    DeleteMessageResponse:
      required:
        - id
        - object
        - deleted
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          enum:
            - thread.message.deleted
          type: string
          x-stainless-const: true
    DeleteModelResponse:
      required:
        - id
        - object
        - deleted
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
    DeleteThreadResponse:
      required:
        - id
        - object
        - deleted
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          enum:
            - thread.deleted
          type: string
          x-stainless-const: true
    DeleteVectorStoreFileResponse:
      required:
        - id
        - object
        - deleted
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          enum:
            - vector_store.file.deleted
          type: string
          x-stainless-const: true
    DeleteVectorStoreResponse:
      required:
        - id
        - object
        - deleted
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          enum:
            - vector_store.deleted
          type: string
          x-stainless-const: true
    DeletedConversation:
      title: The deleted conversation object
      allOf:
        - $ref: '#/components/schemas/DeletedConversationResource'
      x-oaiMeta:
        group: conversations
        name: The deleted conversation object
    DeletedConversationResource:
      required:
        - object
        - deleted
        - id
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          enum:
            - conversation.deleted
          type: string
          default: conversation.deleted
          x-stainless-const: true
    DoneEvent:
      required:
        - event
        - data
      type: object
      properties:
        data:
          enum:
            - '[DONE]'
          type: string
          x-stainless-const: true
        event:
          enum:
            - done
          type: string
          x-stainless-const: true
      description: Occurs when a stream ends.
      x-oaiMeta:
        dataDescription: '`data` is `[DONE]`'
    DoubleClick:
      title: DoubleClick
      required:
        - type
        - x
        - y
      type: object
      properties:
        type:
          enum:
            - double_click
          type: string
          description: "Specifies the event type. For a double click action, this property is \nalways set to `double_click`.\n"
          default: double_click
          x-stainless-const: true
        x:
          type: integer
          description: "The x-coordinate where the double click occurred.\n"
        y:
          type: integer
          description: "The y-coordinate where the double click occurred.\n"
      description: "A double click action.\n"
    Drag:
      title: Drag
      required:
        - type
        - path
      type: object
      properties:
        path:
          type: array
          items:
            $ref: '#/components/schemas/Coordinate'
          description: "An array of coordinates representing the path of the drag action. Coordinates will appear as an array\nof objects, eg\n```\n[\n  { x: 100, y: 200 },\n  { x: 200, y: 300 }\n]\n```\n"
        type:
          enum:
            - drag
          type: string
          description: "Specifies the event type. For a drag action, this property is \nalways set to `drag`.\n"
          default: drag
          x-stainless-const: true
      description: "A drag action.\n"
    EasyInputMessage:
      title: Input message
      required:
        - role
        - content
      type: object
      properties:
        content:
          anyOf:
            - title: Text input
              type: string
              description: "A text input to the model.\n"
            - $ref: '#/components/schemas/InputMessageContentList'
          description: "Text, image, or audio input to the model, used to generate a response.\nCan also contain previous assistant responses.\n"
        role:
          enum:
            - user
            - assistant
            - system
            - developer
          type: string
          description: "The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n"
        type:
          enum:
            - message
          type: string
          description: "The type of the message input. Always `message`.\n"
          x-stainless-const: true
      description: "A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n"
    Embedding:
      required:
        - index
        - object
        - embedding
      type: object
      properties:
        embedding:
          type: array
          items:
            type: number
            format: float
          description: "The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](https://platform.openai.com/docs/guides/embeddings).\n"
        index:
          type: integer
          description: The index of the embedding in the list of embeddings.
        object:
          enum:
            - embedding
          type: string
          description: 'The object type, which is always "embedding".'
          x-stainless-const: true
      description: "Represents an embedding vector returned by embedding endpoint.\n"
      x-oaiMeta:
        example: "{\n  \"object\": \"embedding\",\n  \"embedding\": [\n    0.0023064255,\n    -0.009327292,\n    .... (1536 floats total for ada-002)\n    -0.0028842222,\n  ],\n  \"index\": 0\n}\n"
        name: The embedding object
    Error:
      required:
        - type
        - message
        - param
        - code
      type: object
      properties:
        code:
          type: string
          nullable: true
        message:
          type: string
        param:
          type: string
          nullable: true
        type:
          type: string
    ErrorEvent:
      required:
        - event
        - data
      type: object
      properties:
        data:
          $ref: '#/components/schemas/Error'
        event:
          enum:
            - error
          type: string
          x-stainless-const: true
      description: 'Occurs when an [error](https://platform.openai.com/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.'
      x-oaiMeta:
        dataDescription: '`data` is an [error](/docs/guides/error-codes#api-errors)'
    ErrorResponse:
      required:
        - error
      type: object
      properties:
        error:
          $ref: '#/components/schemas/Error'
    Eval:
      title: Eval
      required:
        - id
        - data_source_config
        - object
        - testing_criteria
        - name
        - created_at
        - metadata
      type: object
      properties:
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the eval was created.
        data_source_config:
          type: object
          anyOf:
            - $ref: '#/components/schemas/EvalCustomDataSourceConfig'
            - $ref: '#/components/schemas/EvalLogsDataSourceConfig'
            - $ref: '#/components/schemas/EvalStoredCompletionsDataSourceConfig'
          description: Configuration of data sources used in runs of the evaluation.
          discriminator:
            propertyName: type
        id:
          type: string
          description: Unique identifier for the evaluation.
        metadata:
          $ref: '#/components/schemas/Metadata'
        name:
          type: string
          description: The name of the evaluation.
          example: Chatbot effectiveness Evaluation
        object:
          enum:
            - eval
          type: string
          description: The object type.
          default: eval
          x-stainless-const: true
        testing_criteria:
          type: array
          items:
            anyOf:
              - $ref: '#/components/schemas/EvalGraderLabelModel'
              - $ref: '#/components/schemas/EvalGraderStringCheck'
              - $ref: '#/components/schemas/EvalGraderTextSimilarity'
              - $ref: '#/components/schemas/EvalGraderPython'
              - $ref: '#/components/schemas/EvalGraderScoreModel'
          description: A list of testing criteria.
      description: "An Eval object with a data source config and testing criteria.\nAn Eval represents a task to be done for your LLM integration.\nLike:\n - Improve the quality of my chatbot\n - See how well my chatbot handles customer support\n - Check if o4-mini is better at my usecase than gpt-4o\n"
      x-oaiMeta:
        example: "{\n  \"object\": \"eval\",\n  \"id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n  \"data_source_config\": {\n    \"type\": \"custom\",\n    \"item_schema\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"label\": {\"type\": \"string\"},\n      },\n      \"required\": [\"label\"]\n    },\n    \"include_sample_schema\": true\n  },\n  \"testing_criteria\": [\n    {\n      \"name\": \"My string check grader\",\n      \"type\": \"string_check\",\n      \"input\": \"{{sample.output_text}}\",\n      \"reference\": \"{{item.label}}\",\n      \"operation\": \"eq\",\n    }\n  ],\n  \"name\": \"External Data Eval\",\n  \"created_at\": 1739314509,\n  \"metadata\": {\n    \"test\": \"synthetics\",\n  }\n}\n"
        group: evals
        name: The eval object
    EvalApiError:
      title: EvalApiError
      required:
        - code
        - message
      type: object
      properties:
        code:
          type: string
          description: The error code.
        message:
          type: string
          description: The error message.
      description: "An object representing an error response from the Eval API.\n"
      x-oaiMeta:
        example: "{\n  \"code\": \"internal_error\",\n  \"message\": \"The eval run failed due to an internal error.\"\n}\n"
        group: evals
        name: The API error object
    EvalCustomDataSourceConfig:
      title: CustomDataSourceConfig
      required:
        - type
        - schema
      type: object
      properties:
        schema:
          type: object
          description: "The json schema for the run data source items.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n"
        type:
          enum:
            - custom
          type: string
          description: The type of data source. Always `custom`.
          default: custom
          x-stainless-const: true
      description: "A CustomDataSourceConfig which specifies the schema of your `item` and optionally `sample` namespaces.\nThe response schema defines the shape of the data that will be:\n- Used to define your testing criteria and\n- What data is required when creating a run\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"custom\",\n  \"schema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"item\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"label\": {\"type\": \"string\"},\n        },\n        \"required\": [\"label\"]\n      }\n    },\n    \"required\": [\"item\"]\n  }\n}\n"
        group: evals
        name: The eval custom data source config object
    EvalGraderLabelModel:
      title: LabelModelGrader
      type: object
      allOf:
        - $ref: '#/components/schemas/GraderLabelModel'
    EvalGraderPython:
      title: PythonGrader
      type: object
      allOf:
        - $ref: '#/components/schemas/GraderPython'
        - type: object
          properties:
            pass_threshold:
              type: number
              description: The threshold for the score.
          x-oaiMeta:
            example: "{\n  \"type\": \"python\",\n  \"name\": \"Example python grader\",\n  \"image_tag\": \"2025-05-08\",\n  \"source\": \"\"\"\ndef grade(sample: dict, item: dict) -> float:\n    \\\"\"\"\n    Returns 1.0 if `output_text` equals `label`, otherwise 0.0.\n    \\\"\"\"\n    output = sample.get(\"output_text\")\n    label = item.get(\"label\")\n    return 1.0 if output == label else 0.0\n\"\"\",\n  \"pass_threshold\": 0.8\n}\n"
            group: graders
            name: Eval Python Grader
    EvalGraderScoreModel:
      title: ScoreModelGrader
      type: object
      allOf:
        - $ref: '#/components/schemas/GraderScoreModel'
        - type: object
          properties:
            pass_threshold:
              type: number
              description: The threshold for the score.
    EvalGraderStringCheck:
      title: StringCheckGrader
      type: object
      allOf:
        - $ref: '#/components/schemas/GraderStringCheck'
    EvalGraderTextSimilarity:
      title: TextSimilarityGrader
      type: object
      allOf:
        - $ref: '#/components/schemas/GraderTextSimilarity'
        - required:
            - pass_threshold
          type: object
          properties:
            pass_threshold:
              type: number
              description: The threshold for the score.
          x-oaiMeta:
            example: "{\n  \"type\": \"text_similarity\",\n  \"name\": \"Example text similarity grader\",\n  \"input\": \"{{sample.output_text}}\",\n  \"reference\": \"{{item.label}}\",\n  \"pass_threshold\": 0.8,\n  \"evaluation_metric\": \"fuzzy_match\"\n}\n"
            group: graders
            name: Text Similarity Grader
    EvalItem:
      title: Eval message object
      required:
        - role
        - content
      type: object
      properties:
        content:
          anyOf:
            - title: Text input
              type: string
              description: "A text input to the model.\n"
            - $ref: '#/components/schemas/InputTextContent'
            - title: Output text
              required:
                - type
                - text
              type: object
              properties:
                text:
                  type: string
                  description: "The text output from the model.\n"
                type:
                  enum:
                    - output_text
                  type: string
                  description: "The type of the output text. Always `output_text`.\n"
                  x-stainless-const: true
              description: "A text output from the model.\n"
            - title: Input image
              required:
                - type
                - image_url
              type: object
              properties:
                detail:
                  type: string
                  description: "The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n"
                image_url:
                  type: string
                  description: "The URL of the image input.\n"
                type:
                  enum:
                    - input_image
                  type: string
                  description: "The type of the image input. Always `input_image`.\n"
                  x-stainless-const: true
              description: "An image input to the model.\n"
            - $ref: '#/components/schemas/InputAudio'
            - title: 'An array of Input text, Input image, and Input audio'
              type: array
              description: "A list of inputs, each of which may be either an input text, input image, or input audio object.\n"
          description: "Inputs to the model - can contain template strings.\n"
        role:
          enum:
            - user
            - assistant
            - system
            - developer
          type: string
          description: "The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n"
        type:
          enum:
            - message
          type: string
          description: "The type of the message input. Always `message`.\n"
          x-stainless-const: true
      description: "A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n"
    EvalJsonlFileContentSource:
      title: EvalJsonlFileContentSource
      required:
        - type
        - content
      type: object
      properties:
        content:
          type: array
          items:
            required:
              - item
            type: object
            properties:
              item:
                type: object
              sample:
                type: object
          description: The content of the jsonl file.
        type:
          enum:
            - file_content
          type: string
          description: The type of jsonl source. Always `file_content`.
          default: file_content
          x-stainless-const: true
    EvalJsonlFileIdSource:
      title: EvalJsonlFileIdSource
      required:
        - type
        - id
      type: object
      properties:
        id:
          type: string
          description: The identifier of the file.
        type:
          enum:
            - file_id
          type: string
          description: The type of jsonl source. Always `file_id`.
          default: file_id
          x-stainless-const: true
    EvalList:
      title: EvalList
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/Eval'
          description: "An array of eval objects.\n"
        first_id:
          type: string
          description: The identifier of the first eval in the data array.
        has_more:
          type: boolean
          description: Indicates whether there are more evals available.
        last_id:
          type: string
          description: The identifier of the last eval in the data array.
        object:
          enum:
            - list
          type: string
          description: "The type of this object. It is always set to \"list\".\n"
          default: list
          x-stainless-const: true
      description: "An object representing a list of evals.\n"
      x-oaiMeta:
        example: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"eval\",\n      \"id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n      \"data_source_config\": {\n        \"type\": \"custom\",\n        \"schema\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"item\": {\n              \"type\": \"object\",\n              \"properties\": {\n                \"input\": {\n                  \"type\": \"string\"\n                },\n                \"ground_truth\": {\n                  \"type\": \"string\"\n                }\n              },\n              \"required\": [\n                \"input\",\n                \"ground_truth\"\n              ]\n            }\n          },\n          \"required\": [\n            \"item\"\n          ]\n        }\n      },\n      \"testing_criteria\": [\n        {\n          \"name\": \"String check\",\n          \"id\": \"String check-2eaf2d8d-d649-4335-8148-9535a7ca73c2\",\n          \"type\": \"string_check\",\n          \"input\": \"{{item.input}}\",\n          \"reference\": \"{{item.ground_truth}}\",\n          \"operation\": \"eq\"\n        }\n      ],\n      \"name\": \"External Data Eval\",\n      \"created_at\": 1739314509,\n      \"metadata\": {},\n    }\n  ],\n  \"first_id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n  \"last_id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n  \"has_more\": true\n}\n"
        group: evals
        name: The eval list object
    EvalLogsDataSourceConfig:
      title: LogsDataSourceConfig
      required:
        - type
        - schema
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
        schema:
          type: object
          description: "The json schema for the run data source items.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n"
        type:
          enum:
            - logs
          type: string
          description: The type of data source. Always `logs`.
          default: logs
          x-stainless-const: true
      description: "A LogsDataSourceConfig which specifies the metadata property of your logs query.\nThis is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc.\nThe schema returned by this data source config is used to defined what variables are available in your evals.\n`item` and `sample` are both defined when using this data source config.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"logs\",\n  \"metadata\": {\n    \"language\": \"english\"\n  },\n  \"schema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"item\": {\n        \"type\": \"object\"\n      },\n      \"sample\": {\n        \"type\": \"object\"\n      }\n    },\n    \"required\": [\n      \"item\",\n      \"sample\"\n    }\n}\n"
        group: evals
        name: The logs data source object for evals
    EvalResponsesSource:
      title: EvalResponsesSource
      required:
        - type
      type: object
      properties:
        created_after:
          minimum: 0
          type: integer
          description: Only include items created after this timestamp (inclusive). This is a query parameter used to select responses.
          nullable: true
        created_before:
          minimum: 0
          type: integer
          description: Only include items created before this timestamp (inclusive). This is a query parameter used to select responses.
          nullable: true
        instructions_search:
          type: string
          description: Optional string to search the 'instructions' field. This is a query parameter used to select responses.
          nullable: true
        metadata:
          type: object
          description: Metadata filter for the responses. This is a query parameter used to select responses.
          nullable: true
        model:
          type: string
          description: The name of the model to find responses for. This is a query parameter used to select responses.
          nullable: true
        reasoning_effort:
          $ref: '#/components/schemas/ReasoningEffort'
        temperature:
          type: number
          description: Sampling temperature. This is a query parameter used to select responses.
          nullable: true
        tools:
          type: array
          items:
            type: string
          description: List of tool names. This is a query parameter used to select responses.
          nullable: true
        top_p:
          type: number
          description: Nucleus sampling parameter. This is a query parameter used to select responses.
          nullable: true
        type:
          enum:
            - responses
          type: string
          description: The type of run data source. Always `responses`.
        users:
          type: array
          items:
            type: string
          description: List of user identifiers. This is a query parameter used to select responses.
          nullable: true
      description: "A EvalResponsesSource object describing a run data source configuration.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"responses\",\n  \"model\": \"gpt-4o-mini-2024-07-18\",\n  \"temperature\": 0.7,\n  \"top_p\": 1.0,\n  \"users\": [\"user1\", \"user2\"],\n  \"tools\": [\"tool1\", \"tool2\"],\n  \"instructions_search\": \"You are a coding assistant\"\n}\n"
        group: eval runs
        name: The run data source object used to configure an individual run
    EvalRun:
      title: EvalRun
      required:
        - object
        - id
        - eval_id
        - status
        - model
        - name
        - created_at
        - report_url
        - result_counts
        - per_model_usage
        - per_testing_criteria_results
        - data_source
        - metadata
        - error
      type: object
      properties:
        created_at:
          type: integer
          description: Unix timestamp (in seconds) when the evaluation run was created.
        data_source:
          type: object
          anyOf:
            - $ref: '#/components/schemas/CreateEvalJsonlRunDataSource'
            - $ref: '#/components/schemas/CreateEvalCompletionsRunDataSource'
            - $ref: '#/components/schemas/CreateEvalResponsesRunDataSource'
          description: Information about the run's data source.
          discriminator:
            propertyName: type
        error:
          $ref: '#/components/schemas/EvalApiError'
        eval_id:
          type: string
          description: The identifier of the associated evaluation.
        id:
          type: string
          description: Unique identifier for the evaluation run.
        metadata:
          $ref: '#/components/schemas/Metadata'
        model:
          type: string
          description: 'The model that is evaluated, if applicable.'
        name:
          type: string
          description: The name of the evaluation run.
        object:
          enum:
            - eval.run
          type: string
          description: The type of the object. Always "eval.run".
          default: eval.run
          x-stainless-const: true
        per_model_usage:
          type: array
          items:
            required:
              - model_name
              - invocation_count
              - prompt_tokens
              - completion_tokens
              - total_tokens
              - cached_tokens
            type: object
            properties:
              cached_tokens:
                type: integer
                description: The number of tokens retrieved from cache.
              completion_tokens:
                type: integer
                description: The number of completion tokens generated.
              invocation_count:
                type: integer
                description: The number of invocations.
              model_name:
                type: string
                description: The name of the model.
                x-stainless-naming:
                  python:
                    property_name: run_model_name
              prompt_tokens:
                type: integer
                description: The number of prompt tokens used.
              total_tokens:
                type: integer
                description: The total number of tokens used.
          description: Usage statistics for each model during the evaluation run.
        per_testing_criteria_results:
          type: array
          items:
            required:
              - testing_criteria
              - passed
              - failed
            type: object
            properties:
              failed:
                type: integer
                description: Number of tests failed for this criteria.
              passed:
                type: integer
                description: Number of tests passed for this criteria.
              testing_criteria:
                type: string
                description: A description of the testing criteria.
          description: Results per testing criteria applied during the evaluation run.
        report_url:
          type: string
          description: The URL to the rendered evaluation run report on the UI dashboard.
        result_counts:
          required:
            - total
            - errored
            - failed
            - passed
          type: object
          properties:
            errored:
              type: integer
              description: Number of output items that resulted in an error.
            failed:
              type: integer
              description: Number of output items that failed to pass the evaluation.
            passed:
              type: integer
              description: Number of output items that passed the evaluation.
            total:
              type: integer
              description: Total number of executed output items.
          description: Counters summarizing the outcomes of the evaluation run.
        status:
          type: string
          description: The status of the evaluation run.
      description: "A schema representing an evaluation run.\n"
      x-oaiMeta:
        example: "{\n  \"object\": \"eval.run\",\n  \"id\": \"evalrun_67e57965b480819094274e3a32235e4c\",\n  \"eval_id\": \"eval_67e579652b548190aaa83ada4b125f47\",\n  \"report_url\": \"https://platform.openai.com/evaluations/eval_67e579652b548190aaa83ada4b125f47?run_id=evalrun_67e57965b480819094274e3a32235e4c\",\n  \"status\": \"queued\",\n  \"model\": \"gpt-4o-mini\",\n  \"name\": \"gpt-4o-mini\",\n  \"created_at\": 1743092069,\n  \"result_counts\": {\n    \"total\": 0,\n    \"errored\": 0,\n    \"failed\": 0,\n    \"passed\": 0\n  },\n  \"per_model_usage\": null,\n  \"per_testing_criteria_results\": null,\n  \"data_source\": {\n    \"type\": \"completions\",\n    \"source\": {\n      \"type\": \"file_content\",\n      \"content\": [\n        {\n          \"item\": {\n            \"input\": \"Tech Company Launches Advanced Artificial Intelligence Platform\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Central Bank Increases Interest Rates Amid Inflation Concerns\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"International Summit Addresses Climate Change Strategies\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Major Retailer Reports Record-Breaking Holiday Sales\",\n            \"ground_truth\": \"Business\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"National Team Qualifies for World Championship Finals\",\n            \"ground_truth\": \"Sports\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Stock Markets Rally After Positive Economic Data Released\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Global Manufacturer Announces Merger with Competitor\",\n            \"ground_truth\": \"Business\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Breakthrough in Renewable Energy Technology Unveiled\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"World Leaders Sign Historic Climate Agreement\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Professional Athlete Sets New Record in Championship Event\",\n            \"ground_truth\": \"Sports\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Financial Institutions Adapt to New Regulatory Requirements\",\n            \"ground_truth\": \"Business\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Tech Conference Showcases Advances in Artificial Intelligence\",\n            \"ground_truth\": \"Technology\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Global Markets Respond to Oil Price Fluctuations\",\n            \"ground_truth\": \"Markets\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"International Cooperation Strengthened Through New Treaty\",\n            \"ground_truth\": \"World\"\n          }\n        },\n        {\n          \"item\": {\n            \"input\": \"Sports League Announces Revised Schedule for Upcoming Season\",\n            \"ground_truth\": \"Sports\"\n          }\n        }\n      ]\n    },\n    \"input_messages\": {\n      \"type\": \"template\",\n      \"template\": [\n        {\n          \"type\": \"message\",\n          \"role\": \"developer\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\\n\\n# Steps\\n\\n1. Analyze the content of the news headline to understand its primary focus.\\n2. Extract the subject matter, identifying any key indicators or keywords.\\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\\n4. Ensure only one category is selected per headline.\\n\\n# Output Format\\n\\nRespond with the chosen category as a single word. For instance: \\\"Technology\\\", \\\"Markets\\\", \\\"World\\\", \\\"Business\\\", or \\\"Sports\\\".\\n\\n# Examples\\n\\n**Input**: \\\"Apple Unveils New iPhone Model, Featuring Advanced AI Features\\\"  \\n**Output**: \\\"Technology\\\"\\n\\n**Input**: \\\"Global Stocks Mixed as Investors Await Central Bank Decisions\\\"  \\n**Output**: \\\"Markets\\\"\\n\\n**Input**: \\\"War in Ukraine: Latest Updates on Negotiation Status\\\"  \\n**Output**: \\\"World\\\"\\n\\n**Input**: \\\"Microsoft in Talks to Acquire Gaming Company for $2 Billion\\\"  \\n**Output**: \\\"Business\\\"\\n\\n**Input**: \\\"Manchester United Secures Win in Premier League Football Match\\\"  \\n**Output**: \\\"Sports\\\" \\n\\n# Notes\\n\\n- If the headline appears to fit into more than one category, choose the most dominant theme.\\n- Keywords or phrases such as \\\"stocks\\\", \\\"company acquisition\\\", \\\"match\\\", or technological brands can be good indicators for classification.\\n\"\n          }\n        },\n        {\n          \"type\": \"message\",\n          \"role\": \"user\",\n          \"content\": {\n            \"type\": \"input_text\",\n            \"text\": \"{{item.input}}\"\n          }\n        }\n      ]\n    },\n    \"model\": \"gpt-4o-mini\",\n    \"sampling_params\": {\n      \"seed\": 42,\n      \"temperature\": 1.0,\n      \"top_p\": 1.0,\n      \"max_completions_tokens\": 2048\n    }\n  },\n  \"error\": null,\n  \"metadata\": {}\n}\n"
        group: evals
        name: The eval run object
    EvalRunList:
      title: EvalRunList
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/EvalRun'
          description: "An array of eval run objects.\n"
        first_id:
          type: string
          description: The identifier of the first eval run in the data array.
        has_more:
          type: boolean
          description: Indicates whether there are more evals available.
        last_id:
          type: string
          description: The identifier of the last eval run in the data array.
        object:
          enum:
            - list
          type: string
          description: "The type of this object. It is always set to \"list\".\n"
          default: list
          x-stainless-const: true
      description: "An object representing a list of runs for an evaluation.\n"
      x-oaiMeta:
        example: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"eval.run\",\n      \"id\": \"evalrun_67b7fbdad46c819092f6fe7a14189620\",\n      \"eval_id\": \"eval_67b7fa9a81a88190ab4aa417e397ea21\",\n      \"report_url\": \"https://platform.openai.com/evaluations/eval_67b7fa9a81a88190ab4aa417e397ea21?run_id=evalrun_67b7fbdad46c819092f6fe7a14189620\",\n      \"status\": \"completed\",\n      \"model\": \"o3-mini\",\n      \"name\": \"Academic Assistant\",\n      \"created_at\": 1740110812,\n      \"result_counts\": {\n        \"total\": 171,\n        \"errored\": 0,\n        \"failed\": 80,\n        \"passed\": 91\n      },\n      \"per_model_usage\": null,\n      \"per_testing_criteria_results\": [\n        {\n          \"testing_criteria\": \"String check grader\",\n          \"passed\": 91,\n          \"failed\": 80\n        }\n      ],\n      \"run_data_source\": {\n        \"type\": \"completions\",\n        \"template_messages\": [\n          {\n            \"type\": \"message\",\n            \"role\": \"system\",\n            \"content\": {\n              \"type\": \"input_text\",\n              \"text\": \"You are a helpful assistant.\"\n            }\n          },\n          {\n            \"type\": \"message\",\n            \"role\": \"user\",\n            \"content\": {\n              \"type\": \"input_text\",\n              \"text\": \"Hello, can you help me with my homework?\"\n            }\n          }\n        ],\n        \"datasource_reference\": null,\n        \"model\": \"o3-mini\",\n        \"max_completion_tokens\": null,\n        \"seed\": null,\n        \"temperature\": null,\n        \"top_p\": null\n      },\n      \"error\": null,\n      \"metadata\": {\"test\": \"synthetics\"}\n    }\n  ],\n  \"first_id\": \"evalrun_67abd54d60ec8190832b46859da808f7\",\n  \"last_id\": \"evalrun_67abd54d60ec8190832b46859da808f7\",\n  \"has_more\": false\n}\n"
        group: evals
        name: The eval run list object
    EvalRunOutputItem:
      title: EvalRunOutputItem
      required:
        - object
        - id
        - run_id
        - eval_id
        - created_at
        - status
        - datasource_item_id
        - datasource_item
        - results
        - sample
      type: object
      properties:
        created_at:
          type: integer
          description: Unix timestamp (in seconds) when the evaluation run was created.
        datasource_item:
          type: object
          description: Details of the input data source item.
        datasource_item_id:
          type: integer
          description: The identifier for the data source item.
        eval_id:
          type: string
          description: The identifier of the evaluation group.
        id:
          type: string
          description: Unique identifier for the evaluation run output item.
        object:
          enum:
            - eval.run.output_item
          type: string
          description: The type of the object. Always "eval.run.output_item".
          default: eval.run.output_item
          x-stainless-const: true
        results:
          type: array
          items:
            type: object
            description: A result object.
          description: A list of results from the evaluation run.
        run_id:
          type: string
          description: The identifier of the evaluation run associated with this output item.
        sample:
          required:
            - input
            - output
            - finish_reason
            - model
            - usage
            - error
            - temperature
            - max_completion_tokens
            - top_p
            - seed
          type: object
          properties:
            error:
              $ref: '#/components/schemas/EvalApiError'
            finish_reason:
              type: string
              description: The reason why the sample generation was finished.
            input:
              type: array
              items:
                required:
                  - role
                  - content
                type: object
                properties:
                  content:
                    type: string
                    description: The content of the message.
                  role:
                    type: string
                    description: 'The role of the message sender (e.g., system, user, developer).'
                description: An input message.
              description: An array of input messages.
            max_completion_tokens:
              type: integer
              description: The maximum number of tokens allowed for completion.
            model:
              type: string
              description: The model used for generating the sample.
            output:
              type: array
              items:
                type: object
                properties:
                  content:
                    type: string
                    description: The content of the message.
                  role:
                    type: string
                    description: 'The role of the message (e.g. "system", "assistant", "user").'
              description: An array of output messages.
            seed:
              type: integer
              description: The seed used for generating the sample.
            temperature:
              type: number
              description: The sampling temperature used.
            top_p:
              type: number
              description: The top_p value used for sampling.
            usage:
              required:
                - total_tokens
                - completion_tokens
                - prompt_tokens
                - cached_tokens
              type: object
              properties:
                cached_tokens:
                  type: integer
                  description: The number of tokens retrieved from cache.
                completion_tokens:
                  type: integer
                  description: The number of completion tokens generated.
                prompt_tokens:
                  type: integer
                  description: The number of prompt tokens used.
                total_tokens:
                  type: integer
                  description: The total number of tokens used.
              description: Token usage details for the sample.
          description: A sample containing the input and output of the evaluation run.
        status:
          type: string
          description: The status of the evaluation run.
      description: "A schema representing an evaluation run output item.\n"
      x-oaiMeta:
        example: "{\n  \"object\": \"eval.run.output_item\",\n  \"id\": \"outputitem_67abd55eb6548190bb580745d5644a33\",\n  \"run_id\": \"evalrun_67abd54d60ec8190832b46859da808f7\",\n  \"eval_id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n  \"created_at\": 1739314509,\n  \"status\": \"pass\",\n  \"datasource_item_id\": 137,\n  \"datasource_item\": {\n      \"teacher\": \"To grade essays, I only check for style, content, and grammar.\",\n      \"student\": \"I am a student who is trying to write the best essay.\"\n  },\n  \"results\": [\n    {\n      \"name\": \"String Check Grader\",\n      \"type\": \"string-check-grader\",\n      \"score\": 1.0,\n      \"passed\": true,\n    }\n  ],\n  \"sample\": {\n    \"input\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are an evaluator bot...\"\n      },\n      {\n        \"role\": \"user\",\n        \"content\": \"You are assessing...\"\n      }\n    ],\n    \"output\": [\n      {\n        \"role\": \"assistant\",\n        \"content\": \"The rubric is not clear nor concise.\"\n      }\n    ],\n    \"finish_reason\": \"stop\",\n    \"model\": \"gpt-4o-2024-08-06\",\n    \"usage\": {\n      \"total_tokens\": 521,\n      \"completion_tokens\": 2,\n      \"prompt_tokens\": 519,\n      \"cached_tokens\": 0\n    },\n    \"error\": null,\n    \"temperature\": 1.0,\n    \"max_completion_tokens\": 2048,\n    \"top_p\": 1.0,\n    \"seed\": 42\n  }\n}\n"
        group: evals
        name: The eval run output item object
    EvalRunOutputItemList:
      title: EvalRunOutputItemList
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/EvalRunOutputItem'
          description: "An array of eval run output item objects.\n"
        first_id:
          type: string
          description: The identifier of the first eval run output item in the data array.
        has_more:
          type: boolean
          description: Indicates whether there are more eval run output items available.
        last_id:
          type: string
          description: The identifier of the last eval run output item in the data array.
        object:
          enum:
            - list
          type: string
          description: "The type of this object. It is always set to \"list\".\n"
          default: list
          x-stainless-const: true
      description: "An object representing a list of output items for an evaluation run.\n"
      x-oaiMeta:
        example: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"eval.run.output_item\",\n      \"id\": \"outputitem_67abd55eb6548190bb580745d5644a33\",\n      \"run_id\": \"evalrun_67abd54d60ec8190832b46859da808f7\",\n      \"eval_id\": \"eval_67abd54d9b0081909a86353f6fb9317a\",\n      \"created_at\": 1739314509,\n      \"status\": \"pass\",\n      \"datasource_item_id\": 137,\n      \"datasource_item\": {\n          \"teacher\": \"To grade essays, I only check for style, content, and grammar.\",\n          \"student\": \"I am a student who is trying to write the best essay.\"\n      },\n      \"results\": [\n        {\n          \"name\": \"String Check Grader\",\n          \"type\": \"string-check-grader\",\n          \"score\": 1.0,\n          \"passed\": true,\n        }\n      ],\n      \"sample\": {\n        \"input\": [\n          {\n            \"role\": \"system\",\n            \"content\": \"You are an evaluator bot...\"\n          },\n          {\n            \"role\": \"user\",\n            \"content\": \"You are assessing...\"\n          }\n        ],\n        \"output\": [\n          {\n            \"role\": \"assistant\",\n            \"content\": \"The rubric is not clear nor concise.\"\n          }\n        ],\n        \"finish_reason\": \"stop\",\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"usage\": {\n          \"total_tokens\": 521,\n          \"completion_tokens\": 2,\n          \"prompt_tokens\": 519,\n          \"cached_tokens\": 0\n        },\n        \"error\": null,\n        \"temperature\": 1.0,\n        \"max_completion_tokens\": 2048,\n        \"top_p\": 1.0,\n        \"seed\": 42\n      }\n    },\n  ],\n  \"first_id\": \"outputitem_67abd55eb6548190bb580745d5644a33\",\n  \"last_id\": \"outputitem_67abd55eb6548190bb580745d5644a33\",\n  \"has_more\": false\n}\n"
        group: evals
        name: The eval run output item list object
    EvalStoredCompletionsDataSourceConfig:
      title: StoredCompletionsDataSourceConfig
      required:
        - type
        - schema
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
        schema:
          type: object
          description: "The json schema for the run data source items.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n"
        type:
          enum:
            - stored_completions
          type: string
          description: The type of data source. Always `stored_completions`.
          default: stored_completions
          x-stainless-const: true
      description: "Deprecated in favor of LogsDataSourceConfig.\n"
      deprecated: true
      x-oaiMeta:
        example: "{\n  \"type\": \"stored_completions\",\n  \"metadata\": {\n    \"language\": \"english\"\n  },\n  \"schema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"item\": {\n        \"type\": \"object\"\n      },\n      \"sample\": {\n        \"type\": \"object\"\n      }\n    },\n    \"required\": [\n      \"item\",\n      \"sample\"\n    }\n}\n"
        group: evals
        name: The stored completions data source object for evals
    EvalStoredCompletionsSource:
      title: StoredCompletionsRunDataSource
      required:
        - type
      type: object
      properties:
        created_after:
          type: integer
          description: An optional Unix timestamp to filter items created after this time.
          nullable: true
        created_before:
          type: integer
          description: An optional Unix timestamp to filter items created before this time.
          nullable: true
        limit:
          type: integer
          description: An optional maximum number of items to return.
          nullable: true
        metadata:
          $ref: '#/components/schemas/Metadata'
        model:
          type: string
          description: 'An optional model to filter by (e.g., ''gpt-4o'').'
          nullable: true
        type:
          enum:
            - stored_completions
          type: string
          description: The type of source. Always `stored_completions`.
          default: stored_completions
          x-stainless-const: true
      description: "A StoredCompletionsRunDataSource configuration describing a set of filters\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"stored_completions\",\n  \"model\": \"gpt-4o\",\n  \"created_after\": 1668124800,\n  \"created_before\": 1668124900,\n  \"limit\": 100,\n  \"metadata\": {}\n}\n"
        group: eval runs
        name: The stored completions data source object used to configure an individual run
    FileCitationBody:
      title: File citation
      required:
        - type
        - file_id
        - index
        - filename
      type: object
      properties:
        file_id:
          type: string
          description: The ID of the file.
        filename:
          type: string
          description: The filename of the file cited.
        index:
          type: integer
          description: The index of the file in the list of files.
        type:
          enum:
            - file_citation
          type: string
          description: The type of the file citation. Always `file_citation`.
          default: file_citation
          x-stainless-const: true
      description: A citation to a file.
    FileCitationBody-2:
      title: File citation
      required:
        - type
        - file_id
        - index
        - filename
      type: object
      properties:
        file_id:
          type: string
          description: The ID of the file.
        filename:
          type: string
          description: The filename of the file cited.
        index:
          type: integer
          description: The index of the file in the list of files.
        type:
          enum:
            - file_citation
          type: string
          description: The type of the file citation. Always `file_citation`.
          default: file_citation
          x-stainless-const: true
    FileExpirationAfter:
      title: File expiration policy
      required:
        - anchor
        - seconds
      type: object
      properties:
        anchor:
          enum:
            - created_at
          type: string
          description: 'Anchor timestamp after which the expiration policy applies. Supported anchors: `created_at`.'
          x-stainless-const: true
        seconds:
          maximum: 2592000
          minimum: 3600
          type: integer
          description: The number of seconds after the anchor time that the file will expire. Must be between 3600 (1 hour) and 2592000 (30 days).
      description: 'The expiration policy for a file. By default, files with `purpose=batch` expire after 30 days and all other files are persisted until they are manually deleted.'
    FilePath:
      title: File path
      required:
        - type
        - file_id
        - index
      type: object
      properties:
        file_id:
          type: string
          description: "The ID of the file.\n"
        index:
          type: integer
          description: "The index of the file in the list of files.\n"
        type:
          enum:
            - file_path
          type: string
          description: "The type of the file path. Always `file_path`.\n"
          x-stainless-const: true
      description: "A path to a file.\n"
    FilePurpose:
      enum:
        - assistants
        - batch
        - fine-tune
        - vision
        - user_data
        - evals
      type: string
      description: "The intended purpose of the uploaded file. One of: - `assistants`: Used in the Assistants API - `batch`: Used in the Batch API - `fine-tune`: Used for fine-tuning - `vision`: Images used for vision fine-tuning - `user_data`: Flexible file type for any purpose - `evals`: Used for eval data sets\n"
    FileSearchRanker:
      enum:
        - auto
        - default_2024_08_21
      type: string
      description: The ranker to use for the file search. If not specified will use the `auto` ranker.
    FileSearchRankingOptions:
      title: File search tool call ranking options
      required:
        - score_threshold
      type: object
      properties:
        ranker:
          $ref: '#/components/schemas/FileSearchRanker'
        score_threshold:
          maximum: 1
          minimum: 0
          type: number
          description: The score threshold for the file search. All values must be a floating point number between 0 and 1.
      description: "The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n"
    FileSearchTool:
      title: File search
      required:
        - type
        - vector_store_ids
      type: object
      properties:
        filters:
          type: 'null'
          nullable: true
        max_num_results:
          type: integer
          description: The maximum number of results to return. This number should be between 1 and 50 inclusive.
        ranking_options:
          $ref: '#/components/schemas/RankingOptions'
        type:
          enum:
            - file_search
          type: string
          description: The type of the file search tool. Always `file_search`.
          default: file_search
          x-stainless-const: true
        vector_store_ids:
          type: array
          items:
            type: string
          description: The IDs of the vector stores to search.
      description: 'A tool that searches for relevant content from uploaded files. Learn more about the [file search tool](https://platform.openai.com/docs/guides/tools-file-search).'
    FileSearchToolCall:
      title: File search tool call
      required:
        - id
        - type
        - status
        - queries
      type: object
      properties:
        id:
          type: string
          description: "The unique ID of the file search tool call.\n"
        queries:
          type: array
          items:
            type: string
          description: "The queries used to search for files.\n"
        results:
          type: array
          items:
            type: object
            properties:
              attributes:
                $ref: '#/components/schemas/VectorStoreFileAttributes'
              file_id:
                type: string
                description: "The unique ID of the file.\n"
              filename:
                type: string
                description: "The name of the file.\n"
              score:
                type: number
                description: "The relevance score of the file - a value between 0 and 1.\n"
                format: float
              text:
                type: string
                description: "The text that was retrieved from the file.\n"
          description: "The results of the file search tool call.\n"
          nullable: true
        status:
          enum:
            - in_progress
            - searching
            - completed
            - incomplete
            - failed
          type: string
          description: "The status of the file search tool call. One of `in_progress`, \n`searching`, `incomplete` or `failed`,\n"
        type:
          enum:
            - file_search_call
          type: string
          description: "The type of the file search tool call. Always `file_search_call`.\n"
          x-stainless-const: true
      description: "The results of a file search tool call. See the \n[file search guide](https://platform.openai.com/docs/guides/tools-file-search) for more information.\n"
    Filters:
      anyOf:
        - $ref: '#/components/schemas/ComparisonFilter'
        - $ref: '#/components/schemas/CompoundFilter'
    FineTuneChatCompletionRequestAssistantMessage:
      required:
        - role
      allOf:
        - title: Assistant message
          type: object
          properties:
            weight:
              enum:
                - 0
                - 1
              type: integer
              description: Controls whether the assistant message is trained against (0 or 1)
        - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage'
    FineTuneChatRequestInput:
      type: object
      properties:
        functions:
          maxItems: 128
          minItems: 1
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionFunctions'
          description: A list of functions the model may generate JSON inputs for.
          deprecated: true
        messages:
          minItems: 1
          type: array
          items:
            anyOf:
              - $ref: '#/components/schemas/ChatCompletionRequestSystemMessage'
              - $ref: '#/components/schemas/ChatCompletionRequestUserMessage'
              - $ref: '#/components/schemas/FineTuneChatCompletionRequestAssistantMessage'
              - $ref: '#/components/schemas/ChatCompletionRequestToolMessage'
              - $ref: '#/components/schemas/ChatCompletionRequestFunctionMessage'
        parallel_tool_calls:
          $ref: '#/components/schemas/ParallelToolCalls'
        tools:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionTool'
          description: A list of tools the model may generate JSON inputs for.
      description: "The per-line training example of a fine-tuning input file for chat models using the supervised method.\nInput messages may contain text or image content only. Audio and file input messages\nare not currently supported for fine-tuning.\n"
      x-oaiMeta:
        example: "{\n  \"messages\": [\n    { \"role\": \"user\", \"content\": \"What is the weather in San Francisco?\" },\n    {\n      \"role\": \"assistant\",\n      \"tool_calls\": [\n        {\n          \"id\": \"call_id\",\n          \"type\": \"function\",\n          \"function\": {\n            \"name\": \"get_current_weather\",\n            \"arguments\": \"{\\\"location\\\": \\\"San Francisco, USA\\\", \\\"format\\\": \\\"celsius\\\"}\"\n          }\n        }\n      ]\n    }\n  ],\n  \"parallel_tool_calls\": false,\n  \"tools\": [\n    {\n      \"type\": \"function\",\n      \"function\": {\n        \"name\": \"get_current_weather\",\n        \"description\": \"Get the current weather\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"location\": {\n                \"type\": \"string\",\n                \"description\": \"The city and country, eg. San Francisco, USA\"\n            },\n            \"format\": { \"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"] }\n          },\n          \"required\": [\"location\", \"format\"]\n        }\n      }\n    }\n  ]\n}\n"
        name: Training format for chat models using the supervised method
    FineTuneDPOHyperparameters:
      type: object
      properties:
        batch_size:
          anyOf:
            - enum:
                - auto
              type: string
              x-stainless-const: true
            - maximum: 256
              minimum: 1
              type: integer
          description: "Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n"
          default: auto
        beta:
          anyOf:
            - enum:
                - auto
              type: string
              x-stainless-const: true
            - maximum: 2
              minimum: 0
              exclusiveMinimum: true
              type: number
          description: "The beta value for the DPO method. A higher beta value will increase the weight of the penalty between the policy and reference model.\n"
        learning_rate_multiplier:
          anyOf:
            - enum:
                - auto
              type: string
              x-stainless-const: true
            - minimum: 0
              exclusiveMinimum: true
              type: number
          description: "Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n"
        n_epochs:
          anyOf:
            - enum:
                - auto
              type: string
              x-stainless-const: true
            - maximum: 50
              minimum: 1
              type: integer
          description: "The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n"
          default: auto
      description: The hyperparameters used for the DPO fine-tuning job.
    FineTuneDPOMethod:
      type: object
      properties:
        hyperparameters:
          $ref: '#/components/schemas/FineTuneDPOHyperparameters'
      description: Configuration for the DPO fine-tuning method.
    FineTuneMethod:
      required:
        - type
      type: object
      properties:
        dpo:
          $ref: '#/components/schemas/FineTuneDPOMethod'
        reinforcement:
          $ref: '#/components/schemas/FineTuneReinforcementMethod'
        supervised:
          $ref: '#/components/schemas/FineTuneSupervisedMethod'
        type:
          enum:
            - supervised
            - dpo
            - reinforcement
          type: string
          description: 'The type of method. Is either `supervised`, `dpo`, or `reinforcement`.'
      description: The method used for fine-tuning.
    FineTunePreferenceRequestInput:
      type: object
      properties:
        input:
          type: object
          properties:
            messages:
              minItems: 1
              type: array
              items:
                anyOf:
                  - $ref: '#/components/schemas/ChatCompletionRequestSystemMessage'
                  - $ref: '#/components/schemas/ChatCompletionRequestUserMessage'
                  - $ref: '#/components/schemas/FineTuneChatCompletionRequestAssistantMessage'
                  - $ref: '#/components/schemas/ChatCompletionRequestToolMessage'
                  - $ref: '#/components/schemas/ChatCompletionRequestFunctionMessage'
            parallel_tool_calls:
              $ref: '#/components/schemas/ParallelToolCalls'
            tools:
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionTool'
              description: A list of tools the model may generate JSON inputs for.
        non_preferred_output:
          maxItems: 1
          type: array
          items:
            anyOf:
              - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage'
          description: The non-preferred completion message for the output.
        preferred_output:
          maxItems: 1
          type: array
          items:
            anyOf:
              - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage'
          description: The preferred completion message for the output.
      description: "The per-line training example of a fine-tuning input file for chat models using the dpo method.\nInput messages may contain text or image content only. Audio and file input messages\nare not currently supported for fine-tuning.\n"
      x-oaiMeta:
        example: "{\n  \"input\": {\n    \"messages\": [\n      { \"role\": \"user\", \"content\": \"What is the weather in San Francisco?\" }\n    ]\n  },\n  \"preferred_output\": [\n    {\n      \"role\": \"assistant\",\n      \"content\": \"The weather in San Francisco is 70 degrees Fahrenheit.\"\n    }\n  ],\n  \"non_preferred_output\": [\n    {\n      \"role\": \"assistant\",\n      \"content\": \"The weather in San Francisco is 21 degrees Celsius.\"\n    }\n  ]\n}\n"
        name: Training format for chat models using the preference method
    FineTuneReinforcementHyperparameters:
      type: object
      properties:
        batch_size:
          anyOf:
            - enum:
                - auto
              type: string
              x-stainless-const: true
            - maximum: 256
              minimum: 1
              type: integer
          description: "Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n"
          default: auto
        compute_multiplier:
          anyOf:
            - enum:
                - auto
              type: string
              x-stainless-const: true
            - maximum: 10
              minimum: 0.000010000000000000001
              exclusiveMinimum: true
              type: number
          description: "Multiplier on amount of compute used for exploring search space during training.\n"
        eval_interval:
          anyOf:
            - enum:
                - auto
              type: string
              x-stainless-const: true
            - minimum: 1
              type: integer
          description: "The number of training steps between evaluation runs.\n"
          default: auto
        eval_samples:
          anyOf:
            - enum:
                - auto
              type: string
              x-stainless-const: true
            - minimum: 1
              type: integer
          description: "Number of evaluation samples to generate per training step.\n"
          default: auto
        learning_rate_multiplier:
          anyOf:
            - enum:
                - auto
              type: string
              x-stainless-const: true
            - minimum: 0
              exclusiveMinimum: true
              type: number
          description: "Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n"
        n_epochs:
          anyOf:
            - enum:
                - auto
              type: string
              x-stainless-const: true
            - maximum: 50
              minimum: 1
              type: integer
          description: "The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n"
          default: auto
        reasoning_effort:
          enum:
            - default
            - low
            - medium
            - high
          type: string
          description: "Level of reasoning effort.\n"
          default: default
      description: The hyperparameters used for the reinforcement fine-tuning job.
    FineTuneReinforcementMethod:
      required:
        - grader
      type: object
      properties:
        grader:
          type: object
          anyOf:
            - $ref: '#/components/schemas/GraderStringCheck'
            - $ref: '#/components/schemas/GraderTextSimilarity'
            - $ref: '#/components/schemas/GraderPython'
            - $ref: '#/components/schemas/GraderScoreModel'
            - $ref: '#/components/schemas/GraderMulti'
          description: The grader used for the fine-tuning job.
        hyperparameters:
          $ref: '#/components/schemas/FineTuneReinforcementHyperparameters'
      description: Configuration for the reinforcement fine-tuning method.
    FineTuneReinforcementRequestInput:
      required:
        - messages
      type: object
      properties:
        messages:
          minItems: 1
          type: array
          items:
            anyOf:
              - $ref: '#/components/schemas/ChatCompletionRequestDeveloperMessage'
              - $ref: '#/components/schemas/ChatCompletionRequestUserMessage'
              - $ref: '#/components/schemas/FineTuneChatCompletionRequestAssistantMessage'
              - $ref: '#/components/schemas/ChatCompletionRequestToolMessage'
        tools:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionTool'
          description: A list of tools the model may generate JSON inputs for.
      description: "Per-line training example for reinforcement fine-tuning. Note that `messages` and `tools` are the only reserved keywords.\nAny other arbitrary key-value data can be included on training datapoints and will be available to reference during grading under the `{{ item.XXX }}` template variable.\nInput messages may contain text or image content only. Audio and file input messages\nare not currently supported for fine-tuning.\n"
      x-oaiMeta:
        example: "{\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"Your task is to take a chemical in SMILES format and predict the number of hydrobond bond donors and acceptors according to Lipinkski's rule. CCN(CC)CCC(=O)c1sc(N)nc1C\"\n    },\n  ],\n  # Any other JSON data can be inserted into an example and referenced during RFT grading\n  \"reference_answer\": {\n    \"donor_bond_counts\": 5,\n    \"acceptor_bond_counts\": 7\n  }\n}\n"
        name: Training format for reasoning models using the reinforcement method
    FineTuneSupervisedHyperparameters:
      type: object
      properties:
        batch_size:
          anyOf:
            - enum:
                - auto
              type: string
              x-stainless-const: true
            - maximum: 256
              minimum: 1
              type: integer
          description: "Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n"
          default: auto
        learning_rate_multiplier:
          anyOf:
            - enum:
                - auto
              type: string
              x-stainless-const: true
            - minimum: 0
              exclusiveMinimum: true
              type: number
          description: "Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n"
        n_epochs:
          anyOf:
            - enum:
                - auto
              type: string
              x-stainless-const: true
            - maximum: 50
              minimum: 1
              type: integer
          description: "The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n"
          default: auto
      description: The hyperparameters used for the fine-tuning job.
    FineTuneSupervisedMethod:
      type: object
      properties:
        hyperparameters:
          $ref: '#/components/schemas/FineTuneSupervisedHyperparameters'
      description: Configuration for the supervised fine-tuning method.
    FineTuningCheckpointPermission:
      title: FineTuningCheckpointPermission
      required:
        - created_at
        - id
        - object
        - project_id
      type: object
      properties:
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the permission was created.
        id:
          type: string
          description: 'The permission identifier, which can be referenced in the API endpoints.'
        object:
          enum:
            - checkpoint.permission
          type: string
          description: 'The object type, which is always "checkpoint.permission".'
          x-stainless-const: true
        project_id:
          type: string
          description: The project identifier that the permission is for.
      description: "The `checkpoint.permission` object represents a permission for a fine-tuned model checkpoint.\n"
      x-oaiMeta:
        example: "{\n  \"object\": \"checkpoint.permission\",\n  \"id\": \"cp_zc4Q7MP6XxulcVzj4MZdwsAB\",\n  \"created_at\": 1712211699,\n  \"project_id\": \"proj_abGMw1llN8IrBb6SvvY5A1iH\"\n}\n"
        name: The fine-tuned model checkpoint permission object
    FineTuningIntegration:
      title: Fine-Tuning Job Integration
      required:
        - type
        - wandb
      type: object
      properties:
        type:
          enum:
            - wandb
          type: string
          description: The type of the integration being enabled for the fine-tuning job
          x-stainless-const: true
        wandb:
          required:
            - project
          type: object
          properties:
            entity:
              type: string
              description: "The entity to use for the run. This allows you to set the team or username of the WandB user that you would\nlike associated with the run. If not set, the default entity for the registered WandB API key is used.\n"
              nullable: true
            name:
              type: string
              description: "A display name to set for the run. If not set, we will use the Job ID as the name.\n"
              nullable: true
            project:
              type: string
              description: "The name of the project that the new run will be created under.\n"
              example: my-wandb-project
            tags:
              type: array
              items:
                type: string
                example: custom-tag
              description: "A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some\ndefault tags are generated by OpenAI: \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n"
          description: "The settings for your integration with Weights and Biases. This payload specifies the project that\nmetrics will be sent to. Optionally, you can set an explicit display name for your run, add tags\nto your run, and set a default entity (team, username, etc) to be associated with your run.\n"
    FineTuningJob:
      title: FineTuningJob
      required:
        - created_at
        - error
        - finished_at
        - fine_tuned_model
        - hyperparameters
        - id
        - model
        - object
        - organization_id
        - result_files
        - status
        - trained_tokens
        - training_file
        - validation_file
        - seed
      type: object
      properties:
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the fine-tuning job was created.
        error:
          required:
            - code
            - message
            - param
          type: object
          properties:
            code:
              type: string
              description: A machine-readable error code.
            message:
              type: string
              description: A human-readable error message.
            param:
              type: string
              description: 'The parameter that was invalid, usually `training_file` or `validation_file`. This field will be null if the failure was not parameter-specific.'
              nullable: true
          description: 'For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.'
          nullable: true
        estimated_finish:
          type: integer
          description: The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running.
          nullable: true
        fine_tuned_model:
          type: string
          description: The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.
          nullable: true
        finished_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.
          nullable: true
        hyperparameters:
          type: object
          properties:
            batch_size:
              anyOf:
                - title: Auto
                  enum:
                    - auto
                  type: string
                  x-stainless-const: true
                - title: Manual
                  maximum: 256
                  minimum: 1
                  type: integer
              description: "Number of examples in each batch. A larger batch size means that model parameters\nare updated less frequently, but with lower variance.\n"
              nullable: true
            learning_rate_multiplier:
              anyOf:
                - title: Auto
                  enum:
                    - auto
                  type: string
                  x-stainless-const: true
                - minimum: 0
                  exclusiveMinimum: true
                  type: number
              description: "Scaling factor for the learning rate. A smaller learning rate may be useful to avoid\noverfitting.\n"
            n_epochs:
              anyOf:
                - title: Auto
                  enum:
                    - auto
                  type: string
                  x-stainless-const: true
                - maximum: 50
                  minimum: 1
                  type: integer
              description: "The number of epochs to train the model for. An epoch refers to one full cycle\nthrough the training dataset.\n"
              default: auto
          description: The hyperparameters used for the fine-tuning job. This value will only be returned when running `supervised` jobs.
        id:
          type: string
          description: 'The object identifier, which can be referenced in the API endpoints.'
        integrations:
          maxItems: 5
          type: array
          items:
            anyOf:
              - $ref: '#/components/schemas/FineTuningIntegration'
            discriminator:
              propertyName: type
          description: A list of integrations to enable for this fine-tuning job.
          nullable: true
        metadata:
          $ref: '#/components/schemas/Metadata'
        method:
          $ref: '#/components/schemas/FineTuneMethod'
        model:
          type: string
          description: The base model that is being fine-tuned.
        object:
          enum:
            - fine_tuning.job
          type: string
          description: 'The object type, which is always "fine_tuning.job".'
          x-stainless-const: true
        organization_id:
          type: string
          description: The organization that owns the fine-tuning job.
        result_files:
          type: array
          items:
            type: string
            example: file-abc123
          description: 'The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).'
        seed:
          type: integer
          description: The seed used for the fine-tuning job.
        status:
          enum:
            - validating_files
            - queued
            - running
            - succeeded
            - failed
            - cancelled
          type: string
          description: 'The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.'
        trained_tokens:
          type: integer
          description: The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.
          nullable: true
        training_file:
          type: string
          description: 'The file ID used for training. You can retrieve the training data with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).'
        validation_file:
          type: string
          description: 'The file ID used for validation. You can retrieve the validation results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).'
          nullable: true
      description: "The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.\n"
      x-oaiMeta:
        example: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"davinci-002\",\n  \"created_at\": 1692661014,\n  \"finished_at\": 1692661190,\n  \"fine_tuned_model\": \"ft:davinci-002:my-org:custom_suffix:7q8mpxmy\",\n  \"organization_id\": \"org-123\",\n  \"result_files\": [\n      \"file-abc123\"\n  ],\n  \"status\": \"succeeded\",\n  \"validation_file\": null,\n  \"training_file\": \"file-abc123\",\n  \"hyperparameters\": {\n      \"n_epochs\": 4,\n      \"batch_size\": 1,\n      \"learning_rate_multiplier\": 1.0\n  },\n  \"trained_tokens\": 5768,\n  \"integrations\": [],\n  \"seed\": 0,\n  \"estimated_finish\": 0,\n  \"method\": {\n    \"type\": \"supervised\",\n    \"supervised\": {\n      \"hyperparameters\": {\n        \"n_epochs\": 4,\n        \"batch_size\": 1,\n        \"learning_rate_multiplier\": 1.0\n      }\n    }\n  },\n  \"metadata\": {\n    \"key\": \"value\"\n  }\n}\n"
        name: The fine-tuning job object
    FineTuningJobCheckpoint:
      title: FineTuningJobCheckpoint
      required:
        - created_at
        - fine_tuning_job_id
        - fine_tuned_model_checkpoint
        - id
        - metrics
        - object
        - step_number
      type: object
      properties:
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the checkpoint was created.
        fine_tuned_model_checkpoint:
          type: string
          description: The name of the fine-tuned checkpoint model that is created.
        fine_tuning_job_id:
          type: string
          description: The name of the fine-tuning job that this checkpoint was created from.
        id:
          type: string
          description: 'The checkpoint identifier, which can be referenced in the API endpoints.'
        metrics:
          type: object
          properties:
            full_valid_loss:
              type: number
            full_valid_mean_token_accuracy:
              type: number
            step:
              type: number
            train_loss:
              type: number
            train_mean_token_accuracy:
              type: number
            valid_loss:
              type: number
            valid_mean_token_accuracy:
              type: number
          description: Metrics at the step number during the fine-tuning job.
        object:
          enum:
            - fine_tuning.job.checkpoint
          type: string
          description: 'The object type, which is always "fine_tuning.job.checkpoint".'
          x-stainless-const: true
        step_number:
          type: integer
          description: The step number that the checkpoint was created at.
      description: "The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.\n"
      x-oaiMeta:
        example: "{\n  \"object\": \"fine_tuning.job.checkpoint\",\n  \"id\": \"ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P\",\n  \"created_at\": 1712211699,\n  \"fine_tuned_model_checkpoint\": \"ft:gpt-4o-mini-2024-07-18:my-org:custom_suffix:9ABel2dg:ckpt-step-88\",\n  \"fine_tuning_job_id\": \"ftjob-fpbNQ3H1GrMehXRf8cO97xTN\",\n  \"metrics\": {\n    \"step\": 88,\n    \"train_loss\": 0.478,\n    \"train_mean_token_accuracy\": 0.924,\n    \"valid_loss\": 10.112,\n    \"valid_mean_token_accuracy\": 0.145,\n    \"full_valid_loss\": 0.567,\n    \"full_valid_mean_token_accuracy\": 0.944\n  },\n  \"step_number\": 88\n}\n"
        name: The fine-tuning job checkpoint object
    FineTuningJobEvent:
      required:
        - id
        - object
        - created_at
        - level
        - message
      type: object
      properties:
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the fine-tuning job was created.
        data:
          type: object
          description: The data associated with the event.
        id:
          type: string
          description: The object identifier.
        level:
          enum:
            - info
            - warn
            - error
          type: string
          description: The log level of the event.
        message:
          type: string
          description: The message of the event.
        object:
          enum:
            - fine_tuning.job.event
          type: string
          description: 'The object type, which is always "fine_tuning.job.event".'
          x-stainless-const: true
        type:
          enum:
            - message
            - metrics
          type: string
          description: The type of event.
      description: Fine-tuning job event object
      x-oaiMeta:
        example: "{\n  \"object\": \"fine_tuning.job.event\",\n  \"id\": \"ftevent-abc123\"\n  \"created_at\": 1677610602,\n  \"level\": \"info\",\n  \"message\": \"Created fine-tuning job\",\n  \"data\": {},\n  \"type\": \"message\"\n}\n"
        name: The fine-tuning job event object
    FunctionCallOutputItemParam:
      title: Function tool call output
      required:
        - call_id
        - type
        - output
      type: object
      properties:
        call_id:
          maxLength: 64
          minLength: 1
          type: string
          description: The unique ID of the function tool call generated by the model.
        id:
          type: string
          description: The unique ID of the function tool call output. Populated when this item is returned via API.
          nullable: true
        output:
          maxLength: 10485760
          type: string
          description: A JSON string of the output of the function tool call.
        status:
          enum:
            - in_progress
            - completed
            - incomplete
          type: string
          description: 'The status of the item. One of `in_progress`, `completed`, or `incomplete`. Populated when items are returned via API.'
          nullable: true
        type:
          enum:
            - function_call_output
          type: string
          description: The type of the function tool call output. Always `function_call_output`.
          default: function_call_output
          x-stainless-const: true
      description: The output of a function tool call.
    FunctionObject:
      required:
        - name
      type: object
      properties:
        description:
          type: string
          description: 'A description of what the function does, used by the model to choose when and how to call the function.'
        name:
          type: string
          description: 'The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'
        parameters:
          $ref: '#/components/schemas/FunctionParameters'
        strict:
          type: boolean
          description: 'Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).'
          default: false
          nullable: true
    FunctionParameters:
      type: object
      description: "The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format. \n\nOmitting `parameters` defines a function with an empty parameter list."
    FunctionTool:
      title: Function
      required:
        - type
        - name
        - strict
        - parameters
      type: object
      properties:
        description:
          type: string
          description: A description of the function. Used by the model to determine whether or not to call the function.
          nullable: true
        name:
          type: string
          description: The name of the function to call.
        parameters:
          type: object
          additionalProperties: { }
          description: A JSON schema object describing the parameters of the function.
          nullable: true
        strict:
          type: boolean
          description: Whether to enforce strict parameter validation. Default `true`.
          nullable: true
        type:
          enum:
            - function
          type: string
          description: The type of the function tool. Always `function`.
          default: function
          x-stainless-const: true
      description: 'Defines a function in your own code the model can choose to call. Learn more about [function calling](https://platform.openai.com/docs/guides/function-calling).'
    FunctionToolCall:
      title: Function tool call
      required:
        - type
        - call_id
        - name
        - arguments
      type: object
      properties:
        arguments:
          type: string
          description: "A JSON string of the arguments to pass to the function.\n"
        call_id:
          type: string
          description: "The unique ID of the function tool call generated by the model.\n"
        id:
          type: string
          description: "The unique ID of the function tool call.\n"
        name:
          type: string
          description: "The name of the function to run.\n"
        status:
          enum:
            - in_progress
            - completed
            - incomplete
          type: string
          description: "The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n"
        type:
          enum:
            - function_call
          type: string
          description: "The type of the function tool call. Always `function_call`.\n"
          x-stainless-const: true
      description: "A tool call to run a function. See the \n[function calling guide](https://platform.openai.com/docs/guides/function-calling) for more information.\n"
    FunctionToolCallOutput:
      title: Function tool call output
      required:
        - type
        - call_id
        - output
      type: object
      properties:
        call_id:
          type: string
          description: "The unique ID of the function tool call generated by the model.\n"
        id:
          type: string
          description: "The unique ID of the function tool call output. Populated when this item\nis returned via API.\n"
        output:
          type: string
          description: "A JSON string of the output of the function tool call.\n"
        status:
          enum:
            - in_progress
            - completed
            - incomplete
          type: string
          description: "The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n"
        type:
          enum:
            - function_call_output
          type: string
          description: "The type of the function tool call output. Always `function_call_output`.\n"
          x-stainless-const: true
      description: "The output of a function tool call.\n"
    FunctionToolCallOutputResource:
      allOf:
        - $ref: '#/components/schemas/FunctionToolCallOutput'
        - required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "The unique ID of the function call tool output.\n"
    FunctionToolCallResource:
      allOf:
        - $ref: '#/components/schemas/FunctionToolCall'
        - required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "The unique ID of the function tool call.\n"
    GraderLabelModel:
      title: LabelModelGrader
      required:
        - type
        - model
        - input
        - passing_labels
        - labels
        - name
      type: object
      properties:
        input:
          type: array
          items:
            $ref: '#/components/schemas/EvalItem'
        labels:
          type: array
          items:
            type: string
          description: The labels to assign to each item in the evaluation.
        model:
          type: string
          description: The model to use for the evaluation. Must support structured outputs.
        name:
          type: string
          description: The name of the grader.
        passing_labels:
          type: array
          items:
            type: string
          description: The labels that indicate a passing result. Must be a subset of labels.
        type:
          enum:
            - label_model
          type: string
          description: 'The object type, which is always `label_model`.'
          x-stainless-const: true
      description: "A LabelModelGrader object which uses a model to assign labels to each item\nin the evaluation.\n"
      x-oaiMeta:
        example: "{\n  \"name\": \"First label grader\",\n  \"type\": \"label_model\",\n  \"model\": \"gpt-4o-2024-08-06\",\n  \"input\": [\n    {\n      \"type\": \"message\",\n      \"role\": \"system\",\n      \"content\": {\n        \"type\": \"input_text\",\n        \"text\": \"Classify the sentiment of the following statement as one of positive, neutral, or negative\"\n      }\n    },\n    {\n      \"type\": \"message\",\n      \"role\": \"user\",\n      \"content\": {\n        \"type\": \"input_text\",\n        \"text\": \"Statement: {{item.response}}\"\n      }\n    }\n  ],\n  \"passing_labels\": [\n    \"positive\"\n  ],\n  \"labels\": [\n    \"positive\",\n    \"neutral\",\n    \"negative\"\n  ]\n}\n"
        group: graders
        name: Label Model Grader
    GraderMulti:
      title: MultiGrader
      required:
        - name
        - type
        - graders
        - calculate_output
      type: object
      properties:
        calculate_output:
          type: string
          description: A formula to calculate the output based on grader results.
        graders:
          anyOf:
            - $ref: '#/components/schemas/GraderStringCheck'
            - $ref: '#/components/schemas/GraderTextSimilarity'
            - $ref: '#/components/schemas/GraderPython'
            - $ref: '#/components/schemas/GraderScoreModel'
            - $ref: '#/components/schemas/GraderLabelModel'
        name:
          type: string
          description: The name of the grader.
        type:
          enum:
            - multi
          type: string
          description: 'The object type, which is always `multi`.'
          default: multi
          x-stainless-const: true
      description: A MultiGrader object combines the output of multiple graders to produce a single score.
      x-oaiMeta:
        example: "{\n  \"type\": \"multi\",\n  \"name\": \"example multi grader\",\n  \"graders\": [\n    {\n      \"type\": \"text_similarity\",\n      \"name\": \"example text similarity grader\",\n      \"input\": \"The graded text\",\n      \"reference\": \"The reference text\",\n      \"evaluation_metric\": \"fuzzy_match\"\n    },\n    {\n      \"type\": \"string_check\",\n      \"name\": \"Example string check grader\",\n      \"input\": \"{{sample.output_text}}\",\n      \"reference\": \"{{item.label}}\",\n      \"operation\": \"eq\"\n    }\n  ],\n  \"calculate_output\": \"0.5 * text_similarity_score +  0.5 * string_check_score)\"\n}\n"
        group: graders
        name: Multi Grader
    GraderPython:
      title: PythonGrader
      required:
        - type
        - name
        - source
      type: object
      properties:
        image_tag:
          type: string
          description: The image tag to use for the python script.
        name:
          type: string
          description: The name of the grader.
        source:
          type: string
          description: The source code of the python script.
        type:
          enum:
            - python
          type: string
          description: 'The object type, which is always `python`.'
          x-stainless-const: true
      description: "A PythonGrader object that runs a python script on the input.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"python\",\n  \"name\": \"Example python grader\",\n  \"image_tag\": \"2025-05-08\",\n  \"source\": \"\"\"\ndef grade(sample: dict, item: dict) -> float:\n    \\\"\"\"\n    Returns 1.0 if `output_text` equals `label`, otherwise 0.0.\n    \\\"\"\"\n    output = sample.get(\"output_text\")\n    label = item.get(\"label\")\n    return 1.0 if output == label else 0.0\n\"\"\",\n}\n"
        group: graders
        name: Python Grader
    GraderScoreModel:
      title: ScoreModelGrader
      required:
        - type
        - name
        - input
        - model
      type: object
      properties:
        input:
          type: array
          items:
            $ref: '#/components/schemas/EvalItem'
          description: The input text. This may include template strings.
        model:
          type: string
          description: The model to use for the evaluation.
        name:
          type: string
          description: The name of the grader.
        range:
          type: array
          items:
            type: number
          description: 'The range of the score. Defaults to `[0, 1]`.'
        sampling_params:
          type: object
          description: The sampling parameters for the model.
        type:
          enum:
            - score_model
          type: string
          description: 'The object type, which is always `score_model`.'
          x-stainless-const: true
      description: "A ScoreModelGrader object that uses a model to assign a score to the input.\n"
      x-oaiMeta:
        example: "{\n    \"type\": \"score_model\",\n    \"name\": \"Example score model grader\",\n    \"input\": [\n        {\n            \"role\": \"user\",\n            \"content\": (\n                \"Score how close the reference answer is to the model answer. Score 1.0 if they are the same and 0.0 if they are different.\"\n                \" Return just a floating point score\\n\\n\"\n                \" Reference answer: {{item.label}}\\n\\n\"\n                \" Model answer: {{sample.output_text}}\"\n            ),\n        }\n    ],\n    \"model\": \"gpt-4o-2024-08-06\",\n    \"sampling_params\": {\n        \"temperature\": 1,\n        \"top_p\": 1,\n        \"seed\": 42,\n    },\n}\n"
        group: graders
        name: Score Model Grader
    GraderStringCheck:
      title: StringCheckGrader
      required:
        - type
        - name
        - input
        - reference
        - operation
      type: object
      properties:
        input:
          type: string
          description: The input text. This may include template strings.
        name:
          type: string
          description: The name of the grader.
        operation:
          enum:
            - eq
            - ne
            - like
            - ilike
          type: string
          description: 'The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.'
        reference:
          type: string
          description: The reference text. This may include template strings.
        type:
          enum:
            - string_check
          type: string
          description: 'The object type, which is always `string_check`.'
          x-stainless-const: true
      description: "A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"string_check\",\n  \"name\": \"Example string check grader\",\n  \"input\": \"{{sample.output_text}}\",\n  \"reference\": \"{{item.label}}\",\n  \"operation\": \"eq\"\n}\n"
        group: graders
        name: String Check Grader
    GraderTextSimilarity:
      title: TextSimilarityGrader
      required:
        - type
        - name
        - input
        - reference
        - evaluation_metric
      type: object
      properties:
        evaluation_metric:
          enum:
            - cosine
            - fuzzy_match
            - bleu
            - gleu
            - meteor
            - rouge_1
            - rouge_2
            - rouge_3
            - rouge_4
            - rouge_5
            - rouge_l
          type: string
          description: "The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`, \n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`, \nor `rouge_l`.\n"
        input:
          type: string
          description: The text being graded.
        name:
          type: string
          description: The name of the grader.
        reference:
          type: string
          description: The text being graded against.
        type:
          enum:
            - text_similarity
          type: string
          description: The type of grader.
          default: text_similarity
          x-stainless-const: true
      description: "A TextSimilarityGrader object which grades text based on similarity metrics.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"text_similarity\",\n  \"name\": \"Example text similarity grader\",\n  \"input\": \"{{sample.output_text}}\",\n  \"reference\": \"{{item.label}}\",\n  \"evaluation_metric\": \"fuzzy_match\"\n}\n"
        group: graders
        name: Text Similarity Grader
    Image:
      type: object
      properties:
        b64_json:
          type: string
          description: 'The base64-encoded JSON of the generated image. Default value for `gpt-image-1`, and only present if `response_format` is set to `b64_json` for `dall-e-2` and `dall-e-3`.'
        revised_prompt:
          type: string
          description: 'For `dall-e-3` only, the revised prompt that was used to generate the image.'
        url:
          type: string
          description: 'When using `dall-e-2` or `dall-e-3`, the URL of the generated image if `response_format` is set to `url` (default value). Unsupported for `gpt-image-1`.'
      description: Represents the content or the URL of an image generated by the OpenAI API.
    ImageEditCompletedEvent:
      required:
        - type
        - b64_json
        - created_at
        - size
        - quality
        - background
        - output_format
        - usage
      type: object
      properties:
        b64_json:
          type: string
          description: "Base64-encoded final edited image data, suitable for rendering as an image.\n"
        background:
          enum:
            - transparent
            - opaque
            - auto
          type: string
          description: "The background setting for the edited image.\n"
        created_at:
          type: integer
          description: "The Unix timestamp when the event was created.\n"
        output_format:
          enum:
            - png
            - webp
            - jpeg
          type: string
          description: "The output format for the edited image.\n"
        quality:
          enum:
            - low
            - medium
            - high
            - auto
          type: string
          description: "The quality setting for the edited image.\n"
        size:
          enum:
            - 1024x1024
            - 1024x1536
            - 1536x1024
            - auto
          type: string
          description: "The size of the edited image.\n"
        type:
          enum:
            - image_edit.completed
          type: string
          description: "The type of the event. Always `image_edit.completed`.\n"
          x-stainless-const: true
        usage:
          $ref: '#/components/schemas/ImagesUsage'
      description: "Emitted when image editing has completed and the final image is available.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"image_edit.completed\",\n  \"b64_json\": \"...\",\n  \"created_at\": 1620000000,\n  \"size\": \"1024x1024\",\n  \"quality\": \"high\",\n  \"background\": \"transparent\",\n  \"output_format\": \"png\",\n  \"usage\": {\n    \"total_tokens\": 100,\n    \"input_tokens\": 50,\n    \"output_tokens\": 50,\n    \"input_tokens_details\": {\n      \"text_tokens\": 10,\n      \"image_tokens\": 40\n    }\n  }\n}\n"
        group: images
        name: image_edit.completed
    ImageEditPartialImageEvent:
      required:
        - type
        - b64_json
        - created_at
        - size
        - quality
        - background
        - output_format
        - partial_image_index
      type: object
      properties:
        b64_json:
          type: string
          description: "Base64-encoded partial image data, suitable for rendering as an image.\n"
        background:
          enum:
            - transparent
            - opaque
            - auto
          type: string
          description: "The background setting for the requested edited image.\n"
        created_at:
          type: integer
          description: "The Unix timestamp when the event was created.\n"
        output_format:
          enum:
            - png
            - webp
            - jpeg
          type: string
          description: "The output format for the requested edited image.\n"
        partial_image_index:
          type: integer
          description: "0-based index for the partial image (streaming).\n"
        quality:
          enum:
            - low
            - medium
            - high
            - auto
          type: string
          description: "The quality setting for the requested edited image.\n"
        size:
          enum:
            - 1024x1024
            - 1024x1536
            - 1536x1024
            - auto
          type: string
          description: "The size of the requested edited image.\n"
        type:
          enum:
            - image_edit.partial_image
          type: string
          description: "The type of the event. Always `image_edit.partial_image`.\n"
          x-stainless-const: true
      description: "Emitted when a partial image is available during image editing streaming.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"image_edit.partial_image\",\n  \"b64_json\": \"...\",\n  \"created_at\": 1620000000,\n  \"size\": \"1024x1024\",\n  \"quality\": \"high\",\n  \"background\": \"transparent\",\n  \"output_format\": \"png\",\n  \"partial_image_index\": 0\n}\n"
        group: images
        name: image_edit.partial_image
    ImageEditStreamEvent:
      anyOf:
        - $ref: '#/components/schemas/ImageEditPartialImageEvent'
        - $ref: '#/components/schemas/ImageEditCompletedEvent'
      discriminator:
        propertyName: type
    ImageGenCompletedEvent:
      required:
        - type
        - b64_json
        - created_at
        - size
        - quality
        - background
        - output_format
        - usage
      type: object
      properties:
        b64_json:
          type: string
          description: "Base64-encoded image data, suitable for rendering as an image.\n"
        background:
          enum:
            - transparent
            - opaque
            - auto
          type: string
          description: "The background setting for the generated image.\n"
        created_at:
          type: integer
          description: "The Unix timestamp when the event was created.\n"
        output_format:
          enum:
            - png
            - webp
            - jpeg
          type: string
          description: "The output format for the generated image.\n"
        quality:
          enum:
            - low
            - medium
            - high
            - auto
          type: string
          description: "The quality setting for the generated image.\n"
        size:
          enum:
            - 1024x1024
            - 1024x1536
            - 1536x1024
            - auto
          type: string
          description: "The size of the generated image.\n"
        type:
          enum:
            - image_generation.completed
          type: string
          description: "The type of the event. Always `image_generation.completed`.\n"
          x-stainless-const: true
        usage:
          $ref: '#/components/schemas/ImagesUsage'
      description: "Emitted when image generation has completed and the final image is available.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"image_generation.completed\",\n  \"b64_json\": \"...\",\n  \"created_at\": 1620000000,\n  \"size\": \"1024x1024\",\n  \"quality\": \"high\",\n  \"background\": \"transparent\",\n  \"output_format\": \"png\",\n  \"usage\": {\n    \"total_tokens\": 100,\n    \"input_tokens\": 50,\n    \"output_tokens\": 50,\n    \"input_tokens_details\": {\n      \"text_tokens\": 10,\n      \"image_tokens\": 40\n    }\n  }\n}\n"
        group: images
        name: image_generation.completed
    ImageGenInputUsageDetails:
      title: Input usage details
      required:
        - text_tokens
        - image_tokens
      type: object
      properties:
        image_tokens:
          type: integer
          description: The number of image tokens in the input prompt.
        text_tokens:
          type: integer
          description: The number of text tokens in the input prompt.
      description: The input tokens detailed information for the image generation.
    ImageGenPartialImageEvent:
      required:
        - type
        - b64_json
        - created_at
        - size
        - quality
        - background
        - output_format
        - partial_image_index
      type: object
      properties:
        b64_json:
          type: string
          description: "Base64-encoded partial image data, suitable for rendering as an image.\n"
        background:
          enum:
            - transparent
            - opaque
            - auto
          type: string
          description: "The background setting for the requested image.\n"
        created_at:
          type: integer
          description: "The Unix timestamp when the event was created.\n"
        output_format:
          enum:
            - png
            - webp
            - jpeg
          type: string
          description: "The output format for the requested image.\n"
        partial_image_index:
          type: integer
          description: "0-based index for the partial image (streaming).\n"
        quality:
          enum:
            - low
            - medium
            - high
            - auto
          type: string
          description: "The quality setting for the requested image.\n"
        size:
          enum:
            - 1024x1024
            - 1024x1536
            - 1536x1024
            - auto
          type: string
          description: "The size of the requested image.\n"
        type:
          enum:
            - image_generation.partial_image
          type: string
          description: "The type of the event. Always `image_generation.partial_image`.\n"
          x-stainless-const: true
      description: "Emitted when a partial image is available during image generation streaming.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"image_generation.partial_image\",\n  \"b64_json\": \"...\",\n  \"created_at\": 1620000000,\n  \"size\": \"1024x1024\",\n  \"quality\": \"high\",\n  \"background\": \"transparent\",\n  \"output_format\": \"png\",\n  \"partial_image_index\": 0\n}\n"
        group: images
        name: image_generation.partial_image
    ImageGenStreamEvent:
      anyOf:
        - $ref: '#/components/schemas/ImageGenPartialImageEvent'
        - $ref: '#/components/schemas/ImageGenCompletedEvent'
      discriminator:
        propertyName: type
    ImageGenTool:
      title: Image generation tool
      required:
        - type
      type: object
      properties:
        background:
          enum:
            - transparent
            - opaque
            - auto
          type: string
          description: "Background type for the generated image. One of `transparent`, \n`opaque`, or `auto`. Default: `auto`.\n"
          default: auto
        input_fidelity:
          $ref: '#/components/schemas/ImageInputFidelity'
        input_image_mask:
          type: object
          properties:
            file_id:
              type: string
              description: "File ID for the mask image.\n"
            image_url:
              type: string
              description: "Base64-encoded mask image.\n"
          additionalProperties: false
          description: "Optional mask for inpainting. Contains `image_url` \n(string, optional) and `file_id` (string, optional).\n"
        model:
          enum:
            - gpt-image-1
          type: string
          description: "The image generation model to use. Default: `gpt-image-1`.\n"
          default: gpt-image-1
        moderation:
          enum:
            - auto
            - low
          type: string
          description: "Moderation level for the generated image. Default: `auto`.\n"
          default: auto
        output_compression:
          maximum: 100
          minimum: 0
          type: integer
          description: "Compression level for the output image. Default: 100.\n"
          default: 100
        output_format:
          enum:
            - png
            - webp
            - jpeg
          type: string
          description: "The output format of the generated image. One of `png`, `webp`, or \n`jpeg`. Default: `png`.\n"
          default: png
        partial_images:
          maximum: 3
          minimum: 0
          type: integer
          description: "Number of partial images to generate in streaming mode, from 0 (default value) to 3.\n"
          default: 0
        quality:
          enum:
            - low
            - medium
            - high
            - auto
          type: string
          description: "The quality of the generated image. One of `low`, `medium`, `high`, \nor `auto`. Default: `auto`.\n"
          default: auto
        size:
          enum:
            - 1024x1024
            - 1024x1536
            - 1536x1024
            - auto
          type: string
          description: "The size of the generated image. One of `1024x1024`, `1024x1536`, \n`1536x1024`, or `auto`. Default: `auto`.\n"
          default: auto
        type:
          enum:
            - image_generation
          type: string
          description: "The type of the image generation tool. Always `image_generation`.\n"
          x-stainless-const: true
      description: "A tool that generates images using a model like `gpt-image-1`.\n"
    ImageGenToolCall:
      title: Image generation call
      required:
        - type
        - id
        - status
        - result
      type: object
      properties:
        id:
          type: string
          description: "The unique ID of the image generation call.\n"
        result:
          type: string
          description: "The generated image encoded in base64.\n"
          nullable: true
        status:
          enum:
            - in_progress
            - completed
            - generating
            - failed
          type: string
          description: "The status of the image generation call.\n"
        type:
          enum:
            - image_generation_call
          type: string
          description: "The type of the image generation call. Always `image_generation_call`.\n"
          x-stainless-const: true
      description: "An image generation request made by the model.\n"
    ImageGenUsage:
      title: Image generation usage
      required:
        - input_tokens
        - total_tokens
        - output_tokens
        - input_tokens_details
      type: object
      properties:
        input_tokens:
          type: integer
          description: The number of tokens (images and text) in the input prompt.
        input_tokens_details:
          $ref: '#/components/schemas/ImageGenInputUsageDetails'
        output_tokens:
          type: integer
          description: The number of output tokens generated by the model.
        total_tokens:
          type: integer
          description: The total number of tokens (images and text) used for the image generation.
      description: 'For `gpt-image-1` only, the token usage information for the image generation.'
    ImageInputFidelity:
      enum:
        - high
        - low
      type: string
      description: "Control how much effort the model will exert to match the style and features,\nespecially facial features, of input images. This parameter is only supported\nfor `gpt-image-1`. Supports `high` and `low`. Defaults to `low`.\n"
      default: low
      nullable: true
    ImagesResponse:
      title: Image generation response
      required:
        - created
      type: object
      properties:
        background:
          enum:
            - transparent
            - opaque
          type: string
          description: The background parameter used for the image generation. Either `transparent` or `opaque`.
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the image was created.
        data:
          type: array
          items:
            $ref: '#/components/schemas/Image'
          description: The list of generated images.
        output_format:
          enum:
            - png
            - webp
            - jpeg
          type: string
          description: 'The output format of the image generation. Either `png`, `webp`, or `jpeg`.'
        quality:
          enum:
            - low
            - medium
            - high
          type: string
          description: 'The quality of the image generated. Either `low`, `medium`, or `high`.'
        size:
          enum:
            - 1024x1024
            - 1024x1536
            - 1536x1024
          type: string
          description: 'The size of the image generated. Either `1024x1024`, `1024x1536`, or `1536x1024`.'
        usage:
          $ref: '#/components/schemas/ImageGenUsage'
      description: The response from the image generation endpoint.
      x-oaiMeta:
        example: "{\n  \"created\": 1713833628,\n  \"data\": [\n    {\n      \"b64_json\": \"...\"\n    }\n  ],\n  \"background\": \"transparent\",\n  \"output_format\": \"png\",\n  \"size\": \"1024x1024\",\n  \"quality\": \"high\",\n  \"usage\": {\n    \"total_tokens\": 100,\n    \"input_tokens\": 50,\n    \"output_tokens\": 50,\n    \"input_tokens_details\": {\n      \"text_tokens\": 10,\n      \"image_tokens\": 40\n    }\n  }\n}\n"
        group: images
        name: The image generation response
    ImagesUsage:
      required:
        - total_tokens
        - input_tokens
        - output_tokens
        - input_tokens_details
      type: object
      properties:
        input_tokens:
          type: integer
          description: The number of tokens (images and text) in the input prompt.
        input_tokens_details:
          required:
            - text_tokens
            - image_tokens
          type: object
          properties:
            image_tokens:
              type: integer
              description: The number of image tokens in the input prompt.
            text_tokens:
              type: integer
              description: The number of text tokens in the input prompt.
          description: The input tokens detailed information for the image generation.
        output_tokens:
          type: integer
          description: The number of image tokens in the output image.
        total_tokens:
          type: integer
          description: "The total number of tokens (images and text) used for the image generation.\n"
      description: "For `gpt-image-1` only, the token usage information for the image generation.\n"
    Includable:
      enum:
        - code_interpreter_call.outputs
        - computer_call_output.output.image_url
        - file_search_call.results
        - message.input_image.image_url
        - message.output_text.logprobs
        - reasoning.encrypted_content
      type: string
      description: "Specify additional output data to include in the model response. Currently\nsupported values are:\n- `web_search_call.action.sources`: Include the sources of the web search tool call.\n- `code_interpreter_call.outputs`: Includes the outputs of python code execution\n  in code interpreter tool call items.\n- `computer_call_output.output.image_url`: Include image urls from the computer call output.\n- `file_search_call.results`: Include the search results of\n  the file search tool call.\n- `message.input_image.image_url`: Include image urls from the input message.\n- `message.output_text.logprobs`: Include logprobs with assistant messages.\n- `reasoning.encrypted_content`: Includes an encrypted version of reasoning\n  tokens in reasoning item outputs. This enables reasoning items to be used in\n  multi-turn conversations when using the Responses API statelessly (like\n  when the `store` parameter is set to `false`, or when an organization is\n  enrolled in the zero data retention program).\n"
    InputAudio:
      title: Input audio
      required:
        - type
        - input_audio
      type: object
      properties:
        input_audio:
          required:
            - data
            - format
          type: object
          properties:
            data:
              type: string
              description: "Base64-encoded audio data.\n"
            format:
              enum:
                - mp3
                - wav
              type: string
              description: "The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n"
        type:
          enum:
            - input_audio
          type: string
          description: "The type of the input item. Always `input_audio`.\n"
          x-stainless-const: true
      description: "An audio input to the model.\n"
    InputContent:
      anyOf:
        - $ref: '#/components/schemas/InputTextContent'
        - $ref: '#/components/schemas/InputImageContent'
        - $ref: '#/components/schemas/InputFileContent'
        - $ref: '#/components/schemas/InputAudio'
      discriminator:
        propertyName: type
    InputFileContent:
      title: Input file
      required:
        - type
      type: object
      properties:
        file_data:
          type: string
          description: "The content of the file to be sent to the model.\n"
        file_id:
          type: string
          description: The ID of the file to be sent to the model.
          nullable: true
        file_url:
          type: string
          description: The URL of the file to be sent to the model.
        filename:
          type: string
          description: The name of the file to be sent to the model.
        type:
          enum:
            - input_file
          type: string
          description: The type of the input item. Always `input_file`.
          default: input_file
          x-stainless-const: true
      description: A file input to the model.
    InputFileContent-2:
      title: Input file
      required:
        - type
        - file_id
      type: object
      properties:
        file_id:
          type: string
          description: The ID of the file to be sent to the model.
          nullable: true
        file_url:
          type: string
          description: The URL of the file to be sent to the model.
        filename:
          type: string
          description: The name of the file to be sent to the model.
        type:
          enum:
            - input_file
          type: string
          description: The type of the input item. Always `input_file`.
          default: input_file
          x-stainless-const: true
    InputImageContent:
      title: Input image
      required:
        - type
        - detail
      type: object
      properties:
        detail:
          enum:
            - low
            - high
            - auto
          type: string
          description: 'The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.'
        file_id:
          type: string
          description: The ID of the file to be sent to the model.
          nullable: true
        image_url:
          type: string
          description: The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.
          nullable: true
        type:
          enum:
            - input_image
          type: string
          description: The type of the input item. Always `input_image`.
          default: input_image
          x-stainless-const: true
      description: 'An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'
    InputImageContent-2:
      title: Input image
      required:
        - type
        - image_url
        - file_id
        - detail
      type: object
      properties:
        detail:
          enum:
            - low
            - high
            - auto
          type: string
          description: 'The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.'
        file_id:
          type: string
          description: The ID of the file to be sent to the model.
          nullable: true
        image_url:
          type: string
          description: The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.
          nullable: true
        type:
          enum:
            - input_image
          type: string
          description: The type of the input item. Always `input_image`.
          default: input_image
          x-stainless-const: true
    InputItem:
      anyOf:
        - $ref: '#/components/schemas/EasyInputMessage'
        - $ref: '#/components/schemas/Item'
        - $ref: '#/components/schemas/ItemReferenceParam'
      discriminator:
        propertyName: type
    InputMessage:
      title: Input message
      required:
        - role
        - content
      type: object
      properties:
        content:
          $ref: '#/components/schemas/InputMessageContentList'
        role:
          enum:
            - user
            - system
            - developer
          type: string
          description: "The role of the message input. One of `user`, `system`, or `developer`.\n"
        status:
          enum:
            - in_progress
            - completed
            - incomplete
          type: string
          description: "The status of item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n"
        type:
          enum:
            - message
          type: string
          description: "The type of the message input. Always set to `message`.\n"
          x-stainless-const: true
      description: "A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role.\n"
    InputMessageContentList:
      title: Input item content list
      type: array
      items:
        $ref: '#/components/schemas/InputContent'
      description: "A list of one or many input items to the model, containing different content \ntypes.\n"
    InputMessageResource:
      allOf:
        - $ref: '#/components/schemas/InputMessage'
        - required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "The unique ID of the message input.\n"
    InputTextContent:
      title: Input text
      required:
        - type
        - text
      type: object
      properties:
        text:
          type: string
          description: The text input to the model.
        type:
          enum:
            - input_text
          type: string
          description: The type of the input item. Always `input_text`.
          default: input_text
          x-stainless-const: true
      description: A text input to the model.
    InputTextContent-2:
      title: Input text
      required:
        - type
        - text
      type: object
      properties:
        text:
          type: string
          description: The text input to the model.
        type:
          enum:
            - input_text
          type: string
          description: The type of the input item. Always `input_text`.
          default: input_text
          x-stainless-const: true
    Invite:
      required:
        - object
        - id
        - email
        - role
        - status
        - invited_at
        - expires_at
      type: object
      properties:
        accepted_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the invite was accepted.
        email:
          type: string
          description: The email address of the individual to whom the invite was sent
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the invite expires.
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints'
        invited_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the invite was sent.
        object:
          enum:
            - organization.invite
          type: string
          description: 'The object type, which is always `organization.invite`'
          x-stainless-const: true
        projects:
          type: array
          items:
            type: object
            properties:
              id:
                type: string
                description: Project's public ID
              role:
                enum:
                  - member
                  - owner
                type: string
                description: Project membership role
          description: The projects that were granted membership upon acceptance of the invite.
        role:
          enum:
            - owner
            - reader
          type: string
          description: '`owner` or `reader`'
        status:
          enum:
            - accepted
            - expired
            - pending
          type: string
          description: '`accepted`,`expired`, or `pending`'
      description: Represents an individual `invite` to the organization.
      x-oaiMeta:
        example: "{\n  \"object\": \"organization.invite\",\n  \"id\": \"invite-abc\",\n  \"email\": \"user@example.com\",\n  \"role\": \"owner\",\n  \"status\": \"accepted\",\n  \"invited_at\": 1711471533,\n  \"expires_at\": 1711471533,\n  \"accepted_at\": 1711471533,\n  \"projects\": [\n    {\n      \"id\": \"project-xyz\",\n      \"role\": \"member\"\n    }\n  ]\n}\n"
        name: The invite object
    InviteDeleteResponse:
      required:
        - object
        - id
        - deleted
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          enum:
            - organization.invite.deleted
          type: string
          description: 'The object type, which is always `organization.invite.deleted`'
          x-stainless-const: true
    InviteListResponse:
      required:
        - object
        - data
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/Invite'
        first_id:
          type: string
          description: The first `invite_id` in the retrieved `list`
        has_more:
          type: boolean
          description: The `has_more` property is used for pagination to indicate there are additional results.
        last_id:
          type: string
          description: The last `invite_id` in the retrieved `list`
        object:
          enum:
            - list
          type: string
          description: 'The object type, which is always `list`'
          x-stainless-const: true
    InviteRequest:
      required:
        - email
        - role
      type: object
      properties:
        email:
          type: string
          description: Send an email to this address
        projects:
          type: array
          items:
            required:
              - id
              - role
            type: object
            properties:
              id:
                type: string
                description: Project's public ID
              role:
                enum:
                  - member
                  - owner
                type: string
                description: Project membership role
          description: 'An array of projects to which membership is granted at the same time the org invite is accepted. If omitted, the user will be invited to the default project for compatibility with legacy behavior.'
        role:
          enum:
            - reader
            - owner
          type: string
          description: '`owner` or `reader`'
    Item:
      type: object
      anyOf:
        - $ref: '#/components/schemas/InputMessage'
        - $ref: '#/components/schemas/OutputMessage'
        - $ref: '#/components/schemas/FileSearchToolCall'
        - $ref: '#/components/schemas/ComputerToolCall'
        - $ref: '#/components/schemas/ComputerCallOutputItemParam'
        - $ref: '#/components/schemas/WebSearchToolCall'
        - $ref: '#/components/schemas/FunctionToolCall'
        - $ref: '#/components/schemas/FunctionCallOutputItemParam'
        - $ref: '#/components/schemas/ReasoningItem'
        - $ref: '#/components/schemas/ImageGenToolCall'
        - $ref: '#/components/schemas/CodeInterpreterToolCall'
        - $ref: '#/components/schemas/LocalShellToolCall'
        - $ref: '#/components/schemas/LocalShellToolCallOutput'
        - $ref: '#/components/schemas/MCPListTools'
        - $ref: '#/components/schemas/MCPApprovalRequest'
        - $ref: '#/components/schemas/MCPApprovalResponse'
        - $ref: '#/components/schemas/MCPToolCall'
        - $ref: '#/components/schemas/CustomToolCallOutput'
        - $ref: '#/components/schemas/CustomToolCall'
      description: "Content item used to generate a response.\n"
      discriminator:
        propertyName: type
    ItemReferenceParam:
      title: Item reference
      required:
        - id
      type: object
      properties:
        id:
          type: string
          description: The ID of the item to reference.
        type:
          enum:
            - item_reference
          type: string
          description: The type of item to reference. Always `item_reference`.
          default: item_reference
          nullable: true
          x-stainless-const: true
      description: An internal identifier for an item to reference.
    ItemResource:
      anyOf:
        - $ref: '#/components/schemas/InputMessageResource'
        - $ref: '#/components/schemas/OutputMessage'
        - $ref: '#/components/schemas/FileSearchToolCall'
        - $ref: '#/components/schemas/ComputerToolCall'
        - $ref: '#/components/schemas/ComputerToolCallOutputResource'
        - $ref: '#/components/schemas/WebSearchToolCall'
        - $ref: '#/components/schemas/FunctionToolCallResource'
        - $ref: '#/components/schemas/FunctionToolCallOutputResource'
        - $ref: '#/components/schemas/ImageGenToolCall'
        - $ref: '#/components/schemas/CodeInterpreterToolCall'
        - $ref: '#/components/schemas/LocalShellToolCall'
        - $ref: '#/components/schemas/LocalShellToolCallOutput'
        - $ref: '#/components/schemas/MCPListTools'
        - $ref: '#/components/schemas/MCPApprovalRequest'
        - $ref: '#/components/schemas/MCPApprovalResponseResource'
        - $ref: '#/components/schemas/MCPToolCall'
      description: "Content item used to generate a response.\n"
      discriminator:
        propertyName: type
    KeyPress:
      title: KeyPress
      required:
        - type
        - keys
      type: object
      properties:
        keys:
          type: array
          items:
            type: string
            description: "One of the keys the model is requesting to be pressed.\n"
          description: "The combination of keys the model is requesting to be pressed. This is an\narray of strings, each representing a key.\n"
        type:
          enum:
            - keypress
          type: string
          description: "Specifies the event type. For a keypress action, this property is \nalways set to `keypress`.\n"
          default: keypress
          x-stainless-const: true
      description: "A collection of keypresses the model would like to perform.\n"
    ListAssistantsResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/AssistantObject'
        first_id:
          type: string
          example: asst_abc123
        has_more:
          type: boolean
          example: false
        last_id:
          type: string
          example: asst_abc456
        object:
          type: string
          example: list
      x-oaiMeta:
        example: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"asst_abc123\",\n      \"object\": \"assistant\",\n      \"created_at\": 1698982736,\n      \"name\": \"Coding Tutor\",\n      \"description\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": \"You are a helpful assistant designed to make me better at coding!\",\n      \"tools\": [],\n      \"tool_resources\": {},\n      \"metadata\": {},\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\": \"auto\"\n    },\n    {\n      \"id\": \"asst_abc456\",\n      \"object\": \"assistant\",\n      \"created_at\": 1698982718,\n      \"name\": \"My Assistant\",\n      \"description\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": \"You are a helpful assistant designed to make me better at coding!\",\n      \"tools\": [],\n      \"tool_resources\": {},\n      \"metadata\": {},\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\": \"auto\"\n    },\n    {\n      \"id\": \"asst_abc789\",\n      \"object\": \"assistant\",\n      \"created_at\": 1698982643,\n      \"name\": null,\n      \"description\": null,\n      \"model\": \"gpt-4o\",\n      \"instructions\": null,\n      \"tools\": [],\n      \"tool_resources\": {},\n      \"metadata\": {},\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\": \"auto\"\n    }\n  ],\n  \"first_id\": \"asst_abc123\",\n  \"last_id\": \"asst_abc789\",\n  \"has_more\": false\n}\n"
        group: chat
        name: List assistants response object
    ListAuditLogsResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/AuditLog'
        first_id:
          type: string
          example: audit_log-defb456h8dks
        has_more:
          type: boolean
        last_id:
          type: string
          example: audit_log-hnbkd8s93s
        object:
          enum:
            - list
          type: string
          x-stainless-const: true
    ListBatchesResponse:
      required:
        - object
        - data
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/Batch'
        first_id:
          type: string
          example: batch_abc123
        has_more:
          type: boolean
        last_id:
          type: string
          example: batch_abc456
        object:
          enum:
            - list
          type: string
          x-stainless-const: true
    ListCertificatesResponse:
      required:
        - object
        - data
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/Certificate'
        first_id:
          type: string
          example: cert_abc
        has_more:
          type: boolean
        last_id:
          type: string
          example: cert_abc
        object:
          enum:
            - list
          type: string
          x-stainless-const: true
    ListFilesResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/OpenAIFile'
        first_id:
          type: string
          example: file-abc123
        has_more:
          type: boolean
          example: false
        last_id:
          type: string
          example: file-abc456
        object:
          type: string
          example: list
    ListFineTuningCheckpointPermissionResponse:
      required:
        - object
        - data
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuningCheckpointPermission'
        first_id:
          type: string
          nullable: true
        has_more:
          type: boolean
        last_id:
          type: string
          nullable: true
        object:
          enum:
            - list
          type: string
          x-stainless-const: true
    ListFineTuningJobCheckpointsResponse:
      required:
        - object
        - data
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuningJobCheckpoint'
        first_id:
          type: string
          nullable: true
        has_more:
          type: boolean
        last_id:
          type: string
          nullable: true
        object:
          enum:
            - list
          type: string
          x-stainless-const: true
    ListFineTuningJobEventsResponse:
      required:
        - object
        - data
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuningJobEvent'
        has_more:
          type: boolean
        object:
          enum:
            - list
          type: string
          x-stainless-const: true
    ListMessagesResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/MessageObject'
        first_id:
          type: string
          example: msg_abc123
        has_more:
          type: boolean
          example: false
        last_id:
          type: string
          example: msg_abc123
        object:
          type: string
          example: list
    ListModelsResponse:
      required:
        - object
        - data
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/Model'
        object:
          enum:
            - list
          type: string
          x-stainless-const: true
    ListPaginatedFineTuningJobsResponse:
      required:
        - object
        - data
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuningJob'
        has_more:
          type: boolean
        object:
          enum:
            - list
          type: string
          x-stainless-const: true
    ListRunStepsResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/RunStepObject'
        first_id:
          type: string
          example: step_abc123
        has_more:
          type: boolean
          example: false
        last_id:
          type: string
          example: step_abc456
        object:
          type: string
          example: list
    ListRunsResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/RunObject'
        first_id:
          type: string
          example: run_abc123
        has_more:
          type: boolean
          example: false
        last_id:
          type: string
          example: run_abc456
        object:
          type: string
          example: list
    ListVectorStoreFilesResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/VectorStoreFileObject'
        first_id:
          type: string
          example: file-abc123
        has_more:
          type: boolean
          example: false
        last_id:
          type: string
          example: file-abc456
        object:
          type: string
          example: list
    ListVectorStoresResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/VectorStoreObject'
        first_id:
          type: string
          example: vs_abc123
        has_more:
          type: boolean
          example: false
        last_id:
          type: string
          example: vs_abc456
        object:
          type: string
          example: list
    LocalShellExecAction:
      title: Local shell exec action
      required:
        - type
        - command
        - env
      type: object
      properties:
        command:
          type: array
          items:
            type: string
          description: "The command to run.\n"
        env:
          type: object
          additionalProperties:
            type: string
          description: "Environment variables to set for the command.\n"
        timeout_ms:
          type: integer
          description: "Optional timeout in milliseconds for the command.\n"
          nullable: true
        type:
          enum:
            - exec
          type: string
          description: "The type of the local shell action. Always `exec`.\n"
          x-stainless-const: true
        user:
          type: string
          description: "Optional user to run the command as.\n"
          nullable: true
        working_directory:
          type: string
          description: "Optional working directory to run the command in.\n"
          nullable: true
      description: "Execute a shell command on the server.\n"
    LocalShellTool:
      title: Local shell tool
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - local_shell
          type: string
          description: The type of the local shell tool. Always `local_shell`.
          x-stainless-const: true
      description: "A tool that allows the model to execute shell commands in a local environment.\n"
    LocalShellToolCall:
      title: Local shell call
      required:
        - type
        - id
        - call_id
        - action
        - status
      type: object
      properties:
        action:
          $ref: '#/components/schemas/LocalShellExecAction'
        call_id:
          type: string
          description: "The unique ID of the local shell tool call generated by the model.\n"
        id:
          type: string
          description: "The unique ID of the local shell call.\n"
        status:
          enum:
            - in_progress
            - completed
            - incomplete
          type: string
          description: "The status of the local shell call.\n"
        type:
          enum:
            - local_shell_call
          type: string
          description: "The type of the local shell call. Always `local_shell_call`.\n"
          x-stainless-const: true
      description: "A tool call to run a command on the local shell.\n"
    LocalShellToolCallOutput:
      title: Local shell call output
      required:
        - id
        - type
        - call_id
        - output
      type: object
      properties:
        id:
          type: string
          description: "The unique ID of the local shell tool call generated by the model.\n"
        output:
          type: string
          description: "A JSON string of the output of the local shell tool call.\n"
        status:
          enum:
            - in_progress
            - completed
            - incomplete
          type: string
          description: "The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n"
          nullable: true
        type:
          enum:
            - local_shell_call_output
          type: string
          description: "The type of the local shell tool call output. Always `local_shell_call_output`.\n"
          x-stainless-const: true
      description: "The output of a local shell tool call.\n"
    LogProb:
      title: Log probability
      required:
        - token
        - logprob
        - bytes
        - top_logprobs
      type: object
      properties:
        bytes:
          type: array
          items:
            type: integer
        logprob:
          type: number
        token:
          type: string
        top_logprobs:
          type: array
          items:
            $ref: '#/components/schemas/TopLogProb'
      description: The log probability of a token.
    LogProb-2:
      title: Log probability
      required:
        - token
        - logprob
        - bytes
        - top_logprobs
      type: object
      properties:
        bytes:
          type: array
          items:
            type: integer
        logprob:
          type: number
        token:
          type: string
        top_logprobs:
          type: array
          items:
            $ref: '#/components/schemas/TopLogProb-2'
    LogProbProperties:
      required:
        - token
        - logprob
        - bytes
      type: object
      properties:
        bytes:
          type: array
          items:
            type: integer
          description: "The bytes that were used to generate the log probability.\n"
        logprob:
          type: number
          description: "The log probability of the token.\n"
        token:
          type: string
          description: "The token that was used to generate the log probability.\n"
      description: "A log probability object.\n"
    MCPApprovalRequest:
      title: MCP approval request
      required:
        - type
        - id
        - server_label
        - name
        - arguments
      type: object
      properties:
        arguments:
          type: string
          description: "A JSON string of arguments for the tool.\n"
        id:
          type: string
          description: "The unique ID of the approval request.\n"
        name:
          type: string
          description: "The name of the tool to run.\n"
        server_label:
          type: string
          description: "The label of the MCP server making the request.\n"
        type:
          enum:
            - mcp_approval_request
          type: string
          description: "The type of the item. Always `mcp_approval_request`.\n"
          x-stainless-const: true
      description: "A request for human approval of a tool invocation.\n"
    MCPApprovalResponse:
      title: MCP approval response
      required:
        - type
        - request_id
        - approve
        - approval_request_id
      type: object
      properties:
        approval_request_id:
          type: string
          description: "The ID of the approval request being answered.\n"
        approve:
          type: boolean
          description: "Whether the request was approved.\n"
        id:
          type: string
          description: "The unique ID of the approval response\n"
          nullable: true
        reason:
          type: string
          description: "Optional reason for the decision.\n"
          nullable: true
        type:
          enum:
            - mcp_approval_response
          type: string
          description: "The type of the item. Always `mcp_approval_response`.\n"
          x-stainless-const: true
      description: "A response to an MCP approval request.\n"
    MCPApprovalResponseResource:
      title: MCP approval response
      required:
        - type
        - id
        - request_id
        - approve
        - approval_request_id
      type: object
      properties:
        approval_request_id:
          type: string
          description: "The ID of the approval request being answered.\n"
        approve:
          type: boolean
          description: "Whether the request was approved.\n"
        id:
          type: string
          description: "The unique ID of the approval response\n"
        reason:
          type: string
          description: "Optional reason for the decision.\n"
          nullable: true
        type:
          enum:
            - mcp_approval_response
          type: string
          description: "The type of the item. Always `mcp_approval_response`.\n"
          x-stainless-const: true
      description: "A response to an MCP approval request.\n"
    MCPListTools:
      title: MCP list tools
      required:
        - type
        - id
        - server_label
        - tools
      type: object
      properties:
        error:
          type: string
          description: "Error message if the server could not list tools.\n"
          nullable: true
        id:
          type: string
          description: "The unique ID of the list.\n"
        server_label:
          type: string
          description: "The label of the MCP server.\n"
        tools:
          type: array
          items:
            $ref: '#/components/schemas/MCPListToolsTool'
          description: "The tools available on the server.\n"
        type:
          enum:
            - mcp_list_tools
          type: string
          description: "The type of the item. Always `mcp_list_tools`.\n"
          x-stainless-const: true
      description: "A list of tools available on an MCP server.\n"
    MCPListToolsTool:
      title: MCP list tools tool
      required:
        - name
        - input_schema
      type: object
      properties:
        annotations:
          type: object
          description: "Additional annotations about the tool.\n"
          nullable: true
        description:
          type: string
          description: "The description of the tool.\n"
          nullable: true
        input_schema:
          type: object
          description: "The JSON schema describing the tool's input.\n"
        name:
          type: string
          description: "The name of the tool.\n"
      description: "A tool available on an MCP server.\n"
    MCPTool:
      title: MCP tool
      required:
        - type
        - server_label
      type: object
      properties:
        allowed_tools:
          anyOf:
            - title: MCP allowed tools
              type: array
              items:
                type: string
              description: A string array of allowed tool names
            - $ref: '#/components/schemas/MCPToolFilter'
          description: "List of allowed tool names or a filter object.\n"
          nullable: true
        authorization:
          type: string
          description: "An OAuth access token that can be used with a remote MCP server, either \nwith a custom MCP server URL or a service connector. Your application\nmust handle the OAuth authorization flow and provide the token here.\n"
        connector_id:
          enum:
            - connector_dropbox
            - connector_gmail
            - connector_googlecalendar
            - connector_googledrive
            - connector_microsoftteams
            - connector_outlookcalendar
            - connector_outlookemail
            - connector_sharepoint
          type: string
          description: "Identifier for service connectors, like those available in ChatGPT. One of\n`server_url` or `connector_id` must be provided. Learn more about service\nconnectors [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).\n\nCurrently supported `connector_id` values are:\n\n- Dropbox: `connector_dropbox`\n- Gmail: `connector_gmail`\n- Google Calendar: `connector_googlecalendar`\n- Google Drive: `connector_googledrive`\n- Microsoft Teams: `connector_microsoftteams`\n- Outlook Calendar: `connector_outlookcalendar`\n- Outlook Email: `connector_outlookemail`\n- SharePoint: `connector_sharepoint`\n"
        headers:
          type: object
          additionalProperties:
            type: string
          description: "Optional HTTP headers to send to the MCP server. Use for authentication\nor other purposes.\n"
          nullable: true
        require_approval:
          anyOf:
            - title: MCP tool approval filter
              type: object
              properties:
                always:
                  $ref: '#/components/schemas/MCPToolFilter'
                never:
                  $ref: '#/components/schemas/MCPToolFilter'
              additionalProperties: false
              description: "Specify which of the MCP server's tools require approval. Can be\n`always`, `never`, or a filter object associated with tools\nthat require approval.\n"
            - title: MCP tool approval setting
              enum:
                - always
                - never
              type: string
              description: "Specify a single approval policy for all tools. One of `always` or \n`never`. When set to `always`, all tools will require approval. When \nset to `never`, all tools will not require approval.\n"
          description: Specify which of the MCP server's tools require approval.
          nullable: true
        server_description:
          type: string
          description: "Optional description of the MCP server, used to provide more context.\n"
        server_label:
          type: string
          description: "A label for this MCP server, used to identify it in tool calls.\n"
        server_url:
          type: string
          description: "The URL for the MCP server. One of `server_url` or `connector_id` must be \nprovided.\n"
        type:
          enum:
            - mcp
          type: string
          description: The type of the MCP tool. Always `mcp`.
          x-stainless-const: true
      description: "Give the model access to additional tools via remote Model Context Protocol \n(MCP) servers. [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n"
    MCPToolCall:
      title: MCP tool call
      required:
        - type
        - id
        - server_label
        - name
        - arguments
      type: object
      properties:
        arguments:
          type: string
          description: "A JSON string of the arguments passed to the tool.\n"
        error:
          type: string
          description: "The error from the tool call, if any.\n"
          nullable: true
        id:
          type: string
          description: "The unique ID of the tool call.\n"
        name:
          type: string
          description: "The name of the tool that was run.\n"
        output:
          type: string
          description: "The output from the tool call.\n"
          nullable: true
        server_label:
          type: string
          description: "The label of the MCP server running the tool.\n"
        type:
          enum:
            - mcp_call
          type: string
          description: "The type of the item. Always `mcp_call`.\n"
          x-stainless-const: true
      description: "An invocation of a tool on an MCP server.\n"
    MCPToolFilter:
      title: MCP tool filter
      type: object
      properties:
        read_only:
          type: boolean
          description: "Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n"
        tool_names:
          title: MCP allowed tools
          type: array
          items:
            type: string
          description: List of allowed tool names.
      additionalProperties: false
      description: "A filter object to specify which tools are allowed.\n"
    Message:
      title: Message
      required:
        - type
        - id
        - status
        - role
        - content
      type: object
      properties:
        content:
          type: array
          items:
            anyOf:
              - $ref: '#/components/schemas/InputTextContent-2'
              - $ref: '#/components/schemas/OutputTextContent-2'
              - $ref: '#/components/schemas/TextContent'
              - $ref: '#/components/schemas/SummaryTextContent'
              - $ref: '#/components/schemas/RefusalContent-2'
              - $ref: '#/components/schemas/InputImageContent-2'
              - $ref: '#/components/schemas/ComputerScreenshotContent'
              - $ref: '#/components/schemas/InputFileContent-2'
            discriminator:
              propertyName: type
          description: The content of the message
        id:
          type: string
          description: The unique ID of the message.
        role:
          enum:
            - unknown
            - user
            - assistant
            - system
            - critic
            - discriminator
            - developer
            - tool
          type: string
          description: 'The role of the message. One of `unknown`, `user`, `assistant`, `system`, `critic`, `discriminator`, `developer`, or `tool`.'
        status:
          enum:
            - in_progress
            - completed
            - incomplete
          type: string
          description: 'The status of item. One of `in_progress`, `completed`, or `incomplete`. Populated when items are returned via API.'
        type:
          enum:
            - message
          type: string
          description: The type of the message. Always set to `message`.
          default: message
          x-stainless-const: true
    MessageContent:
      anyOf:
        - $ref: '#/components/schemas/MessageContentImageFileObject'
        - $ref: '#/components/schemas/MessageContentImageUrlObject'
        - $ref: '#/components/schemas/MessageContentTextObject'
        - $ref: '#/components/schemas/MessageContentRefusalObject'
      discriminator:
        propertyName: type
    MessageContentDelta:
      anyOf:
        - $ref: '#/components/schemas/MessageDeltaContentImageFileObject'
        - $ref: '#/components/schemas/MessageDeltaContentTextObject'
        - $ref: '#/components/schemas/MessageDeltaContentRefusalObject'
        - $ref: '#/components/schemas/MessageDeltaContentImageUrlObject'
      discriminator:
        propertyName: type
    MessageContentImageFileObject:
      title: Image file
      required:
        - type
        - image_file
      type: object
      properties:
        image_file:
          required:
            - file_id
          type: object
          properties:
            detail:
              enum:
                - auto
                - low
                - high
              type: string
              description: 'Specifies the detail level of the image if specified by the user. `low` uses fewer tokens, you can opt in to high resolution using `high`.'
              default: auto
            file_id:
              type: string
              description: 'The [File](https://platform.openai.com/docs/api-reference/files) ID of the image in the message content. Set `purpose="vision"` when uploading the File if you need to later display the file content.'
        type:
          enum:
            - image_file
          type: string
          description: Always `image_file`.
          x-stainless-const: true
      description: 'References an image [File](https://platform.openai.com/docs/api-reference/files) in the content of a message.'
    MessageContentImageUrlObject:
      title: Image URL
      required:
        - type
        - image_url
      type: object
      properties:
        image_url:
          required:
            - url
          type: object
          properties:
            detail:
              enum:
                - auto
                - low
                - high
              type: string
              description: 'Specifies the detail level of the image. `low` uses fewer tokens, you can opt in to high resolution using `high`. Default value is `auto`'
              default: auto
            url:
              type: string
              description: 'The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp.'
              format: uri
        type:
          enum:
            - image_url
          type: string
          description: The type of the content part.
          x-stainless-const: true
      description: References an image URL in the content of a message.
    MessageContentRefusalObject:
      title: Refusal
      required:
        - type
        - refusal
      type: object
      properties:
        refusal:
          type: string
        type:
          enum:
            - refusal
          type: string
          description: Always `refusal`.
          x-stainless-const: true
      description: The refusal content generated by the assistant.
    MessageContentTextAnnotationsFileCitationObject:
      title: File citation
      required:
        - type
        - text
        - file_citation
        - start_index
        - end_index
      type: object
      properties:
        end_index:
          minimum: 0
          type: integer
        file_citation:
          required:
            - file_id
          type: object
          properties:
            file_id:
              type: string
              description: The ID of the specific File the citation is from.
        start_index:
          minimum: 0
          type: integer
        text:
          type: string
          description: The text in the message content that needs to be replaced.
        type:
          enum:
            - file_citation
          type: string
          description: Always `file_citation`.
          x-stainless-const: true
      description: A citation within the message that points to a specific quote from a specific File associated with the assistant or the message. Generated when the assistant uses the "file_search" tool to search files.
    MessageContentTextAnnotationsFilePathObject:
      title: File path
      required:
        - type
        - text
        - file_path
        - start_index
        - end_index
      type: object
      properties:
        end_index:
          minimum: 0
          type: integer
        file_path:
          required:
            - file_id
          type: object
          properties:
            file_id:
              type: string
              description: The ID of the file that was generated.
        start_index:
          minimum: 0
          type: integer
        text:
          type: string
          description: The text in the message content that needs to be replaced.
        type:
          enum:
            - file_path
          type: string
          description: Always `file_path`.
          x-stainless-const: true
      description: A URL for the file that's generated when the assistant used the `code_interpreter` tool to generate a file.
    MessageContentTextObject:
      title: Text
      required:
        - type
        - text
      type: object
      properties:
        text:
          required:
            - value
            - annotations
          type: object
          properties:
            annotations:
              type: array
              items:
                $ref: '#/components/schemas/TextAnnotation'
            value:
              type: string
              description: The data that makes up the text.
        type:
          enum:
            - text
          type: string
          description: Always `text`.
          x-stainless-const: true
      description: The text content that is part of a message.
    MessageDeltaContentImageFileObject:
      title: Image file
      required:
        - index
        - type
      type: object
      properties:
        image_file:
          type: object
          properties:
            detail:
              enum:
                - auto
                - low
                - high
              type: string
              description: 'Specifies the detail level of the image if specified by the user. `low` uses fewer tokens, you can opt in to high resolution using `high`.'
              default: auto
            file_id:
              type: string
              description: 'The [File](https://platform.openai.com/docs/api-reference/files) ID of the image in the message content. Set `purpose="vision"` when uploading the File if you need to later display the file content.'
        index:
          type: integer
          description: The index of the content part in the message.
        type:
          enum:
            - image_file
          type: string
          description: Always `image_file`.
          x-stainless-const: true
      description: 'References an image [File](https://platform.openai.com/docs/api-reference/files) in the content of a message.'
    MessageDeltaContentImageUrlObject:
      title: Image URL
      required:
        - index
        - type
      type: object
      properties:
        image_url:
          type: object
          properties:
            detail:
              enum:
                - auto
                - low
                - high
              type: string
              description: 'Specifies the detail level of the image. `low` uses fewer tokens, you can opt in to high resolution using `high`.'
              default: auto
            url:
              type: string
              description: 'The URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp.'
        index:
          type: integer
          description: The index of the content part in the message.
        type:
          enum:
            - image_url
          type: string
          description: Always `image_url`.
          x-stainless-const: true
      description: References an image URL in the content of a message.
    MessageDeltaContentRefusalObject:
      title: Refusal
      required:
        - index
        - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the refusal part in the message.
        refusal:
          type: string
        type:
          enum:
            - refusal
          type: string
          description: Always `refusal`.
          x-stainless-const: true
      description: The refusal content that is part of a message.
    MessageDeltaContentTextAnnotationsFileCitationObject:
      title: File citation
      required:
        - index
        - type
      type: object
      properties:
        end_index:
          minimum: 0
          type: integer
        file_citation:
          type: object
          properties:
            file_id:
              type: string
              description: The ID of the specific File the citation is from.
            quote:
              type: string
              description: The specific quote in the file.
        index:
          type: integer
          description: The index of the annotation in the text content part.
        start_index:
          minimum: 0
          type: integer
        text:
          type: string
          description: The text in the message content that needs to be replaced.
        type:
          enum:
            - file_citation
          type: string
          description: Always `file_citation`.
          x-stainless-const: true
      description: A citation within the message that points to a specific quote from a specific File associated with the assistant or the message. Generated when the assistant uses the "file_search" tool to search files.
    MessageDeltaContentTextAnnotationsFilePathObject:
      title: File path
      required:
        - index
        - type
      type: object
      properties:
        end_index:
          minimum: 0
          type: integer
        file_path:
          type: object
          properties:
            file_id:
              type: string
              description: The ID of the file that was generated.
        index:
          type: integer
          description: The index of the annotation in the text content part.
        start_index:
          minimum: 0
          type: integer
        text:
          type: string
          description: The text in the message content that needs to be replaced.
        type:
          enum:
            - file_path
          type: string
          description: Always `file_path`.
          x-stainless-const: true
      description: A URL for the file that's generated when the assistant used the `code_interpreter` tool to generate a file.
    MessageDeltaContentTextObject:
      title: Text
      required:
        - index
        - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the content part in the message.
        text:
          type: object
          properties:
            annotations:
              type: array
              items:
                $ref: '#/components/schemas/TextAnnotationDelta'
            value:
              type: string
              description: The data that makes up the text.
        type:
          enum:
            - text
          type: string
          description: Always `text`.
          x-stainless-const: true
      description: The text content that is part of a message.
    MessageDeltaObject:
      title: Message delta object
      required:
        - id
        - object
        - delta
      type: object
      properties:
        delta:
          type: object
          properties:
            content:
              type: array
              items:
                $ref: '#/components/schemas/MessageContentDelta'
              description: The content of the message in array of text and/or images.
            role:
              enum:
                - user
                - assistant
              type: string
              description: The entity that produced the message. One of `user` or `assistant`.
          description: The delta containing the fields that have changed on the Message.
        id:
          type: string
          description: 'The identifier of the message, which can be referenced in API endpoints.'
        object:
          enum:
            - thread.message.delta
          type: string
          description: 'The object type, which is always `thread.message.delta`.'
          x-stainless-const: true
      description: "Represents a message delta i.e. any changed fields on a message during streaming.\n"
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"msg_123\",\n  \"object\": \"thread.message.delta\",\n  \"delta\": {\n    \"content\": [\n      {\n        \"index\": 0,\n        \"type\": \"text\",\n        \"text\": { \"value\": \"Hello\", \"annotations\": [] }\n      }\n    ]\n  }\n}\n"
        name: The message delta object
    MessageObject:
      title: The message object
      required:
        - id
        - object
        - created_at
        - thread_id
        - role
        - content
        - assistant_id
        - run_id
        - attachments
        - metadata
      type: object
      properties:
        assistant_id:
          type: string
          description: 'If applicable, the ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) that authored this message.'
          nullable: true
        attachments:
          type: array
          items:
            type: object
            properties:
              file_id:
                type: string
                description: The ID of the file to attach to the message.
              tools:
                type: array
                items:
                  anyOf:
                    - $ref: '#/components/schemas/AssistantToolsCode'
                    - $ref: '#/components/schemas/AssistantToolsFileSearchTypeOnly'
                description: The tools to add this file to.
          description: 'A list of files attached to the message, and the tools they were added to.'
          nullable: true
        completed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the message was completed.
          nullable: true
        content:
          type: array
          items:
            $ref: '#/components/schemas/MessageContent'
          description: The content of the message in array of text and/or images.
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the message was created.
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints.'
        incomplete_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the message was marked as incomplete.
          nullable: true
        incomplete_details:
          required:
            - reason
          type: object
          properties:
            reason:
              enum:
                - content_filter
                - max_tokens
                - run_cancelled
                - run_expired
                - run_failed
              type: string
              description: The reason the message is incomplete.
          description: 'On an incomplete message, details about why the message is incomplete.'
          nullable: true
        metadata:
          $ref: '#/components/schemas/Metadata'
        object:
          enum:
            - thread.message
          type: string
          description: 'The object type, which is always `thread.message`.'
          x-stainless-const: true
        role:
          enum:
            - user
            - assistant
          type: string
          description: The entity that produced the message. One of `user` or `assistant`.
        run_id:
          type: string
          description: 'The ID of the [run](https://platform.openai.com/docs/api-reference/runs) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.'
          nullable: true
        status:
          enum:
            - in_progress
            - incomplete
            - completed
          type: string
          description: 'The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.'
        thread_id:
          type: string
          description: 'The [thread](https://platform.openai.com/docs/api-reference/threads) ID that this message belongs to.'
      description: 'Represents a message within a [thread](https://platform.openai.com/docs/api-reference/threads).'
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\",\n  \"created_at\": 1698983503,\n  \"thread_id\": \"thread_abc123\",\n  \"role\": \"assistant\",\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"value\": \"Hi! How can I help you today?\",\n        \"annotations\": []\n      }\n    }\n  ],\n  \"assistant_id\": \"asst_abc123\",\n  \"run_id\": \"run_abc123\",\n  \"attachments\": [],\n  \"metadata\": {}\n}\n"
        name: The message object
    MessageRequestContentTextObject:
      title: Text
      required:
        - type
        - text
      type: object
      properties:
        text:
          type: string
          description: Text content to be sent to the model
        type:
          enum:
            - text
          type: string
          description: Always `text`.
          x-stainless-const: true
      description: The text content that is part of a message.
    MessageStreamEvent:
      anyOf:
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/MessageObject'
            event:
              enum:
                - thread.message.created
              type: string
              x-stainless-const: true
          description: 'Occurs when a [message](https://platform.openai.com/docs/api-reference/messages/object) is created.'
          x-oaiMeta:
            dataDescription: '`data` is a [message](/docs/api-reference/messages/object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/MessageObject'
            event:
              enum:
                - thread.message.in_progress
              type: string
              x-stainless-const: true
          description: 'Occurs when a [message](https://platform.openai.com/docs/api-reference/messages/object) moves to an `in_progress` state.'
          x-oaiMeta:
            dataDescription: '`data` is a [message](/docs/api-reference/messages/object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/MessageDeltaObject'
            event:
              enum:
                - thread.message.delta
              type: string
              x-stainless-const: true
          description: 'Occurs when parts of a [Message](https://platform.openai.com/docs/api-reference/messages/object) are being streamed.'
          x-oaiMeta:
            dataDescription: '`data` is a [message delta](/docs/api-reference/assistants-streaming/message-delta-object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/MessageObject'
            event:
              enum:
                - thread.message.completed
              type: string
              x-stainless-const: true
          description: 'Occurs when a [message](https://platform.openai.com/docs/api-reference/messages/object) is completed.'
          x-oaiMeta:
            dataDescription: '`data` is a [message](/docs/api-reference/messages/object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/MessageObject'
            event:
              enum:
                - thread.message.incomplete
              type: string
              x-stainless-const: true
          description: 'Occurs when a [message](https://platform.openai.com/docs/api-reference/messages/object) ends before it is completed.'
          x-oaiMeta:
            dataDescription: '`data` is a [message](/docs/api-reference/messages/object)'
      discriminator:
        propertyName: event
    Metadata:
      type: object
      additionalProperties:
        type: string
      description: "Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard. \n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n"
      nullable: true
      x-oaiTypeLabel: map
    MetadataParam:
      maxProperties: 16
      type: object
      additionalProperties:
        maxLength: 512
        type: string
    Model:
      title: Model
      required:
        - id
        - object
        - created
        - owned_by
      properties:
        created:
          type: integer
          description: The Unix timestamp (in seconds) when the model was created.
        id:
          type: string
          description: 'The model identifier, which can be referenced in the API endpoints.'
        object:
          enum:
            - model
          type: string
          description: 'The object type, which is always "model".'
          x-stainless-const: true
        owned_by:
          type: string
          description: The organization that owns the model.
      description: Describes an OpenAI model offering that can be used with the API.
      x-oaiMeta:
        example: "{\n  \"id\": \"VAR_chat_model_id\",\n  \"object\": \"model\",\n  \"created\": 1686935002,\n  \"owned_by\": \"openai\"\n}\n"
        name: The model object
    ModelIds:
      anyOf:
        - $ref: '#/components/schemas/ModelIdsShared'
        - $ref: '#/components/schemas/ModelIdsResponses'
    ModelIdsResponses:
      anyOf:
        - $ref: '#/components/schemas/ModelIdsShared'
        - title: ResponsesOnlyModel
          enum:
            - o1-pro
            - o1-pro-2025-03-19
            - o3-pro
            - o3-pro-2025-06-10
            - o3-deep-research
            - o3-deep-research-2025-06-26
            - o4-mini-deep-research
            - o4-mini-deep-research-2025-06-26
            - computer-use-preview
            - computer-use-preview-2025-03-11
          type: string
      example: gpt-4o
    ModelIdsShared:
      anyOf:
        - type: string
        - $ref: '#/components/schemas/ChatModel'
      example: gpt-4o
    ModelResponseProperties:
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
        prompt_cache_key:
          type: string
          description: "Used by OpenAI to cache responses for similar requests to optimize your cache hit rates. Replaces the `user` field. [Learn more](https://platform.openai.com/docs/guides/prompt-caching).\n"
          example: prompt-cache-key-1234
        safety_identifier:
          type: string
          description: "A stable identifier used to help detect users of your application that may be violating OpenAI's usage policies. \nThe IDs should be a string that uniquely identifies each user. We recommend hashing their username or email address, in order to avoid sending us any identifying information. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n"
          example: safety-identifier-1234
        service_tier:
          $ref: '#/components/schemas/ServiceTier'
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\nWe generally recommend altering this or `top_p` but not both.\n"
          default: 1
          nullable: true
          example: 1
        top_logprobs:
          maximum: 20
          minimum: 0
          type: integer
          description: "An integer between 0 and 20 specifying the number of most likely tokens to\nreturn at each token position, each with an associated log probability.\n"
          nullable: true
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: "An alternative to sampling with temperature, called nucleus sampling,\nwhere the model considers the results of the tokens with top_p probability\nmass. So 0.1 means only the tokens comprising the top 10% probability mass\nare considered.\n\nWe generally recommend altering this or `temperature` but not both.\n"
          default: 1
          nullable: true
          example: 1
        user:
          type: string
          description: "This field is being replaced by `safety_identifier` and `prompt_cache_key`. Use `prompt_cache_key` instead to maintain caching optimizations.\nA stable identifier for your end-users. \nUsed to boost cache hit rates by better bucketing similar requests and  to help OpenAI detect and prevent abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n"
          example: user-1234
          deprecated: true
    ModerationImageURLInput:
      required:
        - type
        - image_url
      type: object
      properties:
        image_url:
          required:
            - url
          type: object
          properties:
            url:
              type: string
              description: Either a URL of the image or the base64 encoded image data.
              format: uri
              example: https://example.com/image.jpg
          description: Contains either an image URL or a data URL for a base64 encoded image.
        type:
          enum:
            - image_url
          type: string
          description: Always `image_url`.
          x-stainless-const: true
      description: An object describing an image to classify.
    ModerationTextInput:
      required:
        - type
        - text
      type: object
      properties:
        text:
          type: string
          description: A string of text to classify.
          example: I want to kill them
        type:
          enum:
            - text
          type: string
          description: Always `text`.
          x-stainless-const: true
      description: An object describing text to classify.
    ModifyAssistantRequest:
      type: object
      properties:
        description:
          maxLength: 512
          type: string
          description: "The description of the assistant. The maximum length is 512 characters.\n"
          nullable: true
        instructions:
          maxLength: 256000
          type: string
          description: "The system instructions that the assistant uses. The maximum length is 256,000 characters.\n"
          nullable: true
        metadata:
          $ref: '#/components/schemas/Metadata'
        model:
          anyOf:
            - type: string
            - $ref: '#/components/schemas/AssistantSupportedModels'
          description: "ID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models) for descriptions of them.\n"
        name:
          maxLength: 256
          type: string
          description: "The name of the assistant. The maximum length is 256 characters.\n"
          nullable: true
        reasoning_effort:
          $ref: '#/components/schemas/ReasoningEffort'
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n"
          default: 1
          nullable: true
          example: 1
        tool_resources:
          type: object
          properties:
            code_interpreter:
              type: object
              properties:
                file_ids:
                  maxItems: 20
                  type: array
                  items:
                    type: string
                  description: "Overrides the list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n"
            file_search:
              type: object
              properties:
                vector_store_ids:
                  maxItems: 1
                  type: array
                  items:
                    type: string
                  description: "Overrides the [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.\n"
          description: "A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n"
          nullable: true
        tools:
          maxItems: 128
          type: array
          items:
            $ref: '#/components/schemas/AssistantTool'
          description: "A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.\n"
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n"
          default: 1
          nullable: true
          example: 1
      additionalProperties: false
    ModifyCertificateRequest:
      required:
        - name
      type: object
      properties:
        name:
          type: string
          description: The updated name for the certificate
    ModifyMessageRequest:
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
      additionalProperties: false
    ModifyRunRequest:
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
      additionalProperties: false
    ModifyThreadRequest:
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
        tool_resources:
          type: object
          properties:
            code_interpreter:
              type: object
              properties:
                file_ids:
                  maxItems: 20
                  type: array
                  items:
                    type: string
                  description: "A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n"
            file_search:
              type: object
              properties:
                vector_store_ids:
                  maxItems: 1
                  type: array
                  items:
                    type: string
                  description: "The [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.\n"
          description: "A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n"
          nullable: true
      additionalProperties: false
    Move:
      title: Move
      required:
        - type
        - x
        - y
      type: object
      properties:
        type:
          enum:
            - move
          type: string
          description: "Specifies the event type. For a move action, this property is \nalways set to `move`.\n"
          default: move
          x-stainless-const: true
        x:
          type: integer
          description: "The x-coordinate to move to.\n"
        y:
          type: integer
          description: "The y-coordinate to move to.\n"
      description: "A mouse move action.\n"
    OpenAIFile:
      title: OpenAIFile
      required:
        - id
        - object
        - bytes
        - created_at
        - filename
        - purpose
        - status
      properties:
        bytes:
          type: integer
          description: 'The size of the file, in bytes.'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the file was created.
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the file will expire.
        filename:
          type: string
          description: The name of the file.
        id:
          type: string
          description: 'The file identifier, which can be referenced in the API endpoints.'
        object:
          enum:
            - file
          type: string
          description: 'The object type, which is always `file`.'
          x-stainless-const: true
        purpose:
          enum:
            - assistants
            - assistants_output
            - batch
            - batch_output
            - fine-tune
            - fine-tune-results
            - vision
            - user_data
          type: string
          description: 'The intended purpose of the file. Supported values are `assistants`, `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results`, `vision`, and `user_data`.'
        status:
          enum:
            - uploaded
            - processed
            - error
          type: string
          description: 'Deprecated. The current status of the file, which can be either `uploaded`, `processed`, or `error`.'
          deprecated: true
        status_details:
          type: string
          description: 'Deprecated. For details on why a fine-tuning training file failed validation, see the `error` field on `fine_tuning.job`.'
          deprecated: true
      description: The `File` object represents a document that has been uploaded to OpenAI.
      x-oaiMeta:
        example: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"bytes\": 120000,\n  \"created_at\": 1677610602,\n  \"expires_at\": 1680202602,\n  \"filename\": \"salesOverview.pdf\",\n  \"purpose\": \"assistants\",\n}\n"
        name: The file object
    OtherChunkingStrategyResponseParam:
      title: Other Chunking Strategy
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - other
          type: string
          description: Always `other`.
          x-stainless-const: true
      additionalProperties: false
      description: 'This is returned when the chunking strategy is unknown. Typically, this is because the file was indexed before the `chunking_strategy` concept was introduced in the API.'
    OutputAudio:
      title: Output audio
      required:
        - type
        - data
        - transcript
      type: object
      properties:
        data:
          type: string
          description: "Base64-encoded audio data from the model.\n"
        transcript:
          type: string
          description: "The transcript of the audio data from the model.\n"
        type:
          enum:
            - output_audio
          type: string
          description: "The type of the output audio. Always `output_audio`.\n"
          x-stainless-const: true
      description: "An audio output from the model.\n"
    OutputContent:
      anyOf:
        - $ref: '#/components/schemas/OutputTextContent'
        - $ref: '#/components/schemas/RefusalContent'
      discriminator:
        propertyName: type
    OutputItem:
      anyOf:
        - $ref: '#/components/schemas/OutputMessage'
        - $ref: '#/components/schemas/FileSearchToolCall'
        - $ref: '#/components/schemas/FunctionToolCall'
        - $ref: '#/components/schemas/WebSearchToolCall'
        - $ref: '#/components/schemas/ComputerToolCall'
        - $ref: '#/components/schemas/ReasoningItem'
        - $ref: '#/components/schemas/ImageGenToolCall'
        - $ref: '#/components/schemas/CodeInterpreterToolCall'
        - $ref: '#/components/schemas/LocalShellToolCall'
        - $ref: '#/components/schemas/MCPToolCall'
        - $ref: '#/components/schemas/MCPListTools'
        - $ref: '#/components/schemas/MCPApprovalRequest'
        - $ref: '#/components/schemas/CustomToolCall'
      discriminator:
        propertyName: type
    OutputMessage:
      title: Output message
      required:
        - id
        - type
        - role
        - content
        - status
      type: object
      properties:
        content:
          type: array
          items:
            $ref: '#/components/schemas/OutputContent'
          description: "The content of the output message.\n"
        id:
          type: string
          description: "The unique ID of the output message.\n"
          x-stainless-go-json: omitzero
        role:
          enum:
            - assistant
          type: string
          description: "The role of the output message. Always `assistant`.\n"
          x-stainless-const: true
        status:
          enum:
            - in_progress
            - completed
            - incomplete
          type: string
          description: "The status of the message input. One of `in_progress`, `completed`, or\n`incomplete`. Populated when input items are returned via API.\n"
        type:
          enum:
            - message
          type: string
          description: "The type of the output message. Always `message`.\n"
          x-stainless-const: true
      description: "An output message from the model.\n"
    OutputTextContent:
      title: Output text
      required:
        - type
        - text
        - annotations
      type: object
      properties:
        annotations:
          type: array
          items:
            $ref: '#/components/schemas/Annotation'
          description: The annotations of the text output.
        logprobs:
          type: array
          items:
            $ref: '#/components/schemas/LogProb'
        text:
          type: string
          description: The text output from the model.
        type:
          enum:
            - output_text
          type: string
          description: The type of the output text. Always `output_text`.
          default: output_text
          x-stainless-const: true
      description: A text output from the model.
    OutputTextContent-2:
      title: Output text
      required:
        - type
        - text
        - annotations
      type: object
      properties:
        annotations:
          type: array
          items:
            $ref: '#/components/schemas/Annotation-2'
          description: The annotations of the text output.
        logprobs:
          type: array
          items:
            $ref: '#/components/schemas/LogProb-2'
        text:
          type: string
          description: The text output from the model.
        type:
          enum:
            - output_text
          type: string
          description: The type of the output text. Always `output_text`.
          default: output_text
          x-stainless-const: true
    ParallelToolCalls:
      type: boolean
      description: 'Whether to enable [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.'
      nullable: true
    PartialImages:
      maximum: 3
      minimum: 0
      type: integer
      description: "The number of partial images to generate. This parameter is used for\nstreaming responses that return partial images. Value must be between 0 and 3.\nWhen set to 0, the response will be a single image sent in one streaming event.\n\nNote that the final image may be sent before the full number of partial images \nare generated if the full image is generated more quickly.\n"
      default: 0
      nullable: true
      example: 1
    PredictionContent:
      title: Static Content
      required:
        - type
        - content
      type: object
      properties:
        content:
          anyOf:
            - title: Text content
              type: string
              description: "The content used for a Predicted Output. This is often the\ntext of a file you are regenerating with minor changes.\n"
            - title: Array of content parts
              minItems: 1
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
              description: 'An array of content parts with a defined type. Supported options differ based on the [model](https://platform.openai.com/docs/models) being used to generate the response. Can contain text inputs.'
          description: "The content that should be matched when generating a model response.\nIf generated tokens would match this content, the entire model response\ncan be returned much more quickly.\n"
        type:
          enum:
            - content
          type: string
          description: "The type of the predicted content you want to provide. This type is\ncurrently always `content`.\n"
          x-stainless-const: true
      description: "Static predicted output content, such as the content of a text file that is\nbeing regenerated.\n"
    Project:
      required:
        - id
        - object
        - name
        - created_at
        - status
      type: object
      properties:
        archived_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the project was archived or `null`.
          nullable: true
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the project was created.
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints'
        name:
          type: string
          description: The name of the project. This appears in reporting.
        object:
          enum:
            - organization.project
          type: string
          description: 'The object type, which is always `organization.project`'
          x-stainless-const: true
        status:
          enum:
            - active
            - archived
          type: string
          description: '`active` or `archived`'
      description: Represents an individual project.
      x-oaiMeta:
        example: "{\n    \"id\": \"proj_abc\",\n    \"object\": \"organization.project\",\n    \"name\": \"Project example\",\n    \"created_at\": 1711471533,\n    \"archived_at\": null,\n    \"status\": \"active\"\n}\n"
        name: The project object
    ProjectApiKey:
      required:
        - object
        - redacted_value
        - name
        - created_at
        - last_used_at
        - id
        - owner
      type: object
      properties:
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the API key was created
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints'
        last_used_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the API key was last used.
        name:
          type: string
          description: The name of the API key
        object:
          enum:
            - organization.project.api_key
          type: string
          description: 'The object type, which is always `organization.project.api_key`'
          x-stainless-const: true
        owner:
          type: object
          properties:
            service_account:
              $ref: '#/components/schemas/ProjectServiceAccount'
            type:
              enum:
                - user
                - service_account
              type: string
              description: '`user` or `service_account`'
            user:
              $ref: '#/components/schemas/ProjectUser'
        redacted_value:
          type: string
          description: The redacted value of the API key
      description: Represents an individual API key in a project.
      x-oaiMeta:
        example: "{\n    \"object\": \"organization.project.api_key\",\n    \"redacted_value\": \"sk-abc...def\",\n    \"name\": \"My API Key\",\n    \"created_at\": 1711471533,\n    \"last_used_at\": 1711471534,\n    \"id\": \"key_abc\",\n    \"owner\": {\n        \"type\": \"user\",\n        \"user\": {\n            \"object\": \"organization.project.user\",\n            \"id\": \"user_abc\",\n            \"name\": \"First Last\",\n            \"email\": \"user@example.com\",\n            \"role\": \"owner\",\n            \"created_at\": 1711471533\n        }\n    }\n}\n"
        name: The project API key object
    ProjectApiKeyDeleteResponse:
      required:
        - object
        - id
        - deleted
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          enum:
            - organization.project.api_key.deleted
          type: string
          x-stainless-const: true
    ProjectApiKeyListResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/ProjectApiKey'
        first_id:
          type: string
        has_more:
          type: boolean
        last_id:
          type: string
        object:
          enum:
            - list
          type: string
          x-stainless-const: true
    ProjectCreateRequest:
      required:
        - name
      type: object
      properties:
        name:
          type: string
          description: 'The friendly name of the project, this name appears in reports.'
    ProjectListResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/Project'
        first_id:
          type: string
        has_more:
          type: boolean
        last_id:
          type: string
        object:
          enum:
            - list
          type: string
          x-stainless-const: true
    ProjectRateLimit:
      required:
        - object
        - id
        - model
        - max_requests_per_1_minute
        - max_tokens_per_1_minute
      type: object
      properties:
        batch_1_day_max_input_tokens:
          type: integer
          description: The maximum batch input tokens per day. Only present for relevant models.
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints.'
        max_audio_megabytes_per_1_minute:
          type: integer
          description: The maximum audio megabytes per minute. Only present for relevant models.
        max_images_per_1_minute:
          type: integer
          description: The maximum images per minute. Only present for relevant models.
        max_requests_per_1_day:
          type: integer
          description: The maximum requests per day. Only present for relevant models.
        max_requests_per_1_minute:
          type: integer
          description: The maximum requests per minute.
        max_tokens_per_1_minute:
          type: integer
          description: The maximum tokens per minute.
        model:
          type: string
          description: The model this rate limit applies to.
        object:
          enum:
            - project.rate_limit
          type: string
          description: 'The object type, which is always `project.rate_limit`'
          x-stainless-const: true
      description: Represents a project rate limit config.
      x-oaiMeta:
        example: "{\n    \"object\": \"project.rate_limit\",\n    \"id\": \"rl_ada\",\n    \"model\": \"ada\",\n    \"max_requests_per_1_minute\": 600,\n    \"max_tokens_per_1_minute\": 150000,\n    \"max_images_per_1_minute\": 10\n}\n"
        name: The project rate limit object
    ProjectRateLimitListResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/ProjectRateLimit'
        first_id:
          type: string
        has_more:
          type: boolean
        last_id:
          type: string
        object:
          enum:
            - list
          type: string
          x-stainless-const: true
    ProjectRateLimitUpdateRequest:
      type: object
      properties:
        batch_1_day_max_input_tokens:
          type: integer
          description: The maximum batch input tokens per day. Only relevant for certain models.
        max_audio_megabytes_per_1_minute:
          type: integer
          description: The maximum audio megabytes per minute. Only relevant for certain models.
        max_images_per_1_minute:
          type: integer
          description: The maximum images per minute. Only relevant for certain models.
        max_requests_per_1_day:
          type: integer
          description: The maximum requests per day. Only relevant for certain models.
        max_requests_per_1_minute:
          type: integer
          description: The maximum requests per minute.
        max_tokens_per_1_minute:
          type: integer
          description: The maximum tokens per minute.
    ProjectServiceAccount:
      required:
        - object
        - id
        - name
        - role
        - created_at
      type: object
      properties:
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the service account was created
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints'
        name:
          type: string
          description: The name of the service account
        object:
          enum:
            - organization.project.service_account
          type: string
          description: 'The object type, which is always `organization.project.service_account`'
          x-stainless-const: true
        role:
          enum:
            - owner
            - member
          type: string
          description: '`owner` or `member`'
      description: Represents an individual service account in a project.
      x-oaiMeta:
        example: "{\n    \"object\": \"organization.project.service_account\",\n    \"id\": \"svc_acct_abc\",\n    \"name\": \"Service Account\",\n    \"role\": \"owner\",\n    \"created_at\": 1711471533\n}\n"
        name: The project service account object
    ProjectServiceAccountApiKey:
      required:
        - object
        - value
        - name
        - created_at
        - id
      type: object
      properties:
        created_at:
          type: integer
        id:
          type: string
        name:
          type: string
        object:
          enum:
            - organization.project.service_account.api_key
          type: string
          description: 'The object type, which is always `organization.project.service_account.api_key`'
          x-stainless-const: true
        value:
          type: string
    ProjectServiceAccountCreateRequest:
      required:
        - name
      type: object
      properties:
        name:
          type: string
          description: The name of the service account being created.
    ProjectServiceAccountCreateResponse:
      required:
        - object
        - id
        - name
        - role
        - created_at
        - api_key
      type: object
      properties:
        api_key:
          $ref: '#/components/schemas/ProjectServiceAccountApiKey'
        created_at:
          type: integer
        id:
          type: string
        name:
          type: string
        object:
          enum:
            - organization.project.service_account
          type: string
          x-stainless-const: true
        role:
          enum:
            - member
          type: string
          description: Service accounts can only have one role of type `member`
          x-stainless-const: true
    ProjectServiceAccountDeleteResponse:
      required:
        - object
        - id
        - deleted
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          enum:
            - organization.project.service_account.deleted
          type: string
          x-stainless-const: true
    ProjectServiceAccountListResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/ProjectServiceAccount'
        first_id:
          type: string
        has_more:
          type: boolean
        last_id:
          type: string
        object:
          enum:
            - list
          type: string
          x-stainless-const: true
    ProjectUpdateRequest:
      required:
        - name
      type: object
      properties:
        name:
          type: string
          description: 'The updated name of the project, this name appears in reports.'
    ProjectUser:
      required:
        - object
        - id
        - name
        - email
        - role
        - added_at
      type: object
      properties:
        added_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the project was added.
        email:
          type: string
          description: The email address of the user
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints'
        name:
          type: string
          description: The name of the user
        object:
          enum:
            - organization.project.user
          type: string
          description: 'The object type, which is always `organization.project.user`'
          x-stainless-const: true
        role:
          enum:
            - owner
            - member
          type: string
          description: '`owner` or `member`'
      description: Represents an individual user in a project.
      x-oaiMeta:
        example: "{\n    \"object\": \"organization.project.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\n"
        name: The project user object
    ProjectUserCreateRequest:
      required:
        - user_id
        - role
      type: object
      properties:
        role:
          enum:
            - owner
            - member
          type: string
          description: '`owner` or `member`'
        user_id:
          type: string
          description: The ID of the user.
    ProjectUserDeleteResponse:
      required:
        - object
        - id
        - deleted
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          enum:
            - organization.project.user.deleted
          type: string
          x-stainless-const: true
    ProjectUserListResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/ProjectUser'
        first_id:
          type: string
        has_more:
          type: boolean
        last_id:
          type: string
        object:
          type: string
    ProjectUserUpdateRequest:
      required:
        - role
      type: object
      properties:
        role:
          enum:
            - owner
            - member
          type: string
          description: '`owner` or `member`'
    Prompt:
      required:
        - id
      type: object
      properties:
        id:
          type: string
          description: The unique identifier of the prompt template to use.
        variables:
          $ref: '#/components/schemas/ResponsePromptVariables'
        version:
          type: string
          description: Optional version of the prompt template.
          nullable: true
      description: "Reference to a prompt template and its variables. \n[Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n"
      nullable: true
    RankingOptions:
      type: object
      properties:
        ranker:
          enum:
            - auto
            - default-2024-11-15
          type: string
          description: The ranker to use for the file search.
        score_threshold:
          type: number
          description: 'The score threshold for the file search, a number between 0 and 1. Numbers closer to 1 will attempt to return only the most relevant results, but may return fewer results.'
    RealtimeAudioFormats:
      anyOf:
        - title: PCM audio format
          type: object
          properties:
            rate:
              enum:
                - 24000
              type: integer
              description: The sample rate of the audio. Always `24000`.
            type:
              enum:
                - audio/pcm
              type: string
              description: The audio format. Always `audio/pcm`.
          description: The PCM audio format. Only a 24kHz sample rate is supported.
        - title: PCMU audio format
          type: object
          properties:
            type:
              enum:
                - audio/pcmu
              type: string
              description: The audio format. Always `audio/pcmu`.
          description: The G.711 μ-law format.
        - title: PCMA audio format
          type: object
          properties:
            type:
              enum:
                - audio/pcma
              type: string
              description: The audio format. Always `audio/pcma`.
          description: The G.711 A-law format.
      discriminator:
        propertyName: type
    RealtimeClientEvent:
      anyOf:
        - $ref: '#/components/schemas/RealtimeClientEventConversationItemCreate'
        - $ref: '#/components/schemas/RealtimeClientEventConversationItemDelete'
        - $ref: '#/components/schemas/RealtimeClientEventConversationItemRetrieve'
        - $ref: '#/components/schemas/RealtimeClientEventConversationItemTruncate'
        - $ref: '#/components/schemas/RealtimeClientEventInputAudioBufferAppend'
        - $ref: '#/components/schemas/RealtimeClientEventInputAudioBufferClear'
        - $ref: '#/components/schemas/RealtimeClientEventOutputAudioBufferClear'
        - $ref: '#/components/schemas/RealtimeClientEventInputAudioBufferCommit'
        - $ref: '#/components/schemas/RealtimeClientEventResponseCancel'
        - $ref: '#/components/schemas/RealtimeClientEventResponseCreate'
        - $ref: '#/components/schemas/RealtimeClientEventSessionUpdate'
        - $ref: '#/components/schemas/RealtimeClientEventTranscriptionSessionUpdate'
      description: "A realtime client event.\n"
      discriminator:
        propertyName: type
    RealtimeClientEventConversationItemCreate:
      required:
        - type
        - item
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
        previous_item_id:
          type: string
          description: "The ID of the preceding item after which the new item will be inserted. \nIf not set, the new item will be appended to the end of the conversation.\nIf set to `root`, the new item will be added to the beginning of the conversation.\nIf set to an existing ID, it allows an item to be inserted mid-conversation. If the\nID cannot be found, an error will be returned and the item will not be added.\n"
        type:
          enum:
            - conversation.item.create
          description: 'The event type, must be `conversation.item.create`.'
          x-stainless-const: true
      description: "Add a new Item to the Conversation's context, including messages, function \ncalls, and function call responses. This event can be used both to populate a \n\"history\" of the conversation and to add new items mid-stream, but has the \ncurrent limitation that it cannot populate assistant audio messages.\n\nIf successful, the server will respond with a `conversation.item.created` \nevent, otherwise an `error` event will be sent.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"conversation.item.create\",\n  \"item\": {\n    \"type\": \"message\",\n    \"role\": \"user\",\n    \"content\": [\n      {\n        \"type\": \"input_text\",\n        \"text\": \"hi\"\n      }\n    ]\n  },\n  \"event_id\": \"b904fba0-0ec4-40af-8bbb-f908a9b26793\",\n  \"timestamp\": \"2:30:35 PM\"\n}\n"
        group: realtime
        name: conversation.item.create
    RealtimeClientEventConversationItemDelete:
      required:
        - type
        - item_id
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        item_id:
          type: string
          description: The ID of the item to delete.
        type:
          enum:
            - conversation.item.delete
          description: 'The event type, must be `conversation.item.delete`.'
          x-stainless-const: true
      description: "Send this event when you want to remove any item from the conversation \nhistory. The server will respond with a `conversation.item.deleted` event, \nunless the item does not exist in the conversation history, in which case the \nserver will respond with an error.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_901\",\n    \"type\": \"conversation.item.delete\",\n    \"item_id\": \"msg_003\"\n}\n"
        group: realtime
        name: conversation.item.delete
    RealtimeClientEventConversationItemRetrieve:
      required:
        - type
        - item_id
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        item_id:
          type: string
          description: The ID of the item to retrieve.
        type:
          enum:
            - conversation.item.retrieve
          description: 'The event type, must be `conversation.item.retrieve`.'
          x-stainless-const: true
      description: "Send this event when you want to retrieve the server's representation of a specific item in the conversation history. This is useful, for example, to inspect user audio after noise cancellation and VAD.\nThe server will respond with a `conversation.item.retrieved` event, \nunless the item does not exist in the conversation history, in which case the \nserver will respond with an error.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_901\",\n    \"type\": \"conversation.item.retrieve\",\n    \"item_id\": \"msg_003\"\n}\n"
        group: realtime
        name: conversation.item.retrieve
    RealtimeClientEventConversationItemTruncate:
      required:
        - type
        - item_id
        - content_index
        - audio_end_ms
      type: object
      properties:
        audio_end_ms:
          type: integer
          description: "Inclusive duration up to which audio is truncated, in milliseconds. If \nthe audio_end_ms is greater than the actual audio duration, the server \nwill respond with an error.\n"
        content_index:
          type: integer
          description: The index of the content part to truncate. Set this to 0.
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        item_id:
          type: string
          description: "The ID of the assistant message item to truncate. Only assistant message \nitems can be truncated.\n"
        type:
          enum:
            - conversation.item.truncate
          description: 'The event type, must be `conversation.item.truncate`.'
          x-stainless-const: true
      description: "Send this event to truncate a previous assistant message’s audio. The server \nwill produce audio faster than realtime, so this event is useful when the user \ninterrupts to truncate audio that has already been sent to the client but not \nyet played. This will synchronize the server's understanding of the audio with \nthe client's playback.\n\nTruncating audio will delete the server-side text transcript to ensure there \nis not text in the context that hasn't been heard by the user.\n\nIf successful, the server will respond with a `conversation.item.truncated` \nevent. \n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_678\",\n    \"type\": \"conversation.item.truncate\",\n    \"item_id\": \"msg_002\",\n    \"content_index\": 0,\n    \"audio_end_ms\": 1500\n}\n"
        group: realtime
        name: conversation.item.truncate
    RealtimeClientEventInputAudioBufferAppend:
      required:
        - type
        - audio
      type: object
      properties:
        audio:
          type: string
          description: "Base64-encoded audio bytes. This must be in the format specified by the \n`input_audio_format` field in the session configuration.\n"
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        type:
          enum:
            - input_audio_buffer.append
          description: 'The event type, must be `input_audio_buffer.append`.'
          x-stainless-const: true
      description: "Send this event to append audio bytes to the input audio buffer. The audio \nbuffer is temporary storage you can write to and later commit. In Server VAD \nmode, the audio buffer is used to detect speech and the server will decide \nwhen to commit. When Server VAD is disabled, you must commit the audio buffer\nmanually.\n\nThe client may choose how much audio to place in each event up to a maximum \nof 15 MiB, for example streaming smaller chunks from the client may allow the \nVAD to be more responsive. Unlike made other client events, the server will \nnot send a confirmation response to this event.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_456\",\n    \"type\": \"input_audio_buffer.append\",\n    \"audio\": \"Base64EncodedAudioData\"\n}\n"
        group: realtime
        name: input_audio_buffer.append
    RealtimeClientEventInputAudioBufferClear:
      required:
        - type
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        type:
          enum:
            - input_audio_buffer.clear
          description: 'The event type, must be `input_audio_buffer.clear`.'
          x-stainless-const: true
      description: "Send this event to clear the audio bytes in the buffer. The server will \nrespond with an `input_audio_buffer.cleared` event.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_012\",\n    \"type\": \"input_audio_buffer.clear\"\n}\n"
        group: realtime
        name: input_audio_buffer.clear
    RealtimeClientEventInputAudioBufferCommit:
      required:
        - type
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        type:
          enum:
            - input_audio_buffer.commit
          description: 'The event type, must be `input_audio_buffer.commit`.'
          x-stainless-const: true
      description: "Send this event to commit the user input audio buffer, which will create a \nnew user message item in the conversation. This event will produce an error \nif the input audio buffer is empty. When in Server VAD mode, the client does \nnot need to send this event, the server will commit the audio buffer \nautomatically.\n\nCommitting the input audio buffer will trigger input audio transcription \n(if enabled in session configuration), but it will not create a response \nfrom the model. The server will respond with an `input_audio_buffer.committed` \nevent.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_789\",\n    \"type\": \"input_audio_buffer.commit\"\n}\n"
        group: realtime
        name: input_audio_buffer.commit
    RealtimeClientEventOutputAudioBufferClear:
      required:
        - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the client event used for error handling.
        type:
          enum:
            - output_audio_buffer.clear
          description: 'The event type, must be `output_audio_buffer.clear`.'
          x-stainless-const: true
      description: "**WebRTC Only:** Emit to cut off the current audio response. This will trigger the server to\nstop generating audio and emit a `output_audio_buffer.cleared` event. This \nevent should be preceded by a `response.cancel` client event to stop the \ngeneration of the current response.\n[Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"optional_client_event_id\",\n    \"type\": \"output_audio_buffer.clear\"\n}\n"
        group: realtime
        name: output_audio_buffer.clear
    RealtimeClientEventResponseCancel:
      required:
        - type
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        response_id:
          type: string
          description: "A specific response ID to cancel - if not provided, will cancel an \nin-progress response in the default conversation.\n"
        type:
          enum:
            - response.cancel
          description: 'The event type, must be `response.cancel`.'
          x-stainless-const: true
      description: "Send this event to cancel an in-progress response. The server will respond \nwith a `response.done` event with a status of `response.status=cancelled`. If \nthere is no response to cancel, the server will respond with an error.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_567\",\n    \"type\": \"response.cancel\"\n}\n"
        group: realtime
        name: response.cancel
    RealtimeClientEventResponseCreate:
      required:
        - type
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        response:
          $ref: '#/components/schemas/RealtimeResponseCreateParams'
        type:
          enum:
            - response.create
          description: 'The event type, must be `response.create`.'
          x-stainless-const: true
      description: "This event instructs the server to create a Response, which means triggering \nmodel inference. When in Server VAD mode, the server will create Responses \nautomatically.\n\nA Response will include at least one Item, and may have two, in which case \nthe second will be a function call. These Items will be appended to the \nconversation history.\n\nThe server will respond with a `response.created` event, events for Items \nand content created, and finally a `response.done` event to indicate the \nResponse is complete.\n\nThe `response.create` event includes inference configuration like \n`instructions`, and `temperature`. These fields will override the Session's \nconfiguration for this Response only.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.create\",\n  \"event_id\": \"xxx\",\n  \"timestamp\": \"2:30:35 PM\"\n}\n"
        group: realtime
        name: response.create
    RealtimeClientEventSessionUpdate:
      required:
        - type
        - session
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        session:
          $ref: '#/components/schemas/RealtimeSessionCreateRequest'
        type:
          enum:
            - session.update
          description: 'The event type, must be `session.update`.'
          x-stainless-const: true
      description: "Send this event to update the session’s default configuration.\nThe client may send this event at any time to update any field,\nexcept for `voice`. However, note that once a session has been\ninitialized with a particular `model`, it can’t be changed to\nanother model using `session.update`.\n\nWhen the server receives a `session.update`, it will respond\nwith a `session.updated` event showing the full, effective configuration.\nOnly the fields that are present are updated. To clear a field like\n`instructions`, pass an empty string.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"session.update\",\n  \"session\": {\n    \"type\": \"realtime\",\n    \"tools\": [\n      {\n        \"type\": \"function\",\n        \"name\": \"display_color_palette\",\n        \"description\": \"\\nCall this function when a user asks for a color palette.\\n\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"strict\": true,\n          \"properties\": {\n            \"theme\": {\n              \"type\": \"string\",\n              \"description\": \"Description of the theme for the color scheme.\"\n            },\n            \"colors\": {\n              \"type\": \"array\",\n              \"description\": \"Array of five hex color codes based on the theme.\",\n              \"items\": {\n                \"type\": \"string\",\n                \"description\": \"Hex color code\"\n              }\n            }\n          },\n          \"required\": [\n            \"theme\",\n            \"colors\"\n          ]\n        }\n      }\n    ],\n    \"tool_choice\": \"auto\"\n  },\n  \"event_id\": \"5fc543c4-f59c-420f-8fb9-68c45d1546a7\",\n  \"timestamp\": \"2:30:32 PM\"\n}\n"
        group: realtime
        name: session.update
    RealtimeClientEventTranscriptionSessionUpdate:
      required:
        - type
        - session
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        session:
          $ref: '#/components/schemas/RealtimeTranscriptionSessionCreateRequest'
        type:
          enum:
            - transcription_session.update
          description: 'The event type, must be `transcription_session.update`.'
          x-stainless-const: true
      description: "Send this event to update a transcription session.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"transcription_session.update\",\n  \"session\": {\n    \"input_audio_format\": \"pcm16\",\n    \"input_audio_transcription\": {\n      \"model\": \"gpt-4o-transcribe\",\n      \"prompt\": \"\",\n      \"language\": \"\"\n    },\n    \"turn_detection\": {\n      \"type\": \"server_vad\",\n      \"threshold\": 0.5,\n      \"prefix_padding_ms\": 300,\n      \"silence_duration_ms\": 500,\n      \"create_response\": true,\n    },\n    \"input_audio_noise_reduction\": {\n      \"type\": \"near_field\"\n    },\n    \"include\": [\n      \"item.input_audio_transcription.logprobs\",\n    ]\n  }\n}\n"
        group: realtime
        name: transcription_session.update
    RealtimeConnectParams:
      required:
        - model
      type: object
      properties:
        model:
          type: string
    RealtimeConversationItem:
      type: object
      properties:
        id:
          type: string
          description: The unique ID of the item.
          example: msg_003
        object:
          enum:
            - realtime.item
          type: string
          description: 'The object type, must be "realtime.item".'
          example: realtime.item
        type:
          enum:
            - message
            - function_call
            - function_call_output
          type: string
          description: The type of the item.
          example: message
        status:
          enum:
            - completed
            - in_progress
            - incomplete
          type: string
          description: The status of the item.
          example: completed
        role:
          enum:
            - user
            - assistant
            - system
          type: string
          description: The role of the message sender.
          example: user
        content:
          type: array
          items:
            type: object
            properties:
              type:
                enum:
                  - input_text
                  - input_audio
                  - text
                  - audio
                type: string
                description: The content type.
                example: input_text
              text:
                type: string
                description: The text content (for text or input_text items).
                example: 'Hello, how are you?'
              audio:
                type: string
                description: Base64-encoded audio bytes (for audio or input_audio items).
              transcript:
                type: string
                description: The transcript of the audio (for audio items).
              call_id:
                type: string
                description: The ID of the function call (for function_call items).
              name:
                type: string
                description: The name of the function being called (for function_call items).
              arguments:
                type: string
                description: The arguments of the function call (for function_call items).
              output:
                type: string
                description: The output of the function call (for function_call_output items).
          description: The content of the message.
      description: "A realtime Item is of three types: message, function_call, or function_call_output.\n\nA message item can contain text or audio.\nA function_call item indicates a model's desire to call a function, which is the only tool supported for now\nA function_call_output item indicates a function response.\nThe client may add and remove message and function_call_output Items using conversation.item.create and conversation.item.delete.\n"
    RealtimeConversationItemFunctionCall:
      title: Realtime function call item
      required:
        - type
        - name
        - arguments
      type: object
      properties:
        arguments:
          type: string
          description: The arguments of the function call.
        call_id:
          type: string
          description: The ID of the function call.
        id:
          type: string
          description: The unique ID of the item.
        name:
          type: string
          description: The name of the function being called.
        object:
          enum:
            - realtime.item
          type: string
          description: Identifier for the API object being returned - always `realtime.item`.
          x-stainless-const: true
        status:
          enum:
            - completed
            - incomplete
            - in_progress
          type: string
          description: The status of the item. Has no effect on the conversation.
        type:
          enum:
            - function_call
          type: string
          description: The type of the item. Always `function_call`.
          x-stainless-const: true
      description: A function call item in a Realtime conversation.
    RealtimeConversationItemFunctionCallOutput:
      title: Realtime function call output item
      required:
        - type
        - call_id
        - output
      type: object
      properties:
        call_id:
          type: string
          description: The ID of the function call this output is for.
        id:
          type: string
          description: The unique ID of the item.
        object:
          enum:
            - realtime.item
          type: string
          description: Identifier for the API object being returned - always `realtime.item`.
          x-stainless-const: true
        output:
          type: string
          description: The output of the function call.
        status:
          enum:
            - completed
            - incomplete
            - in_progress
          type: string
          description: The status of the item. Has no effect on the conversation.
        type:
          enum:
            - function_call_output
          type: string
          description: The type of the item. Always `function_call_output`.
          x-stainless-const: true
      description: A function call output item in a Realtime conversation.
    RealtimeConversationItemMessageAssistant:
      title: Realtime assistant message item
      required:
        - type
        - role
        - content
      type: object
      properties:
        content:
          type: array
          items:
            type: object
            properties:
              text:
                type: string
                description: The text content.
              type:
                enum:
                  - text
                type: string
                description: The content type. Always `text` for assistant messages.
                x-stainless-const: true
          description: The content of the message.
        id:
          type: string
          description: The unique ID of the item.
        object:
          enum:
            - realtime.item
          type: string
          description: Identifier for the API object being returned - always `realtime.item`.
          x-stainless-const: true
        role:
          enum:
            - assistant
          type: string
          description: The role of the message sender. Always `assistant`.
          x-stainless-const: true
        status:
          enum:
            - completed
            - incomplete
            - in_progress
          type: string
          description: The status of the item. Has no effect on the conversation.
        type:
          enum:
            - message
          type: string
          description: The type of the item. Always `message`.
          x-stainless-const: true
      description: An assistant message item in a Realtime conversation.
    RealtimeConversationItemMessageSystem:
      title: Realtime system message item
      required:
        - type
        - role
        - content
      type: object
      properties:
        content:
          type: array
          items:
            type: object
            properties:
              text:
                type: string
                description: The text content.
              type:
                enum:
                  - input_text
                type: string
                description: The content type. Always `input_text` for system messages.
                x-stainless-const: true
          description: The content of the message.
        id:
          type: string
          description: The unique ID of the item.
        object:
          enum:
            - realtime.item
          type: string
          description: Identifier for the API object being returned - always `realtime.item`.
          x-stainless-const: true
        role:
          enum:
            - system
          type: string
          description: The role of the message sender. Always `system`.
          x-stainless-const: true
        status:
          enum:
            - completed
            - incomplete
            - in_progress
          type: string
          description: The status of the item. Has no effect on the conversation.
        type:
          enum:
            - message
          type: string
          description: The type of the item. Always `message`.
          x-stainless-const: true
      description: A system message item in a Realtime conversation.
    RealtimeConversationItemMessageUser:
      title: Realtime user message item
      required:
        - type
        - role
        - content
      type: object
      properties:
        content:
          type: array
          items:
            type: object
            properties:
              audio:
                type: string
                description: Base64-encoded audio bytes (for `input_audio`).
              text:
                type: string
                description: The text content (for `input_text`).
              transcript:
                type: string
                description: Transcript of the audio (for `input_audio`).
              type:
                enum:
                  - input_text
                  - input_audio
                type: string
                description: The content type (`input_text` or `input_audio`).
          description: The content of the message.
        id:
          type: string
          description: The unique ID of the item.
        object:
          enum:
            - realtime.item
          type: string
          description: Identifier for the API object being returned - always `realtime.item`.
          x-stainless-const: true
        role:
          enum:
            - user
          type: string
          description: The role of the message sender. Always `user`.
          x-stainless-const: true
        status:
          enum:
            - completed
            - incomplete
            - in_progress
          type: string
          description: The status of the item. Has no effect on the conversation.
        type:
          enum:
            - message
          type: string
          description: The type of the item. Always `message`.
          x-stainless-const: true
      description: A user message item in a Realtime conversation.
    RealtimeConversationItemWithReference:
      type: object
      properties:
        arguments:
          type: string
          description: "The arguments of the function call (for `function_call` items).\n"
        call_id:
          type: string
          description: "The ID of the function call (for `function_call` and \n`function_call_output` items). If passed on a `function_call_output` \nitem, the server will check that a `function_call` item with the same \nID exists in the conversation history.\n"
        content:
          type: array
          items:
            type: object
            properties:
              audio:
                type: string
                description: "Base64-encoded audio bytes, used for `input_audio` content type.\n"
              id:
                type: string
                description: "ID of a previous conversation item to reference (for `item_reference`\ncontent types in `response.create` events). These can reference both\nclient and server created items.\n"
              text:
                type: string
                description: "The text content, used for `input_text` and `text` content types.\n"
              transcript:
                type: string
                description: "The transcript of the audio, used for `input_audio` content type.\n"
              type:
                enum:
                  - input_text
                  - input_audio
                  - item_reference
                  - text
                type: string
                description: "The content type (`input_text`, `input_audio`, `item_reference`, `text`).\n"
          description: "The content of the message, applicable for `message` items. \n- Message items of role `system` support only `input_text` content\n- Message items of role `user` support `input_text` and `input_audio` \n  content\n- Message items of role `assistant` support `text` content.\n"
        id:
          type: string
          description: "For an item of type (`message` | `function_call` | `function_call_output`)\nthis field allows the client to assign the unique ID of the item. It is\nnot required because the server will generate one if not provided.\n\nFor an item of type `item_reference`, this field is required and is a\nreference to any item that has previously existed in the conversation.\n"
        name:
          type: string
          description: "The name of the function being called (for `function_call` items).\n"
        object:
          enum:
            - realtime.item
          type: string
          description: "Identifier for the API object being returned - always `realtime.item`.\n"
          x-stainless-const: true
        output:
          type: string
          description: "The output of the function call (for `function_call_output` items).\n"
        role:
          enum:
            - user
            - assistant
            - system
          type: string
          description: "The role of the message sender (`user`, `assistant`, `system`), only \napplicable for `message` items.\n"
        status:
          enum:
            - completed
            - incomplete
            - in_progress
          type: string
          description: "The status of the item (`completed`, `incomplete`, `in_progress`). These have no effect \non the conversation, but are accepted for consistency with the \n`conversation.item.created` event.\n"
        type:
          enum:
            - message
            - function_call
            - function_call_output
            - item_reference
          type: string
          description: "The type of the item (`message`, `function_call`, `function_call_output`, `item_reference`).\n"
      description: The item to add to the conversation.
    RealtimeCreateClientSecretRequest:
      title: Realtime session configuration
      type: object
      properties:
        expires_after:
          title: Client secret expiration
          type: object
          properties:
            anchor:
              enum:
                - created_at
              type: string
              description: "The anchor point for the ephemeral token expiration. Only `created_at` is currently supported.\n"
              default: created_at
              x-stainless-const: true
            seconds:
              maximum: 7200
              minimum: 10
              type: integer
              description: "The number of seconds from the anchor point to the expiration. Select a value between `10` and `7200`.\n"
              default: 600
          description: "Configuration for the ephemeral token expiration.\n"
        session:
          title: Session configuration
          anyOf:
            - $ref: '#/components/schemas/RealtimeSessionCreateRequest'
            - $ref: '#/components/schemas/RealtimeTranscriptionSessionCreateRequest'
          description: "Session configuration to use for the client secret. Choose either a realtime\nsession or a transcription session.\n"
          discriminator:
            propertyName: type
      description: "Create a session and client secret for the Realtime API. The request can specify\neither a realtime or a transcription session configuration.\n[Learn more about the Realtime API](https://platform.openai.com/docs/guides/realtime).\n"
    RealtimeCreateClientSecretResponse:
      title: Realtime session and client secret
      required:
        - value
        - expires_at
        - session
      type: object
      properties:
        expires_at:
          type: integer
          description: 'Expiration timestamp for the client secret, in seconds since epoch.'
        session:
          title: Session configuration
          anyOf:
            - $ref: '#/components/schemas/RealtimeSessionCreateResponse'
            - $ref: '#/components/schemas/RealtimeTranscriptionSessionCreateResponse'
          description: "The session configuration for either a realtime or transcription session.\n"
        value:
          type: string
          description: The generated client secret value.
      description: "Response from creating a session and client secret for the Realtime API.\n"
      x-oaiMeta:
        example: "{\n  \"value\": \"ek_68af296e8e408191a1120ab6383263c2\",\n  \"expires_at\": 1756310470,\n  \"session\": {\n    \"type\": \"realtime\",\n    \"object\": \"realtime.session\",\n    \"id\": \"sess_C9CiUVUzUzYIssh3ELY1d\",\n    \"model\": \"gpt-4o-realtime-preview\",\n    \"output_modalities\": [\n      \"audio\"\n    ],\n    \"instructions\": \"You are a friendly assistant.\",\n    \"tools\": [],\n    \"tool_choice\": \"auto\",\n    \"max_output_tokens\": \"inf\",\n    \"tracing\": null,\n    \"truncation\": \"auto\",\n    \"prompt\": null,\n    \"expires_at\": 0,\n    \"audio\": {\n      \"input\": {\n        \"format\": {\n          \"type\": \"audio/pcm\",\n          \"rate\": 24000\n        },\n        \"transcription\": null,\n        \"noise_reduction\": null,\n        \"turn_detection\": {\n          \"type\": \"server_vad\",\n          \"threshold\": 0.5,\n          \"prefix_padding_ms\": 300,\n          \"silence_duration_ms\": 200,\n          \"idle_timeout_ms\": null,\n          \"create_response\": true,\n          \"interrupt_response\": true\n        }\n      },\n      \"output\": {\n        \"format\": {\n          \"type\": \"audio/pcm\",\n          \"rate\": 24000\n        },\n        \"voice\": \"alloy\",\n        \"speed\": 1.0\n      }\n    },\n    \"include\": null\n  }\n}\n"
        group: realtime
        name: Session response object
    RealtimeMCPApprovalRequest:
      title: Realtime MCP approval request
      required:
        - type
        - id
        - server_label
        - name
        - arguments
      type: object
      properties:
        arguments:
          type: string
          description: A JSON string of arguments for the tool.
        id:
          type: string
          description: The unique ID of the approval request.
        name:
          type: string
          description: The name of the tool to run.
        server_label:
          type: string
          description: The label of the MCP server making the request.
        type:
          enum:
            - mcp_approval_request
          type: string
          description: The type of the item. Always `mcp_approval_request`.
          x-stainless-const: true
      description: "A Realtime item requesting human approval of a tool invocation.\n"
    RealtimeMCPApprovalResponse:
      title: Realtime MCP approval response
      required:
        - type
        - id
        - approval_request_id
        - approve
      type: object
      properties:
        approval_request_id:
          type: string
          description: The ID of the approval request being answered.
        approve:
          type: boolean
          description: Whether the request was approved.
        id:
          type: string
          description: The unique ID of the approval response.
        reason:
          type: string
          description: Optional reason for the decision.
          nullable: true
        type:
          enum:
            - mcp_approval_response
          type: string
          description: The type of the item. Always `mcp_approval_response`.
          x-stainless-const: true
      description: "A Realtime item responding to an MCP approval request.\n"
    RealtimeMCPHTTPError:
      title: Realtime MCP HTTP error
      required:
        - type
        - code
        - message
      type: object
      properties:
        code:
          type: integer
        message:
          type: string
        type:
          enum:
            - http_error
          type: string
          x-stainless-const: true
    RealtimeMCPListTools:
      title: Realtime MCP list tools
      required:
        - type
        - server_label
        - tools
      type: object
      properties:
        id:
          type: string
          description: The unique ID of the list.
        server_label:
          type: string
          description: The label of the MCP server.
        tools:
          type: array
          items:
            $ref: '#/components/schemas/MCPListToolsTool'
          description: The tools available on the server.
        type:
          enum:
            - mcp_list_tools
          type: string
          description: The type of the item. Always `mcp_list_tools`.
          x-stainless-const: true
      description: "A Realtime item listing tools available on an MCP server.\n"
    RealtimeMCPProtocolError:
      title: Realtime MCP protocol error
      required:
        - type
        - code
        - message
      type: object
      properties:
        code:
          type: integer
        message:
          type: string
        type:
          enum:
            - protocol_error
          type: string
          x-stainless-const: true
    RealtimeMCPToolCall:
      title: Realtime MCP tool call
      required:
        - type
        - id
        - server_label
        - name
        - arguments
      type: object
      properties:
        approval_request_id:
          type: string
          description: 'The ID of an associated approval request, if any.'
          nullable: true
        arguments:
          type: string
          description: A JSON string of the arguments passed to the tool.
        error:
          anyOf:
            - $ref: '#/components/schemas/RealtimeMCPProtocolError'
            - $ref: '#/components/schemas/RealtimeMCPToolExecutionError'
            - $ref: '#/components/schemas/RealtimeMCPHTTPError'
          description: 'The error from the tool call, if any.'
          nullable: true
          discriminator:
            propertyName: type
        id:
          type: string
          description: The unique ID of the tool call.
        name:
          type: string
          description: The name of the tool that was run.
        output:
          type: string
          description: The output from the tool call.
          nullable: true
        server_label:
          type: string
          description: The label of the MCP server running the tool.
        type:
          enum:
            - mcp_tool_call
          type: string
          description: The type of the item. Always `mcp_tool_call`.
          x-stainless-const: true
      description: "A Realtime item representing an invocation of a tool on an MCP server.\n"
    RealtimeMCPToolExecutionError:
      title: Realtime MCP tool execution error
      required:
        - type
        - message
      type: object
      properties:
        message:
          type: string
        type:
          enum:
            - tool_execution_error
          type: string
          x-stainless-const: true
    RealtimeResponse:
      type: object
      properties:
        id:
          type: string
          description: The unique ID of the response.
          example: resp_001
        object:
          enum:
            - realtime.response
          type: string
          description: 'The object type, must be "realtime.response".'
          example: realtime.response
        status:
          enum:
            - completed
            - in_progress
            - cancelled
            - failed
            - incomplete
          type: string
          description: The status of the response.
          example: in_progress
        status_details:
          type: object
          description: Additional details about the status.
          example: 
        output:
          type: array
          items:
            $ref: '#/components/schemas/RealtimeConversationItem'
          description: The list of output items generated by the response.
        usage:
          type: object
          properties:
            total_tokens:
              type: integer
              description: The total number of tokens used.
              example: 50
            input_tokens:
              type: integer
              description: The number of input tokens used.
              example: 20
            output_tokens:
              type: integer
              description: The number of output tokens used.
              example: 30
          description: Usage statistics for the response.
      description: The response resource.
    RealtimeResponseCreateParams:
      type: object
      properties:
        conversation:
          anyOf:
            - type: string
            - enum:
                - auto
                - none
              type: string
              default: auto
          description: "Controls which conversation the response is added to. Currently supports\n`auto` and `none`, with `auto` as the default value. The `auto` value\nmeans that the contents of the response will be added to the default\nconversation. Set this to `none` to create an out-of-band response which \nwill not add items to default conversation.\n"
        input:
          type: array
          items:
            $ref: '#/components/schemas/RealtimeConversationItem'
          description: "Input items to include in the prompt for the model. Using this field\ncreates a new context for this Response instead of using the default\nconversation. An empty array `[]` will clear the context for this Response.\nNote that this can include references to items from the default conversation.\n"
        instructions:
          type: string
          description: "The default system instructions (i.e. system message) prepended to model \ncalls. This field allows the client to guide the model on desired \nresponses. The model can be instructed on response content and format, \n(e.g. \"be extremely succinct\", \"act friendly\", \"here are examples of good \nresponses\") and on audio behavior (e.g. \"talk quickly\", \"inject emotion \ninto your voice\", \"laugh frequently\"). The instructions are not guaranteed \nto be followed by the model, but they provide guidance to the model on the \ndesired behavior.\n\nNote that the server sets default instructions which will be used if this \nfield is not set and are visible in the `session.created` event at the \nstart of the session.\n"
        max_output_tokens:
          anyOf:
            - type: integer
            - enum:
                - inf
              type: string
              x-stainless-const: true
          description: "Maximum number of output tokens for a single assistant response,\ninclusive of tool calls. Provide an integer between 1 and 4096 to\nlimit output tokens, or `inf` for the maximum available tokens for a\ngiven model. Defaults to `inf`.\n"
        metadata:
          $ref: '#/components/schemas/Metadata'
        modalities:
          type: array
          items:
            enum:
              - text
              - audio
            type: string
          description: "The set of modalities the model can respond with. To disable audio,\nset this to [\"text\"].\n"
        output_audio_format:
          enum:
            - pcm16
            - g711_ulaw
            - g711_alaw
          type: string
          description: "The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n"
        prompt:
          $ref: '#/components/schemas/Prompt'
        temperature:
          type: number
          description: "Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.\n"
        tool_choice:
          anyOf:
            - $ref: '#/components/schemas/ToolChoiceOptions'
            - $ref: '#/components/schemas/ToolChoiceFunction'
            - $ref: '#/components/schemas/ToolChoiceMCP'
          description: "How the model chooses tools. Provide one of the string modes or force a specific\nfunction/MCP tool.\n"
          default: auto
        tools:
          type: array
          items:
            type: object
            properties:
              description:
                type: string
                description: "The description of the function, including guidance on when and how \nto call it, and guidance about what to tell the user when calling \n(if anything).\n"
              name:
                type: string
                description: The name of the function.
              parameters:
                type: object
                description: Parameters of the function in JSON Schema.
              type:
                enum:
                  - function
                type: string
                description: 'The type of the tool, i.e. `function`.'
                x-stainless-const: true
          description: Tools (functions) available to the model.
        voice:
          $ref: '#/components/schemas/VoiceIdsShared'
      description: Create a new Realtime response with these parameters
    RealtimeServerEvent:
      oneOf:
        - $ref: '#/components/schemas/RealtimeError'
        - $ref: '#/components/schemas/RealtimeSessionCreated'
        - $ref: '#/components/schemas/RealtimeSessionUpdated'
        - $ref: '#/components/schemas/RealtimeConversationCreated'
        - $ref: '#/components/schemas/RealtimeConversationItemCreated'
        - $ref: '#/components/schemas/RealtimeConversationItemInputAudioTranscriptionCompleted'
        - $ref: '#/components/schemas/RealtimeConversationItemInputAudioTranscriptionFailed'
        - $ref: '#/components/schemas/RealtimeConversationItemTruncated'
        - $ref: '#/components/schemas/RealtimeConversationItemDeleted'
        - $ref: '#/components/schemas/RealtimeInputAudioBufferCommitted'
        - $ref: '#/components/schemas/RealtimeInputAudioBufferCleared'
        - $ref: '#/components/schemas/RealtimeInputAudioBufferSpeechStarted'
        - $ref: '#/components/schemas/RealtimeInputAudioBufferSpeechStopped'
        - $ref: '#/components/schemas/RealtimeResponseCreated'
        - $ref: '#/components/schemas/RealtimeResponseDone'
        - $ref: '#/components/schemas/RealtimeResponseOutputItemAdded'
        - $ref: '#/components/schemas/RealtimeResponseOutputItemDone'
        - $ref: '#/components/schemas/RealtimeResponseContentPartAdded'
        - $ref: '#/components/schemas/RealtimeResponseContentPartDone'
        - $ref: '#/components/schemas/RealtimeResponseTextDelta'
        - $ref: '#/components/schemas/RealtimeResponseTextDone'
        - $ref: '#/components/schemas/RealtimeResponseAudioTranscriptDelta'
        - $ref: '#/components/schemas/RealtimeResponseAudioTranscriptDone'
        - $ref: '#/components/schemas/RealtimeResponseAudioDelta'
        - $ref: '#/components/schemas/RealtimeResponseAudioDone'
        - $ref: '#/components/schemas/RealtimeResponseFunctionCallArgumentsDelta'
        - $ref: '#/components/schemas/RealtimeResponseFunctionCallArgumentsDone'
        - $ref: '#/components/schemas/RealtimeRateLimitsUpdated'
    RealtimeServerEventConversationCreated:
      required:
        - event_id
        - type
        - conversation
      type: object
      properties:
        conversation:
          type: object
          properties:
            id:
              type: string
              description: The unique ID of the conversation.
            object:
              enum:
                - realtime.conversation
              description: 'The object type, must be `realtime.conversation`.'
          description: The conversation resource.
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - conversation.created
          description: 'The event type, must be `conversation.created`.'
          x-stainless-const: true
      description: "Returned when a conversation is created. Emitted right after session creation.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_9101\",\n    \"type\": \"conversation.created\",\n    \"conversation\": {\n        \"id\": \"conv_001\",\n        \"object\": \"realtime.conversation\"\n    }\n}\n"
        group: realtime
        name: conversation.created
    RealtimeServerEventConversationItemAdded:
      required:
        - event_id
        - type
        - item
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
        previous_item_id:
          type: string
          description: "The ID of the item that precedes this one, if any. This is used to\nmaintain ordering when items are inserted.\n"
          nullable: true
        type:
          enum:
            - conversation.item.added
          description: 'The event type, must be `conversation.item.added`.'
          x-stainless-const: true
      description: "Returned when a conversation item is added.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"conversation.item.added\",\n  \"event_id\": \"event_C9G8pjSJCfRNEhMEnYAVy\",\n  \"previous_item_id\": null,\n  \"item\": {\n    \"id\": \"item_C9G8pGVKYnaZu8PH5YQ9O\",\n    \"type\": \"message\",\n    \"status\": \"completed\",\n    \"role\": \"user\",\n    \"content\": [\n      {\n        \"type\": \"input_text\",\n        \"text\": \"hi\"\n      }\n    ]\n  },\n  \"timestamp\": \"2:30:35 PM\"\n}\n"
        group: realtime
        name: conversation.item.added
    RealtimeServerEventConversationItemCreated:
      required:
        - event_id
        - type
        - item
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
        previous_item_id:
          type: string
          description: "The ID of the preceding item in the Conversation context, allows the \nclient to understand the order of the conversation. Can be `null` if the \nitem has no predecessor.\n"
          nullable: true
        type:
          enum:
            - conversation.item.created
          description: 'The event type, must be `conversation.item.created`.'
          x-stainless-const: true
      description: "Returned when a conversation item is created. There are several scenarios that produce this event:\n  - The server is generating a Response, which if successful will produce \n    either one or two Items, which will be of type `message` \n    (role `assistant`) or type `function_call`.\n  - The input audio buffer has been committed, either by the client or the \n    server (in `server_vad` mode). The server will take the content of the \n    input audio buffer and add it to a new user message Item.\n  - The client has sent a `conversation.item.create` event to add a new Item \n    to the Conversation.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_1920\",\n    \"type\": \"conversation.item.created\",\n    \"previous_item_id\": \"msg_002\",\n    \"item\": {\n        \"id\": \"msg_003\",\n        \"object\": \"realtime.item\",\n        \"type\": \"message\",\n        \"status\": \"completed\",\n        \"role\": \"user\",\n        \"content\": []\n    }\n}\n"
        group: realtime
        name: conversation.item.created
    RealtimeServerEventConversationItemDeleted:
      required:
        - event_id
        - type
        - item_id
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the item that was deleted.
        type:
          enum:
            - conversation.item.deleted
          description: 'The event type, must be `conversation.item.deleted`.'
          x-stainless-const: true
      description: "Returned when an item in the conversation is deleted by the client with a \n`conversation.item.delete` event. This event is used to synchronize the \nserver's understanding of the conversation history with the client's view.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_2728\",\n    \"type\": \"conversation.item.deleted\",\n    \"item_id\": \"msg_005\"\n}\n"
        group: realtime
        name: conversation.item.deleted
    RealtimeServerEventConversationItemDone:
      required:
        - event_id
        - type
        - item
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
        previous_item_id:
          type: string
          description: "The ID of the item that precedes this one, if any. This is used to\nmaintain ordering when items are inserted.\n"
          nullable: true
        type:
          enum:
            - conversation.item.done
          description: 'The event type, must be `conversation.item.done`.'
          x-stainless-const: true
      description: "Returned when a conversation item is finalized.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"conversation.item.done\",\n  \"event_id\": \"event_C9G8ps2i70P5Wd6OA0ftc\",\n  \"previous_item_id\": null,\n  \"item\": {\n    \"id\": \"item_C9G8pGVKYnaZu8PH5YQ9O\",\n    \"type\": \"message\",\n    \"status\": \"completed\",\n    \"role\": \"user\",\n    \"content\": [\n      {\n        \"type\": \"input_text\",\n        \"text\": \"hi\"\n      }\n    ]\n  },\n  \"timestamp\": \"2:30:35 PM\"\n}\n"
        group: realtime
        name: conversation.item.done
    RealtimeServerEventConversationItemInputAudioTranscriptionCompleted:
      required:
        - event_id
        - type
        - item_id
        - content_index
        - transcript
        - usage
      type: object
      properties:
        content_index:
          type: integer
          description: The index of the content part containing the audio.
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the user message item containing the audio.
        logprobs:
          type: array
          items:
            $ref: '#/components/schemas/LogProbProperties'
          description: The log probabilities of the transcription.
          nullable: true
        transcript:
          type: string
          description: The transcribed text.
        type:
          enum:
            - conversation.item.input_audio_transcription.completed
          type: string
          description: "The event type, must be\n`conversation.item.input_audio_transcription.completed`.\n"
          x-stainless-const: true
        usage:
          type: object
          anyOf:
            - $ref: '#/components/schemas/TranscriptTextUsageTokens'
            - $ref: '#/components/schemas/TranscriptTextUsageDuration'
          description: Usage statistics for the transcription.
      description: "This event is the output of audio transcription for user audio written to the\nuser audio buffer. Transcription begins when the input audio buffer is\ncommitted by the client or server (in `server_vad` mode). Transcription runs\nasynchronously with Response creation, so this event may come before or after\nthe Response events.\n\nRealtime API models accept audio natively, and thus input transcription is a\nseparate process run on a separate ASR (Automatic Speech Recognition) model.\nThe transcript may diverge somewhat from the model's interpretation, and\nshould be treated as a rough guide.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_2122\",\n    \"type\": \"conversation.item.input_audio_transcription.completed\",\n    \"item_id\": \"msg_003\",\n    \"content_index\": 0,\n    \"transcript\": \"Hello, how are you?\",\n    \"usage\": {\n      \"type\": \"tokens\",\n      \"total_tokens\": 48,\n      \"input_tokens\": 38,\n      \"input_token_details\": {\n        \"text_tokens\": 10,\n        \"audio_tokens\": 28,\n      },\n      \"output_tokens\": 10,\n    }\n}\n"
        group: realtime
        name: conversation.item.input_audio_transcription.completed
    RealtimeServerEventConversationItemInputAudioTranscriptionDelta:
      required:
        - event_id
        - type
        - item_id
      type: object
      properties:
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
        delta:
          type: string
          description: The text delta.
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the item.
        logprobs:
          type: array
          items:
            $ref: '#/components/schemas/LogProbProperties'
          description: The log probabilities of the transcription.
          nullable: true
        type:
          enum:
            - conversation.item.input_audio_transcription.delta
          description: 'The event type, must be `conversation.item.input_audio_transcription.delta`.'
          x-stainless-const: true
      description: "Returned when the text value of an input audio transcription content part is updated.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"conversation.item.input_audio_transcription.delta\",\n  \"event_id\": \"event_001\",\n  \"item_id\": \"item_001\",\n  \"content_index\": 0,\n  \"delta\": \"Hello\"\n}\n"
        group: realtime
        name: conversation.item.input_audio_transcription.delta
    RealtimeServerEventConversationItemInputAudioTranscriptionFailed:
      required:
        - event_id
        - type
        - item_id
        - content_index
        - error
      type: object
      properties:
        content_index:
          type: integer
          description: The index of the content part containing the audio.
        error:
          type: object
          properties:
            code:
              type: string
              description: 'Error code, if any.'
            message:
              type: string
              description: A human-readable error message.
            param:
              type: string
              description: 'Parameter related to the error, if any.'
            type:
              type: string
              description: The type of error.
          description: Details of the transcription error.
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the user message item.
        type:
          enum:
            - conversation.item.input_audio_transcription.failed
          type: string
          description: "The event type, must be\n`conversation.item.input_audio_transcription.failed`.\n"
          x-stainless-const: true
      description: "Returned when input audio transcription is configured, and a transcription \nrequest for a user message failed. These events are separate from other \n`error` events so that the client can identify the related Item.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_2324\",\n    \"type\": \"conversation.item.input_audio_transcription.failed\",\n    \"item_id\": \"msg_003\",\n    \"content_index\": 0,\n    \"error\": {\n        \"type\": \"transcription_error\",\n        \"code\": \"audio_unintelligible\",\n        \"message\": \"The audio could not be transcribed.\",\n        \"param\": null\n    }\n}\n"
        group: realtime
        name: conversation.item.input_audio_transcription.failed
    RealtimeServerEventConversationItemInputAudioTranscriptionSegment:
      required:
        - event_id
        - type
        - item_id
        - content_index
        - text
        - id
        - speaker
        - start
        - end
      type: object
      properties:
        content_index:
          type: integer
          description: The index of the input audio content part within the item.
        end:
          type: number
          description: End time of the segment in seconds.
          format: float
        event_id:
          type: string
          description: The unique ID of the server event.
        id:
          type: string
          description: The segment identifier.
        item_id:
          type: string
          description: The ID of the item containing the input audio content.
        speaker:
          type: string
          description: The detected speaker label for this segment.
        start:
          type: number
          description: Start time of the segment in seconds.
          format: float
        text:
          type: string
          description: The text for this segment.
        type:
          enum:
            - conversation.item.input_audio_transcription.segment
          description: 'The event type, must be `conversation.item.input_audio_transcription.segment`.'
          x-stainless-const: true
      description: Returned when an input audio transcription segment is identified for an item.
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_6501\",\n    \"type\": \"conversation.item.input_audio_transcription.segment\",\n    \"item_id\": \"msg_011\",\n    \"content_index\": 0,\n    \"text\": \"hello\",\n    \"id\": \"seg_0001\",\n    \"speaker\": \"spk_1\",\n    \"start\": 0.0,\n    \"end\": 0.4\n}\n"
        group: realtime
        name: conversation.item.input_audio_transcription.segment
    RealtimeServerEventConversationItemRetrieved:
      required:
        - event_id
        - type
        - item
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
        type:
          enum:
            - conversation.item.retrieved
          description: 'The event type, must be `conversation.item.retrieved`.'
          x-stainless-const: true
      description: "Returned when a conversation item is retrieved with `conversation.item.retrieve`.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_1920\",\n    \"type\": \"conversation.item.created\",\n    \"previous_item_id\": \"msg_002\",\n    \"item\": {\n        \"id\": \"msg_003\",\n        \"object\": \"realtime.item\",\n        \"type\": \"message\",\n        \"status\": \"completed\",\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"type\": \"input_audio\",\n                \"transcript\": \"hello how are you\",\n                \"audio\": \"base64encodedaudio==\"\n            }\n        ]\n    }\n}\n"
        group: realtime
        name: conversation.item.retrieved
    RealtimeServerEventConversationItemTruncated:
      required:
        - event_id
        - type
        - item_id
        - content_index
        - audio_end_ms
      type: object
      properties:
        audio_end_ms:
          type: integer
          description: "The duration up to which the audio was truncated, in milliseconds.\n"
        content_index:
          type: integer
          description: The index of the content part that was truncated.
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the assistant message item that was truncated.
        type:
          enum:
            - conversation.item.truncated
          description: 'The event type, must be `conversation.item.truncated`.'
          x-stainless-const: true
      description: "Returned when an earlier assistant audio message item is truncated by the \nclient with a `conversation.item.truncate` event. This event is used to \nsynchronize the server's understanding of the audio with the client's playback.\n\nThis action will truncate the audio and remove the server-side text transcript \nto ensure there is no text in the context that hasn't been heard by the user.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_2526\",\n    \"type\": \"conversation.item.truncated\",\n    \"item_id\": \"msg_004\",\n    \"content_index\": 0,\n    \"audio_end_ms\": 1500\n}\n"
        group: realtime
        name: conversation.item.truncated
    RealtimeServerEventError:
      required:
        - event_id
        - type
        - error
      type: object
      properties:
        error:
          required:
            - type
            - message
          type: object
          properties:
            code:
              type: string
              description: 'Error code, if any.'
              nullable: true
            event_id:
              type: string
              description: "The event_id of the client event that caused the error, if applicable.\n"
              nullable: true
            message:
              type: string
              description: A human-readable error message.
            param:
              type: string
              description: 'Parameter related to the error, if any.'
              nullable: true
            type:
              type: string
              description: "The type of error (e.g., \"invalid_request_error\", \"server_error\").\n"
          description: Details of the error.
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - error
          description: 'The event type, must be `error`.'
          x-stainless-const: true
      description: "Returned when an error occurs, which could be a client problem or a server \nproblem. Most errors are recoverable and the session will stay open, we \nrecommend to implementors to monitor and log error messages by default.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_890\",\n    \"type\": \"error\",\n    \"error\": {\n        \"type\": \"invalid_request_error\",\n        \"code\": \"invalid_event\",\n        \"message\": \"The 'type' field is missing.\",\n        \"param\": null,\n        \"event_id\": \"event_567\"\n    }\n}\n"
        group: realtime
        name: error
    RealtimeServerEventInputAudioBufferCleared:
      required:
        - event_id
        - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        type:
          enum:
            - input_audio_buffer.cleared
          description: 'The event type, must be `input_audio_buffer.cleared`.'
          x-stainless-const: true
      description: "Returned when the input audio buffer is cleared by the client with a \n`input_audio_buffer.clear` event.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_1314\",\n    \"type\": \"input_audio_buffer.cleared\"\n}\n"
        group: realtime
        name: input_audio_buffer.cleared
    RealtimeServerEventInputAudioBufferCommitted:
      required:
        - event_id
        - type
        - item_id
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the user message item that will be created.
        previous_item_id:
          type: string
          description: "The ID of the preceding item after which the new item will be inserted.\nCan be `null` if the item has no predecessor.\n"
          nullable: true
        type:
          enum:
            - input_audio_buffer.committed
          description: 'The event type, must be `input_audio_buffer.committed`.'
          x-stainless-const: true
      description: "Returned when an input audio buffer is committed, either by the client or \nautomatically in server VAD mode. The `item_id` property is the ID of the user\nmessage item that will be created, thus a `conversation.item.created` event \nwill also be sent to the client.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_1121\",\n    \"type\": \"input_audio_buffer.committed\",\n    \"previous_item_id\": \"msg_001\",\n    \"item_id\": \"msg_002\"\n}\n"
        group: realtime
        name: input_audio_buffer.committed
    RealtimeServerEventInputAudioBufferSpeechStarted:
      required:
        - event_id
        - type
        - audio_start_ms
        - item_id
      type: object
      properties:
        audio_start_ms:
          type: integer
          description: "Milliseconds from the start of all audio written to the buffer during the \nsession when speech was first detected. This will correspond to the \nbeginning of audio sent to the model, and thus includes the \n`prefix_padding_ms` configured in the Session.\n"
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: "The ID of the user message item that will be created when speech stops.\n"
        type:
          enum:
            - input_audio_buffer.speech_started
          description: 'The event type, must be `input_audio_buffer.speech_started`.'
          x-stainless-const: true
      description: "Sent by the server when in `server_vad` mode to indicate that speech has been \ndetected in the audio buffer. This can happen any time audio is added to the \nbuffer (unless speech is already detected). The client may want to use this \nevent to interrupt audio playback or provide visual feedback to the user. \n\nThe client should expect to receive a `input_audio_buffer.speech_stopped` event \nwhen speech stops. The `item_id` property is the ID of the user message item \nthat will be created when speech stops and will also be included in the \n`input_audio_buffer.speech_stopped` event (unless the client manually commits \nthe audio buffer during VAD activation).\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_1516\",\n    \"type\": \"input_audio_buffer.speech_started\",\n    \"audio_start_ms\": 1000,\n    \"item_id\": \"msg_003\"\n}\n"
        group: realtime
        name: input_audio_buffer.speech_started
    RealtimeServerEventInputAudioBufferSpeechStopped:
      required:
        - event_id
        - type
        - audio_end_ms
        - item_id
      type: object
      properties:
        audio_end_ms:
          type: integer
          description: "Milliseconds since the session started when speech stopped. This will \ncorrespond to the end of audio sent to the model, and thus includes the \n`min_silence_duration_ms` configured in the Session.\n"
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the user message item that will be created.
        type:
          enum:
            - input_audio_buffer.speech_stopped
          description: 'The event type, must be `input_audio_buffer.speech_stopped`.'
          x-stainless-const: true
      description: "Returned in `server_vad` mode when the server detects the end of speech in \nthe audio buffer. The server will also send an `conversation.item.created` \nevent with the user message item that is created from the audio buffer.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_1718\",\n    \"type\": \"input_audio_buffer.speech_stopped\",\n    \"audio_end_ms\": 2000,\n    \"item_id\": \"msg_003\"\n}\n"
        group: realtime
        name: input_audio_buffer.speech_stopped
    RealtimeServerEventInputAudioBufferTimeoutTriggered:
      required:
        - event_id
        - type
        - audio_start_ms
        - audio_end_ms
        - item_id
      type: object
      properties:
        audio_end_ms:
          type: integer
          description: Millisecond offset where speech ended within the buffered audio.
        audio_start_ms:
          type: integer
          description: Millisecond offset where speech started within the buffered audio.
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the item associated with this segment.
        type:
          enum:
            - input_audio_buffer.timeout_triggered
          description: 'The event type, must be `input_audio_buffer.timeout_triggered`.'
          x-stainless-const: true
      description: "Returned when the server VAD timeout is triggered for the input audio buffer.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_6401\",\n    \"type\": \"input_audio_buffer.timeout_triggered\",\n    \"audio_start_ms\": 1200,\n    \"audio_end_ms\": 2150,\n    \"item_id\": \"msg_010\"\n}\n"
        group: realtime
        name: input_audio_buffer.timeout_triggered
    RealtimeServerEventMCPListToolsCompleted:
      required:
        - event_id
        - type
        - item_id
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the MCP list tools item.
        type:
          enum:
            - mcp_list_tools.completed
          description: 'The event type, must be `mcp_list_tools.completed`.'
          x-stainless-const: true
      description: Returned when listing MCP tools has completed for an item.
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_6102\",\n    \"type\": \"mcp_list_tools.completed\",\n    \"item_id\": \"mcp_list_tools_001\"\n}\n"
        group: realtime
        name: mcp_list_tools.completed
    RealtimeServerEventMCPListToolsFailed:
      required:
        - event_id
        - type
        - item_id
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the MCP list tools item.
        type:
          enum:
            - mcp_list_tools.failed
          description: 'The event type, must be `mcp_list_tools.failed`.'
          x-stainless-const: true
      description: Returned when listing MCP tools has failed for an item.
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_6103\",\n    \"type\": \"mcp_list_tools.failed\",\n    \"item_id\": \"mcp_list_tools_001\"\n}\n"
        group: realtime
        name: mcp_list_tools.failed
    RealtimeServerEventMCPListToolsInProgress:
      required:
        - event_id
        - type
        - item_id
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the MCP list tools item.
        type:
          enum:
            - mcp_list_tools.in_progress
          description: 'The event type, must be `mcp_list_tools.in_progress`.'
          x-stainless-const: true
      description: Returned when listing MCP tools is in progress for an item.
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_6101\",\n    \"type\": \"mcp_list_tools.in_progress\",\n    \"item_id\": \"mcp_list_tools_001\"\n}\n"
        group: realtime
        name: mcp_list_tools.in_progress
    RealtimeServerEventOutputAudioBufferCleared:
      required:
        - event_id
        - type
        - response_id
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        response_id:
          type: string
          description: The unique ID of the response that produced the audio.
        type:
          enum:
            - output_audio_buffer.cleared
          description: 'The event type, must be `output_audio_buffer.cleared`.'
          x-stainless-const: true
      description: "**WebRTC Only:** Emitted when the output audio buffer is cleared. This happens either in VAD\nmode when the user has interrupted (`input_audio_buffer.speech_started`),\nor when the client has emitted the `output_audio_buffer.clear` event to manually\ncut off the current audio response.\n[Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_abc123\",\n    \"type\": \"output_audio_buffer.cleared\",\n    \"response_id\": \"resp_abc123\"\n}\n"
        group: realtime
        name: output_audio_buffer.cleared
    RealtimeServerEventOutputAudioBufferStarted:
      required:
        - event_id
        - type
        - response_id
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        response_id:
          type: string
          description: The unique ID of the response that produced the audio.
        type:
          enum:
            - output_audio_buffer.started
          description: 'The event type, must be `output_audio_buffer.started`.'
          x-stainless-const: true
      description: "**WebRTC Only:** Emitted when the server begins streaming audio to the client. This event is\nemitted after an audio content part has been added (`response.content_part.added`)\nto the response.\n[Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_abc123\",\n    \"type\": \"output_audio_buffer.started\",\n    \"response_id\": \"resp_abc123\"\n}\n"
        group: realtime
        name: output_audio_buffer.started
    RealtimeServerEventOutputAudioBufferStopped:
      required:
        - event_id
        - type
        - response_id
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        response_id:
          type: string
          description: The unique ID of the response that produced the audio.
        type:
          enum:
            - output_audio_buffer.stopped
          description: 'The event type, must be `output_audio_buffer.stopped`.'
          x-stainless-const: true
      description: "**WebRTC Only:** Emitted when the output audio buffer has been completely drained on the server,\nand no more audio is forthcoming. This event is emitted after the full response\ndata has been sent to the client (`response.done`).\n[Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_abc123\",\n    \"type\": \"output_audio_buffer.stopped\",\n    \"response_id\": \"resp_abc123\"\n}\n"
        group: realtime
        name: output_audio_buffer.stopped
    RealtimeServerEventRateLimitsUpdated:
      required:
        - event_id
        - type
        - rate_limits
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        rate_limits:
          type: array
          items:
            type: object
            properties:
              limit:
                type: integer
                description: The maximum allowed value for the rate limit.
              name:
                enum:
                  - requests
                  - tokens
                type: string
                description: "The name of the rate limit (`requests`, `tokens`).\n"
              remaining:
                type: integer
                description: The remaining value before the limit is reached.
              reset_seconds:
                type: number
                description: Seconds until the rate limit resets.
          description: List of rate limit information.
        type:
          enum:
            - rate_limits.updated
          description: 'The event type, must be `rate_limits.updated`.'
          x-stainless-const: true
      description: "Emitted at the beginning of a Response to indicate the updated rate limits. \nWhen a Response is created some tokens will be \"reserved\" for the output \ntokens, the rate limits shown here reflect that reservation, which is then \nadjusted accordingly once the Response is completed.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_5758\",\n    \"type\": \"rate_limits.updated\",\n    \"rate_limits\": [\n        {\n            \"name\": \"requests\",\n            \"limit\": 1000,\n            \"remaining\": 999,\n            \"reset_seconds\": 60\n        },\n        {\n            \"name\": \"tokens\",\n            \"limit\": 50000,\n            \"remaining\": 49950,\n            \"reset_seconds\": 60\n        }\n    ]\n}\n"
        group: realtime
        name: rate_limits.updated
    RealtimeServerEventResponseAudioDelta:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - content_index
        - delta
      type: object
      properties:
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
        delta:
          type: string
          description: Base64-encoded audio data delta.
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        response_id:
          type: string
          description: The ID of the response.
        type:
          enum:
            - response.output_audio.delta
          description: 'The event type, must be `response.output_audio.delta`.'
          x-stainless-const: true
      description: Returned when the model-generated audio is updated.
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_4950\",\n    \"type\": \"response.output_audio.delta\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_008\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"delta\": \"Base64EncodedAudioDelta\"\n}\n"
        group: realtime
        name: response.output_audio.delta
    RealtimeServerEventResponseAudioDone:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - content_index
      type: object
      properties:
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        response_id:
          type: string
          description: The ID of the response.
        type:
          enum:
            - response.output_audio.done
          description: 'The event type, must be `response.output_audio.done`.'
          x-stainless-const: true
      description: "Returned when the model-generated audio is done. Also emitted when a Response\nis interrupted, incomplete, or cancelled.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_5152\",\n    \"type\": \"response.output_audio.done\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_008\",\n    \"output_index\": 0,\n    \"content_index\": 0\n}\n"
        group: realtime
        name: response.output_audio.done
    RealtimeServerEventResponseAudioTranscriptDelta:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - content_index
        - delta
      type: object
      properties:
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
        delta:
          type: string
          description: The transcript delta.
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        response_id:
          type: string
          description: The ID of the response.
        type:
          enum:
            - response.output_audio_transcript.delta
          description: 'The event type, must be `response.output_audio_transcript.delta`.'
          x-stainless-const: true
      description: "Returned when the model-generated transcription of audio output is updated.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_4546\",\n    \"type\": \"response.output_audio_transcript.delta\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_008\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"delta\": \"Hello, how can I a\"\n}\n"
        group: realtime
        name: response.output_audio_transcript.delta
    RealtimeServerEventResponseAudioTranscriptDone:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - content_index
        - transcript
      type: object
      properties:
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        response_id:
          type: string
          description: The ID of the response.
        transcript:
          type: string
          description: The final transcript of the audio.
        type:
          enum:
            - response.output_audio_transcript.done
          description: 'The event type, must be `response.output_audio_transcript.done`.'
          x-stainless-const: true
      description: "Returned when the model-generated transcription of audio output is done\nstreaming. Also emitted when a Response is interrupted, incomplete, or\ncancelled.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_4748\",\n    \"type\": \"response.output_audio_transcript.done\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_008\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"transcript\": \"Hello, how can I assist you today?\"\n}\n"
        group: realtime
        name: response.output_audio_transcript.done
    RealtimeServerEventResponseContentPartAdded:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - content_index
        - part
      type: object
      properties:
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the item to which the content part was added.
        output_index:
          type: integer
          description: The index of the output item in the response.
        part:
          type: object
          properties:
            audio:
              type: string
              description: Base64-encoded audio data (if type is "audio").
            text:
              type: string
              description: The text content (if type is "text").
            transcript:
              type: string
              description: The transcript of the audio (if type is "audio").
            type:
              enum:
                - text
                - audio
              type: string
              description: 'The content type ("text", "audio").'
          description: The content part that was added.
        response_id:
          type: string
          description: The ID of the response.
        type:
          enum:
            - response.content_part.added
          description: 'The event type, must be `response.content_part.added`.'
          x-stainless-const: true
      description: "Returned when a new content part is added to an assistant message item during\nresponse generation.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_3738\",\n    \"type\": \"response.content_part.added\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_007\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"part\": {\n        \"type\": \"text\",\n        \"text\": \"\"\n    }\n}\n"
        group: realtime
        name: response.content_part.added
    RealtimeServerEventResponseContentPartDone:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - content_index
        - part
      type: object
      properties:
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        part:
          type: object
          properties:
            audio:
              type: string
              description: Base64-encoded audio data (if type is "audio").
            text:
              type: string
              description: The text content (if type is "text").
            transcript:
              type: string
              description: The transcript of the audio (if type is "audio").
            type:
              enum:
                - text
                - audio
              type: string
              description: 'The content type ("text", "audio").'
          description: The content part that is done.
        response_id:
          type: string
          description: The ID of the response.
        type:
          enum:
            - response.content_part.done
          description: 'The event type, must be `response.content_part.done`.'
          x-stainless-const: true
      description: "Returned when a content part is done streaming in an assistant message item.\nAlso emitted when a Response is interrupted, incomplete, or cancelled.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_3940\",\n    \"type\": \"response.content_part.done\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_007\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"part\": {\n        \"type\": \"text\",\n        \"text\": \"Sure, I can help with that.\"\n    }\n}\n"
        group: realtime
        name: response.content_part.done
    RealtimeServerEventResponseCreated:
      required:
        - event_id
        - type
        - response
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        response:
          $ref: '#/components/schemas/RealtimeResponse'
        type:
          enum:
            - response.created
          description: 'The event type, must be `response.created`.'
          x-stainless-const: true
      description: "Returned when a new Response is created. The first event of response creation,\nwhere the response is in an initial state of `in_progress`.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.created\",\n  \"event_id\": \"event_C9G8pqbTEddBSIxbBN6Os\",\n  \"response\": {\n    \"object\": \"realtime.response\",\n    \"id\": \"resp_C9G8p7IH2WxLbkgPNouYL\",\n    \"status\": \"in_progress\",\n    \"status_details\": null,\n    \"output\": [],\n    \"conversation_id\": \"conv_C9G8mmBkLhQJwCon3hoJN\",\n    \"output_modalities\": [\n      \"audio\"\n    ],\n    \"max_output_tokens\": \"inf\",\n    \"audio\": {\n      \"output\": {\n        \"format\": {\n          \"type\": \"audio/pcm\",\n          \"rate\": 24000\n        },\n        \"voice\": \"marin\"\n      }\n    },\n    \"usage\": null,\n    \"metadata\": null\n  },\n  \"timestamp\": \"2:30:35 PM\"\n}\n"
        group: realtime
        name: response.created
    RealtimeServerEventResponseDone:
      required:
        - event_id
        - type
        - response
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        response:
          $ref: '#/components/schemas/RealtimeResponse'
        type:
          enum:
            - response.done
          description: 'The event type, must be `response.done`.'
          x-stainless-const: true
      description: "Returned when a Response is done streaming. Always emitted, no matter the \nfinal state. The Response object included in the `response.done` event will \ninclude all output Items in the Response but will omit the raw audio data.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_3132\",\n    \"type\": \"response.done\",\n    \"response\": {\n        \"id\": \"resp_001\",\n        \"object\": \"realtime.response\",\n        \"status\": \"completed\",\n        \"status_details\": null,\n        \"output\": [\n            {\n                \"id\": \"msg_006\",\n                \"object\": \"realtime.item\",\n                \"type\": \"message\",\n                \"status\": \"completed\",\n                \"role\": \"assistant\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"Sure, how can I assist you today?\"\n                    }\n                ]\n            }\n        ],\n        \"usage\": {\n            \"total_tokens\":275,\n            \"input_tokens\":127,\n            \"output_tokens\":148,\n            \"input_token_details\": {\n                \"cached_tokens\":384,\n                \"text_tokens\":119,\n                \"audio_tokens\":8,\n                \"cached_tokens_details\": {\n                    \"text_tokens\": 128,\n                    \"audio_tokens\": 256\n                }\n            },\n            \"output_token_details\": {\n              \"text_tokens\":36,\n              \"audio_tokens\":112\n            }\n        }\n    }\n}\n"
        group: realtime
        name: response.done
    RealtimeServerEventResponseFunctionCallArgumentsDelta:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - call_id
        - delta
      type: object
      properties:
        call_id:
          type: string
          description: The ID of the function call.
        delta:
          type: string
          description: The arguments delta as a JSON string.
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the function call item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        response_id:
          type: string
          description: The ID of the response.
        type:
          enum:
            - response.function_call_arguments.delta
          description: "The event type, must be `response.function_call_arguments.delta`.\n"
          x-stainless-const: true
      description: "Returned when the model-generated function call arguments are updated.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_5354\",\n    \"type\": \"response.function_call_arguments.delta\",\n    \"response_id\": \"resp_002\",\n    \"item_id\": \"fc_001\",\n    \"output_index\": 0,\n    \"call_id\": \"call_001\",\n    \"delta\": \"{\\\"location\\\": \\\"San\\\"\"\n}\n"
        group: realtime
        name: response.function_call_arguments.delta
    RealtimeServerEventResponseFunctionCallArgumentsDone:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - call_id
        - arguments
      type: object
      properties:
        arguments:
          type: string
          description: The final arguments as a JSON string.
        call_id:
          type: string
          description: The ID of the function call.
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the function call item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        response_id:
          type: string
          description: The ID of the response.
        type:
          enum:
            - response.function_call_arguments.done
          description: "The event type, must be `response.function_call_arguments.done`.\n"
          x-stainless-const: true
      description: "Returned when the model-generated function call arguments are done streaming.\nAlso emitted when a Response is interrupted, incomplete, or cancelled.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_5556\",\n    \"type\": \"response.function_call_arguments.done\",\n    \"response_id\": \"resp_002\",\n    \"item_id\": \"fc_001\",\n    \"output_index\": 0,\n    \"call_id\": \"call_001\",\n    \"arguments\": \"{\\\"location\\\": \\\"San Francisco\\\"}\"\n}\n"
        group: realtime
        name: response.function_call_arguments.done
    RealtimeServerEventResponseMCPCallArgumentsDelta:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - delta
      type: object
      properties:
        delta:
          type: string
          description: The JSON-encoded arguments delta.
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the MCP tool call item.
        obfuscation:
          type: string
          description: 'If present, indicates the delta text was obfuscated.'
          nullable: true
        output_index:
          type: integer
          description: The index of the output item in the response.
        response_id:
          type: string
          description: The ID of the response.
        type:
          enum:
            - response.mcp_call_arguments.delta
          description: 'The event type, must be `response.mcp_call_arguments.delta`.'
          x-stainless-const: true
      description: Returned when MCP tool call arguments are updated during response generation.
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_6201\",\n    \"type\": \"response.mcp_call_arguments.delta\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"mcp_call_001\",\n    \"output_index\": 0,\n    \"delta\": \"{\\\"partial\\\":true}\"\n}\n"
        group: realtime
        name: response.mcp_call_arguments.delta
    RealtimeServerEventResponseMCPCallArgumentsDone:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - arguments
      type: object
      properties:
        arguments:
          type: string
          description: The final JSON-encoded arguments string.
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the MCP tool call item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        response_id:
          type: string
          description: The ID of the response.
        type:
          enum:
            - response.mcp_call_arguments.done
          description: 'The event type, must be `response.mcp_call_arguments.done`.'
          x-stainless-const: true
      description: Returned when MCP tool call arguments are finalized during response generation.
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_6202\",\n    \"type\": \"response.mcp_call_arguments.done\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"mcp_call_001\",\n    \"output_index\": 0,\n    \"arguments\": \"{\\\"q\\\":\\\"docs\\\"}\"\n}\n"
        group: realtime
        name: response.mcp_call_arguments.done
    RealtimeServerEventResponseMCPCallCompleted:
      required:
        - event_id
        - type
        - output_index
        - item_id
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the MCP tool call item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        type:
          enum:
            - response.mcp_call.completed
          description: 'The event type, must be `response.mcp_call.completed`.'
          x-stainless-const: true
      description: Returned when an MCP tool call has completed successfully.
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_6302\",\n    \"type\": \"response.mcp_call.completed\",\n    \"output_index\": 0,\n    \"item_id\": \"mcp_call_001\"\n}\n"
        group: realtime
        name: response.mcp_call.completed
    RealtimeServerEventResponseMCPCallFailed:
      required:
        - event_id
        - type
        - output_index
        - item_id
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the MCP tool call item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        type:
          enum:
            - response.mcp_call.failed
          description: 'The event type, must be `response.mcp_call.failed`.'
          x-stainless-const: true
      description: Returned when an MCP tool call has failed.
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_6303\",\n    \"type\": \"response.mcp_call.failed\",\n    \"output_index\": 0,\n    \"item_id\": \"mcp_call_001\"\n}\n"
        group: realtime
        name: response.mcp_call.failed
    RealtimeServerEventResponseMCPCallInProgress:
      required:
        - event_id
        - type
        - output_index
        - item_id
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the MCP tool call item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        type:
          enum:
            - response.mcp_call.in_progress
          description: 'The event type, must be `response.mcp_call.in_progress`.'
          x-stainless-const: true
      description: Returned when an MCP tool call has started and is in progress.
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_6301\",\n    \"type\": \"response.mcp_call.in_progress\",\n    \"output_index\": 0,\n    \"item_id\": \"mcp_call_001\"\n}\n"
        group: realtime
        name: response.mcp_call.in_progress
    RealtimeServerEventResponseOutputItemAdded:
      required:
        - event_id
        - type
        - response_id
        - output_index
        - item
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
        output_index:
          type: integer
          description: The index of the output item in the Response.
        response_id:
          type: string
          description: The ID of the Response to which the item belongs.
        type:
          enum:
            - response.output_item.added
          description: 'The event type, must be `response.output_item.added`.'
          x-stainless-const: true
      description: Returned when a new Item is created during Response generation.
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_3334\",\n    \"type\": \"response.output_item.added\",\n    \"response_id\": \"resp_001\",\n    \"output_index\": 0,\n    \"item\": {\n        \"id\": \"msg_007\",\n        \"object\": \"realtime.item\",\n        \"type\": \"message\",\n        \"status\": \"in_progress\",\n        \"role\": \"assistant\",\n        \"content\": []\n    }\n}\n"
        group: realtime
        name: response.output_item.added
    RealtimeServerEventResponseOutputItemDone:
      required:
        - event_id
        - type
        - response_id
        - output_index
        - item
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
        output_index:
          type: integer
          description: The index of the output item in the Response.
        response_id:
          type: string
          description: The ID of the Response to which the item belongs.
        type:
          enum:
            - response.output_item.done
          description: 'The event type, must be `response.output_item.done`.'
          x-stainless-const: true
      description: "Returned when an Item is done streaming. Also emitted when a Response is \ninterrupted, incomplete, or cancelled.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_3536\",\n    \"type\": \"response.output_item.done\",\n    \"response_id\": \"resp_001\",\n    \"output_index\": 0,\n    \"item\": {\n        \"id\": \"msg_007\",\n        \"object\": \"realtime.item\",\n        \"type\": \"message\",\n        \"status\": \"completed\",\n        \"role\": \"assistant\",\n        \"content\": [\n            {\n                \"type\": \"text\",\n                \"text\": \"Sure, I can help with that.\"\n            }\n        ]\n    }\n}\n"
        group: realtime
        name: response.output_item.done
    RealtimeServerEventResponseTextDelta:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - content_index
        - delta
      type: object
      properties:
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
        delta:
          type: string
          description: The text delta.
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        response_id:
          type: string
          description: The ID of the response.
        type:
          enum:
            - response.output_text.delta
          description: 'The event type, must be `response.output_text.delta`.'
          x-stainless-const: true
      description: Returned when the text value of an "output_text" content part is updated.
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_4142\",\n    \"type\": \"response.output_text.delta\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_007\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"delta\": \"Sure, I can h\"\n}\n"
        group: realtime
        name: response.output_text.delta
    RealtimeServerEventResponseTextDone:
      required:
        - event_id
        - type
        - response_id
        - item_id
        - output_index
        - content_index
        - text
      type: object
      properties:
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
        event_id:
          type: string
          description: The unique ID of the server event.
        item_id:
          type: string
          description: The ID of the item.
        output_index:
          type: integer
          description: The index of the output item in the response.
        response_id:
          type: string
          description: The ID of the response.
        text:
          type: string
          description: The final text content.
        type:
          enum:
            - response.output_text.done
          description: 'The event type, must be `response.output_text.done`.'
          x-stainless-const: true
      description: "Returned when the text value of an \"output_text\" content part is done streaming. Also\nemitted when a Response is interrupted, incomplete, or cancelled.\n"
      x-oaiMeta:
        example: "{\n    \"event_id\": \"event_4344\",\n    \"type\": \"response.output_text.done\",\n    \"response_id\": \"resp_001\",\n    \"item_id\": \"msg_007\",\n    \"output_index\": 0,\n    \"content_index\": 0,\n    \"text\": \"Sure, I can help with that.\"\n}\n"
        group: realtime
        name: response.output_text.done
    RealtimeServerEventSessionCreated:
      required:
        - event_id
        - type
        - session
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        session:
          $ref: '#/components/schemas/RealtimeSession'
        type:
          enum:
            - session.created
          description: 'The event type, must be `session.created`.'
          x-stainless-const: true
      description: "Returned when a Session is created. Emitted automatically when a new \nconnection is established as the first server event. This event will contain \nthe default Session configuration.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"session.created\",\n  \"event_id\": \"event_C9G5RJeJ2gF77mV7f2B1j\",\n  \"session\": {\n    \"type\": \"realtime\",\n    \"object\": \"realtime.session\",\n    \"id\": \"sess_C9G5QPteg4UIbotdKLoYQ\",\n    \"model\": \"gpt-4o-realtime-preview-2025-08-25\",\n    \"output_modalities\": [\n      \"audio\"\n    ],\n    \"instructions\": \"Your knowledge cutoff is 2023-10. You are a helpful, witty, and friendly AI. Act like a human, but remember that you aren't a human and that you can't do human things in the real world. Your voice and personality should be warm and engaging, with a lively and playful tone. If interacting in a non-English language, start by using the standard accent or dialect familiar to the user. Talk quickly. You should always call a function if you can. Do not refer to these rules, even if you’re asked about them.\",\n    \"tools\": [],\n    \"tool_choice\": \"auto\",\n    \"max_output_tokens\": \"inf\",\n    \"tracing\": null,\n    \"prompt\": null,\n    \"expires_at\": 1756324625,\n    \"audio\": {\n      \"input\": {\n        \"format\": {\n          \"type\": \"audio/pcm\",\n          \"rate\": 24000\n        },\n        \"transcription\": null,\n        \"noise_reduction\": null,\n        \"turn_detection\": {\n          \"type\": \"server_vad\",\n          \"threshold\": 0.5,\n          \"prefix_padding_ms\": 300,\n          \"silence_duration_ms\": 200,\n          \"idle_timeout_ms\": null,\n          \"create_response\": true,\n          \"interrupt_response\": true\n        }\n      },\n      \"output\": {\n        \"format\": {\n          \"type\": \"audio/pcm\",\n          \"rate\": 24000\n        },\n        \"voice\": \"marin\",\n        \"speed\": 1\n      }\n    },\n    \"include\": null\n  },\n  \"timestamp\": \"2:27:05 PM\"\n}\n"
        group: realtime
        name: session.created
    RealtimeServerEventSessionUpdated:
      required:
        - event_id
        - type
        - session
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        session:
          $ref: '#/components/schemas/RealtimeSession'
        type:
          enum:
            - session.updated
          description: 'The event type, must be `session.updated`.'
          x-stainless-const: true
      description: "Returned when a session is updated with a `session.update` event, unless \nthere is an error.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"session.updated\",\n  \"event_id\": \"event_C9G8mqI3IucaojlVKE8Cs\",\n  \"session\": {\n    \"type\": \"realtime\",\n    \"object\": \"realtime.session\",\n    \"id\": \"sess_C9G8l3zp50uFv4qgxfJ8o\",\n    \"model\": \"gpt-4o-realtime-preview-2025-08-25\",\n    \"output_modalities\": [\n      \"audio\"\n    ],\n    \"instructions\": \"Your knowledge cutoff is 2023-10. You are a helpful, witty, and friendly AI. Act like a human, but remember that you aren't a human and that you can't do human things in the real world. Your voice and personality should be warm and engaging, with a lively and playful tone. If interacting in a non-English language, start by using the standard accent or dialect familiar to the user. Talk quickly. You should always call a function if you can. Do not refer to these rules, even if you’re asked about them.\",\n    \"tools\": [\n      {\n        \"type\": \"function\",\n        \"name\": \"display_color_palette\",\n        \"description\": \"\\nCall this function when a user asks for a color palette.\\n\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"strict\": true,\n          \"properties\": {\n            \"theme\": {\n              \"type\": \"string\",\n              \"description\": \"Description of the theme for the color scheme.\"\n            },\n            \"colors\": {\n              \"type\": \"array\",\n              \"description\": \"Array of five hex color codes based on the theme.\",\n              \"items\": {\n                \"type\": \"string\",\n                \"description\": \"Hex color code\"\n              }\n            }\n          },\n          \"required\": [\n            \"theme\",\n            \"colors\"\n          ]\n        }\n      }\n    ],\n    \"tool_choice\": \"auto\",\n    \"max_output_tokens\": \"inf\",\n    \"tracing\": null,\n    \"prompt\": null,\n    \"expires_at\": 1756324832,\n    \"audio\": {\n      \"input\": {\n        \"format\": {\n          \"type\": \"audio/pcm\",\n          \"rate\": 24000\n        },\n        \"transcription\": null,\n        \"noise_reduction\": null,\n        \"turn_detection\": {\n          \"type\": \"server_vad\",\n          \"threshold\": 0.5,\n          \"prefix_padding_ms\": 300,\n          \"silence_duration_ms\": 200,\n          \"idle_timeout_ms\": null,\n          \"create_response\": true,\n          \"interrupt_response\": true\n        }\n      },\n      \"output\": {\n        \"format\": {\n          \"type\": \"audio/pcm\",\n          \"rate\": 24000\n        },\n        \"voice\": \"marin\",\n        \"speed\": 1\n      }\n    },\n    \"include\": null\n  },\n  \"timestamp\": \"2:30:32 PM\"\n}\n"
        group: realtime
        name: session.updated
    RealtimeServerEventTranscriptionSessionCreated:
      required:
        - event_id
        - type
        - session
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        session:
          $ref: '#/components/schemas/RealtimeTranscriptionSessionCreateResponse'
        type:
          enum:
            - transcription_session.created
          description: 'The event type, must be `transcription_session.created`.'
          x-stainless-const: true
      description: "Returned when a transcription session is created.\n"
      x-oaiMeta:
        example: "{\n  \"event_id\": \"event_5566\",\n  \"type\": \"transcription_session.created\",\n  \"session\": {\n    \"id\": \"sess_001\",\n    \"object\": \"realtime.transcription_session\",\n    \"input_audio_format\": \"pcm16\",\n    \"input_audio_transcription\": {\n      \"model\": \"gpt-4o-transcribe\",\n      \"prompt\": \"\",\n      \"language\": \"\"\n    },\n    \"turn_detection\": {\n      \"type\": \"server_vad\",\n      \"threshold\": 0.5,\n      \"prefix_padding_ms\": 300,\n      \"silence_duration_ms\": 500\n    },\n    \"input_audio_noise_reduction\": {\n      \"type\": \"near_field\"\n    },\n    \"include\": []\n  }\n}\n"
        group: realtime
        name: transcription_session.created
    RealtimeServerEventTranscriptionSessionUpdated:
      required:
        - event_id
        - type
        - session
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
        session:
          $ref: '#/components/schemas/RealtimeTranscriptionSessionCreateResponse'
        type:
          enum:
            - transcription_session.updated
          description: 'The event type, must be `transcription_session.updated`.'
          x-stainless-const: true
      description: "Returned when a transcription session is updated with a `transcription_session.update` event, unless \nthere is an error.\n"
      x-oaiMeta:
        example: "{\n  \"event_id\": \"event_5678\",\n  \"type\": \"transcription_session.updated\",\n  \"session\": {\n    \"id\": \"sess_001\",\n    \"object\": \"realtime.transcription_session\",\n    \"input_audio_format\": \"pcm16\",\n    \"input_audio_transcription\": {\n      \"model\": \"gpt-4o-transcribe\",\n      \"prompt\": \"\",\n      \"language\": \"\"\n    },\n    \"turn_detection\": {\n      \"type\": \"server_vad\",\n      \"threshold\": 0.5,\n      \"prefix_padding_ms\": 300,\n      \"silence_duration_ms\": 500,\n      \"create_response\": true,\n      // \"interrupt_response\": false  -- this will NOT be returned\n    },\n    \"input_audio_noise_reduction\": {\n      \"type\": \"near_field\"\n    },\n    \"include\": [\n      \"item.input_audio_transcription.avg_logprob\",\n    ],\n  }\n}\n"
        group: realtime
        name: transcription_session.updated
    RealtimeSession:
      type: object
      properties:
        id:
          type: string
          description: The unique ID of the session.
          example: sess_001
        object:
          enum:
            - realtime.session
          type: string
          description: 'The object type, must be "realtime.session".'
          example: realtime.session
        model:
          type: string
          description: The default model used for this session.
          example: gpt-4o-realtime-preview-2024-10-01
        modalities:
          type: array
          items:
            type: string
          description: 'The set of modalities the model can respond with. To disable audio, set this to ["text"].'
          example:
            - text
            - audio
        instructions:
          type: string
          description: The default system instructions prepended to model calls.
          example: Your knowledge cutoff is 2023-10. You are a helpful assistant.
        voice:
          enum:
            - alloy
            - echo
            - shimmer
          type: string
          description: The voice the model uses to respond. Cannot be changed once the model has responded with audio at least once.
          example: alloy
        input_audio_format:
          $ref: '#/components/schemas/RealtimeAudioFormat'
        output_audio_format:
          $ref: '#/components/schemas/RealtimeAudioFormat'
        input_audio_transcription:
          type: object
          properties:
            enabled:
              type: boolean
              description: Whether transcription is enabled.
              example: true
            model:
              type: string
              description: The model to use for transcription.
              example: whisper-1
          description: Configuration for input audio transcription. Can be set to null to turn off.
        turn_detection:
          type: object
          properties:
            type:
              enum:
                - server_vad
                - none
              type: string
              description: The type of turn detection.
              example: server_vad
            threshold:
              type: number
              description: Activation threshold for VAD (0.0 to 1.0).
              example: 0.5
            prefix_padding_ms:
              type: integer
              description: Amount of audio to include before speech starts (in milliseconds).
              example: 300
            silence_duration_ms:
              type: integer
              description: Duration of silence to detect speech stop (in milliseconds).
              example: 200
          description: Configuration for turn detection. Can be set to null to turn off.
        tools:
          type: array
          items:
            type: object
            properties:
              type:
                type: string
                description: 'The type of the tool, e.g., "function".'
                example: function
              name:
                type: string
                description: The name of the function.
                example: get_weather
              description:
                type: string
                description: The description of the function.
                example: Get the current weather for a location.
              parameters:
                type: object
                description: Parameters of the function in JSON Schema.
          description: Tools (functions) available to the model.
        tool_choice:
          enum:
            - auto
            - none
            - required
          type: string
          description: How the model chooses tools.
          example: auto
        temperature:
          type: number
          description: Sampling temperature for the model.
          example: 0.8
        max_output_tokens:
          oneOf:
            - type: integer
            - enum:
                - inf
              type: string
          description: 'Maximum number of output tokens for a single assistant response, inclusive of tool calls. Provide an integer between 1 and 4096 to limit output tokens, or "inf" for the maximum available tokens for a given model. Defaults to "inf".'
          default: inf
      description: "A session refers to a single WebSocket connection between a client and the server.\n\nOnce a client creates a session, it then sends JSON-formatted events containing text and audio chunks.\nThe server will respond in kind with audio containing voice output, a text transcript of that voice output,\nand function calls (if functions are provided by the client).\n\nA realtime Session represents the overall client-server interaction, and contains default configuration.\n\nIt has a set of default values which can be updated at any time (via session.update) or on a per-response level (via response.create).\n"
    RealtimeSessionCreateRequest:
      title: Realtime session configuration
      required:
        - type
        - model
      type: object
      properties:
        audio:
          type: object
          properties:
            input:
              type: object
              properties:
                format:
                  enum:
                    - pcm16
                    - g711_ulaw
                    - g711_alaw
                  type: string
                  description: "The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\nFor `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate,\nsingle channel (mono), and little-endian byte order.\n"
                  default: pcm16
                noise_reduction:
                  type: object
                  properties:
                    type:
                      enum:
                        - near_field
                        - far_field
                      type: string
                      description: "Type of noise reduction. `near_field` is for close-talking microphones such as headphones, `far_field` is for far-field microphones such as laptop or conference room microphones.\n"
                  description: "Configuration for input audio noise reduction. This can be set to `null` to turn off.\nNoise reduction filters audio added to the input audio buffer before it is sent to VAD and the model.\nFiltering the audio can improve VAD and turn detection accuracy (reducing false positives) and model performance by improving perception of the input audio.\n"
                transcription:
                  type: object
                  properties:
                    language:
                      type: string
                      description: "The language of the input audio. Supplying the input language in\n[ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`) format\nwill improve accuracy and latency.\n"
                    model:
                      enum:
                        - whisper-1
                        - gpt-4o-transcribe-latest
                        - gpt-4o-mini-transcribe
                        - gpt-4o-transcribe
                        - gpt-4o-transcribe-diarize
                      type: string
                      description: "The model to use for transcription. Current options are\n`whisper-1`, `gpt-4o-transcribe-latest`, `gpt-4o-mini-transcribe`, `gpt-4o-transcribe`,\nand `gpt-4o-transcribe-diarize`.\n"
                    prompt:
                      type: string
                      description: "An optional text to guide the model's style or continue a previous audio\nsegment.\nFor `whisper-1`, the [prompt is a list of keywords](https://platform.openai.com/docs/guides/speech-to-text#prompting).\nFor `gpt-4o-transcribe` models, the prompt is a free text string, for example \"expect words related to technology\".\n"
                  description: "Configuration for input audio transcription, defaults to off and can be set to `null` to turn off once on. Input audio transcription is not native to the model, since the model consumes audio directly. Transcription runs asynchronously through [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription) and should be treated as guidance of input audio content rather than precisely what the model heard. The client can optionally set the language and prompt for transcription, these offer additional guidance to the transcription service.\n"
                turn_detection:
                  type: object
                  properties:
                    create_response:
                      type: boolean
                      description: "Whether or not to automatically generate a response when a VAD stop event occurs.\n"
                      default: true
                    eagerness:
                      enum:
                        - low
                        - medium
                        - high
                        - auto
                      type: string
                      description: "Used only for `semantic_vad` mode. The eagerness of the model to respond. `low` will wait longer for the user to continue speaking, `high` will respond more quickly. `auto` is the default and is equivalent to `medium`.\n"
                      default: auto
                    idle_timeout_ms:
                      type: integer
                      description: "Optional idle timeout after which turn detection will auto-timeout when\nno additional audio is received.\n"
                      nullable: true
                    interrupt_response:
                      type: boolean
                      description: "Whether or not to automatically interrupt any ongoing response with output to the default\nconversation (i.e. `conversation` of `auto`) when a VAD start event occurs.\n"
                      default: true
                    prefix_padding_ms:
                      type: integer
                      description: "Used only for `server_vad` mode. Amount of audio to include before the VAD detected speech (in\nmilliseconds). Defaults to 300ms.\n"
                    silence_duration_ms:
                      type: integer
                      description: "Used only for `server_vad` mode. Duration of silence to detect speech stop (in milliseconds). Defaults\nto 500ms. With shorter values the model will respond more quickly,\nbut may jump in on short pauses from the user.\n"
                    threshold:
                      type: number
                      description: "Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A\nhigher threshold will require louder audio to activate the model, and\nthus might perform better in noisy environments.\n"
                    type:
                      enum:
                        - server_vad
                        - semantic_vad
                      type: string
                      description: "Type of turn detection.\n"
                      default: server_vad
                  description: "Configuration for turn detection, ether Server VAD or Semantic VAD. This can be set to `null` to turn off, in which case the client must manually trigger model response.\nServer VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech.\nSemantic VAD is more advanced and uses a turn detection model (in conjunction with VAD) to semantically estimate whether the user has finished speaking, then dynamically sets a timeout based on this probability. For example, if user audio trails off with \"uhhm\", the model will score a low probability of turn end and wait longer for the user to continue speaking. This can be useful for more natural conversations, but may have a higher latency.\n"
            output:
              type: object
              properties:
                format:
                  enum:
                    - pcm16
                    - g711_ulaw
                    - g711_alaw
                  type: string
                  description: "The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\nFor `pcm16`, output audio is sampled at a rate of 24kHz.\n"
                  default: pcm16
                speed:
                  maximum: 1.5
                  minimum: 0.25
                  type: number
                  description: "The speed of the model's spoken response. 1.0 is the default speed. 0.25 is\nthe minimum speed. 1.5 is the maximum speed. This value can only be changed\nin between model turns, not while a response is in progress.\n"
                  default: 1
                voice:
                  $ref: '#/components/schemas/VoiceIdsShared'
          description: "Configuration for input and output audio.\n"
        client_secret:
          type: object
          properties:
            expires_after:
              required:
                - anchor
              type: object
              properties:
                anchor:
                  enum:
                    - created_at
                  type: string
                  description: "The anchor point for the ephemeral token expiration. Only `created_at` is currently supported.\n"
                seconds:
                  type: integer
                  description: "The number of seconds from the anchor point to the expiration. Select a value between `10` and `7200`.\n"
                  default: 600
              description: "Configuration for the ephemeral token expiration.\n"
          description: "Configuration options for the generated client secret.\n"
        include:
          type: array
          items:
            enum:
              - item.input_audio_transcription.logprobs
            type: string
          description: "Additional fields to include in server outputs.\n- `item.input_audio_transcription.logprobs`: Include logprobs for input audio transcription.\n"
        instructions:
          type: string
          description: "The default system instructions (i.e. system message) prepended to model calls. This field allows the client to guide the model on desired responses. The model can be instructed on response content and format, (e.g. \"be extremely succinct\", \"act friendly\", \"here are examples of good responses\") and on audio behavior (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The instructions are not guaranteed to be followed by the model, but they provide guidance to the model on the desired behavior.\n\nNote that the server sets default instructions which will be used if this field is not set and are visible in the `session.created` event at the start of the session.\n"
        max_output_tokens:
          anyOf:
            - type: integer
            - enum:
                - inf
              type: string
              x-stainless-const: true
          description: "Maximum number of output tokens for a single assistant response,\ninclusive of tool calls. Provide an integer between 1 and 4096 to\nlimit output tokens, or `inf` for the maximum available tokens for a\ngiven model. Defaults to `inf`.\n"
        model:
          anyOf:
            - type: string
            - enum:
                - gpt-realtime
                - gpt-realtime-2025-08-28
                - gpt-4o-realtime
                - gpt-4o-mini-realtime
                - gpt-4o-realtime-preview
                - gpt-4o-realtime-preview-2024-10-01
                - gpt-4o-realtime-preview-2024-12-17
                - gpt-4o-realtime-preview-2025-06-03
                - gpt-4o-mini-realtime-preview
                - gpt-4o-mini-realtime-preview-2024-12-17
              type: string
              x-stainless-nominal: false
          description: "The Realtime model used for this session.\n"
        output_modalities:
          items:
            enum:
              - text
              - audio
            type: string
          description: "The set of modalities the model can respond with. To disable audio,\nset this to [\"text\"].\n"
        prompt:
          $ref: '#/components/schemas/Prompt'
        temperature:
          type: number
          description: "Sampling temperature for the model, limited to [0.6, 1.2]. For audio models a temperature of 0.8 is highly recommended for best performance.\n"
          default: 0.8
        tool_choice:
          anyOf:
            - $ref: '#/components/schemas/ToolChoiceOptions'
            - $ref: '#/components/schemas/ToolChoiceFunction'
            - $ref: '#/components/schemas/ToolChoiceMCP'
          description: "How the model chooses tools. Provide one of the string modes or force a specific\nfunction/MCP tool.\n"
          default: auto
        tools:
          type: array
          items:
            anyOf:
              - title: Function tool
                type: object
                properties:
                  description:
                    type: string
                    description: "The description of the function, including guidance on when and how\nto call it, and guidance about what to tell the user when calling\n(if anything).\n"
                  name:
                    type: string
                    description: The name of the function.
                  parameters:
                    type: object
                    description: Parameters of the function in JSON Schema.
                  type:
                    enum:
                      - function
                    type: string
                    description: 'The type of the tool, i.e. `function`.'
                    x-stainless-const: true
              - $ref: '#/components/schemas/MCPTool'
            discriminator:
              propertyName: type
          description: Tools available to the model.
        tracing:
          title: Tracing Configuration
          anyOf:
            - enum:
                - auto
              type: string
              description: "Default tracing mode for the session.\n"
              default: auto
              x-stainless-const: true
            - title: Tracing Configuration
              type: object
              properties:
                group_id:
                  type: string
                  description: "The group id to attach to this trace to enable filtering and\ngrouping in the traces dashboard.\n"
                metadata:
                  type: object
                  description: "The arbitrary metadata to attach to this trace to enable\nfiltering in the traces dashboard.\n"
                workflow_name:
                  type: string
                  description: "The name of the workflow to attach to this trace. This is used to\nname the trace in the traces dashboard.\n"
              description: "Granular configuration for tracing.\n"
          description: "Configuration options for tracing. Set to null to disable tracing. Once\ntracing is enabled for a session, the configuration cannot be modified.\n\n`auto` will create a trace for the session with default values for the\nworkflow name, group id, and metadata.\n"
          nullable: true
        truncation:
          $ref: '#/components/schemas/RealtimeTruncation'
        type:
          enum:
            - realtime
          type: string
          description: "The type of session to create. Always `realtime` for the Realtime API.\n"
          x-stainless-const: true
      description: Realtime session object configuration.
    RealtimeSessionCreateResponse:
      title: Realtime session configuration object
      required:
        - client_secret
      type: object
      properties:
        audio:
          type: object
          properties:
            input:
              type: object
              properties:
                format:
                  type: string
                  description: "The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n"
                noise_reduction:
                  type: object
                  properties:
                    type:
                      enum:
                        - near_field
                        - far_field
                      type: string
                  description: "Configuration for input audio noise reduction.\n"
                transcription:
                  type: object
                  properties:
                    language:
                      type: string
                      description: "The language of the input audio.\n"
                    model:
                      type: string
                      description: "The model to use for transcription.\n"
                    prompt:
                      type: string
                      description: "Optional text to guide the model's style or continue a previous audio segment.\n"
                  description: "Configuration for input audio transcription.\n"
                turn_detection:
                  type: object
                  properties:
                    prefix_padding_ms:
                      type: integer
                    silence_duration_ms:
                      type: integer
                    threshold:
                      type: number
                    type:
                      type: string
                      description: "Type of turn detection, only `server_vad` is currently supported.\n"
                  description: "Configuration for turn detection.\n"
            output:
              type: object
              properties:
                format:
                  type: string
                  description: "The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n"
                speed:
                  type: number
                voice:
                  $ref: '#/components/schemas/VoiceIdsShared'
          description: "Configuration for input and output audio for the session.\n"
        expires_at:
          type: integer
          description: 'Expiration timestamp for the session, in seconds since epoch.'
        id:
          type: string
          description: "Unique identifier for the session that looks like `sess_1234567890abcdef`.\n"
        include:
          type: array
          items:
            enum:
              - item.input_audio_transcription.logprobs
            type: string
          description: "Additional fields to include in server outputs.\n- `item.input_audio_transcription.logprobs`: Include logprobs for input audio transcription.\n"
        instructions:
          type: string
          description: "The default system instructions (i.e. system message) prepended to model\ncalls. This field allows the client to guide the model on desired\nresponses. The model can be instructed on response content and format,\n(e.g. \"be extremely succinct\", \"act friendly\", \"here are examples of good\nresponses\") and on audio behavior (e.g. \"talk quickly\", \"inject emotion\ninto your voice\", \"laugh frequently\"). The instructions are not guaranteed\nto be followed by the model, but they provide guidance to the model on the\ndesired behavior.\n\nNote that the server sets default instructions which will be used if this\nfield is not set and are visible in the `session.created` event at the\nstart of the session.\n"
        max_output_tokens:
          anyOf:
            - type: integer
            - enum:
                - inf
              type: string
              x-stainless-const: true
          description: "Maximum number of output tokens for a single assistant response,\ninclusive of tool calls. Provide an integer between 1 and 4096 to\nlimit output tokens, or `inf` for the maximum available tokens for a\ngiven model. Defaults to `inf`.\n"
        model:
          type: string
          description: The Realtime model used for this session.
        object:
          type: string
          description: The object type. Always `realtime.session`.
        output_modalities:
          items:
            enum:
              - text
              - audio
            type: string
          description: "The set of modalities the model can respond with. To disable audio,\nset this to [\"text\"].\n"
        tool_choice:
          type: string
          description: "How the model chooses tools. Options are `auto`, `none`, `required`, or\nspecify a function.\n"
        tools:
          type: array
          items:
            type: object
            properties:
              description:
                type: string
                description: "The description of the function, including guidance on when and how\nto call it, and guidance about what to tell the user when calling\n(if anything).\n"
              name:
                type: string
                description: The name of the function.
              parameters:
                type: object
                description: Parameters of the function in JSON Schema.
              type:
                enum:
                  - function
                type: string
                description: 'The type of the tool, i.e. `function`.'
                x-stainless-const: true
          description: Tools (functions) available to the model.
        tracing:
          title: Tracing Configuration
          anyOf:
            - enum:
                - auto
              type: string
              description: "Default tracing mode for the session.\n"
              default: auto
              x-stainless-const: true
            - title: Tracing Configuration
              type: object
              properties:
                group_id:
                  type: string
                  description: "The group id to attach to this trace to enable filtering and\ngrouping in the traces dashboard.\n"
                metadata:
                  type: object
                  description: "The arbitrary metadata to attach to this trace to enable\nfiltering in the traces dashboard.\n"
                workflow_name:
                  type: string
                  description: "The name of the workflow to attach to this trace. This is used to\nname the trace in the traces dashboard.\n"
              description: "Granular configuration for tracing.\n"
          description: "Configuration options for tracing. Set to null to disable tracing. Once\ntracing is enabled for a session, the configuration cannot be modified.\n\n`auto` will create a trace for the session with default values for the\nworkflow name, group id, and metadata.\n"
        turn_detection:
          type: object
          properties:
            prefix_padding_ms:
              type: integer
              description: "Amount of audio to include before the VAD detected speech (in\nmilliseconds). Defaults to 300ms.\n"
            silence_duration_ms:
              type: integer
              description: "Duration of silence to detect speech stop (in milliseconds). Defaults\nto 500ms. With shorter values the model will respond more quickly,\nbut may jump in on short pauses from the user.\n"
            threshold:
              type: number
              description: "Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A\nhigher threshold will require louder audio to activate the model, and\nthus might perform better in noisy environments.\n"
            type:
              type: string
              description: "Type of turn detection, only `server_vad` is currently supported.\n"
          description: "Configuration for turn detection. Can be set to `null` to turn off. Server\nVAD means that the model will detect the start and end of speech based on\naudio volume and respond at the end of user speech.\n"
      description: "A Realtime session configuration object.\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"sess_001\",\n  \"object\": \"realtime.session\",\n  \"expires_at\": 1742188264,\n  \"model\": \"gpt-4o-realtime\",\n  \"output_modalities\": [\"audio\", \"text\"],\n  \"instructions\": \"You are a friendly assistant.\",\n  \"tools\": [],\n  \"tool_choice\": \"none\",\n  \"max_output_tokens\": \"inf\",\n  \"tracing\": \"auto\",\n  \"truncation\": \"auto\",\n  \"prompt\": null,\n  \"audio\": {\n    \"input\": {\n      \"format\": \"pcm16\",\n      \"transcription\": { \"model\": \"whisper-1\" },\n      \"noise_reduction\": null,\n      \"turn_detection\": null\n    },\n    \"output\": {\n      \"format\": \"pcm16\",\n      \"voice\": \"alloy\",\n      \"speed\": 1.0\n    }\n  },\n  \"client_secret\": {\n    \"value\": \"ek_abc123\",\n    \"expires_at\": 1234567890\n  }\n}\n"
        group: realtime
        name: The session object
    RealtimeTranscriptionSessionCreateRequest:
      title: Realtime transcription session configuration
      required:
        - type
        - model
      type: object
      properties:
        include:
          type: array
          items:
            enum:
              - item.input_audio_transcription.logprobs
            type: string
          description: "The set of items to include in the transcription. Current available items are:\n- `item.input_audio_transcription.logprobs`\n"
        input_audio_format:
          enum:
            - pcm16
            - g711_ulaw
            - g711_alaw
          type: string
          description: "The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\nFor `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate,\nsingle channel (mono), and little-endian byte order.\n"
          default: pcm16
        input_audio_noise_reduction:
          type: object
          properties:
            type:
              enum:
                - near_field
                - far_field
              type: string
              description: "Type of noise reduction. `near_field` is for close-talking microphones such as headphones, `far_field` is for far-field microphones such as laptop or conference room microphones.\n"
          description: "Configuration for input audio noise reduction. This can be set to `null` to turn off.\nNoise reduction filters audio added to the input audio buffer before it is sent to VAD and the model.\nFiltering the audio can improve VAD and turn detection accuracy (reducing false positives) and model performance by improving perception of the input audio.\n"
        input_audio_transcription:
          type: object
          properties:
            language:
              type: string
              description: "The language of the input audio. Supplying the input language in\n[ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`) format\nwill improve accuracy and latency.\n"
            model:
              enum:
                - gpt-4o-transcribe
                - gpt-4o-mini-transcribe
                - whisper-1
              type: string
              description: "The model to use for transcription, current options are `gpt-4o-transcribe`, `gpt-4o-mini-transcribe`, and `whisper-1`.\n"
            prompt:
              type: string
              description: "An optional text to guide the model's style or continue a previous audio\nsegment.\nFor `whisper-1`, the [prompt is a list of keywords](https://platform.openai.com/docs/guides/speech-to-text#prompting).\nFor `gpt-4o-transcribe` models, the prompt is a free text string, for example \"expect words related to technology\".\n"
          description: "Configuration for input audio transcription. The client can optionally set the language and prompt for transcription, these offer additional guidance to the transcription service.\n"
        model:
          anyOf:
            - type: string
            - enum:
                - whisper-1
                - gpt-4o-transcribe
                - gpt-4o-mini-transcribe
              type: string
              x-stainless-nominal: false
          description: "ID of the model to use. The options are `gpt-4o-transcribe`, `gpt-4o-mini-transcribe`, and `whisper-1` (which is powered by our open source Whisper V2 model).\n"
          example: gpt-4o-transcribe
        turn_detection:
          type: object
          properties:
            prefix_padding_ms:
              type: integer
              description: "Amount of audio to include before the VAD detected speech (in\nmilliseconds). Defaults to 300ms.\n"
            silence_duration_ms:
              type: integer
              description: "Duration of silence to detect speech stop (in milliseconds). Defaults\nto 500ms. With shorter values the model will respond more quickly,\nbut may jump in on short pauses from the user.\n"
            threshold:
              type: number
              description: "Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A\nhigher threshold will require louder audio to activate the model, and\nthus might perform better in noisy environments.\n"
            type:
              enum:
                - server_vad
              type: string
              description: "Type of turn detection. Only `server_vad` is currently supported for transcription sessions.\n"
          description: "Configuration for turn detection. Can be set to `null` to turn off. Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech.\n"
        type:
          enum:
            - transcription
          type: string
          description: "The type of session to create. Always `transcription` for transcription sessions.\n"
          x-stainless-const: true
      description: Realtime transcription session object configuration.
    RealtimeTranscriptionSessionCreateResponse:
      title: Realtime transcription session configuration object
      type: object
      properties:
        audio:
          type: object
          properties:
            input:
              type: object
              properties:
                format:
                  type: string
                  description: "The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n"
                noise_reduction:
                  type: object
                  properties:
                    type:
                      enum:
                        - near_field
                        - far_field
                      type: string
                  description: "Configuration for input audio noise reduction.\n"
                transcription:
                  type: object
                  properties:
                    language:
                      type: string
                      description: "The language of the input audio. Supplying the input language in\n[ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`) format\nwill improve accuracy and latency.\n"
                    model:
                      enum:
                        - gpt-4o-transcribe
                        - gpt-4o-mini-transcribe
                        - whisper-1
                      type: string
                      description: "The model to use for transcription. Can be `gpt-4o-transcribe`, `gpt-4o-mini-transcribe`, or `whisper-1`.\n"
                    prompt:
                      type: string
                      description: "An optional text to guide the model's style or continue a previous audio segment. The [prompt](https://platform.openai.com/docs/guides/speech-to-text#prompting) should match the audio language.\n"
                  description: "Configuration of the transcription model.\n"
                turn_detection:
                  type: object
                  properties:
                    prefix_padding_ms:
                      type: integer
                    silence_duration_ms:
                      type: integer
                    threshold:
                      type: number
                    type:
                      type: string
                      description: "Type of turn detection, only `server_vad` is currently supported.\n"
                  description: "Configuration for turn detection.\n"
          description: "Configuration for input audio for the session.\n"
        expires_at:
          type: integer
          description: 'Expiration timestamp for the session, in seconds since epoch.'
        id:
          type: string
          description: "Unique identifier for the session that looks like `sess_1234567890abcdef`.\n"
        include:
          type: array
          items:
            enum:
              - item.input_audio_transcription.logprobs
            type: string
          description: "Additional fields to include in server outputs.\n- `item.input_audio_transcription.logprobs`: Include logprobs for input audio transcription.\n"
        object:
          type: string
          description: The object type. Always `realtime.transcription_session`.
      description: "A Realtime transcription session configuration object.\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"sess_BBwZc7cFV3XizEyKGDCGL\",\n  \"object\": \"realtime.transcription_session\",\n  \"expires_at\": 1742188264,\n  \"include\": [\"item.input_audio_transcription.logprobs\"],\n  \"audio\": {\n    \"input\": {\n      \"format\": \"pcm16\",\n      \"transcription\": {\n        \"model\": \"gpt-4o-transcribe\",\n        \"language\": null,\n        \"prompt\": \"\"\n      },\n      \"noise_reduction\": null,\n      \"turn_detection\": {\n        \"type\": \"server_vad\",\n        \"threshold\": 0.5,\n        \"prefix_padding_ms\": 300,\n        \"silence_duration_ms\": 200\n      }\n    }\n  }\n}\n"
        group: realtime
        name: The transcription session object
    RealtimeTruncation:
      title: Realtime Truncation Controls
      anyOf:
        - title: RealtimeTruncationStrategy
          enum:
            - auto
            - disabled
          type: string
          description: The truncation strategy to use for the session.
        - title: Retention ratio truncation
          required:
            - type
            - retention_ratio
          type: object
          properties:
            post_instructions_token_limit:
              type: integer
              description: "Optional cap on tokens allowed after the instructions.\n"
              nullable: true
            retention_ratio:
              maximum: 1
              minimum: 0
              type: number
              description: "Fraction of pre-instruction conversation tokens to retain (0.0 - 1.0).\n"
            type:
              enum:
                - retention_ratio
              type: string
              description: Use retention ratio truncation.
              x-stainless-const: true
          description: Retain a fraction of the conversation tokens.
      description: "Controls how the realtime conversation is truncated prior to model inference.\nThe default is `auto`. When set to `retention_ratio`, the server retains a\nfraction of the conversation tokens prior to the instructions.\n"
    Reasoning:
      title: Reasoning
      type: object
      properties:
        effort:
          $ref: '#/components/schemas/ReasoningEffort'
        generate_summary:
          enum:
            - auto
            - concise
            - detailed
          type: string
          description: "**Deprecated:** use `summary` instead.\n\nA summary of the reasoning performed by the model. This can be\nuseful for debugging and understanding the model's reasoning process.\nOne of `auto`, `concise`, or `detailed`.\n"
          nullable: true
          deprecated: true
        summary:
          enum:
            - auto
            - concise
            - detailed
          type: string
          description: "A summary of the reasoning performed by the model. This can be\nuseful for debugging and understanding the model's reasoning process.\nOne of `auto`, `concise`, or `detailed`.\n"
          nullable: true
      description: "**gpt-5 and o-series models only**\n\nConfiguration options for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\n"
    ReasoningEffort:
      enum:
        - minimal
        - low
        - medium
        - high
      type: string
      description: "Constrains effort on reasoning for \n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n"
      default: medium
      nullable: true
    ReasoningItem:
      title: Reasoning
      required:
        - id
        - summary
        - type
      type: object
      properties:
        content:
          type: array
          items:
            required:
              - type
              - text
            type: object
            properties:
              text:
                type: string
                description: "Reasoning text output from the model.\n"
              type:
                enum:
                  - reasoning_text
                type: string
                description: "The type of the object. Always `reasoning_text`.\n"
                x-stainless-const: true
          description: "Reasoning text content.\n"
        encrypted_content:
          type: string
          description: "The encrypted content of the reasoning item - populated when a response is\ngenerated with `reasoning.encrypted_content` in the `include` parameter.\n"
          nullable: true
        id:
          type: string
          description: "The unique identifier of the reasoning content.\n"
        status:
          enum:
            - in_progress
            - completed
            - incomplete
          type: string
          description: "The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n"
        summary:
          type: array
          items:
            required:
              - type
              - text
            type: object
            properties:
              text:
                type: string
                description: "A summary of the reasoning output from the model so far.\n"
              type:
                enum:
                  - summary_text
                type: string
                description: "The type of the object. Always `summary_text`.\n"
                x-stainless-const: true
          description: "Reasoning summary content.\n"
        type:
          enum:
            - reasoning
          type: string
          description: "The type of the object. Always `reasoning`.\n"
          x-stainless-const: true
      description: "A description of the chain of thought used by a reasoning model while generating\na response. Be sure to include these items in your `input` to the Responses API\nfor subsequent turns of a conversation if you are manually \n[managing context](https://platform.openai.com/docs/guides/conversation-state).\n"
    RefusalContent:
      title: Refusal
      required:
        - type
        - refusal
      type: object
      properties:
        refusal:
          type: string
          description: The refusal explanation from the model.
        type:
          enum:
            - refusal
          type: string
          description: The type of the refusal. Always `refusal`.
          default: refusal
          x-stainless-const: true
      description: A refusal from the model.
    RefusalContent-2:
      title: Refusal
      required:
        - type
        - refusal
      type: object
      properties:
        refusal:
          type: string
          description: The refusal explanation from the model.
        type:
          enum:
            - refusal
          type: string
          description: The type of the refusal. Always `refusal`.
          default: refusal
          x-stainless-const: true
    Response:
      title: The response object
      allOf:
        - $ref: '#/components/schemas/ModelResponseProperties'
        - $ref: '#/components/schemas/ResponseProperties'
        - required:
            - id
            - object
            - created_at
            - error
            - incomplete_details
            - instructions
            - model
            - tools
            - output
            - parallel_tool_calls
            - metadata
            - tool_choice
            - temperature
            - top_p
          type: object
          properties:
            conversation:
              $ref: '#/components/schemas/Conversation-2'
            created_at:
              type: number
              description: "Unix timestamp (in seconds) of when this Response was created.\n"
            error:
              $ref: '#/components/schemas/ResponseError'
            id:
              type: string
              description: "Unique identifier for this Response.\n"
            incomplete_details:
              type: object
              properties:
                reason:
                  enum:
                    - max_output_tokens
                    - content_filter
                  type: string
                  description: The reason why the response is incomplete.
              description: "Details about why the response is incomplete.\n"
              nullable: true
            instructions:
              anyOf:
                - type: string
                  description: "A text input to the model, equivalent to a text input with the\n`developer` role.\n"
                - title: Input item list
                  type: array
                  items:
                    $ref: '#/components/schemas/InputItem'
                  description: "A list of one or many input items to the model, containing\ndifferent content types.\n"
              description: "A system (or developer) message inserted into the model's context.\n\nWhen using along with `previous_response_id`, the instructions from a previous\nresponse will not be carried over to the next response. This makes it simple\nto swap out system (or developer) messages in new responses.\n"
              nullable: true
            object:
              enum:
                - response
              type: string
              description: "The object type of this resource - always set to `response`.\n"
              x-stainless-const: true
            output:
              type: array
              items:
                $ref: '#/components/schemas/OutputItem'
              description: "An array of content items generated by the model.\n\n- The length and order of items in the `output` array is dependent\n  on the model's response.\n- Rather than accessing the first item in the `output` array and\n  assuming it's an `assistant` message with the content generated by\n  the model, you might consider using the `output_text` property where\n  supported in SDKs.\n"
            output_text:
              type: string
              description: "SDK-only convenience property that contains the aggregated text output\nfrom all `output_text` items in the `output` array, if any are present.\nSupported in the Python and JavaScript SDKs.\n"
              nullable: true
              x-oaiSupportedSDKs:
                - python
                - javascript
              x-stainless-skip: true
            parallel_tool_calls:
              type: boolean
              description: "Whether to allow the model to run tool calls in parallel.\n"
              default: true
            status:
              enum:
                - completed
                - failed
                - in_progress
                - cancelled
                - queued
                - incomplete
              type: string
              description: "The status of the response generation. One of `completed`, `failed`,\n`in_progress`, `cancelled`, `queued`, or `incomplete`.\n"
            usage:
              $ref: '#/components/schemas/ResponseUsage'
    ResponseAudioDeltaEvent:
      required:
        - type
        - delta
        - sequence_number
      type: object
      properties:
        delta:
          type: string
          description: "A chunk of Base64 encoded response audio bytes.\n"
        sequence_number:
          type: integer
          description: "A sequence number for this chunk of the stream response.\n"
        type:
          enum:
            - response.audio.delta
          type: string
          description: "The type of the event. Always `response.audio.delta`.\n"
          x-stainless-const: true
      description: Emitted when there is a partial audio response.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.audio.delta\",\n  \"response_id\": \"resp_123\",\n  \"delta\": \"base64encoded...\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.audio.delta
    ResponseAudioDoneEvent:
      required:
        - type
        - sequence_number
        - response_id
      type: object
      properties:
        sequence_number:
          type: integer
          description: "The sequence number of the delta.\n"
        type:
          enum:
            - response.audio.done
          type: string
          description: "The type of the event. Always `response.audio.done`.\n"
          x-stainless-const: true
      description: Emitted when the audio response is complete.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.audio.done\",\n  \"response_id\": \"resp-123\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.audio.done
    ResponseAudioTranscriptDeltaEvent:
      required:
        - type
        - response_id
        - delta
        - sequence_number
      type: object
      properties:
        delta:
          type: string
          description: "The partial transcript of the audio response.\n"
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.audio.transcript.delta
          type: string
          description: "The type of the event. Always `response.audio.transcript.delta`.\n"
          x-stainless-const: true
      description: Emitted when there is a partial transcript of audio.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.audio.transcript.delta\",\n  \"response_id\": \"resp_123\",\n  \"delta\": \" ... partial transcript ... \",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.audio.transcript.delta
    ResponseAudioTranscriptDoneEvent:
      required:
        - type
        - response_id
        - sequence_number
      type: object
      properties:
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.audio.transcript.done
          type: string
          description: "The type of the event. Always `response.audio.transcript.done`.\n"
          x-stainless-const: true
      description: Emitted when the full audio transcript is completed.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.audio.transcript.done\",\n  \"response_id\": \"resp_123\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.audio.transcript.done
    ResponseCodeInterpreterCallCodeDeltaEvent:
      required:
        - type
        - output_index
        - item_id
        - delta
        - sequence_number
      type: object
      properties:
        delta:
          type: string
          description: The partial code snippet being streamed by the code interpreter.
        item_id:
          type: string
          description: The unique identifier of the code interpreter tool call item.
        output_index:
          type: integer
          description: The index of the output item in the response for which the code is being streamed.
        sequence_number:
          type: integer
          description: 'The sequence number of this event, used to order streaming events.'
        type:
          enum:
            - response.code_interpreter_call_code.delta
          type: string
          description: The type of the event. Always `response.code_interpreter_call_code.delta`.
          x-stainless-const: true
      description: Emitted when a partial code snippet is streamed by the code interpreter.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.code_interpreter_call_code.delta\",\n  \"output_index\": 0,\n  \"item_id\": \"ci_12345\",\n  \"delta\": \"print('Hello, world')\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.code_interpreter_call_code.delta
    ResponseCodeInterpreterCallCodeDoneEvent:
      required:
        - type
        - output_index
        - item_id
        - code
        - sequence_number
      type: object
      properties:
        code:
          type: string
          description: The final code snippet output by the code interpreter.
        item_id:
          type: string
          description: The unique identifier of the code interpreter tool call item.
        output_index:
          type: integer
          description: The index of the output item in the response for which the code is finalized.
        sequence_number:
          type: integer
          description: 'The sequence number of this event, used to order streaming events.'
        type:
          enum:
            - response.code_interpreter_call_code.done
          type: string
          description: The type of the event. Always `response.code_interpreter_call_code.done`.
          x-stainless-const: true
      description: Emitted when the code snippet is finalized by the code interpreter.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.code_interpreter_call_code.done\",\n  \"output_index\": 3,\n  \"item_id\": \"ci_12345\",\n  \"code\": \"print('done')\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.code_interpreter_call_code.done
    ResponseCodeInterpreterCallCompletedEvent:
      required:
        - type
        - output_index
        - item_id
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: The unique identifier of the code interpreter tool call item.
        output_index:
          type: integer
          description: The index of the output item in the response for which the code interpreter call is completed.
        sequence_number:
          type: integer
          description: 'The sequence number of this event, used to order streaming events.'
        type:
          enum:
            - response.code_interpreter_call.completed
          type: string
          description: The type of the event. Always `response.code_interpreter_call.completed`.
          x-stainless-const: true
      description: Emitted when the code interpreter call is completed.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.code_interpreter_call.completed\",\n  \"output_index\": 5,\n  \"item_id\": \"ci_12345\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.code_interpreter_call.completed
    ResponseCodeInterpreterCallInProgressEvent:
      required:
        - type
        - output_index
        - item_id
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: The unique identifier of the code interpreter tool call item.
        output_index:
          type: integer
          description: The index of the output item in the response for which the code interpreter call is in progress.
        sequence_number:
          type: integer
          description: 'The sequence number of this event, used to order streaming events.'
        type:
          enum:
            - response.code_interpreter_call.in_progress
          type: string
          description: The type of the event. Always `response.code_interpreter_call.in_progress`.
          x-stainless-const: true
      description: Emitted when a code interpreter call is in progress.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.code_interpreter_call.in_progress\",\n  \"output_index\": 0,\n  \"item_id\": \"ci_12345\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.code_interpreter_call.in_progress
    ResponseCodeInterpreterCallInterpretingEvent:
      required:
        - type
        - output_index
        - item_id
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: The unique identifier of the code interpreter tool call item.
        output_index:
          type: integer
          description: The index of the output item in the response for which the code interpreter is interpreting code.
        sequence_number:
          type: integer
          description: 'The sequence number of this event, used to order streaming events.'
        type:
          enum:
            - response.code_interpreter_call.interpreting
          type: string
          description: The type of the event. Always `response.code_interpreter_call.interpreting`.
          x-stainless-const: true
      description: Emitted when the code interpreter is actively interpreting the code snippet.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.code_interpreter_call.interpreting\",\n  \"output_index\": 4,\n  \"item_id\": \"ci_12345\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.code_interpreter_call.interpreting
    ResponseCompletedEvent:
      required:
        - type
        - response
        - sequence_number
      type: object
      properties:
        response:
          $ref: '#/components/schemas/Response'
        sequence_number:
          type: integer
          description: The sequence number for this event.
        type:
          enum:
            - response.completed
          type: string
          description: "The type of the event. Always `response.completed`.\n"
          x-stainless-const: true
      description: Emitted when the model response is complete.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.completed\",\n  \"response\": {\n    \"id\": \"resp_123\",\n    \"object\": \"response\",\n    \"created_at\": 1740855869,\n    \"status\": \"completed\",\n    \"error\": null,\n    \"incomplete_details\": null,\n    \"input\": [],\n    \"instructions\": null,\n    \"max_output_tokens\": null,\n    \"model\": \"gpt-4o-mini-2024-07-18\",\n    \"output\": [\n      {\n        \"id\": \"msg_123\",\n        \"type\": \"message\",\n        \"role\": \"assistant\",\n        \"content\": [\n          {\n            \"type\": \"output_text\",\n            \"text\": \"In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.\",\n            \"annotations\": []\n          }\n        ]\n      }\n    ],\n    \"previous_response_id\": null,\n    \"reasoning_effort\": null,\n    \"store\": false,\n    \"temperature\": 1,\n    \"text\": {\n      \"format\": {\n        \"type\": \"text\"\n      }\n    },\n    \"tool_choice\": \"auto\",\n    \"tools\": [],\n    \"top_p\": 1,\n    \"truncation\": \"disabled\",\n    \"usage\": {\n      \"input_tokens\": 0,\n      \"output_tokens\": 0,\n      \"output_tokens_details\": {\n        \"reasoning_tokens\": 0\n      },\n      \"total_tokens\": 0\n    },\n    \"user\": null,\n    \"metadata\": {}\n  },\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.completed
    ResponseContentPartAddedEvent:
      required:
        - type
        - item_id
        - output_index
        - content_index
        - part
        - sequence_number
      type: object
      properties:
        content_index:
          type: integer
          description: "The index of the content part that was added.\n"
        item_id:
          type: string
          description: "The ID of the output item that the content part was added to.\n"
        output_index:
          type: integer
          description: "The index of the output item that the content part was added to.\n"
        part:
          $ref: '#/components/schemas/OutputContent'
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.content_part.added
          type: string
          description: "The type of the event. Always `response.content_part.added`.\n"
          x-stainless-const: true
      description: Emitted when a new content part is added.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.content_part.added\",\n  \"item_id\": \"msg_123\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"part\": {\n    \"type\": \"output_text\",\n    \"text\": \"\",\n    \"annotations\": []\n  },\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.content_part.added
    ResponseContentPartDoneEvent:
      required:
        - type
        - item_id
        - output_index
        - content_index
        - part
        - sequence_number
      type: object
      properties:
        content_index:
          type: integer
          description: "The index of the content part that is done.\n"
        item_id:
          type: string
          description: "The ID of the output item that the content part was added to.\n"
        output_index:
          type: integer
          description: "The index of the output item that the content part was added to.\n"
        part:
          $ref: '#/components/schemas/OutputContent'
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.content_part.done
          type: string
          description: "The type of the event. Always `response.content_part.done`.\n"
          x-stainless-const: true
      description: Emitted when a content part is done.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.content_part.done\",\n  \"item_id\": \"msg_123\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"sequence_number\": 1,\n  \"part\": {\n    \"type\": \"output_text\",\n    \"text\": \"In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.\",\n    \"annotations\": []\n  }\n}\n"
        group: responses
        name: response.content_part.done
    ResponseCreatedEvent:
      required:
        - type
        - response
        - sequence_number
      type: object
      properties:
        response:
          $ref: '#/components/schemas/Response'
        sequence_number:
          type: integer
          description: The sequence number for this event.
        type:
          enum:
            - response.created
          type: string
          description: "The type of the event. Always `response.created`.\n"
          x-stainless-const: true
      description: "An event that is emitted when a response is created.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.created\",\n  \"response\": {\n    \"id\": \"resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c\",\n    \"object\": \"response\",\n    \"created_at\": 1741487325,\n    \"status\": \"in_progress\",\n    \"error\": null,\n    \"incomplete_details\": null,\n    \"instructions\": null,\n    \"max_output_tokens\": null,\n    \"model\": \"gpt-4o-2024-08-06\",\n    \"output\": [],\n    \"parallel_tool_calls\": true,\n    \"previous_response_id\": null,\n    \"reasoning\": {\n      \"effort\": null,\n      \"summary\": null\n    },\n    \"store\": true,\n    \"temperature\": 1,\n    \"text\": {\n      \"format\": {\n        \"type\": \"text\"\n      }\n    },\n    \"tool_choice\": \"auto\",\n    \"tools\": [],\n    \"top_p\": 1,\n    \"truncation\": \"disabled\",\n    \"usage\": null,\n    \"user\": null,\n    \"metadata\": {}\n  },\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.created
    ResponseCustomToolCallInputDeltaEvent:
      title: ResponseCustomToolCallInputDelta
      required:
        - type
        - output_index
        - item_id
        - delta
        - sequence_number
      type: object
      properties:
        delta:
          type: string
          description: The incremental input data (delta) for the custom tool call.
        item_id:
          type: string
          description: Unique identifier for the API item associated with this event.
        output_index:
          type: integer
          description: The index of the output this delta applies to.
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.custom_tool_call_input.delta
          type: string
          description: The event type identifier.
          x-stainless-const: true
      description: "Event representing a delta (partial update) to the input of a custom tool call.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.custom_tool_call_input.delta\",\n  \"output_index\": 0,\n  \"item_id\": \"ctc_1234567890abcdef\",\n  \"delta\": \"partial input text\"\n}\n"
        group: responses
        name: response.custom_tool_call_input.delta
    ResponseCustomToolCallInputDoneEvent:
      title: ResponseCustomToolCallInputDone
      required:
        - type
        - output_index
        - item_id
        - input
        - sequence_number
      type: object
      properties:
        input:
          type: string
          description: The complete input data for the custom tool call.
        item_id:
          type: string
          description: Unique identifier for the API item associated with this event.
        output_index:
          type: integer
          description: The index of the output this event applies to.
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.custom_tool_call_input.done
          type: string
          description: The event type identifier.
          x-stainless-const: true
      description: "Event indicating that input for a custom tool call is complete.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.custom_tool_call_input.done\",\n  \"output_index\": 0,\n  \"item_id\": \"ctc_1234567890abcdef\",\n  \"input\": \"final complete input text\"\n}\n"
        group: responses
        name: response.custom_tool_call_input.done
    ResponseError:
      required:
        - code
        - message
      type: object
      properties:
        code:
          $ref: '#/components/schemas/ResponseErrorCode'
        message:
          type: string
          description: "A human-readable description of the error.\n"
      description: "An error object returned when the model fails to generate a Response.\n"
      nullable: true
    ResponseErrorCode:
      enum:
        - server_error
        - rate_limit_exceeded
        - invalid_prompt
        - vector_store_timeout
        - invalid_image
        - invalid_image_format
        - invalid_base64_image
        - invalid_image_url
        - image_too_large
        - image_too_small
        - image_parse_error
        - image_content_policy_violation
        - invalid_image_mode
        - image_file_too_large
        - unsupported_image_media_type
        - empty_image_file
        - failed_to_download_image
        - image_file_not_found
      type: string
      description: "The error code for the response.\n"
    ResponseErrorEvent:
      required:
        - type
        - code
        - message
        - param
        - sequence_number
      type: object
      properties:
        code:
          type: string
          description: "The error code.\n"
          nullable: true
        message:
          type: string
          description: "The error message.\n"
        param:
          type: string
          description: "The error parameter.\n"
          nullable: true
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - error
          type: string
          description: "The type of the event. Always `error`.\n"
          x-stainless-const: true
      description: Emitted when an error occurs.
      x-oaiMeta:
        example: "{\n  \"type\": \"error\",\n  \"code\": \"ERR_SOMETHING\",\n  \"message\": \"Something went wrong\",\n  \"param\": null,\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: error
    ResponseFailedEvent:
      required:
        - type
        - response
        - sequence_number
      type: object
      properties:
        response:
          $ref: '#/components/schemas/Response'
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.failed
          type: string
          description: "The type of the event. Always `response.failed`.\n"
          x-stainless-const: true
      description: "An event that is emitted when a response fails.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.failed\",\n  \"response\": {\n    \"id\": \"resp_123\",\n    \"object\": \"response\",\n    \"created_at\": 1740855869,\n    \"status\": \"failed\",\n    \"error\": {\n      \"code\": \"server_error\",\n      \"message\": \"The model failed to generate a response.\"\n    },\n    \"incomplete_details\": null,\n    \"instructions\": null,\n    \"max_output_tokens\": null,\n    \"model\": \"gpt-4o-mini-2024-07-18\",\n    \"output\": [],\n    \"previous_response_id\": null,\n    \"reasoning_effort\": null,\n    \"store\": false,\n    \"temperature\": 1,\n    \"text\": {\n      \"format\": {\n        \"type\": \"text\"\n      }\n    },\n    \"tool_choice\": \"auto\",\n    \"tools\": [],\n    \"top_p\": 1,\n    \"truncation\": \"disabled\",\n    \"usage\": null,\n    \"user\": null,\n    \"metadata\": {}\n  }\n}\n"
        group: responses
        name: response.failed
    ResponseFileSearchCallCompletedEvent:
      required:
        - type
        - output_index
        - item_id
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: "The ID of the output item that the file search call is initiated.\n"
        output_index:
          type: integer
          description: "The index of the output item that the file search call is initiated.\n"
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.file_search_call.completed
          type: string
          description: "The type of the event. Always `response.file_search_call.completed`.\n"
          x-stainless-const: true
      description: Emitted when a file search call is completed (results found).
      x-oaiMeta:
        example: "{\n  \"type\": \"response.file_search_call.completed\",\n  \"output_index\": 0,\n  \"item_id\": \"fs_123\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.file_search_call.completed
    ResponseFileSearchCallInProgressEvent:
      required:
        - type
        - output_index
        - item_id
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: "The ID of the output item that the file search call is initiated.\n"
        output_index:
          type: integer
          description: "The index of the output item that the file search call is initiated.\n"
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.file_search_call.in_progress
          type: string
          description: "The type of the event. Always `response.file_search_call.in_progress`.\n"
          x-stainless-const: true
      description: Emitted when a file search call is initiated.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.file_search_call.in_progress\",\n  \"output_index\": 0,\n  \"item_id\": \"fs_123\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.file_search_call.in_progress
    ResponseFileSearchCallSearchingEvent:
      required:
        - type
        - output_index
        - item_id
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: "The ID of the output item that the file search call is initiated.\n"
        output_index:
          type: integer
          description: "The index of the output item that the file search call is searching.\n"
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.file_search_call.searching
          type: string
          description: "The type of the event. Always `response.file_search_call.searching`.\n"
          x-stainless-const: true
      description: Emitted when a file search is currently searching.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.file_search_call.searching\",\n  \"output_index\": 0,\n  \"item_id\": \"fs_123\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.file_search_call.searching
    ResponseFormatJsonObject:
      title: JSON object
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - json_object
          type: string
          description: The type of response format being defined. Always `json_object`.
          x-stainless-const: true
      description: "JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n"
    ResponseFormatJsonSchema:
      title: JSON schema
      required:
        - type
        - json_schema
      type: object
      properties:
        json_schema:
          title: JSON schema
          required:
            - name
          type: object
          properties:
            description:
              type: string
              description: "A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n"
            name:
              type: string
              description: "The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n"
            schema:
              $ref: '#/components/schemas/ResponseFormatJsonSchemaSchema'
            strict:
              type: boolean
              description: "Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n"
              default: false
              nullable: true
          description: "Structured Outputs configuration options, including a JSON Schema.\n"
        type:
          enum:
            - json_schema
          type: string
          description: The type of response format being defined. Always `json_schema`.
          x-stainless-const: true
      description: "JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n"
    ResponseFormatJsonSchemaSchema:
      title: JSON schema
      type: object
      description: "The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n"
    ResponseFormatText:
      title: Text
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - text
          type: string
          description: The type of response format being defined. Always `text`.
          x-stainless-const: true
      description: "Default response format. Used to generate text responses.\n"
    ResponseFormatTextGrammar:
      title: Text grammar
      required:
        - type
        - grammar
      type: object
      properties:
        grammar:
          type: string
          description: The custom grammar for the model to follow.
        type:
          enum:
            - grammar
          type: string
          description: The type of response format being defined. Always `grammar`.
          x-stainless-const: true
      description: "A custom grammar for the model to follow when generating text.\nLearn more in the [custom grammars guide](https://platform.openai.com/docs/guides/custom-grammars).\n"
    ResponseFormatTextPython:
      title: Python grammar
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - python
          type: string
          description: The type of response format being defined. Always `python`.
          x-stainless-const: true
      description: "Configure the model to generate valid Python code. See the\n[custom grammars guide](https://platform.openai.com/docs/guides/custom-grammars) for more details.\n"
    ResponseFunctionCallArgumentsDeltaEvent:
      required:
        - type
        - item_id
        - output_index
        - delta
        - sequence_number
      type: object
      properties:
        delta:
          type: string
          description: "The function-call arguments delta that is added.\n"
        item_id:
          type: string
          description: "The ID of the output item that the function-call arguments delta is added to.\n"
        output_index:
          type: integer
          description: "The index of the output item that the function-call arguments delta is added to.\n"
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.function_call_arguments.delta
          type: string
          description: "The type of the event. Always `response.function_call_arguments.delta`.\n"
          x-stainless-const: true
      description: Emitted when there is a partial function-call arguments delta.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.function_call_arguments.delta\",\n  \"item_id\": \"item-abc\",\n  \"output_index\": 0,\n  \"delta\": \"{ \\\"arg\\\":\"\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.function_call_arguments.delta
    ResponseFunctionCallArgumentsDoneEvent:
      required:
        - type
        - item_id
        - output_index
        - arguments
        - sequence_number
      type: object
      properties:
        arguments:
          type: string
          description: The function-call arguments.
        item_id:
          type: string
          description: The ID of the item.
        output_index:
          type: integer
          description: The index of the output item.
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.function_call_arguments.done
          type: string
          x-stainless-const: true
      description: Emitted when function-call arguments are finalized.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.function_call_arguments.done\",\n  \"item_id\": \"item-abc\",\n  \"output_index\": 1,\n  \"arguments\": \"{ \\\"arg\\\": 123 }\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.function_call_arguments.done
    ResponseImageGenCallCompletedEvent:
      title: ResponseImageGenCallCompletedEvent
      required:
        - type
        - output_index
        - item_id
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: The unique identifier of the image generation item being processed.
        output_index:
          type: integer
          description: The index of the output item in the response's output array.
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.image_generation_call.completed
          type: string
          description: The type of the event. Always 'response.image_generation_call.completed'.
          x-stainless-const: true
      description: "Emitted when an image generation tool call has completed and the final image is available.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.image_generation_call.completed\",\n  \"output_index\": 0,\n  \"item_id\": \"item-123\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.image_generation_call.completed
    ResponseImageGenCallGeneratingEvent:
      title: ResponseImageGenCallGeneratingEvent
      required:
        - type
        - output_index
        - item_id
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: The unique identifier of the image generation item being processed.
        output_index:
          type: integer
          description: The index of the output item in the response's output array.
        sequence_number:
          type: integer
          description: The sequence number of the image generation item being processed.
        type:
          enum:
            - response.image_generation_call.generating
          type: string
          description: The type of the event. Always 'response.image_generation_call.generating'.
          x-stainless-const: true
      description: "Emitted when an image generation tool call is actively generating an image (intermediate state).\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.image_generation_call.generating\",\n  \"output_index\": 0,\n  \"item_id\": \"item-123\",\n  \"sequence_number\": 0\n}\n"
        group: responses
        name: response.image_generation_call.generating
    ResponseImageGenCallInProgressEvent:
      title: ResponseImageGenCallInProgressEvent
      required:
        - type
        - output_index
        - item_id
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: The unique identifier of the image generation item being processed.
        output_index:
          type: integer
          description: The index of the output item in the response's output array.
        sequence_number:
          type: integer
          description: The sequence number of the image generation item being processed.
        type:
          enum:
            - response.image_generation_call.in_progress
          type: string
          description: The type of the event. Always 'response.image_generation_call.in_progress'.
          x-stainless-const: true
      description: "Emitted when an image generation tool call is in progress.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.image_generation_call.in_progress\",\n  \"output_index\": 0,\n  \"item_id\": \"item-123\",\n  \"sequence_number\": 0\n}\n"
        group: responses
        name: response.image_generation_call.in_progress
    ResponseImageGenCallPartialImageEvent:
      title: ResponseImageGenCallPartialImageEvent
      required:
        - type
        - output_index
        - item_id
        - sequence_number
        - partial_image_index
        - partial_image_b64
      type: object
      properties:
        item_id:
          type: string
          description: The unique identifier of the image generation item being processed.
        output_index:
          type: integer
          description: The index of the output item in the response's output array.
        partial_image_b64:
          type: string
          description: 'Base64-encoded partial image data, suitable for rendering as an image.'
        partial_image_index:
          type: integer
          description: '0-based index for the partial image (backend is 1-based, but this is 0-based for the user).'
        sequence_number:
          type: integer
          description: The sequence number of the image generation item being processed.
        type:
          enum:
            - response.image_generation_call.partial_image
          type: string
          description: The type of the event. Always 'response.image_generation_call.partial_image'.
          x-stainless-const: true
      description: "Emitted when a partial image is available during image generation streaming.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.image_generation_call.partial_image\",\n  \"output_index\": 0,\n  \"item_id\": \"item-123\",\n  \"sequence_number\": 0,\n  \"partial_image_index\": 0,\n  \"partial_image_b64\": \"...\"\n}\n"
        group: responses
        name: response.image_generation_call.partial_image
    ResponseInProgressEvent:
      required:
        - type
        - response
        - sequence_number
      type: object
      properties:
        response:
          $ref: '#/components/schemas/Response'
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.in_progress
          type: string
          description: "The type of the event. Always `response.in_progress`.\n"
          x-stainless-const: true
      description: Emitted when the response is in progress.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.in_progress\",\n  \"response\": {\n    \"id\": \"resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c\",\n    \"object\": \"response\",\n    \"created_at\": 1741487325,\n    \"status\": \"in_progress\",\n    \"error\": null,\n    \"incomplete_details\": null,\n    \"instructions\": null,\n    \"max_output_tokens\": null,\n    \"model\": \"gpt-4o-2024-08-06\",\n    \"output\": [],\n    \"parallel_tool_calls\": true,\n    \"previous_response_id\": null,\n    \"reasoning\": {\n      \"effort\": null,\n      \"summary\": null\n    },\n    \"store\": true,\n    \"temperature\": 1,\n    \"text\": {\n      \"format\": {\n        \"type\": \"text\"\n      }\n    },\n    \"tool_choice\": \"auto\",\n    \"tools\": [],\n    \"top_p\": 1,\n    \"truncation\": \"disabled\",\n    \"usage\": null,\n    \"user\": null,\n    \"metadata\": {}\n  },\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.in_progress
    ResponseIncompleteEvent:
      required:
        - type
        - response
        - sequence_number
      type: object
      properties:
        response:
          $ref: '#/components/schemas/Response'
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.incomplete
          type: string
          description: "The type of the event. Always `response.incomplete`.\n"
          x-stainless-const: true
      description: "An event that is emitted when a response finishes as incomplete.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.incomplete\",\n  \"response\": {\n    \"id\": \"resp_123\",\n    \"object\": \"response\",\n    \"created_at\": 1740855869,\n    \"status\": \"incomplete\",\n    \"error\": null, \n    \"incomplete_details\": {\n      \"reason\": \"max_tokens\"\n    },\n    \"instructions\": null,\n    \"max_output_tokens\": null,\n    \"model\": \"gpt-4o-mini-2024-07-18\",\n    \"output\": [],\n    \"previous_response_id\": null,\n    \"reasoning_effort\": null,\n    \"store\": false,\n    \"temperature\": 1,\n    \"text\": {\n      \"format\": {\n        \"type\": \"text\"\n      }\n    },\n    \"tool_choice\": \"auto\",\n    \"tools\": [],\n    \"top_p\": 1,\n    \"truncation\": \"disabled\",\n    \"usage\": null,\n    \"user\": null,\n    \"metadata\": {}\n  },\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.incomplete
    ResponseItemList:
      required:
        - object
        - data
        - has_more
        - first_id
        - last_id
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/ItemResource'
          description: A list of items used to generate this response.
        first_id:
          type: string
          description: The ID of the first item in the list.
        has_more:
          type: boolean
          description: Whether there are more items available.
        last_id:
          type: string
          description: The ID of the last item in the list.
        object:
          enum:
            - list
          description: 'The type of object returned, must be `list`.'
          x-stainless-const: true
      description: A list of Response items.
      x-oaiMeta:
        example: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"msg_abc123\",\n      \"type\": \"message\",\n      \"role\": \"user\",\n      \"content\": [\n        {\n          \"type\": \"input_text\",\n          \"text\": \"Tell me a three sentence bedtime story about a unicorn.\"\n        }\n      ]\n    }\n  ],\n  \"first_id\": \"msg_abc123\",\n  \"last_id\": \"msg_abc123\",\n  \"has_more\": false\n}\n"
        group: responses
        name: The input item list
    ResponseLogProb:
      required:
        - token
        - logprob
      type: object
      properties:
        logprob:
          type: number
          description: "The log probability of this token.\n"
        token:
          type: string
          description: A possible text token.
        top_logprobs:
          type: array
          items:
            type: object
            properties:
              logprob:
                type: number
                description: The log probability of this token.
              token:
                type: string
                description: A possible text token.
          description: "The log probability of the top 20 most likely tokens.\n"
      description: "A logprob is the logarithmic probability that the model assigns to producing \na particular token at a given position in the sequence. Less-negative (higher) \nlogprob values indicate greater model confidence in that token choice.\n"
    ResponseMCPCallArgumentsDeltaEvent:
      title: ResponseMCPCallArgumentsDeltaEvent
      required:
        - type
        - output_index
        - item_id
        - delta
        - sequence_number
      type: object
      properties:
        delta:
          type: string
          description: "A JSON string containing the partial update to the arguments for the MCP tool call.\n"
        item_id:
          type: string
          description: The unique identifier of the MCP tool call item being processed.
        output_index:
          type: integer
          description: The index of the output item in the response's output array.
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.mcp_call_arguments.delta
          type: string
          description: The type of the event. Always 'response.mcp_call_arguments.delta'.
          x-stainless-const: true
      description: "Emitted when there is a delta (partial update) to the arguments of an MCP tool call.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.mcp_call_arguments.delta\",\n  \"output_index\": 0,\n  \"item_id\": \"item-abc\",\n  \"delta\": \"{\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.mcp_call_arguments.delta
    ResponseMCPCallArgumentsDoneEvent:
      title: ResponseMCPCallArgumentsDoneEvent
      required:
        - type
        - output_index
        - item_id
        - arguments
        - sequence_number
      type: object
      properties:
        arguments:
          type: string
          description: "A JSON string containing the finalized arguments for the MCP tool call.\n"
        item_id:
          type: string
          description: The unique identifier of the MCP tool call item being processed.
        output_index:
          type: integer
          description: The index of the output item in the response's output array.
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.mcp_call_arguments.done
          type: string
          description: The type of the event. Always 'response.mcp_call_arguments.done'.
          x-stainless-const: true
      description: "Emitted when the arguments for an MCP tool call are finalized.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.mcp_call_arguments.done\",\n  \"output_index\": 0,\n  \"item_id\": \"item-abc\",\n  \"arguments\": \"{\\\"arg1\\\": \\\"value1\\\", \\\"arg2\\\": \\\"value2\\\"}\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.mcp_call_arguments.done
    ResponseMCPCallCompletedEvent:
      title: ResponseMCPCallCompletedEvent
      required:
        - type
        - item_id
        - output_index
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: The ID of the MCP tool call item that completed.
        output_index:
          type: integer
          description: The index of the output item that completed.
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.mcp_call.completed
          type: string
          description: The type of the event. Always 'response.mcp_call.completed'.
          x-stainless-const: true
      description: "Emitted when an MCP  tool call has completed successfully.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.mcp_call.completed\",\n  \"sequence_number\": 1,\n  \"item_id\": \"mcp_682d437d90a88191bf88cd03aae0c3e503937d5f622d7a90\",\n  \"output_index\": 0\n}\n"
        group: responses
        name: response.mcp_call.completed
    ResponseMCPCallFailedEvent:
      title: ResponseMCPCallFailedEvent
      required:
        - type
        - item_id
        - output_index
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: The ID of the MCP tool call item that failed.
        output_index:
          type: integer
          description: The index of the output item that failed.
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.mcp_call.failed
          type: string
          description: The type of the event. Always 'response.mcp_call.failed'.
          x-stainless-const: true
      description: "Emitted when an MCP  tool call has failed.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.mcp_call.failed\",\n  \"sequence_number\": 1,\n  \"item_id\": \"mcp_682d437d90a88191bf88cd03aae0c3e503937d5f622d7a90\",\n  \"output_index\": 0\n}\n"
        group: responses
        name: response.mcp_call.failed
    ResponseMCPCallInProgressEvent:
      title: ResponseMCPCallInProgressEvent
      required:
        - type
        - output_index
        - item_id
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: The unique identifier of the MCP tool call item being processed.
        output_index:
          type: integer
          description: The index of the output item in the response's output array.
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.mcp_call.in_progress
          type: string
          description: The type of the event. Always 'response.mcp_call.in_progress'.
          x-stainless-const: true
      description: "Emitted when an MCP  tool call is in progress.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.mcp_call.in_progress\",\n  \"sequence_number\": 1,\n  \"output_index\": 0,\n  \"item_id\": \"mcp_682d437d90a88191bf88cd03aae0c3e503937d5f622d7a90\"\n}\n"
        group: responses
        name: response.mcp_call.in_progress
    ResponseMCPListToolsCompletedEvent:
      title: ResponseMCPListToolsCompletedEvent
      required:
        - type
        - item_id
        - output_index
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: The ID of the MCP tool call item that produced this output.
        output_index:
          type: integer
          description: The index of the output item that was processed.
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.mcp_list_tools.completed
          type: string
          description: The type of the event. Always 'response.mcp_list_tools.completed'.
          x-stainless-const: true
      description: "Emitted when the list of available MCP tools has been successfully retrieved.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.mcp_list_tools.completed\",\n  \"sequence_number\": 1,\n  \"output_index\": 0,\n  \"item_id\": \"mcpl_682d4379df088191886b70f4ec39f90403937d5f622d7a90\"\n}\n"
        group: responses
        name: response.mcp_list_tools.completed
    ResponseMCPListToolsFailedEvent:
      title: ResponseMCPListToolsFailedEvent
      required:
        - type
        - item_id
        - output_index
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: The ID of the MCP tool call item that failed.
        output_index:
          type: integer
          description: The index of the output item that failed.
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.mcp_list_tools.failed
          type: string
          description: The type of the event. Always 'response.mcp_list_tools.failed'.
          x-stainless-const: true
      description: "Emitted when the attempt to list available MCP tools has failed.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.mcp_list_tools.failed\",\n  \"sequence_number\": 1,\n  \"output_index\": 0,\n  \"item_id\": \"mcpl_682d4379df088191886b70f4ec39f90403937d5f622d7a90\"\n}\n"
        group: responses
        name: response.mcp_list_tools.failed
    ResponseMCPListToolsInProgressEvent:
      title: ResponseMCPListToolsInProgressEvent
      required:
        - type
        - item_id
        - output_index
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: The ID of the MCP tool call item that is being processed.
        output_index:
          type: integer
          description: The index of the output item that is being processed.
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.mcp_list_tools.in_progress
          type: string
          description: The type of the event. Always 'response.mcp_list_tools.in_progress'.
          x-stainless-const: true
      description: "Emitted when the system is in the process of retrieving the list of available MCP tools.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.mcp_list_tools.in_progress\",\n  \"sequence_number\": 1,\n  \"output_index\": 0,\n  \"item_id\": \"mcpl_682d4379df088191886b70f4ec39f90403937d5f622d7a90\"\n}\n"
        group: responses
        name: response.mcp_list_tools.in_progress
    ResponseModalities:
      type: array
      items:
        enum:
          - text
          - audio
        type: string
      description: "Output types that you would like the model to generate.\nMost models are capable of generating text, which is the default:\n\n`[\"text\"]`\n\nThe `gpt-4o-audio-preview` model can also be used to \n[generate audio](https://platform.openai.com/docs/guides/audio). To request that this model generate \nboth text and audio responses, you can use:\n\n`[\"text\", \"audio\"]`\n"
      nullable: true
    ResponseOutputItemAddedEvent:
      required:
        - type
        - output_index
        - item
        - sequence_number
      type: object
      properties:
        item:
          $ref: '#/components/schemas/OutputItem'
        output_index:
          type: integer
          description: "The index of the output item that was added.\n"
        sequence_number:
          type: integer
          description: "The sequence number of this event.\n"
        type:
          enum:
            - response.output_item.added
          type: string
          description: "The type of the event. Always `response.output_item.added`.\n"
          x-stainless-const: true
      description: Emitted when a new output item is added.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.output_item.added\",\n  \"output_index\": 0,\n  \"item\": {\n    \"id\": \"msg_123\",\n    \"status\": \"in_progress\",\n    \"type\": \"message\",\n    \"role\": \"assistant\",\n    \"content\": []\n  },\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.output_item.added
    ResponseOutputItemDoneEvent:
      required:
        - type
        - output_index
        - item
        - sequence_number
      type: object
      properties:
        item:
          $ref: '#/components/schemas/OutputItem'
        output_index:
          type: integer
          description: "The index of the output item that was marked done.\n"
        sequence_number:
          type: integer
          description: "The sequence number of this event.\n"
        type:
          enum:
            - response.output_item.done
          type: string
          description: "The type of the event. Always `response.output_item.done`.\n"
          x-stainless-const: true
      description: Emitted when an output item is marked done.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.output_item.done\",\n  \"output_index\": 0,\n  \"item\": {\n    \"id\": \"msg_123\",\n    \"status\": \"completed\",\n    \"type\": \"message\",\n    \"role\": \"assistant\",\n    \"content\": [\n      {\n        \"type\": \"output_text\",\n        \"text\": \"In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.\",\n        \"annotations\": []\n      }\n    ]\n  },\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.output_item.done
    ResponseOutputTextAnnotationAddedEvent:
      title: ResponseOutputTextAnnotationAddedEvent
      required:
        - type
        - item_id
        - output_index
        - content_index
        - annotation_index
        - annotation
        - sequence_number
      type: object
      properties:
        annotation:
          type: object
          description: The annotation object being added. (See annotation schema for details.)
        annotation_index:
          type: integer
          description: The index of the annotation within the content part.
        content_index:
          type: integer
          description: The index of the content part within the output item.
        item_id:
          type: string
          description: The unique identifier of the item to which the annotation is being added.
        output_index:
          type: integer
          description: The index of the output item in the response's output array.
        sequence_number:
          type: integer
          description: The sequence number of this event.
        type:
          enum:
            - response.output_text.annotation.added
          type: string
          description: The type of the event. Always 'response.output_text.annotation.added'.
          x-stainless-const: true
      description: "Emitted when an annotation is added to output text content.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.output_text.annotation.added\",\n  \"item_id\": \"item-abc\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"annotation_index\": 0,\n  \"annotation\": {\n    \"type\": \"text_annotation\",\n    \"text\": \"This is a test annotation\",\n    \"start\": 0,\n    \"end\": 10\n  },\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.output_text.annotation.added
    ResponsePromptVariables:
      title: Prompt Variables
      type: object
      additionalProperties:
        anyOf:
          - type: string
          - $ref: '#/components/schemas/InputTextContent'
          - $ref: '#/components/schemas/InputImageContent'
          - $ref: '#/components/schemas/InputFileContent'
        x-oaiExpandable: true
        x-oaiTypeLabel: map
      description: "Optional map of values to substitute in for variables in your\nprompt. The substitution values can either be strings, or other\nResponse input types like images or files.\n"
      nullable: true
      x-oaiExpandable: true
      x-oaiTypeLabel: map
    ResponseProperties:
      type: object
      properties:
        background:
          type: boolean
          description: "Whether to run the model response in the background.\n[Learn more](https://platform.openai.com/docs/guides/background).\n"
          default: false
          nullable: true
        max_output_tokens:
          type: integer
          description: "An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).\n"
          nullable: true
        max_tool_calls:
          type: integer
          description: "The maximum number of total calls to built-in tools that can be processed in a response. This maximum number applies across all built-in tool calls, not per individual tool. Any further attempts to call a tool by the model will be ignored.\n"
          nullable: true
        model:
          $ref: '#/components/schemas/ModelIdsResponses'
        previous_response_id:
          type: string
          description: "The unique ID of the previous response to the model. Use this to\ncreate multi-turn conversations. Learn more about\n[conversation state](https://platform.openai.com/docs/guides/conversation-state). Cannot be used in conjunction with `conversation`.\n"
          nullable: true
        prompt:
          $ref: '#/components/schemas/Prompt'
        reasoning:
          $ref: '#/components/schemas/Reasoning'
        text:
          type: object
          properties:
            format:
              $ref: '#/components/schemas/TextResponseFormatConfiguration'
            verbosity:
              $ref: '#/components/schemas/Verbosity'
          description: "Configuration options for a text response from the model. Can be plain\ntext or structured JSON data. Learn more:\n- [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n- [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n"
        tool_choice:
          anyOf:
            - $ref: '#/components/schemas/ToolChoiceOptions'
            - $ref: '#/components/schemas/ToolChoiceAllowed'
            - $ref: '#/components/schemas/ToolChoiceTypes'
            - $ref: '#/components/schemas/ToolChoiceFunction'
            - $ref: '#/components/schemas/ToolChoiceMCP'
            - $ref: '#/components/schemas/ToolChoiceCustom'
          description: "How the model should select which tool (or tools) to use when generating\na response. See the `tools` parameter to see how to specify which tools\nthe model can call.\n"
          discriminator:
            propertyName: type
        tools:
          type: array
          items:
            $ref: '#/components/schemas/Tool'
          description: "An array of tools the model may call while generating a response. You\ncan specify which tool to use by setting the `tool_choice` parameter.\n\nWe support the following categories of tools:\n- **Built-in tools**: Tools that are provided by OpenAI that extend the\n  model's capabilities, like [web search](https://platform.openai.com/docs/guides/tools-web-search)\n  or [file search](https://platform.openai.com/docs/guides/tools-file-search). Learn more about\n  [built-in tools](https://platform.openai.com/docs/guides/tools).\n- **MCP Tools**: Integrations with third-party systems via custom MCP servers\n  or predefined connectors such as Google Drive and SharePoint. Learn more about\n  [MCP Tools](https://platform.openai.com/docs/guides/tools-connectors-mcp).\n- **Function calls (custom tools)**: Functions that are defined by you,\n  enabling the model to call your own code with strongly typed arguments\n  and outputs. Learn more about\n  [function calling](https://platform.openai.com/docs/guides/function-calling). You can also use\n  custom tools to call your own code.\n"
        truncation:
          enum:
            - auto
            - disabled
          type: string
          description: "The truncation strategy to use for the model response.\n- `auto`: If the context of this response and previous ones exceeds\n  the model's context window size, the model will truncate the\n  response to fit the context window by dropping input items in the\n  middle of the conversation.\n- `disabled` (default): If a model response will exceed the context window\n  size for a model, the request will fail with a 400 error.\n"
          default: disabled
          nullable: true
    ResponseQueuedEvent:
      title: ResponseQueuedEvent
      required:
        - type
        - response
        - sequence_number
      type: object
      properties:
        response:
          $ref: '#/components/schemas/Response'
        sequence_number:
          type: integer
          description: The sequence number for this event.
        type:
          enum:
            - response.queued
          type: string
          description: The type of the event. Always 'response.queued'.
          x-stainless-const: true
      description: "Emitted when a response is queued and waiting to be processed.\n"
      x-oaiMeta:
        example: "{\n  \"type\": \"response.queued\",\n  \"response\": {\n    \"id\": \"res_123\",\n    \"status\": \"queued\",\n    \"created_at\": \"2021-01-01T00:00:00Z\",\n    \"updated_at\": \"2021-01-01T00:00:00Z\"\n  },\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.queued
    ResponseReasoningSummaryPartAddedEvent:
      required:
        - type
        - item_id
        - output_index
        - summary_index
        - part
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: "The ID of the item this summary part is associated with.\n"
        output_index:
          type: integer
          description: "The index of the output item this summary part is associated with.\n"
        part:
          required:
            - type
            - text
          type: object
          properties:
            text:
              type: string
              description: The text of the summary part.
            type:
              enum:
                - summary_text
              type: string
              description: The type of the summary part. Always `summary_text`.
              x-stainless-const: true
          description: "The summary part that was added.\n"
        sequence_number:
          type: integer
          description: "The sequence number of this event.\n"
        summary_index:
          type: integer
          description: "The index of the summary part within the reasoning summary.\n"
        type:
          enum:
            - response.reasoning_summary_part.added
          type: string
          description: "The type of the event. Always `response.reasoning_summary_part.added`.\n"
          x-stainless-const: true
      description: Emitted when a new reasoning summary part is added.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.reasoning_summary_part.added\",\n  \"item_id\": \"rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476\",\n  \"output_index\": 0,\n  \"summary_index\": 0,\n  \"part\": {\n    \"type\": \"summary_text\",\n    \"text\": \"\"\n  },\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.reasoning_summary_part.added
    ResponseReasoningSummaryPartDoneEvent:
      required:
        - type
        - item_id
        - output_index
        - summary_index
        - part
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: "The ID of the item this summary part is associated with.\n"
        output_index:
          type: integer
          description: "The index of the output item this summary part is associated with.\n"
        part:
          required:
            - type
            - text
          type: object
          properties:
            text:
              type: string
              description: The text of the summary part.
            type:
              enum:
                - summary_text
              type: string
              description: The type of the summary part. Always `summary_text`.
              x-stainless-const: true
          description: "The completed summary part.\n"
        sequence_number:
          type: integer
          description: "The sequence number of this event.\n"
        summary_index:
          type: integer
          description: "The index of the summary part within the reasoning summary.\n"
        type:
          enum:
            - response.reasoning_summary_part.done
          type: string
          description: "The type of the event. Always `response.reasoning_summary_part.done`.\n"
          x-stainless-const: true
      description: Emitted when a reasoning summary part is completed.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.reasoning_summary_part.done\",\n  \"item_id\": \"rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476\",\n  \"output_index\": 0,\n  \"summary_index\": 0,\n  \"part\": {\n    \"type\": \"summary_text\",\n    \"text\": \"**Responding to a greeting**\\n\\nThe user just said, \\\"Hello!\\\" So, it seems I need to engage. I'll greet them back and offer help since they're looking to chat. I could say something like, \\\"Hello! How can I assist you today?\\\" That feels friendly and open. They didn't ask a specific question, so this approach will work well for starting a conversation. Let's see where it goes from there!\"\n  },\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.reasoning_summary_part.done
    ResponseReasoningSummaryTextDeltaEvent:
      required:
        - type
        - item_id
        - output_index
        - summary_index
        - delta
        - sequence_number
      type: object
      properties:
        delta:
          type: string
          description: "The text delta that was added to the summary.\n"
        item_id:
          type: string
          description: "The ID of the item this summary text delta is associated with.\n"
        output_index:
          type: integer
          description: "The index of the output item this summary text delta is associated with.\n"
        sequence_number:
          type: integer
          description: "The sequence number of this event.\n"
        summary_index:
          type: integer
          description: "The index of the summary part within the reasoning summary.\n"
        type:
          enum:
            - response.reasoning_summary_text.delta
          type: string
          description: "The type of the event. Always `response.reasoning_summary_text.delta`.\n"
          x-stainless-const: true
      description: Emitted when a delta is added to a reasoning summary text.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.reasoning_summary_text.delta\",\n  \"item_id\": \"rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476\",\n  \"output_index\": 0,\n  \"summary_index\": 0,\n  \"delta\": \"**Responding to a greeting**\\n\\nThe user just said, \\\"Hello!\\\" So, it seems I need to engage. I'll greet them back and offer help since they're looking to chat. I could say something like, \\\"Hello! How can I assist you today?\\\" That feels friendly and open. They didn't ask a specific question, so this approach will work well for starting a conversation. Let's see where it goes from there!\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.reasoning_summary_text.delta
    ResponseReasoningSummaryTextDoneEvent:
      required:
        - type
        - item_id
        - output_index
        - summary_index
        - text
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: "The ID of the item this summary text is associated with.\n"
        output_index:
          type: integer
          description: "The index of the output item this summary text is associated with.\n"
        sequence_number:
          type: integer
          description: "The sequence number of this event.\n"
        summary_index:
          type: integer
          description: "The index of the summary part within the reasoning summary.\n"
        text:
          type: string
          description: "The full text of the completed reasoning summary.\n"
        type:
          enum:
            - response.reasoning_summary_text.done
          type: string
          description: "The type of the event. Always `response.reasoning_summary_text.done`.\n"
          x-stainless-const: true
      description: Emitted when a reasoning summary text is completed.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.reasoning_summary_text.done\",\n  \"item_id\": \"rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476\",\n  \"output_index\": 0,\n  \"summary_index\": 0,\n  \"text\": \"**Responding to a greeting**\\n\\nThe user just said, \\\"Hello!\\\" So, it seems I need to engage. I'll greet them back and offer help since they're looking to chat. I could say something like, \\\"Hello! How can I assist you today?\\\" That feels friendly and open. They didn't ask a specific question, so this approach will work well for starting a conversation. Let's see where it goes from there!\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.reasoning_summary_text.done
    ResponseReasoningTextDeltaEvent:
      required:
        - type
        - item_id
        - output_index
        - content_index
        - delta
        - sequence_number
      type: object
      properties:
        content_index:
          type: integer
          description: "The index of the reasoning content part this delta is associated with.\n"
        delta:
          type: string
          description: "The text delta that was added to the reasoning content.\n"
        item_id:
          type: string
          description: "The ID of the item this reasoning text delta is associated with.\n"
        output_index:
          type: integer
          description: "The index of the output item this reasoning text delta is associated with.\n"
        sequence_number:
          type: integer
          description: "The sequence number of this event.\n"
        type:
          enum:
            - response.reasoning_text.delta
          type: string
          description: "The type of the event. Always `response.reasoning_text.delta`.\n"
          x-stainless-const: true
      description: Emitted when a delta is added to a reasoning text.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.reasoning_text.delta\",\n  \"item_id\": \"rs_123\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"delta\": \"The\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.reasoning_text.delta
    ResponseReasoningTextDoneEvent:
      required:
        - type
        - item_id
        - output_index
        - content_index
        - text
        - sequence_number
      type: object
      properties:
        content_index:
          type: integer
          description: "The index of the reasoning content part.\n"
        item_id:
          type: string
          description: "The ID of the item this reasoning text is associated with.\n"
        output_index:
          type: integer
          description: "The index of the output item this reasoning text is associated with.\n"
        sequence_number:
          type: integer
          description: "The sequence number of this event.\n"
        text:
          type: string
          description: "The full text of the completed reasoning content.\n"
        type:
          enum:
            - response.reasoning_text.done
          type: string
          description: "The type of the event. Always `response.reasoning_text.done`.\n"
          x-stainless-const: true
      description: Emitted when a reasoning text is completed.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.reasoning_text.done\",\n  \"item_id\": \"rs_123\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"text\": \"The user is asking...\",\n  \"sequence_number\": 4\n}\n"
        group: responses
        name: response.reasoning_text.done
    ResponseRefusalDeltaEvent:
      required:
        - type
        - item_id
        - output_index
        - content_index
        - delta
        - sequence_number
      type: object
      properties:
        content_index:
          type: integer
          description: "The index of the content part that the refusal text is added to.\n"
        delta:
          type: string
          description: "The refusal text that is added.\n"
        item_id:
          type: string
          description: "The ID of the output item that the refusal text is added to.\n"
        output_index:
          type: integer
          description: "The index of the output item that the refusal text is added to.\n"
        sequence_number:
          type: integer
          description: "The sequence number of this event.\n"
        type:
          enum:
            - response.refusal.delta
          type: string
          description: "The type of the event. Always `response.refusal.delta`.\n"
          x-stainless-const: true
      description: Emitted when there is a partial refusal text.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.refusal.delta\",\n  \"item_id\": \"msg_123\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"delta\": \"refusal text so far\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.refusal.delta
    ResponseRefusalDoneEvent:
      required:
        - type
        - item_id
        - output_index
        - content_index
        - refusal
        - sequence_number
      type: object
      properties:
        content_index:
          type: integer
          description: "The index of the content part that the refusal text is finalized.\n"
        item_id:
          type: string
          description: "The ID of the output item that the refusal text is finalized.\n"
        output_index:
          type: integer
          description: "The index of the output item that the refusal text is finalized.\n"
        refusal:
          type: string
          description: "The refusal text that is finalized.\n"
        sequence_number:
          type: integer
          description: "The sequence number of this event.\n"
        type:
          enum:
            - response.refusal.done
          type: string
          description: "The type of the event. Always `response.refusal.done`.\n"
          x-stainless-const: true
      description: Emitted when refusal text is finalized.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.refusal.done\",\n  \"item_id\": \"item-abc\",\n  \"output_index\": 1,\n  \"content_index\": 2,\n  \"refusal\": \"final refusal text\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.refusal.done
    ResponseStreamEvent:
      anyOf:
        - $ref: '#/components/schemas/ResponseAudioDeltaEvent'
        - $ref: '#/components/schemas/ResponseAudioDoneEvent'
        - $ref: '#/components/schemas/ResponseAudioTranscriptDeltaEvent'
        - $ref: '#/components/schemas/ResponseAudioTranscriptDoneEvent'
        - $ref: '#/components/schemas/ResponseCodeInterpreterCallCodeDeltaEvent'
        - $ref: '#/components/schemas/ResponseCodeInterpreterCallCodeDoneEvent'
        - $ref: '#/components/schemas/ResponseCodeInterpreterCallCompletedEvent'
        - $ref: '#/components/schemas/ResponseCodeInterpreterCallInProgressEvent'
        - $ref: '#/components/schemas/ResponseCodeInterpreterCallInterpretingEvent'
        - $ref: '#/components/schemas/ResponseCompletedEvent'
        - $ref: '#/components/schemas/ResponseContentPartAddedEvent'
        - $ref: '#/components/schemas/ResponseContentPartDoneEvent'
        - $ref: '#/components/schemas/ResponseCreatedEvent'
        - $ref: '#/components/schemas/ResponseErrorEvent'
        - $ref: '#/components/schemas/ResponseFileSearchCallCompletedEvent'
        - $ref: '#/components/schemas/ResponseFileSearchCallInProgressEvent'
        - $ref: '#/components/schemas/ResponseFileSearchCallSearchingEvent'
        - $ref: '#/components/schemas/ResponseFunctionCallArgumentsDeltaEvent'
        - $ref: '#/components/schemas/ResponseFunctionCallArgumentsDoneEvent'
        - $ref: '#/components/schemas/ResponseInProgressEvent'
        - $ref: '#/components/schemas/ResponseFailedEvent'
        - $ref: '#/components/schemas/ResponseIncompleteEvent'
        - $ref: '#/components/schemas/ResponseOutputItemAddedEvent'
        - $ref: '#/components/schemas/ResponseOutputItemDoneEvent'
        - $ref: '#/components/schemas/ResponseReasoningSummaryPartAddedEvent'
        - $ref: '#/components/schemas/ResponseReasoningSummaryPartDoneEvent'
        - $ref: '#/components/schemas/ResponseReasoningSummaryTextDeltaEvent'
        - $ref: '#/components/schemas/ResponseReasoningSummaryTextDoneEvent'
        - $ref: '#/components/schemas/ResponseReasoningTextDeltaEvent'
        - $ref: '#/components/schemas/ResponseReasoningTextDoneEvent'
        - $ref: '#/components/schemas/ResponseRefusalDeltaEvent'
        - $ref: '#/components/schemas/ResponseRefusalDoneEvent'
        - $ref: '#/components/schemas/ResponseTextDeltaEvent'
        - $ref: '#/components/schemas/ResponseTextDoneEvent'
        - $ref: '#/components/schemas/ResponseWebSearchCallCompletedEvent'
        - $ref: '#/components/schemas/ResponseWebSearchCallInProgressEvent'
        - $ref: '#/components/schemas/ResponseWebSearchCallSearchingEvent'
        - $ref: '#/components/schemas/ResponseImageGenCallCompletedEvent'
        - $ref: '#/components/schemas/ResponseImageGenCallGeneratingEvent'
        - $ref: '#/components/schemas/ResponseImageGenCallInProgressEvent'
        - $ref: '#/components/schemas/ResponseImageGenCallPartialImageEvent'
        - $ref: '#/components/schemas/ResponseMCPCallArgumentsDeltaEvent'
        - $ref: '#/components/schemas/ResponseMCPCallArgumentsDoneEvent'
        - $ref: '#/components/schemas/ResponseMCPCallCompletedEvent'
        - $ref: '#/components/schemas/ResponseMCPCallFailedEvent'
        - $ref: '#/components/schemas/ResponseMCPCallInProgressEvent'
        - $ref: '#/components/schemas/ResponseMCPListToolsCompletedEvent'
        - $ref: '#/components/schemas/ResponseMCPListToolsFailedEvent'
        - $ref: '#/components/schemas/ResponseMCPListToolsInProgressEvent'
        - $ref: '#/components/schemas/ResponseOutputTextAnnotationAddedEvent'
        - $ref: '#/components/schemas/ResponseQueuedEvent'
        - $ref: '#/components/schemas/ResponseCustomToolCallInputDeltaEvent'
        - $ref: '#/components/schemas/ResponseCustomToolCallInputDoneEvent'
      discriminator:
        propertyName: type
    ResponseStreamOptions:
      type: object
      properties:
        include_obfuscation:
          type: boolean
          description: "When true, stream obfuscation will be enabled. Stream obfuscation adds\nrandom characters to an `obfuscation` field on streaming delta events to\nnormalize payload sizes as a mitigation to certain side-channel attacks.\nThese obfuscation fields are included by default, but add a small amount\nof overhead to the data stream. You can set `include_obfuscation` to\nfalse to optimize for bandwidth if you trust the network links between\nyour application and the OpenAI API.\n"
      description: "Options for streaming responses. Only set this when you set `stream: true`.\n"
      default: 
      nullable: true
    ResponseTextDeltaEvent:
      required:
        - type
        - item_id
        - output_index
        - content_index
        - delta
        - sequence_number
        - logprobs
      type: object
      properties:
        content_index:
          type: integer
          description: "The index of the content part that the text delta was added to.\n"
        delta:
          type: string
          description: "The text delta that was added.\n"
        item_id:
          type: string
          description: "The ID of the output item that the text delta was added to.\n"
        logprobs:
          type: array
          items:
            $ref: '#/components/schemas/ResponseLogProb'
          description: "The log probabilities of the tokens in the delta.\n"
        output_index:
          type: integer
          description: "The index of the output item that the text delta was added to.\n"
        sequence_number:
          type: integer
          description: The sequence number for this event.
        type:
          enum:
            - response.output_text.delta
          type: string
          description: "The type of the event. Always `response.output_text.delta`.\n"
          x-stainless-const: true
      description: Emitted when there is an additional text delta.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.output_text.delta\",\n  \"item_id\": \"msg_123\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"delta\": \"In\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.output_text.delta
    ResponseTextDoneEvent:
      required:
        - type
        - item_id
        - output_index
        - content_index
        - text
        - sequence_number
        - logprobs
      type: object
      properties:
        content_index:
          type: integer
          description: "The index of the content part that the text content is finalized.\n"
        item_id:
          type: string
          description: "The ID of the output item that the text content is finalized.\n"
        logprobs:
          type: array
          items:
            $ref: '#/components/schemas/ResponseLogProb'
          description: "The log probabilities of the tokens in the delta.\n"
        output_index:
          type: integer
          description: "The index of the output item that the text content is finalized.\n"
        sequence_number:
          type: integer
          description: The sequence number for this event.
        text:
          type: string
          description: "The text content that is finalized.\n"
        type:
          enum:
            - response.output_text.done
          type: string
          description: "The type of the event. Always `response.output_text.done`.\n"
          x-stainless-const: true
      description: Emitted when text content is finalized.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.output_text.done\",\n  \"item_id\": \"msg_123\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"text\": \"In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.\",\n  \"sequence_number\": 1\n}\n"
        group: responses
        name: response.output_text.done
    ResponseUsage:
      required:
        - input_tokens
        - input_tokens_details
        - output_tokens
        - output_tokens_details
        - total_tokens
      type: object
      properties:
        input_tokens:
          type: integer
          description: The number of input tokens.
        input_tokens_details:
          required:
            - cached_tokens
          type: object
          properties:
            cached_tokens:
              type: integer
              description: "The number of tokens that were retrieved from the cache. \n[More on prompt caching](https://platform.openai.com/docs/guides/prompt-caching).\n"
          description: A detailed breakdown of the input tokens.
        output_tokens:
          type: integer
          description: The number of output tokens.
        output_tokens_details:
          required:
            - reasoning_tokens
          type: object
          properties:
            reasoning_tokens:
              type: integer
              description: The number of reasoning tokens.
          description: A detailed breakdown of the output tokens.
        total_tokens:
          type: integer
          description: The total number of tokens used.
      description: "Represents token usage details including input tokens, output tokens,\na breakdown of output tokens, and the total tokens used.\n"
    ResponseWebSearchCallCompletedEvent:
      required:
        - type
        - output_index
        - item_id
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: "Unique ID for the output item associated with the web search call.\n"
        output_index:
          type: integer
          description: "The index of the output item that the web search call is associated with.\n"
        sequence_number:
          type: integer
          description: The sequence number of the web search call being processed.
        type:
          enum:
            - response.web_search_call.completed
          type: string
          description: "The type of the event. Always `response.web_search_call.completed`.\n"
          x-stainless-const: true
      description: Emitted when a web search call is completed.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.web_search_call.completed\",\n  \"output_index\": 0,\n  \"item_id\": \"ws_123\",\n  \"sequence_number\": 0\n}\n"
        group: responses
        name: response.web_search_call.completed
    ResponseWebSearchCallInProgressEvent:
      required:
        - type
        - output_index
        - item_id
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: "Unique ID for the output item associated with the web search call.\n"
        output_index:
          type: integer
          description: "The index of the output item that the web search call is associated with.\n"
        sequence_number:
          type: integer
          description: The sequence number of the web search call being processed.
        type:
          enum:
            - response.web_search_call.in_progress
          type: string
          description: "The type of the event. Always `response.web_search_call.in_progress`.\n"
          x-stainless-const: true
      description: Emitted when a web search call is initiated.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.web_search_call.in_progress\",\n  \"output_index\": 0,\n  \"item_id\": \"ws_123\",\n  \"sequence_number\": 0\n}\n"
        group: responses
        name: response.web_search_call.in_progress
    ResponseWebSearchCallSearchingEvent:
      required:
        - type
        - output_index
        - item_id
        - sequence_number
      type: object
      properties:
        item_id:
          type: string
          description: "Unique ID for the output item associated with the web search call.\n"
        output_index:
          type: integer
          description: "The index of the output item that the web search call is associated with.\n"
        sequence_number:
          type: integer
          description: The sequence number of the web search call being processed.
        type:
          enum:
            - response.web_search_call.searching
          type: string
          description: "The type of the event. Always `response.web_search_call.searching`.\n"
          x-stainless-const: true
      description: Emitted when a web search call is executing.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.web_search_call.searching\",\n  \"output_index\": 0,\n  \"item_id\": \"ws_123\",\n  \"sequence_number\": 0\n}\n"
        group: responses
        name: response.web_search_call.searching
    RunCompletionUsage:
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      type: object
      properties:
        completion_tokens:
          type: integer
          description: Number of completion tokens used over the course of the run.
        prompt_tokens:
          type: integer
          description: Number of prompt tokens used over the course of the run.
        total_tokens:
          type: integer
          description: Total number of tokens used (prompt + completion).
      description: 'Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).'
      nullable: true
    RunGraderRequest:
      title: RunGraderRequest
      required:
        - grader
        - model_sample
      type: object
      properties:
        grader:
          type: object
          anyOf:
            - $ref: '#/components/schemas/GraderStringCheck'
            - $ref: '#/components/schemas/GraderTextSimilarity'
            - $ref: '#/components/schemas/GraderPython'
            - $ref: '#/components/schemas/GraderScoreModel'
            - $ref: '#/components/schemas/GraderMulti'
          description: The grader used for the fine-tuning job.
          discriminator:
            propertyName: type
        item:
          type: object
          description: "The dataset item provided to the grader. This will be used to populate \nthe `item` namespace. See [the guide](https://platform.openai.com/docs/guides/graders) for more details. \n"
        model_sample:
          type: string
          description: "The model sample to be evaluated. This value will be used to populate \nthe `sample` namespace. See [the guide](https://platform.openai.com/docs/guides/graders) for more details.\nThe `output_json` variable will be populated if the model sample is a \nvalid JSON string.\n \n"
    RunGraderResponse:
      required:
        - reward
        - metadata
        - sub_rewards
        - model_grader_token_usage_per_model
      type: object
      properties:
        metadata:
          required:
            - name
            - type
            - errors
            - execution_time
            - scores
            - token_usage
            - sampled_model_name
          type: object
          properties:
            errors:
              required:
                - formula_parse_error
                - sample_parse_error
                - truncated_observation_error
                - unresponsive_reward_error
                - invalid_variable_error
                - other_error
                - python_grader_server_error
                - python_grader_server_error_type
                - python_grader_runtime_error
                - python_grader_runtime_error_details
                - model_grader_server_error
                - model_grader_refusal_error
                - model_grader_parse_error
                - model_grader_server_error_details
              type: object
              properties:
                formula_parse_error:
                  type: boolean
                invalid_variable_error:
                  type: boolean
                model_grader_parse_error:
                  type: boolean
                model_grader_refusal_error:
                  type: boolean
                model_grader_server_error:
                  type: boolean
                model_grader_server_error_details:
                  type: string
                  nullable: true
                other_error:
                  type: boolean
                python_grader_runtime_error:
                  type: boolean
                python_grader_runtime_error_details:
                  type: string
                  nullable: true
                python_grader_server_error:
                  type: boolean
                python_grader_server_error_type:
                  type: string
                  nullable: true
                sample_parse_error:
                  type: boolean
                truncated_observation_error:
                  type: boolean
                unresponsive_reward_error:
                  type: boolean
            execution_time:
              type: number
            name:
              type: string
            sampled_model_name:
              type: string
              nullable: true
            scores:
              type: object
              additionalProperties: { }
            token_usage:
              type: integer
              nullable: true
            type:
              type: string
        model_grader_token_usage_per_model:
          type: object
          additionalProperties: { }
        reward:
          type: number
        sub_rewards:
          type: object
          additionalProperties: { }
    RunObject:
      title: A run on a thread
      required:
        - id
        - object
        - created_at
        - thread_id
        - assistant_id
        - status
        - required_action
        - last_error
        - expires_at
        - started_at
        - cancelled_at
        - failed_at
        - completed_at
        - model
        - instructions
        - tools
        - metadata
        - usage
        - incomplete_details
        - max_prompt_tokens
        - max_completion_tokens
        - truncation_strategy
        - tool_choice
        - parallel_tool_calls
        - response_format
      type: object
      properties:
        assistant_id:
          type: string
          description: 'The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for execution of this run.'
        cancelled_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run was cancelled.
          nullable: true
        completed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run was completed.
          nullable: true
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run was created.
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run will expire.
          nullable: true
        failed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run failed.
          nullable: true
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints.'
        incomplete_details:
          type: object
          properties:
            reason:
              enum:
                - max_completion_tokens
                - max_prompt_tokens
              type: string
              description: The reason why the run is incomplete. This will point to which specific token limit was reached over the course of the run.
          description: Details on why the run is incomplete. Will be `null` if the run is not incomplete.
          nullable: true
        instructions:
          type: string
          description: 'The instructions that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'
        last_error:
          required:
            - code
            - message
          type: object
          properties:
            code:
              enum:
                - server_error
                - rate_limit_exceeded
                - invalid_prompt
              type: string
              description: 'One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.'
            message:
              type: string
              description: A human-readable description of the error.
          description: The last error associated with this run. Will be `null` if there are no errors.
          nullable: true
        max_completion_tokens:
          minimum: 256
          type: integer
          description: "The maximum number of completion tokens specified to have been used over the course of the run.\n"
          nullable: true
        max_prompt_tokens:
          minimum: 256
          type: integer
          description: "The maximum number of prompt tokens specified to have been used over the course of the run.\n"
          nullable: true
        metadata:
          $ref: '#/components/schemas/Metadata'
        model:
          type: string
          description: 'The model that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'
        object:
          enum:
            - thread.run
          type: string
          description: 'The object type, which is always `thread.run`.'
          x-stainless-const: true
        parallel_tool_calls:
          $ref: '#/components/schemas/ParallelToolCalls'
        required_action:
          required:
            - type
            - submit_tool_outputs
          type: object
          properties:
            submit_tool_outputs:
              required:
                - tool_calls
              type: object
              properties:
                tool_calls:
                  type: array
                  items:
                    $ref: '#/components/schemas/RunToolCallObject'
                  description: A list of the relevant tool calls.
              description: Details on the tool outputs needed for this run to continue.
            type:
              enum:
                - submit_tool_outputs
              type: string
              description: 'For now, this is always `submit_tool_outputs`.'
              x-stainless-const: true
          description: Details on the action required to continue the run. Will be `null` if no action is required.
          nullable: true
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
        started_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run was started.
          nullable: true
        status:
          $ref: '#/components/schemas/RunStatus'
        temperature:
          type: number
          description: 'The sampling temperature used for this run. If not set, defaults to 1.'
          nullable: true
        thread_id:
          type: string
          description: 'The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was executed on as a part of this run.'
        tool_choice:
          $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
        tools:
          maxItems: 20
          type: array
          items:
            $ref: '#/components/schemas/AssistantTool'
          description: 'The list of tools that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'
        top_p:
          type: number
          description: 'The nucleus sampling value used for this run. If not set, defaults to 1.'
          nullable: true
        truncation_strategy:
          $ref: '#/components/schemas/TruncationObject'
        usage:
          $ref: '#/components/schemas/RunCompletionUsage'
      description: 'Represents an execution run on a [thread](https://platform.openai.com/docs/api-reference/threads).'
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1698107661,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"completed\",\n  \"started_at\": 1699073476,\n  \"expires_at\": null,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": 1699073498,\n  \"last_error\": null,\n  \"model\": \"gpt-4o\",\n  \"instructions\": null,\n  \"tools\": [{\"type\": \"file_search\"}, {\"type\": \"code_interpreter\"}],\n  \"metadata\": {},\n  \"incomplete_details\": null,\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  },\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\": 1000,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n}\n"
        name: The run object
    RunStatus:
      enum:
        - queued
        - in_progress
        - requires_action
        - cancelling
        - cancelled
        - failed
        - completed
        - incomplete
        - expired
      type: string
      description: 'The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.'
    RunStepCompletionUsage:
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      type: object
      properties:
        completion_tokens:
          type: integer
          description: Number of completion tokens used over the course of the run step.
        prompt_tokens:
          type: integer
          description: Number of prompt tokens used over the course of the run step.
        total_tokens:
          type: integer
          description: Total number of tokens used (prompt + completion).
      description: Usage statistics related to the run step. This value will be `null` while the run step's status is `in_progress`.
      nullable: true
    RunStepDeltaObject:
      title: Run step delta object
      required:
        - id
        - object
        - delta
      type: object
      properties:
        delta:
          $ref: '#/components/schemas/RunStepDeltaObjectDelta'
        id:
          type: string
          description: 'The identifier of the run step, which can be referenced in API endpoints.'
        object:
          enum:
            - thread.run.step.delta
          type: string
          description: 'The object type, which is always `thread.run.step.delta`.'
          x-stainless-const: true
      description: "Represents a run step delta i.e. any changed fields on a run step during streaming.\n"
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"step_123\",\n  \"object\": \"thread.run.step.delta\",\n  \"delta\": {\n    \"step_details\": {\n      \"type\": \"tool_calls\",\n      \"tool_calls\": [\n        {\n          \"index\": 0,\n          \"id\": \"call_123\",\n          \"type\": \"code_interpreter\",\n          \"code_interpreter\": { \"input\": \"\", \"outputs\": [] }\n        }\n      ]\n    }\n  }\n}\n"
        name: The run step delta object
    RunStepDeltaObjectDelta:
      type: object
      properties:
        step_details:
          type: object
          anyOf:
            - $ref: '#/components/schemas/RunStepDeltaStepDetailsMessageCreationObject'
            - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsObject'
          description: The details of the run step.
          discriminator:
            propertyName: type
      description: The delta containing the fields that have changed on the run step.
    RunStepDeltaStepDetailsMessageCreationObject:
      title: Message creation
      required:
        - type
      type: object
      properties:
        message_creation:
          type: object
          properties:
            message_id:
              type: string
              description: The ID of the message that was created by this run step.
        type:
          enum:
            - message_creation
          type: string
          description: Always `message_creation`.
          x-stainless-const: true
      description: Details of the message creation by the run step.
    RunStepDeltaStepDetailsToolCall:
      anyOf:
        - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObject'
        - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsFileSearchObject'
        - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsFunctionObject'
      discriminator:
        propertyName: type
    RunStepDeltaStepDetailsToolCallsCodeObject:
      title: Code interpreter tool call
      required:
        - index
        - type
      type: object
      properties:
        code_interpreter:
          type: object
          properties:
            input:
              type: string
              description: The input to the Code Interpreter tool call.
            outputs:
              type: array
              items:
                type: object
                anyOf:
                  - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject'
                  - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputImageObject'
                discriminator:
                  propertyName: type
              description: 'The outputs from the Code Interpreter tool call. Code Interpreter can output one or more items, including text (`logs`) or images (`image`). Each of these are represented by a different object type.'
          description: The Code Interpreter tool call definition.
        id:
          type: string
          description: The ID of the tool call.
        index:
          type: integer
          description: The index of the tool call in the tool calls array.
        type:
          enum:
            - code_interpreter
          type: string
          description: The type of tool call. This is always going to be `code_interpreter` for this type of tool call.
          x-stainless-const: true
      description: Details of the Code Interpreter tool call the run step was involved in.
    RunStepDeltaStepDetailsToolCallsCodeOutputImageObject:
      title: Code interpreter image output
      required:
        - index
        - type
      type: object
      properties:
        image:
          type: object
          properties:
            file_id:
              type: string
              description: 'The [file](https://platform.openai.com/docs/api-reference/files) ID of the image.'
        index:
          type: integer
          description: The index of the output in the outputs array.
        type:
          enum:
            - image
          type: string
          description: Always `image`.
          x-stainless-const: true
    RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject:
      title: Code interpreter log output
      required:
        - index
        - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the output in the outputs array.
        logs:
          type: string
          description: The text output from the Code Interpreter tool call.
        type:
          enum:
            - logs
          type: string
          description: Always `logs`.
          x-stainless-const: true
      description: Text output from the Code Interpreter tool call as part of a run step.
    RunStepDeltaStepDetailsToolCallsFileSearchObject:
      title: File search tool call
      required:
        - index
        - type
        - file_search
      type: object
      properties:
        file_search:
          type: object
          description: 'For now, this is always going to be an empty object.'
          x-oaiTypeLabel: map
        id:
          type: string
          description: The ID of the tool call object.
        index:
          type: integer
          description: The index of the tool call in the tool calls array.
        type:
          enum:
            - file_search
          type: string
          description: The type of tool call. This is always going to be `file_search` for this type of tool call.
          x-stainless-const: true
    RunStepDeltaStepDetailsToolCallsFunctionObject:
      title: Function tool call
      required:
        - index
        - type
      type: object
      properties:
        function:
          type: object
          properties:
            arguments:
              type: string
              description: The arguments passed to the function.
            name:
              type: string
              description: The name of the function.
            output:
              type: string
              description: 'The output of the function. This will be `null` if the outputs have not been [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs) yet.'
              nullable: true
          description: The definition of the function that was called.
        id:
          type: string
          description: The ID of the tool call object.
        index:
          type: integer
          description: The index of the tool call in the tool calls array.
        type:
          enum:
            - function
          type: string
          description: The type of tool call. This is always going to be `function` for this type of tool call.
          x-stainless-const: true
    RunStepDeltaStepDetailsToolCallsObject:
      title: Tool calls
      required:
        - type
      type: object
      properties:
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCall'
          description: "An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`.\n"
        type:
          enum:
            - tool_calls
          type: string
          description: Always `tool_calls`.
          x-stainless-const: true
      description: Details of the tool call.
    RunStepDetailsMessageCreationObject:
      title: Message creation
      required:
        - type
        - message_creation
      type: object
      properties:
        message_creation:
          required:
            - message_id
          type: object
          properties:
            message_id:
              type: string
              description: The ID of the message that was created by this run step.
        type:
          enum:
            - message_creation
          type: string
          description: Always `message_creation`.
          x-stainless-const: true
      description: Details of the message creation by the run step.
    RunStepDetailsToolCall:
      anyOf:
        - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeObject'
        - $ref: '#/components/schemas/RunStepDetailsToolCallsFileSearchObject'
        - $ref: '#/components/schemas/RunStepDetailsToolCallsFunctionObject'
      discriminator:
        propertyName: type
    RunStepDetailsToolCallsCodeObject:
      title: Code Interpreter tool call
      required:
        - id
        - type
        - code_interpreter
      type: object
      properties:
        code_interpreter:
          required:
            - input
            - outputs
          type: object
          properties:
            input:
              type: string
              description: The input to the Code Interpreter tool call.
            outputs:
              type: array
              items:
                type: object
                anyOf:
                  - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeOutputLogsObject'
                  - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeOutputImageObject'
                discriminator:
                  propertyName: type
              description: 'The outputs from the Code Interpreter tool call. Code Interpreter can output one or more items, including text (`logs`) or images (`image`). Each of these are represented by a different object type.'
          description: The Code Interpreter tool call definition.
        id:
          type: string
          description: The ID of the tool call.
        type:
          enum:
            - code_interpreter
          type: string
          description: The type of tool call. This is always going to be `code_interpreter` for this type of tool call.
          x-stainless-const: true
      description: Details of the Code Interpreter tool call the run step was involved in.
    RunStepDetailsToolCallsCodeOutputImageObject:
      title: Code Interpreter image output
      required:
        - type
        - image
      type: object
      properties:
        image:
          required:
            - file_id
          type: object
          properties:
            file_id:
              type: string
              description: 'The [file](https://platform.openai.com/docs/api-reference/files) ID of the image.'
        type:
          enum:
            - image
          type: string
          description: Always `image`.
          x-stainless-const: true
      x-stainless-naming:
        java:
          type_name: ImageOutput
        kotlin:
          type_name: ImageOutput
    RunStepDetailsToolCallsCodeOutputLogsObject:
      title: Code Interpreter log output
      required:
        - type
        - logs
      type: object
      properties:
        logs:
          type: string
          description: The text output from the Code Interpreter tool call.
        type:
          enum:
            - logs
          type: string
          description: Always `logs`.
          x-stainless-const: true
      description: Text output from the Code Interpreter tool call as part of a run step.
      x-stainless-naming:
        java:
          type_name: LogsOutput
        kotlin:
          type_name: LogsOutput
    RunStepDetailsToolCallsFileSearchObject:
      title: File search tool call
      required:
        - id
        - type
        - file_search
      type: object
      properties:
        file_search:
          type: object
          properties:
            ranking_options:
              $ref: '#/components/schemas/RunStepDetailsToolCallsFileSearchRankingOptionsObject'
            results:
              type: array
              items:
                $ref: '#/components/schemas/RunStepDetailsToolCallsFileSearchResultObject'
              description: The results of the file search.
          description: 'For now, this is always going to be an empty object.'
          x-oaiTypeLabel: map
        id:
          type: string
          description: The ID of the tool call object.
        type:
          enum:
            - file_search
          type: string
          description: The type of tool call. This is always going to be `file_search` for this type of tool call.
          x-stainless-const: true
    RunStepDetailsToolCallsFileSearchRankingOptionsObject:
      title: File search tool call ranking options
      required:
        - ranker
        - score_threshold
      type: object
      properties:
        ranker:
          $ref: '#/components/schemas/FileSearchRanker'
        score_threshold:
          maximum: 1
          minimum: 0
          type: number
          description: The score threshold for the file search. All values must be a floating point number between 0 and 1.
      description: The ranking options for the file search.
    RunStepDetailsToolCallsFileSearchResultObject:
      title: File search tool call result
      required:
        - file_id
        - file_name
        - score
      type: object
      properties:
        content:
          type: array
          items:
            type: object
            properties:
              text:
                type: string
                description: The text content of the file.
              type:
                enum:
                  - text
                type: string
                description: The type of the content.
                x-stainless-const: true
          description: The content of the result that was found. The content is only included if requested via the include query parameter.
        file_id:
          type: string
          description: The ID of the file that result was found in.
        file_name:
          type: string
          description: The name of the file that result was found in.
        score:
          maximum: 1
          minimum: 0
          type: number
          description: The score of the result. All values must be a floating point number between 0 and 1.
      description: A result instance of the file search.
      x-oaiTypeLabel: map
    RunStepDetailsToolCallsFunctionObject:
      title: Function tool call
      required:
        - id
        - type
        - function
      type: object
      properties:
        function:
          required:
            - name
            - arguments
            - output
          type: object
          properties:
            arguments:
              type: string
              description: The arguments passed to the function.
            name:
              type: string
              description: The name of the function.
            output:
              type: string
              description: 'The output of the function. This will be `null` if the outputs have not been [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs) yet.'
              nullable: true
          description: The definition of the function that was called.
        id:
          type: string
          description: The ID of the tool call object.
        type:
          enum:
            - function
          type: string
          description: The type of tool call. This is always going to be `function` for this type of tool call.
          x-stainless-const: true
    RunStepDetailsToolCallsObject:
      title: Tool calls
      required:
        - type
        - tool_calls
      type: object
      properties:
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/RunStepDetailsToolCall'
          description: "An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`.\n"
        type:
          enum:
            - tool_calls
          type: string
          description: Always `tool_calls`.
          x-stainless-const: true
      description: Details of the tool call.
    RunStepObject:
      title: Run steps
      required:
        - id
        - object
        - created_at
        - assistant_id
        - thread_id
        - run_id
        - type
        - status
        - step_details
        - last_error
        - cancelled_at
        - failed_at
        - completed_at
        - usage
      type: object
      properties:
        assistant_id:
          type: string
          description: 'The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) associated with the run step.'
        cancelled_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step was cancelled.
          nullable: true
        completed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step completed.
          nullable: true
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step was created.
        expired_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.
          nullable: true
        failed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step failed.
          nullable: true
        id:
          type: string
          description: 'The identifier of the run step, which can be referenced in API endpoints.'
        last_error:
          required:
            - code
            - message
          type: object
          properties:
            code:
              enum:
                - server_error
                - rate_limit_exceeded
              type: string
              description: One of `server_error` or `rate_limit_exceeded`.
            message:
              type: string
              description: A human-readable description of the error.
          description: The last error associated with this run step. Will be `null` if there are no errors.
          nullable: true
        metadata:
          $ref: '#/components/schemas/Metadata'
        object:
          enum:
            - thread.run.step
          type: string
          description: 'The object type, which is always `thread.run.step`.'
          x-stainless-const: true
        run_id:
          type: string
          description: 'The ID of the [run](https://platform.openai.com/docs/api-reference/runs) that this run step is a part of.'
        status:
          enum:
            - in_progress
            - cancelled
            - failed
            - completed
            - expired
          type: string
          description: 'The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.'
        step_details:
          type: object
          anyOf:
            - $ref: '#/components/schemas/RunStepDetailsMessageCreationObject'
            - $ref: '#/components/schemas/RunStepDetailsToolCallsObject'
          description: The details of the run step.
          discriminator:
            propertyName: type
        thread_id:
          type: string
          description: 'The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was run.'
        type:
          enum:
            - message_creation
            - tool_calls
          type: string
          description: 'The type of run step, which can be either `message_creation` or `tool_calls`.'
        usage:
          $ref: '#/components/schemas/RunStepCompletionUsage'
      description: "Represents a step in execution of a run.\n"
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"step_abc123\",\n  \"object\": \"thread.run.step\",\n  \"created_at\": 1699063291,\n  \"run_id\": \"run_abc123\",\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"type\": \"message_creation\",\n  \"status\": \"completed\",\n  \"cancelled_at\": null,\n  \"completed_at\": 1699063291,\n  \"expired_at\": null,\n  \"failed_at\": null,\n  \"last_error\": null,\n  \"step_details\": {\n    \"type\": \"message_creation\",\n    \"message_creation\": {\n      \"message_id\": \"msg_abc123\"\n    }\n  },\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  }\n}\n"
        name: The run step object
    RunStepStreamEvent:
      anyOf:
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/RunStepObject'
            event:
              enum:
                - thread.run.step.created
              type: string
              x-stainless-const: true
          description: 'Occurs when a [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object) is created.'
          x-oaiMeta:
            dataDescription: '`data` is a [run step](/docs/api-reference/run-steps/step-object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/RunStepObject'
            event:
              enum:
                - thread.run.step.in_progress
              type: string
              x-stainless-const: true
          description: 'Occurs when a [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object) moves to an `in_progress` state.'
          x-oaiMeta:
            dataDescription: '`data` is a [run step](/docs/api-reference/run-steps/step-object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/RunStepDeltaObject'
            event:
              enum:
                - thread.run.step.delta
              type: string
              x-stainless-const: true
          description: 'Occurs when parts of a [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object) are being streamed.'
          x-oaiMeta:
            dataDescription: '`data` is a [run step delta](/docs/api-reference/assistants-streaming/run-step-delta-object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/RunStepObject'
            event:
              enum:
                - thread.run.step.completed
              type: string
              x-stainless-const: true
          description: 'Occurs when a [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object) is completed.'
          x-oaiMeta:
            dataDescription: '`data` is a [run step](/docs/api-reference/run-steps/step-object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/RunStepObject'
            event:
              enum:
                - thread.run.step.failed
              type: string
              x-stainless-const: true
          description: 'Occurs when a [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object) fails.'
          x-oaiMeta:
            dataDescription: '`data` is a [run step](/docs/api-reference/run-steps/step-object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/RunStepObject'
            event:
              enum:
                - thread.run.step.cancelled
              type: string
              x-stainless-const: true
          description: 'Occurs when a [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object) is cancelled.'
          x-oaiMeta:
            dataDescription: '`data` is a [run step](/docs/api-reference/run-steps/step-object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/RunStepObject'
            event:
              enum:
                - thread.run.step.expired
              type: string
              x-stainless-const: true
          description: 'Occurs when a [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object) expires.'
          x-oaiMeta:
            dataDescription: '`data` is a [run step](/docs/api-reference/run-steps/step-object)'
      discriminator:
        propertyName: event
    RunStreamEvent:
      anyOf:
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/RunObject'
            event:
              enum:
                - thread.run.created
              type: string
              x-stainless-const: true
          description: 'Occurs when a new [run](https://platform.openai.com/docs/api-reference/runs/object) is created.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/RunObject'
            event:
              enum:
                - thread.run.queued
              type: string
              x-stainless-const: true
          description: 'Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object) moves to a `queued` status.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/RunObject'
            event:
              enum:
                - thread.run.in_progress
              type: string
              x-stainless-const: true
          description: 'Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object) moves to an `in_progress` status.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/RunObject'
            event:
              enum:
                - thread.run.requires_action
              type: string
              x-stainless-const: true
          description: 'Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object) moves to a `requires_action` status.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/RunObject'
            event:
              enum:
                - thread.run.completed
              type: string
              x-stainless-const: true
          description: 'Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object) is completed.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/RunObject'
            event:
              enum:
                - thread.run.incomplete
              type: string
              x-stainless-const: true
          description: 'Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object) ends with status `incomplete`.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/RunObject'
            event:
              enum:
                - thread.run.failed
              type: string
              x-stainless-const: true
          description: 'Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object) fails.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/RunObject'
            event:
              enum:
                - thread.run.cancelling
              type: string
              x-stainless-const: true
          description: 'Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object) moves to a `cancelling` status.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/RunObject'
            event:
              enum:
                - thread.run.cancelled
              type: string
              x-stainless-const: true
          description: 'Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object) is cancelled.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/RunObject'
            event:
              enum:
                - thread.run.expired
              type: string
              x-stainless-const: true
          description: 'Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object) expires.'
          x-oaiMeta:
            dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
      discriminator:
        propertyName: event
    RunToolCallObject:
      required:
        - id
        - type
        - function
      type: object
      properties:
        function:
          required:
            - name
            - arguments
          type: object
          properties:
            arguments:
              type: string
              description: The arguments that the model expects you to pass to the function.
            name:
              type: string
              description: The name of the function.
          description: The function definition.
        id:
          type: string
          description: 'The ID of the tool call. This ID must be referenced when you submit the tool outputs in using the [Submit tool outputs to run](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs) endpoint.'
        type:
          enum:
            - function
          type: string
          description: 'The type of tool call the output is required for. For now, this is always `function`.'
          x-stainless-const: true
      description: Tool call objects
    Screenshot:
      title: Screenshot
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - screenshot
          type: string
          description: "Specifies the event type. For a screenshot action, this property is \nalways set to `screenshot`.\n"
          default: screenshot
          x-stainless-const: true
      description: "A screenshot action.\n"
    Scroll:
      title: Scroll
      required:
        - type
        - x
        - y
        - scroll_x
        - scroll_y
      type: object
      properties:
        scroll_x:
          type: integer
          description: "The horizontal scroll distance.\n"
        scroll_y:
          type: integer
          description: "The vertical scroll distance.\n"
        type:
          enum:
            - scroll
          type: string
          description: "Specifies the event type. For a scroll action, this property is \nalways set to `scroll`.\n"
          default: scroll
          x-stainless-const: true
        x:
          type: integer
          description: "The x-coordinate where the scroll occurred.\n"
        y:
          type: integer
          description: "The y-coordinate where the scroll occurred.\n"
      description: "A scroll action.\n"
    ServiceTier:
      enum:
        - auto
        - default
        - flex
        - scale
        - priority
      type: string
      description: "Specifies the processing type used for serving the request.\n  - If set to 'auto', then the request will be processed with the service tier configured in the Project settings. Unless otherwise configured, the Project will use 'default'.\n  - If set to 'default', then the request will be processed with the standard pricing and performance for the selected model.\n  - If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)' or '[priority](https://openai.com/api-priority-processing/)', then the request will be processed with the corresponding service tier.\n  - When not set, the default behavior is 'auto'.\n\n  When the `service_tier` parameter is set, the response body will include the `service_tier` value based on the processing mode actually used to serve the request. This response value may be different from the value set in the parameter.\n"
      default: auto
      nullable: true
    SpeechAudioDeltaEvent:
      required:
        - type
        - audio
      type: object
      properties:
        audio:
          type: string
          description: "A chunk of Base64-encoded audio data.\n"
        type:
          enum:
            - speech.audio.delta
          type: string
          description: "The type of the event. Always `speech.audio.delta`.\n"
          x-stainless-const: true
      description: Emitted for each chunk of audio data generated during speech synthesis.
      x-oaiMeta:
        example: "{\n  \"type\": \"speech.audio.delta\",\n  \"audio\": \"base64-encoded-audio-data\"\n}\n"
        group: speech
        name: Stream Event (speech.audio.delta)
    SpeechAudioDoneEvent:
      required:
        - type
        - usage
      type: object
      properties:
        type:
          enum:
            - speech.audio.done
          type: string
          description: "The type of the event. Always `speech.audio.done`.\n"
          x-stainless-const: true
        usage:
          required:
            - input_tokens
            - output_tokens
            - total_tokens
          type: object
          properties:
            input_tokens:
              type: integer
              description: Number of input tokens in the prompt.
            output_tokens:
              type: integer
              description: Number of output tokens generated.
            total_tokens:
              type: integer
              description: Total number of tokens used (input + output).
          description: "Token usage statistics for the request.\n"
      description: Emitted when the speech synthesis is complete and all audio has been streamed.
      x-oaiMeta:
        example: "{\n  \"type\": \"speech.audio.done\",\n  \"usage\": {\n    \"input_tokens\": 14,\n    \"output_tokens\": 101,\n    \"total_tokens\": 115\n  }\n}\n"
        group: speech
        name: Stream Event (speech.audio.done)
    StaticChunkingStrategy:
      required:
        - max_chunk_size_tokens
        - chunk_overlap_tokens
      type: object
      properties:
        chunk_overlap_tokens:
          type: integer
          description: "The number of tokens that overlap between chunks. The default value is `400`.\n\nNote that the overlap must not exceed half of `max_chunk_size_tokens`.\n"
        max_chunk_size_tokens:
          maximum: 4096
          minimum: 100
          type: integer
          description: The maximum number of tokens in each chunk. The default value is `800`. The minimum value is `100` and the maximum value is `4096`.
      additionalProperties: false
    StaticChunkingStrategyRequestParam:
      title: Static Chunking Strategy
      required:
        - type
        - static
      type: object
      properties:
        static:
          $ref: '#/components/schemas/StaticChunkingStrategy'
        type:
          enum:
            - static
          type: string
          description: Always `static`.
          x-stainless-const: true
      additionalProperties: false
      description: Customize your own chunking strategy by setting chunk size and chunk overlap.
    StaticChunkingStrategyResponseParam:
      title: Static Chunking Strategy
      required:
        - type
        - static
      type: object
      properties:
        static:
          $ref: '#/components/schemas/StaticChunkingStrategy'
        type:
          enum:
            - static
          type: string
          description: Always `static`.
          x-stainless-const: true
      additionalProperties: false
    StopConfiguration:
      anyOf:
        - type: string
          default: <|endoftext|>
          nullable: true
          example: "\n"
        - maxItems: 4
          minItems: 1
          type: array
          items:
            type: string
            example: '["\n"]'
      description: "Not supported with latest reasoning models `o3` and `o4-mini`.\n\nUp to 4 sequences where the API will stop generating further tokens. The\nreturned text will not contain the stop sequence.\n"
      nullable: true
    SubmitToolOutputsRunRequest:
      required:
        - tool_outputs
      type: object
      properties:
        stream:
          type: boolean
          description: "If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.\n"
          nullable: true
        tool_outputs:
          type: array
          items:
            type: object
            properties:
              output:
                type: string
                description: The output of the tool call to be submitted to continue the run.
              tool_call_id:
                type: string
                description: The ID of the tool call in the `required_action` object within the run object the output is being submitted for.
          description: A list of tools for which the outputs are being submitted.
      additionalProperties: false
    SubmitToolOutputsRunRequestWithoutStream:
      required:
        - tool_outputs
      type: object
      properties:
        tool_outputs:
          type: array
          items:
            type: object
            properties:
              output:
                type: string
                description: The output of the tool call to be submitted to continue the run.
              tool_call_id:
                type: string
                description: The ID of the tool call in the `required_action` object within the run object the output is being submitted for.
          description: A list of tools for which the outputs are being submitted.
      additionalProperties: false
    SummaryTextContent:
      title: Summary text
      required:
        - type
        - text
      type: object
      properties:
        text:
          type: string
        type:
          enum:
            - summary_text
          type: string
          default: summary_text
          x-stainless-const: true
    TextAnnotation:
      anyOf:
        - $ref: '#/components/schemas/MessageContentTextAnnotationsFileCitationObject'
        - $ref: '#/components/schemas/MessageContentTextAnnotationsFilePathObject'
      discriminator:
        propertyName: type
    TextAnnotationDelta:
      anyOf:
        - $ref: '#/components/schemas/MessageDeltaContentTextAnnotationsFileCitationObject'
        - $ref: '#/components/schemas/MessageDeltaContentTextAnnotationsFilePathObject'
      discriminator:
        propertyName: type
    TextContent:
      title: Text Content
      required:
        - type
        - text
      type: object
      properties:
        text:
          type: string
        type:
          enum:
            - text
          type: string
          default: text
          x-stainless-const: true
    TextResponseFormatConfiguration:
      anyOf:
        - $ref: '#/components/schemas/ResponseFormatText'
        - $ref: '#/components/schemas/TextResponseFormatJsonSchema'
        - $ref: '#/components/schemas/ResponseFormatJsonObject'
      description: "An object specifying the format that the model must output.\n\nConfiguring `{ \"type\": \"json_schema\" }` enables Structured Outputs, \nwhich ensures the model will match your supplied JSON schema. Learn more in the \n[Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nThe default format is `{ \"type\": \"text\" }` with no additional options.\n\n**Not recommended for gpt-4o and newer models:**\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it.\n"
      discriminator:
        propertyName: type
    TextResponseFormatJsonSchema:
      title: JSON schema
      required:
        - type
        - schema
        - name
      type: object
      properties:
        description:
          type: string
          description: "A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n"
        name:
          type: string
          description: "The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n"
        schema:
          $ref: '#/components/schemas/ResponseFormatJsonSchemaSchema'
        strict:
          type: boolean
          description: "Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n"
          default: false
          nullable: true
        type:
          enum:
            - json_schema
          type: string
          description: The type of response format being defined. Always `json_schema`.
          x-stainless-const: true
      description: "JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n"
    ThreadObject:
      title: Thread
      required:
        - id
        - object
        - created_at
        - tool_resources
        - metadata
      type: object
      properties:
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the thread was created.
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints.'
        metadata:
          $ref: '#/components/schemas/Metadata'
        object:
          enum:
            - thread
          type: string
          description: 'The object type, which is always `thread`.'
          x-stainless-const: true
        tool_resources:
          type: object
          properties:
            code_interpreter:
              type: object
              properties:
                file_ids:
                  maxItems: 20
                  type: array
                  items:
                    type: string
                  description: "A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n"
            file_search:
              type: object
              properties:
                vector_store_ids:
                  maxItems: 1
                  type: array
                  items:
                    type: string
                  description: "The [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.\n"
          description: "A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n"
          nullable: true
      description: 'Represents a thread that contains [messages](https://platform.openai.com/docs/api-reference/messages).'
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n  \"created_at\": 1698107661,\n  \"metadata\": {}\n}\n"
        name: The thread object
    ThreadStreamEvent:
      anyOf:
        - required:
            - event
            - data
          type: object
          properties:
            data:
              $ref: '#/components/schemas/ThreadObject'
            enabled:
              type: boolean
              description: Whether to enable input audio transcription.
            event:
              enum:
                - thread.created
              type: string
              x-stainless-const: true
          description: 'Occurs when a new [thread](https://platform.openai.com/docs/api-reference/threads/object) is created.'
          x-oaiMeta:
            dataDescription: '`data` is a [thread](/docs/api-reference/threads/object)'
      discriminator:
        propertyName: event
    ToggleCertificatesRequest:
      required:
        - certificate_ids
      type: object
      properties:
        certificate_ids:
          maxItems: 10
          minItems: 1
          type: array
          items:
            type: string
            example: cert_abc
    Tool:
      anyOf:
        - $ref: '#/components/schemas/FunctionTool'
        - $ref: '#/components/schemas/FileSearchTool'
        - $ref: '#/components/schemas/ComputerUsePreviewTool'
        - $ref: '#/components/schemas/WebSearchTool'
        - $ref: '#/components/schemas/MCPTool'
        - $ref: '#/components/schemas/CodeInterpreterTool'
        - $ref: '#/components/schemas/ImageGenTool'
        - $ref: '#/components/schemas/LocalShellTool'
        - $ref: '#/components/schemas/CustomTool'
        - $ref: '#/components/schemas/WebSearchPreviewTool'
      description: "A tool that can be used to generate a response.\n"
      discriminator:
        propertyName: type
    ToolChoiceAllowed:
      title: Allowed tools
      required:
        - type
        - mode
        - tools
      type: object
      properties:
        mode:
          enum:
            - auto
            - required
          type: string
          description: "Constrains the tools available to the model to a pre-defined set.\n\n`auto` allows the model to pick from among the allowed tools and generate a\nmessage.\n\n`required` requires the model to call one or more of the allowed tools.\n"
        tools:
          type: array
          items:
            type: object
            description: "A tool definition that the model should be allowed to call.\n"
            x-oaiExpandable: false
          description: "A list of tool definitions that the model should be allowed to call.\n\nFor the Responses API, the list of tool definitions might look like:\n```json\n[\n  { \"type\": \"function\", \"name\": \"get_weather\" },\n  { \"type\": \"mcp\", \"server_label\": \"deepwiki\" },\n  { \"type\": \"image_generation\" }\n]\n```\n"
        type:
          enum:
            - allowed_tools
          type: string
          description: Allowed tool configuration type. Always `allowed_tools`.
          x-stainless-const: true
      description: "Constrains the tools available to the model to a pre-defined set.\n"
    ToolChoiceCustom:
      title: Custom tool
      required:
        - type
        - name
      type: object
      properties:
        name:
          type: string
          description: The name of the custom tool to call.
        type:
          enum:
            - custom
          type: string
          description: 'For custom tool calling, the type is always `custom`.'
          x-stainless-const: true
      description: "Use this option to force the model to call a specific custom tool.\n"
    ToolChoiceFunction:
      title: Function tool
      required:
        - type
        - name
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call.
        type:
          enum:
            - function
          type: string
          description: 'For function calling, the type is always `function`.'
          x-stainless-const: true
      description: "Use this option to force the model to call a specific function.\n"
    ToolChoiceMCP:
      title: MCP tool
      required:
        - type
        - server_label
      type: object
      properties:
        name:
          type: string
          description: "The name of the tool to call on the server.\n"
          nullable: true
        server_label:
          type: string
          description: "The label of the MCP server to use.\n"
        type:
          enum:
            - mcp
          type: string
          description: 'For MCP tools, the type is always `mcp`.'
          x-stainless-const: true
      description: "Use this option to force the model to call a specific tool on a remote MCP server.\n"
    ToolChoiceOptions:
      title: Tool choice mode
      enum:
        - none
        - auto
        - required
      type: string
      description: "Controls which (if any) tool is called by the model.\n\n`none` means the model will not call any tool and instead generates a message.\n\n`auto` means the model can pick between generating a message or calling one or\nmore tools.\n\n`required` means the model must call one or more tools.\n"
    ToolChoiceTypes:
      title: Hosted tool
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - file_search
            - web_search_preview
            - computer_use_preview
            - web_search_preview_2025_03_11
            - image_generation
            - code_interpreter
          type: string
          description: "The type of hosted tool the model should to use. Learn more about\n[built-in tools](https://platform.openai.com/docs/guides/tools).\n\nAllowed values are:\n- `file_search`\n- `web_search_preview`\n- `computer_use_preview`\n- `code_interpreter`\n- `image_generation`\n"
      description: "Indicates that the model should use a built-in tool to generate a response.\n[Learn more about built-in tools](https://platform.openai.com/docs/guides/tools).\n"
    TopLogProb:
      title: Top log probability
      required:
        - token
        - logprob
        - bytes
      type: object
      properties:
        bytes:
          type: array
          items:
            type: integer
        logprob:
          type: number
        token:
          type: string
      description: The top log probability of a token.
    TopLogProb-2:
      title: Top log probability
      required:
        - token
        - logprob
        - bytes
      type: object
      properties:
        bytes:
          type: array
          items:
            type: integer
        logprob:
          type: number
        token:
          type: string
    TranscriptTextDeltaEvent:
      required:
        - type
        - delta
      type: object
      properties:
        delta:
          type: string
          description: "The text delta that was additionally transcribed.\n"
        logprobs:
          type: array
          items:
            type: object
            properties:
              bytes:
                type: array
                items:
                  type: integer
                description: "The bytes that were used to generate the log probability.\n"
              logprob:
                type: number
                description: "The log probability of the token.\n"
              token:
                type: string
                description: "The token that was used to generate the log probability.\n"
          description: "The log probabilities of the delta. Only included if you [create a transcription](https://platform.openai.com/docs/api-reference/audio/create-transcription) with the `include[]` parameter set to `logprobs`.\n"
        type:
          enum:
            - transcript.text.delta
          type: string
          description: "The type of the event. Always `transcript.text.delta`.\n"
          x-stainless-const: true
      description: 'Emitted when there is an additional text delta. This is also the first event emitted when the transcription starts. Only emitted when you [create a transcription](https://platform.openai.com/docs/api-reference/audio/create-transcription) with the `Stream` parameter set to `true`.'
      x-oaiMeta:
        example: "{\n  \"type\": \"transcript.text.delta\",\n  \"delta\": \" wonderful\"\n}\n"
        group: transcript
        name: Stream Event (transcript.text.delta)
    TranscriptTextDoneEvent:
      required:
        - type
        - text
      type: object
      properties:
        logprobs:
          type: array
          items:
            type: object
            properties:
              bytes:
                type: array
                items:
                  type: integer
                description: "The bytes that were used to generate the log probability.\n"
              logprob:
                type: number
                description: "The log probability of the token.\n"
              token:
                type: string
                description: "The token that was used to generate the log probability.\n"
          description: "The log probabilities of the individual tokens in the transcription. Only included if you [create a transcription](https://platform.openai.com/docs/api-reference/audio/create-transcription) with the `include[]` parameter set to `logprobs`.\n"
        text:
          type: string
          description: "The text that was transcribed.\n"
        type:
          enum:
            - transcript.text.done
          type: string
          description: "The type of the event. Always `transcript.text.done`.\n"
          x-stainless-const: true
        usage:
          $ref: '#/components/schemas/TranscriptTextUsageTokens'
      description: 'Emitted when the transcription is complete. Contains the complete transcription text. Only emitted when you [create a transcription](https://platform.openai.com/docs/api-reference/audio/create-transcription) with the `Stream` parameter set to `true`.'
      x-oaiMeta:
        example: "{\n  \"type\": \"transcript.text.done\",\n  \"text\": \"I see skies of blue and clouds of white, the bright blessed days, the dark sacred nights, and I think to myself, what a wonderful world.\",\n  \"usage\": {\n    \"type\": \"tokens\",\n    \"input_tokens\": 14,\n    \"input_token_details\": {\n      \"text_tokens\": 10,\n      \"audio_tokens\": 4\n    },\n    \"output_tokens\": 31,\n    \"total_tokens\": 45\n  }\n}\n"
        group: transcript
        name: Stream Event (transcript.text.done)
    TranscriptTextUsageDuration:
      title: Duration Usage
      required:
        - type
        - seconds
      type: object
      properties:
        seconds:
          type: number
          description: Duration of the input audio in seconds.
        type:
          enum:
            - duration
          type: string
          description: The type of the usage object. Always `duration` for this variant.
          x-stainless-const: true
      description: Usage statistics for models billed by audio input duration.
    TranscriptTextUsageTokens:
      title: Token Usage
      required:
        - type
        - input_tokens
        - output_tokens
        - total_tokens
      type: object
      properties:
        input_token_details:
          type: object
          properties:
            audio_tokens:
              type: integer
              description: Number of audio tokens billed for this request.
            text_tokens:
              type: integer
              description: Number of text tokens billed for this request.
          description: Details about the input tokens billed for this request.
        input_tokens:
          type: integer
          description: Number of input tokens billed for this request.
        output_tokens:
          type: integer
          description: Number of output tokens generated.
        total_tokens:
          type: integer
          description: Total number of tokens used (input + output).
        type:
          enum:
            - tokens
          type: string
          description: The type of the usage object. Always `tokens` for this variant.
          x-stainless-const: true
      description: Usage statistics for models billed by token usage.
    TranscriptionChunkingStrategy:
      anyOf:
        - enum:
            - auto
          type: string
          description: "Automatically set chunking parameters based on the audio. Must be set to `\"auto\"`.\n"
          x-stainless-const: true
        - $ref: '#/components/schemas/VadConfig'
      description: 'Controls how the audio is cut into chunks. When set to `"auto"`, the server first normalizes loudness and then uses voice activity detection (VAD) to choose boundaries. `server_vad` object can be provided to tweak VAD detection parameters manually. If unset, the audio is transcribed as a single block. '
      nullable: true
      x-oaiTypeLabel: string
    TranscriptionInclude:
      enum:
        - logprobs
      type: string
    TranscriptionSegment:
      required:
        - id
        - seek
        - start
        - end
        - text
        - tokens
        - temperature
        - avg_logprob
        - compression_ratio
        - no_speech_prob
      type: object
      properties:
        avg_logprob:
          type: number
          description: 'Average logprob of the segment. If the value is lower than -1, consider the logprobs failed.'
          format: float
        compression_ratio:
          type: number
          description: 'Compression ratio of the segment. If the value is greater than 2.4, consider the compression failed.'
          format: float
        end:
          type: number
          description: End time of the segment in seconds.
          format: float
        id:
          type: integer
          description: Unique identifier of the segment.
        no_speech_prob:
          type: number
          description: 'Probability of no speech in the segment. If the value is higher than 1.0 and the `avg_logprob` is below -1, consider this segment silent.'
          format: float
        seek:
          type: integer
          description: Seek offset of the segment.
        start:
          type: number
          description: Start time of the segment in seconds.
          format: float
        temperature:
          type: number
          description: Temperature parameter used for generating the segment.
          format: float
        text:
          type: string
          description: Text content of the segment.
        tokens:
          type: array
          items:
            type: integer
          description: Array of token IDs for the text content.
    TranscriptionWord:
      required:
        - word
        - start
        - end
      type: object
      properties:
        end:
          type: number
          description: End time of the word in seconds.
          format: float
        start:
          type: number
          description: Start time of the word in seconds.
          format: float
        word:
          type: string
          description: The text content of the word.
    TruncationObject:
      title: Thread Truncation Controls
      required:
        - type
      type: object
      properties:
        last_messages:
          minimum: 1
          type: integer
          description: The number of most recent messages from the thread when constructing the context for the run.
          nullable: true
        type:
          enum:
            - auto
            - last_messages
          type: string
          description: 'The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.'
      description: Controls for how a thread will be truncated prior to the run. Use this to control the initial context window of the run.
    Type:
      title: Type
      required:
        - type
        - text
      type: object
      properties:
        text:
          type: string
          description: "The text to type.\n"
        type:
          enum:
            - type
          type: string
          description: "Specifies the event type. For a type action, this property is \nalways set to `type`.\n"
          default: type
          x-stainless-const: true
      description: "An action to type in text.\n"
    UpdateConversationBody:
      required:
        - metadata
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/MetadataParam'
    UpdateVectorStoreFileAttributesRequest:
      required:
        - attributes
      type: object
      properties:
        attributes:
          $ref: '#/components/schemas/VectorStoreFileAttributes'
      additionalProperties: false
      x-oaiMeta:
        name: Update vector store file attributes request
    UpdateVectorStoreRequest:
      type: object
      properties:
        expires_after:
          $ref: '#/components/schemas/VectorStoreExpirationAfter'
        metadata:
          $ref: '#/components/schemas/Metadata'
        name:
          type: string
          description: The name of the vector store.
          nullable: true
      additionalProperties: false
    Upload:
      title: Upload
      required:
        - bytes
        - created_at
        - expires_at
        - filename
        - id
        - purpose
        - status
        - object
      type: object
      properties:
        bytes:
          type: integer
          description: The intended number of bytes to be uploaded.
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the Upload was created.
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the Upload will expire.
        file:
          $ref: '#/components/schemas/OpenAIFile'
        filename:
          type: string
          description: The name of the file to be uploaded.
        id:
          type: string
          description: 'The Upload unique identifier, which can be referenced in API endpoints.'
        object:
          enum:
            - upload
          type: string
          description: 'The object type, which is always "upload".'
          x-stainless-const: true
        purpose:
          type: string
          description: 'The intended purpose of the file. [Please refer here](https://platform.openai.com/docs/api-reference/files/object#files/object-purpose) for acceptable values.'
        status:
          enum:
            - pending
            - completed
            - cancelled
            - expired
          type: string
          description: The status of the Upload.
      description: "The Upload object can accept byte chunks in the form of Parts.\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"upload_abc123\",\n  \"object\": \"upload\",\n  \"bytes\": 2147483648,\n  \"created_at\": 1719184911,\n  \"filename\": \"training_examples.jsonl\",\n  \"purpose\": \"fine-tune\",\n  \"status\": \"completed\",\n  \"expires_at\": 1719127296,\n  \"file\": {\n    \"id\": \"file-xyz321\",\n    \"object\": \"file\",\n    \"bytes\": 2147483648,\n    \"created_at\": 1719186911,\n    \"filename\": \"training_examples.jsonl\",\n    \"purpose\": \"fine-tune\",\n  }\n}\n"
        name: The upload object
    UploadCertificateRequest:
      required:
        - content
      type: object
      properties:
        content:
          type: string
          description: The certificate content in PEM format
        name:
          type: string
          description: An optional name for the certificate
    UploadPart:
      title: UploadPart
      required:
        - created_at
        - id
        - object
        - upload_id
      type: object
      properties:
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the Part was created.
        id:
          type: string
          description: 'The upload Part unique identifier, which can be referenced in API endpoints.'
        object:
          enum:
            - upload.part
          type: string
          description: 'The object type, which is always `upload.part`.'
          x-stainless-const: true
        upload_id:
          type: string
          description: The ID of the Upload object that this Part was added to.
      description: "The upload Part represents a chunk of bytes we can add to an Upload object.\n"
      x-oaiMeta:
        example: "{\n    \"id\": \"part_def456\",\n    \"object\": \"upload.part\",\n    \"created_at\": 1719186911,\n    \"upload_id\": \"upload_abc123\"\n}\n"
        name: The upload part object
    UrlCitationBody:
      title: URL citation
      required:
        - type
        - url
        - start_index
        - end_index
        - title
      type: object
      properties:
        end_index:
          type: integer
          description: The index of the last character of the URL citation in the message.
        start_index:
          type: integer
          description: The index of the first character of the URL citation in the message.
        title:
          type: string
          description: The title of the web resource.
        type:
          enum:
            - url_citation
          type: string
          description: The type of the URL citation. Always `url_citation`.
          default: url_citation
          x-stainless-const: true
        url:
          type: string
          description: The URL of the web resource.
      description: A citation for a web resource used to generate a model response.
    UrlCitationBody-2:
      title: URL citation
      required:
        - type
        - url
        - start_index
        - end_index
        - title
      type: object
      properties:
        end_index:
          type: integer
          description: The index of the last character of the URL citation in the message.
        start_index:
          type: integer
          description: The index of the first character of the URL citation in the message.
        title:
          type: string
          description: The title of the web resource.
        type:
          enum:
            - url_citation
          type: string
          description: The type of the URL citation. Always `url_citation`.
          default: url_citation
          x-stainless-const: true
        url:
          type: string
          description: The URL of the web resource.
    UsageAudioSpeechesResult:
      required:
        - object
        - characters
        - num_model_requests
      type: object
      properties:
        api_key_id:
          type: string
          description: 'When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.'
          nullable: true
        characters:
          type: integer
          description: The number of characters processed.
        model:
          type: string
          description: 'When `group_by=model`, this field provides the model name of the grouped usage result.'
          nullable: true
        num_model_requests:
          type: integer
          description: The count of requests made to the model.
        object:
          enum:
            - organization.usage.audio_speeches.result
          type: string
          x-stainless-const: true
        project_id:
          type: string
          description: 'When `group_by=project_id`, this field provides the project ID of the grouped usage result.'
          nullable: true
        user_id:
          type: string
          description: 'When `group_by=user_id`, this field provides the user ID of the grouped usage result.'
          nullable: true
      description: The aggregated audio speeches usage details of the specific time bucket.
      x-oaiMeta:
        example: "{\n    \"object\": \"organization.usage.audio_speeches.result\",\n    \"characters\": 45,\n    \"num_model_requests\": 1,\n    \"project_id\": \"proj_abc\",\n    \"user_id\": \"user-abc\",\n    \"api_key_id\": \"key_abc\",\n    \"model\": \"tts-1\"\n}\n"
        name: Audio speeches usage object
    UsageAudioTranscriptionsResult:
      required:
        - object
        - seconds
        - num_model_requests
      type: object
      properties:
        api_key_id:
          type: string
          description: 'When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.'
          nullable: true
        model:
          type: string
          description: 'When `group_by=model`, this field provides the model name of the grouped usage result.'
          nullable: true
        num_model_requests:
          type: integer
          description: The count of requests made to the model.
        object:
          enum:
            - organization.usage.audio_transcriptions.result
          type: string
          x-stainless-const: true
        project_id:
          type: string
          description: 'When `group_by=project_id`, this field provides the project ID of the grouped usage result.'
          nullable: true
        seconds:
          type: integer
          description: The number of seconds processed.
        user_id:
          type: string
          description: 'When `group_by=user_id`, this field provides the user ID of the grouped usage result.'
          nullable: true
      description: The aggregated audio transcriptions usage details of the specific time bucket.
      x-oaiMeta:
        example: "{\n    \"object\": \"organization.usage.audio_transcriptions.result\",\n    \"seconds\": 10,\n    \"num_model_requests\": 1,\n    \"project_id\": \"proj_abc\",\n    \"user_id\": \"user-abc\",\n    \"api_key_id\": \"key_abc\",\n    \"model\": \"tts-1\"\n}\n"
        name: Audio transcriptions usage object
    UsageCodeInterpreterSessionsResult:
      required:
        - object
        - sessions
      type: object
      properties:
        num_sessions:
          type: integer
          description: The number of code interpreter sessions.
        object:
          enum:
            - organization.usage.code_interpreter_sessions.result
          type: string
          x-stainless-const: true
        project_id:
          type: string
          description: 'When `group_by=project_id`, this field provides the project ID of the grouped usage result.'
          nullable: true
      description: The aggregated code interpreter sessions usage details of the specific time bucket.
      x-oaiMeta:
        example: "{\n    \"object\": \"organization.usage.code_interpreter_sessions.result\",\n    \"num_sessions\": 1,\n    \"project_id\": \"proj_abc\"\n}\n"
        name: Code interpreter sessions usage object
    UsageCompletionsResult:
      required:
        - object
        - input_tokens
        - output_tokens
        - num_model_requests
      type: object
      properties:
        api_key_id:
          type: string
          description: 'When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.'
          nullable: true
        batch:
          type: boolean
          description: 'When `group_by=batch`, this field tells whether the grouped usage result is batch or not.'
          nullable: true
        input_audio_tokens:
          type: integer
          description: 'The aggregated number of audio input tokens used, including cached tokens.'
        input_cached_tokens:
          type: integer
          description: 'The aggregated number of text input tokens that has been cached from previous requests. For customers subscribe to scale tier, this includes scale tier tokens.'
        input_tokens:
          type: integer
          description: 'The aggregated number of text input tokens used, including cached tokens. For customers subscribe to scale tier, this includes scale tier tokens.'
        model:
          type: string
          description: 'When `group_by=model`, this field provides the model name of the grouped usage result.'
          nullable: true
        num_model_requests:
          type: integer
          description: The count of requests made to the model.
        object:
          enum:
            - organization.usage.completions.result
          type: string
          x-stainless-const: true
        output_audio_tokens:
          type: integer
          description: The aggregated number of audio output tokens used.
        output_tokens:
          type: integer
          description: 'The aggregated number of text output tokens used. For customers subscribe to scale tier, this includes scale tier tokens.'
        project_id:
          type: string
          description: 'When `group_by=project_id`, this field provides the project ID of the grouped usage result.'
          nullable: true
        user_id:
          type: string
          description: 'When `group_by=user_id`, this field provides the user ID of the grouped usage result.'
          nullable: true
      description: The aggregated completions usage details of the specific time bucket.
      x-oaiMeta:
        example: "{\n    \"object\": \"organization.usage.completions.result\",\n    \"input_tokens\": 5000,\n    \"output_tokens\": 1000,\n    \"input_cached_tokens\": 4000,\n    \"input_audio_tokens\": 300,\n    \"output_audio_tokens\": 200,\n    \"num_model_requests\": 5,\n    \"project_id\": \"proj_abc\",\n    \"user_id\": \"user-abc\",\n    \"api_key_id\": \"key_abc\",\n    \"model\": \"gpt-4o-mini-2024-07-18\",\n    \"batch\": false\n}\n"
        name: Completions usage object
    UsageEmbeddingsResult:
      required:
        - object
        - input_tokens
        - num_model_requests
      type: object
      properties:
        api_key_id:
          type: string
          description: 'When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.'
          nullable: true
        input_tokens:
          type: integer
          description: The aggregated number of input tokens used.
        model:
          type: string
          description: 'When `group_by=model`, this field provides the model name of the grouped usage result.'
          nullable: true
        num_model_requests:
          type: integer
          description: The count of requests made to the model.
        object:
          enum:
            - organization.usage.embeddings.result
          type: string
          x-stainless-const: true
        project_id:
          type: string
          description: 'When `group_by=project_id`, this field provides the project ID of the grouped usage result.'
          nullable: true
        user_id:
          type: string
          description: 'When `group_by=user_id`, this field provides the user ID of the grouped usage result.'
          nullable: true
      description: The aggregated embeddings usage details of the specific time bucket.
      x-oaiMeta:
        example: "{\n    \"object\": \"organization.usage.embeddings.result\",\n    \"input_tokens\": 20,\n    \"num_model_requests\": 2,\n    \"project_id\": \"proj_abc\",\n    \"user_id\": \"user-abc\",\n    \"api_key_id\": \"key_abc\",\n    \"model\": \"text-embedding-ada-002-v2\"\n}\n"
        name: Embeddings usage object
    UsageImagesResult:
      required:
        - object
        - images
        - num_model_requests
      type: object
      properties:
        api_key_id:
          type: string
          description: 'When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.'
          nullable: true
        images:
          type: integer
          description: The number of images processed.
        model:
          type: string
          description: 'When `group_by=model`, this field provides the model name of the grouped usage result.'
          nullable: true
        num_model_requests:
          type: integer
          description: The count of requests made to the model.
        object:
          enum:
            - organization.usage.images.result
          type: string
          x-stainless-const: true
        project_id:
          type: string
          description: 'When `group_by=project_id`, this field provides the project ID of the grouped usage result.'
          nullable: true
        size:
          type: string
          description: 'When `group_by=size`, this field provides the image size of the grouped usage result.'
          nullable: true
        source:
          type: string
          description: 'When `group_by=source`, this field provides the source of the grouped usage result, possible values are `image.generation`, `image.edit`, `image.variation`.'
          nullable: true
        user_id:
          type: string
          description: 'When `group_by=user_id`, this field provides the user ID of the grouped usage result.'
          nullable: true
      description: The aggregated images usage details of the specific time bucket.
      x-oaiMeta:
        example: "{\n    \"object\": \"organization.usage.images.result\",\n    \"images\": 2,\n    \"num_model_requests\": 2,\n    \"size\": \"1024x1024\",\n    \"source\": \"image.generation\",\n    \"project_id\": \"proj_abc\",\n    \"user_id\": \"user-abc\",\n    \"api_key_id\": \"key_abc\",\n    \"model\": \"dall-e-3\"\n}\n"
        name: Images usage object
    UsageModerationsResult:
      required:
        - object
        - input_tokens
        - num_model_requests
      type: object
      properties:
        api_key_id:
          type: string
          description: 'When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.'
          nullable: true
        input_tokens:
          type: integer
          description: The aggregated number of input tokens used.
        model:
          type: string
          description: 'When `group_by=model`, this field provides the model name of the grouped usage result.'
          nullable: true
        num_model_requests:
          type: integer
          description: The count of requests made to the model.
        object:
          enum:
            - organization.usage.moderations.result
          type: string
          x-stainless-const: true
        project_id:
          type: string
          description: 'When `group_by=project_id`, this field provides the project ID of the grouped usage result.'
          nullable: true
        user_id:
          type: string
          description: 'When `group_by=user_id`, this field provides the user ID of the grouped usage result.'
          nullable: true
      description: The aggregated moderations usage details of the specific time bucket.
      x-oaiMeta:
        example: "{\n    \"object\": \"organization.usage.moderations.result\",\n    \"input_tokens\": 20,\n    \"num_model_requests\": 2,\n    \"project_id\": \"proj_abc\",\n    \"user_id\": \"user-abc\",\n    \"api_key_id\": \"key_abc\",\n    \"model\": \"text-moderation\"\n}\n"
        name: Moderations usage object
    UsageResponse:
      required:
        - object
        - data
        - has_more
        - next_page
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/UsageTimeBucket'
        has_more:
          type: boolean
        next_page:
          type: string
        object:
          enum:
            - page
          type: string
          x-stainless-const: true
    UsageTimeBucket:
      required:
        - object
        - start_time
        - end_time
        - result
      type: object
      properties:
        end_time:
          type: integer
        object:
          enum:
            - bucket
          type: string
          x-stainless-const: true
        result:
          type: array
          items:
            anyOf:
              - $ref: '#/components/schemas/UsageCompletionsResult'
              - $ref: '#/components/schemas/UsageEmbeddingsResult'
              - $ref: '#/components/schemas/UsageModerationsResult'
              - $ref: '#/components/schemas/UsageImagesResult'
              - $ref: '#/components/schemas/UsageAudioSpeechesResult'
              - $ref: '#/components/schemas/UsageAudioTranscriptionsResult'
              - $ref: '#/components/schemas/UsageVectorStoresResult'
              - $ref: '#/components/schemas/UsageCodeInterpreterSessionsResult'
              - $ref: '#/components/schemas/CostsResult'
            discriminator:
              propertyName: object
        start_time:
          type: integer
    UsageVectorStoresResult:
      required:
        - object
        - usage_bytes
      type: object
      properties:
        object:
          enum:
            - organization.usage.vector_stores.result
          type: string
          x-stainless-const: true
        project_id:
          type: string
          description: 'When `group_by=project_id`, this field provides the project ID of the grouped usage result.'
          nullable: true
        usage_bytes:
          type: integer
          description: The vector stores usage in bytes.
      description: The aggregated vector stores usage details of the specific time bucket.
      x-oaiMeta:
        example: "{\n    \"object\": \"organization.usage.vector_stores.result\",\n    \"usage_bytes\": 1024,\n    \"project_id\": \"proj_abc\"\n}\n"
        name: Vector stores usage object
    User:
      required:
        - object
        - id
        - name
        - email
        - role
        - added_at
      type: object
      properties:
        added_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the user was added.
        email:
          type: string
          description: The email address of the user
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints'
        name:
          type: string
          description: The name of the user
        object:
          enum:
            - organization.user
          type: string
          description: 'The object type, which is always `organization.user`'
          x-stainless-const: true
        role:
          enum:
            - owner
            - reader
          type: string
          description: '`owner` or `reader`'
      description: Represents an individual `user` within an organization.
      x-oaiMeta:
        example: "{\n    \"object\": \"organization.user\",\n    \"id\": \"user_abc\",\n    \"name\": \"First Last\",\n    \"email\": \"user@example.com\",\n    \"role\": \"owner\",\n    \"added_at\": 1711471533\n}\n"
        name: The user object
    UserDeleteResponse:
      required:
        - object
        - id
        - deleted
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          enum:
            - organization.user.deleted
          type: string
          x-stainless-const: true
    UserListResponse:
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/User'
        first_id:
          type: string
        has_more:
          type: boolean
        last_id:
          type: string
        object:
          enum:
            - list
          type: string
          x-stainless-const: true
    UserRoleUpdateRequest:
      required:
        - role
      type: object
      properties:
        role:
          enum:
            - owner
            - reader
          type: string
          description: '`owner` or `reader`'
    VadConfig:
      required:
        - type
      type: object
      properties:
        prefix_padding_ms:
          type: integer
          description: "Amount of audio to include before the VAD detected speech (in \nmilliseconds).\n"
          default: 300
        silence_duration_ms:
          type: integer
          description: "Duration of silence to detect speech stop (in milliseconds).\nWith shorter values the model will respond more quickly, \nbut may jump in on short pauses from the user.\n"
          default: 200
        threshold:
          type: number
          description: "Sensitivity threshold (0.0 to 1.0) for voice activity detection. A \nhigher threshold will require louder audio to activate the model, and \nthus might perform better in noisy environments.\n"
          default: 0.5
        type:
          enum:
            - server_vad
          type: string
          description: Must be set to `server_vad` to enable manual chunking using server side VAD.
      additionalProperties: false
    ValidateGraderRequest:
      title: ValidateGraderRequest
      required:
        - grader
      type: object
      properties:
        grader:
          type: object
          anyOf:
            - $ref: '#/components/schemas/GraderStringCheck'
            - $ref: '#/components/schemas/GraderTextSimilarity'
            - $ref: '#/components/schemas/GraderPython'
            - $ref: '#/components/schemas/GraderScoreModel'
            - $ref: '#/components/schemas/GraderMulti'
          description: The grader used for the fine-tuning job.
    ValidateGraderResponse:
      title: ValidateGraderResponse
      type: object
      properties:
        grader:
          type: object
          anyOf:
            - $ref: '#/components/schemas/GraderStringCheck'
            - $ref: '#/components/schemas/GraderTextSimilarity'
            - $ref: '#/components/schemas/GraderPython'
            - $ref: '#/components/schemas/GraderScoreModel'
            - $ref: '#/components/schemas/GraderMulti'
          description: The grader used for the fine-tuning job.
    VectorStoreExpirationAfter:
      title: Vector store expiration policy
      required:
        - anchor
        - days
      type: object
      properties:
        anchor:
          enum:
            - last_active_at
          type: string
          description: 'Anchor timestamp after which the expiration policy applies. Supported anchors: `last_active_at`.'
          x-stainless-const: true
        days:
          maximum: 365
          minimum: 1
          type: integer
          description: The number of days after the anchor time that the vector store will expire.
      description: The expiration policy for a vector store.
    VectorStoreFileAttributes:
      maxProperties: 16
      type: object
      additionalProperties:
        anyOf:
          - maxLength: 512
            type: string
          - type: number
          - type: boolean
      description: "Set of 16 key-value pairs that can be attached to an object. This can be \nuseful for storing additional information about the object in a structured \nformat, and querying for objects via API or the dashboard. Keys are strings \nwith a maximum length of 64 characters. Values are strings with a maximum \nlength of 512 characters, booleans, or numbers.\n"
      nullable: true
      x-oaiTypeLabel: map
    VectorStoreFileBatchObject:
      title: Vector store file batch
      required:
        - id
        - object
        - created_at
        - vector_store_id
        - status
        - file_counts
      type: object
      properties:
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store files batch was created.
        file_counts:
          required:
            - in_progress
            - completed
            - cancelled
            - failed
            - total
          type: object
          properties:
            cancelled:
              type: integer
              description: The number of files that where cancelled.
            completed:
              type: integer
              description: The number of files that have been processed.
            failed:
              type: integer
              description: The number of files that have failed to process.
            in_progress:
              type: integer
              description: The number of files that are currently being processed.
            total:
              type: integer
              description: The total number of files.
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints.'
        object:
          enum:
            - vector_store.files_batch
          type: string
          description: 'The object type, which is always `vector_store.file_batch`.'
          x-stainless-const: true
        status:
          enum:
            - in_progress
            - completed
            - cancelled
            - failed
          type: string
          description: 'The status of the vector store files batch, which can be either `in_progress`, `completed`, `cancelled` or `failed`.'
        vector_store_id:
          type: string
          description: 'The ID of the [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) that the [File](https://platform.openai.com/docs/api-reference/files) is attached to.'
      description: A batch of files attached to a vector store.
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"vsfb_123\",\n  \"object\": \"vector_store.files_batch\",\n  \"created_at\": 1698107661,\n  \"vector_store_id\": \"vs_abc123\",\n  \"status\": \"completed\",\n  \"file_counts\": {\n    \"in_progress\": 0,\n    \"completed\": 100,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 100\n  }\n}\n"
        name: The vector store files batch object
    VectorStoreFileContentResponse:
      required:
        - object
        - data
        - has_more
        - next_page
      type: object
      properties:
        data:
          type: array
          items:
            type: object
            properties:
              text:
                type: string
                description: The text content
              type:
                type: string
                description: The content type (currently only `"text"`)
          description: Parsed content of the file.
        has_more:
          type: boolean
          description: Indicates if there are more content pages to fetch.
        next_page:
          type: string
          description: 'The token for the next page, if any.'
          nullable: true
        object:
          enum:
            - vector_store.file_content.page
          type: string
          description: 'The object type, which is always `vector_store.file_content.page`'
          x-stainless-const: true
      description: Represents the parsed content of a vector store file.
    VectorStoreFileObject:
      title: Vector store files
      required:
        - id
        - object
        - usage_bytes
        - created_at
        - vector_store_id
        - status
        - last_error
      type: object
      properties:
        attributes:
          $ref: '#/components/schemas/VectorStoreFileAttributes'
        chunking_strategy:
          $ref: '#/components/schemas/ChunkingStrategyResponse'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store file was created.
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints.'
        last_error:
          required:
            - code
            - message
          type: object
          properties:
            code:
              enum:
                - server_error
                - unsupported_file
                - invalid_file
              type: string
              description: One of `server_error` or `rate_limit_exceeded`.
            message:
              type: string
              description: A human-readable description of the error.
          description: The last error associated with this vector store file. Will be `null` if there are no errors.
          nullable: true
        object:
          enum:
            - vector_store.file
          type: string
          description: 'The object type, which is always `vector_store.file`.'
          x-stainless-const: true
        status:
          enum:
            - in_progress
            - completed
            - cancelled
            - failed
          type: string
          description: 'The status of the vector store file, which can be either `in_progress`, `completed`, `cancelled`, or `failed`. The status `completed` indicates that the vector store file is ready for use.'
        usage_bytes:
          type: integer
          description: The total vector store usage in bytes. Note that this may be different from the original file size.
        vector_store_id:
          type: string
          description: 'The ID of the [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) that the [File](https://platform.openai.com/docs/api-reference/files) is attached to.'
      description: A list of files attached to a vector store.
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"vector_store.file\",\n  \"usage_bytes\": 1234,\n  \"created_at\": 1698107661,\n  \"vector_store_id\": \"vs_abc123\",\n  \"status\": \"completed\",\n  \"last_error\": null,\n  \"chunking_strategy\": {\n    \"type\": \"static\",\n    \"static\": {\n      \"max_chunk_size_tokens\": 800,\n      \"chunk_overlap_tokens\": 400\n    }\n  }\n}\n"
        name: The vector store file object
    VectorStoreObject:
      title: Vector store
      required:
        - id
        - object
        - usage_bytes
        - created_at
        - status
        - last_active_at
        - name
        - file_counts
        - metadata
      type: object
      properties:
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store was created.
        expires_after:
          $ref: '#/components/schemas/VectorStoreExpirationAfter'
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store will expire.
          nullable: true
        file_counts:
          required:
            - in_progress
            - completed
            - failed
            - cancelled
            - total
          type: object
          properties:
            cancelled:
              type: integer
              description: The number of files that were cancelled.
            completed:
              type: integer
              description: The number of files that have been successfully processed.
            failed:
              type: integer
              description: The number of files that have failed to process.
            in_progress:
              type: integer
              description: The number of files that are currently being processed.
            total:
              type: integer
              description: The total number of files.
        id:
          type: string
          description: 'The identifier, which can be referenced in API endpoints.'
        last_active_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store was last active.
          nullable: true
        metadata:
          $ref: '#/components/schemas/Metadata'
        name:
          type: string
          description: The name of the vector store.
        object:
          enum:
            - vector_store
          type: string
          description: 'The object type, which is always `vector_store`.'
          x-stainless-const: true
        status:
          enum:
            - expired
            - in_progress
            - completed
          type: string
          description: 'The status of the vector store, which can be either `expired`, `in_progress`, or `completed`. A status of `completed` indicates that the vector store is ready for use.'
        usage_bytes:
          type: integer
          description: The total number of bytes used by the files in the vector store.
      description: A vector store is a collection of processed files can be used by the `file_search` tool.
      x-oaiMeta:
        example: "{\n  \"id\": \"vs_123\",\n  \"object\": \"vector_store\",\n  \"created_at\": 1698107661,\n  \"usage_bytes\": 123456,\n  \"last_active_at\": 1698107661,\n  \"name\": \"my_vector_store\",\n  \"status\": \"completed\",\n  \"file_counts\": {\n    \"in_progress\": 0,\n    \"completed\": 100,\n    \"cancelled\": 0,\n    \"failed\": 0,\n    \"total\": 100\n  },\n  \"last_used_at\": 1698107661\n}\n"
        name: The vector store object
    VectorStoreSearchRequest:
      required:
        - query
      type: object
      properties:
        filters:
          anyOf:
            - $ref: '#/components/schemas/ComparisonFilter'
            - $ref: '#/components/schemas/CompoundFilter'
          description: A filter to apply based on file attributes.
        max_num_results:
          maximum: 50
          minimum: 1
          type: integer
          description: The maximum number of results to return. This number should be between 1 and 50 inclusive.
          default: 10
        query:
          anyOf:
            - type: string
            - type: array
              items:
                minItems: 1
                type: string
                description: A list of queries to search for.
          description: A query string for a search
        ranking_options:
          type: object
          properties:
            ranker:
              enum:
                - none
                - auto
                - default-2024-11-15
              type: string
              description: 'Enable re-ranking; set to `none` to disable, which can help reduce latency.'
              default: auto
            score_threshold:
              maximum: 1
              minimum: 0
              type: number
              default: 0
          additionalProperties: false
          description: Ranking options for search.
        rewrite_query:
          type: boolean
          description: Whether to rewrite the natural language query for vector search.
          default: false
      additionalProperties: false
      x-oaiMeta:
        name: Vector store search request
    VectorStoreSearchResultContentObject:
      required:
        - type
        - text
      type: object
      properties:
        text:
          type: string
          description: The text content returned from search.
        type:
          enum:
            - text
          type: string
          description: The type of content.
      additionalProperties: false
      x-oaiMeta:
        name: Vector store search result content object
    VectorStoreSearchResultItem:
      required:
        - file_id
        - filename
        - score
        - attributes
        - content
      type: object
      properties:
        attributes:
          $ref: '#/components/schemas/VectorStoreFileAttributes'
        content:
          type: array
          items:
            $ref: '#/components/schemas/VectorStoreSearchResultContentObject'
          description: Content chunks from the file.
        file_id:
          type: string
          description: The ID of the vector store file.
        filename:
          type: string
          description: The name of the vector store file.
        score:
          maximum: 1
          minimum: 0
          type: number
          description: The similarity score for the result.
      additionalProperties: false
      x-oaiMeta:
        name: Vector store search result item
    VectorStoreSearchResultsPage:
      required:
        - object
        - search_query
        - data
        - has_more
        - next_page
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/VectorStoreSearchResultItem'
          description: The list of search result items.
        has_more:
          type: boolean
          description: Indicates if there are more results to fetch.
        next_page:
          type: string
          description: 'The token for the next page, if any.'
          nullable: true
        object:
          enum:
            - vector_store.search_results.page
          type: string
          description: 'The object type, which is always `vector_store.search_results.page`'
          x-stainless-const: true
        search_query:
          type: array
          items:
            minItems: 1
            type: string
            description: The query used for this search.
      additionalProperties: false
      x-oaiMeta:
        name: Vector store search results page
    Verbosity:
      enum:
        - low
        - medium
        - high
      type: string
      description: "Constrains the verbosity of the model's response. Lower values will result in\nmore concise responses, while higher values will result in more verbose responses.\nCurrently supported values are `low`, `medium`, and `high`.\n"
      default: medium
      nullable: true
    VoiceIdsShared:
      anyOf:
        - type: string
        - enum:
            - alloy
            - ash
            - ballad
            - coral
            - echo
            - sage
            - shimmer
            - verse
            - marin
            - cedar
          type: string
      example: ash
    Wait:
      title: Wait
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - wait
          type: string
          description: "Specifies the event type. For a wait action, this property is \nalways set to `wait`.\n"
          default: wait
          x-stainless-const: true
      description: "A wait action.\n"
    WebSearchActionFind:
      title: Find action
      required:
        - type
        - url
        - pattern
      type: object
      properties:
        pattern:
          type: string
          description: "The pattern or text to search for within the page.\n"
        type:
          enum:
            - find
          type: string
          description: "The action type.\n"
          x-stainless-const: true
        url:
          type: string
          description: "The URL of the page searched for the pattern.\n"
          format: uri
      description: "Action type \"find\": Searches for a pattern within a loaded page.\n"
    WebSearchActionOpenPage:
      title: Open page action
      required:
        - type
        - url
      type: object
      properties:
        type:
          enum:
            - open_page
          type: string
          description: "The action type.\n"
          x-stainless-const: true
        url:
          type: string
          description: "The URL opened by the model.\n"
          format: uri
      description: "Action type \"open_page\" - Opens a specific URL from search results.\n"
    WebSearchActionSearch:
      title: Search action
      required:
        - type
        - query
      type: object
      properties:
        query:
          type: string
          description: "The search query.\n"
        sources:
          title: Web search sources
          type: array
          items:
            title: Web search source
            required:
              - type
              - url
            type: object
            properties:
              type:
                enum:
                  - url
                type: string
                description: "The type of source. Always `url`.\n"
                x-stainless-const: true
              url:
                type: string
                description: "The URL of the source.\n"
            description: "A source used in the search.\n"
          description: "The sources used in the search.\n"
        type:
          enum:
            - search
          type: string
          description: "The action type.\n"
          x-stainless-const: true
      description: "Action type \"search\" - Performs a web search query.\n"
    WebSearchApproximateLocation:
      title: Web search approximate location
      type: object
      properties:
        city:
          type: string
          description: 'Free text input for the city of the user, e.g. `San Francisco`.'
          nullable: true
        country:
          type: string
          description: 'The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.'
          nullable: true
        region:
          type: string
          description: 'Free text input for the region of the user, e.g. `California`.'
          nullable: true
        timezone:
          type: string
          description: 'The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.'
          nullable: true
        type:
          enum:
            - approximate
          type: string
          description: The type of location approximation. Always `approximate`.
          default: approximate
          x-stainless-const: true
      description: "The approximate location of the user.\n"
      nullable: true
    WebSearchContextSize:
      enum:
        - low
        - medium
        - high
      type: string
      description: "High level guidance for the amount of context window space to use for the \nsearch. One of `low`, `medium`, or `high`. `medium` is the default.\n"
      default: medium
    WebSearchLocation:
      title: Web search location
      type: object
      properties:
        city:
          type: string
          description: "Free text input for the city of the user, e.g. `San Francisco`.\n"
        country:
          type: string
          description: "The two-letter \n[ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user,\ne.g. `US`.\n"
        region:
          type: string
          description: "Free text input for the region of the user, e.g. `California`.\n"
        timezone:
          type: string
          description: "The [IANA timezone](https://timeapi.io/documentation/iana-timezones) \nof the user, e.g. `America/Los_Angeles`.\n"
      description: Approximate location parameters for the search.
    WebSearchPreviewTool:
      title: Web search preview
      required:
        - type
      type: object
      properties:
        search_context_size:
          enum:
            - low
            - medium
            - high
          type: string
          description: 'High level guidance for the amount of context window space to use for the search. One of `low`, `medium`, or `high`. `medium` is the default.'
        type:
          enum:
            - web_search_preview
            - web_search_preview_2025_03_11
          type: string
          description: The type of the web search tool. One of `web_search_preview` or `web_search_preview_2025_03_11`.
          default: web_search_preview
          x-stainless-const: true
        user_location:
          type: 'null'
          nullable: true
      description: 'This tool searches the web for relevant results to use in a response. Learn more about the [web search tool](https://platform.openai.com/docs/guides/tools-web-search).'
    WebSearchTool:
      title: Web search
      required:
        - type
      type: object
      properties:
        filters:
          type: object
          properties:
            allowed_domains:
              title: Allowed domains for the search.
              type: array
              items:
                type: string
                description: Allowed domain for the search.
              description: "Allowed domains for the search. If not provided, all domains are allowed.\nSubdomains of the provided domains are allowed as well.\n\nExample: `[\"pubmed.ncbi.nlm.nih.gov\"]`\n"
              nullable: true
          description: "Filters for the search.\n"
          nullable: true
        search_context_size:
          enum:
            - low
            - medium
            - high
          type: string
          description: 'High level guidance for the amount of context window space to use for the search. One of `low`, `medium`, or `high`. `medium` is the default.'
          default: medium
        type:
          enum:
            - web_search
            - web_search_2025_08_26
          type: string
          description: The type of the web search tool. One of `web_search` or `web_search_2025_08_26`.
          default: web_search
        user_location:
          $ref: '#/components/schemas/WebSearchApproximateLocation'
      description: "Search the Internet for sources related to the prompt. Learn more about the \n[web search tool](https://platform.openai.com/docs/guides/tools-web-search).\n"
    WebSearchToolCall:
      title: Web search tool call
      required:
        - id
        - type
        - status
        - action
      type: object
      properties:
        action:
          type: object
          anyOf:
            - $ref: '#/components/schemas/WebSearchActionSearch'
            - $ref: '#/components/schemas/WebSearchActionOpenPage'
            - $ref: '#/components/schemas/WebSearchActionFind'
          description: "An object describing the specific action taken in this web search call.\nIncludes details on how the model used the web (search, open_page, find).\n"
          discriminator:
            propertyName: type
        id:
          type: string
          description: "The unique ID of the web search tool call.\n"
        status:
          enum:
            - in_progress
            - searching
            - completed
            - failed
          type: string
          description: "The status of the web search tool call.\n"
        type:
          enum:
            - web_search_call
          type: string
          description: "The type of the web search tool call. Always `web_search_call`.\n"
          x-stainless-const: true
      description: "The results of a web search tool call. See the \n[web search guide](https://platform.openai.com/docs/guides/tools-web-search) for more information.\n"
    WebhookBatchCancelled:
      title: batch.cancelled
      required:
        - created_at
        - id
        - data
        - type
      type: object
      properties:
        created_at:
          type: integer
          description: "The Unix timestamp (in seconds) of when the batch API request was cancelled.\n"
        data:
          required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "The unique ID of the batch API request.\n"
          description: "Event data payload.\n"
        id:
          type: string
          description: "The unique ID of the event.\n"
        object:
          enum:
            - event
          type: string
          description: "The object of the event. Always `event`.\n"
          x-stainless-const: true
        type:
          enum:
            - batch.cancelled
          type: string
          description: "The type of the event. Always `batch.cancelled`.\n"
          x-stainless-const: true
      description: "Sent when a batch API request has been cancelled.\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"batch.cancelled\",\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"batch_abc123\"\n  }\n}\n"
        group: webhook-events
        name: batch.cancelled
    WebhookBatchCompleted:
      title: batch.completed
      required:
        - created_at
        - id
        - data
        - type
      type: object
      properties:
        created_at:
          type: integer
          description: "The Unix timestamp (in seconds) of when the batch API request was completed.\n"
        data:
          required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "The unique ID of the batch API request.\n"
          description: "Event data payload.\n"
        id:
          type: string
          description: "The unique ID of the event.\n"
        object:
          enum:
            - event
          type: string
          description: "The object of the event. Always `event`.\n"
          x-stainless-const: true
        type:
          enum:
            - batch.completed
          type: string
          description: "The type of the event. Always `batch.completed`.\n"
          x-stainless-const: true
      description: "Sent when a batch API request has been completed.\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"batch.completed\",\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"batch_abc123\"\n  }\n}\n"
        group: webhook-events
        name: batch.completed
    WebhookBatchExpired:
      title: batch.expired
      required:
        - created_at
        - id
        - data
        - type
      type: object
      properties:
        created_at:
          type: integer
          description: "The Unix timestamp (in seconds) of when the batch API request expired.\n"
        data:
          required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "The unique ID of the batch API request.\n"
          description: "Event data payload.\n"
        id:
          type: string
          description: "The unique ID of the event.\n"
        object:
          enum:
            - event
          type: string
          description: "The object of the event. Always `event`.\n"
          x-stainless-const: true
        type:
          enum:
            - batch.expired
          type: string
          description: "The type of the event. Always `batch.expired`.\n"
          x-stainless-const: true
      description: "Sent when a batch API request has expired.\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"batch.expired\",\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"batch_abc123\"\n  }\n}\n"
        group: webhook-events
        name: batch.expired
    WebhookBatchFailed:
      title: batch.failed
      required:
        - created_at
        - id
        - data
        - type
      type: object
      properties:
        created_at:
          type: integer
          description: "The Unix timestamp (in seconds) of when the batch API request failed.\n"
        data:
          required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "The unique ID of the batch API request.\n"
          description: "Event data payload.\n"
        id:
          type: string
          description: "The unique ID of the event.\n"
        object:
          enum:
            - event
          type: string
          description: "The object of the event. Always `event`.\n"
          x-stainless-const: true
        type:
          enum:
            - batch.failed
          type: string
          description: "The type of the event. Always `batch.failed`.\n"
          x-stainless-const: true
      description: "Sent when a batch API request has failed.\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"batch.failed\",\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"batch_abc123\"\n  }\n}\n"
        group: webhook-events
        name: batch.failed
    WebhookEvalRunCanceled:
      title: eval.run.canceled
      required:
        - created_at
        - id
        - data
        - type
      type: object
      properties:
        created_at:
          type: integer
          description: "The Unix timestamp (in seconds) of when the eval run was canceled.\n"
        data:
          required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "The unique ID of the eval run.\n"
          description: "Event data payload.\n"
        id:
          type: string
          description: "The unique ID of the event.\n"
        object:
          enum:
            - event
          type: string
          description: "The object of the event. Always `event`.\n"
          x-stainless-const: true
        type:
          enum:
            - eval.run.canceled
          type: string
          description: "The type of the event. Always `eval.run.canceled`.\n"
          x-stainless-const: true
      description: "Sent when an eval run has been canceled.\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"eval.run.canceled\",\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"evalrun_abc123\"\n  }\n} \n"
        group: webhook-events
        name: eval.run.canceled
    WebhookEvalRunFailed:
      title: eval.run.failed
      required:
        - created_at
        - id
        - data
        - type
      type: object
      properties:
        created_at:
          type: integer
          description: "The Unix timestamp (in seconds) of when the eval run failed.\n"
        data:
          required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "The unique ID of the eval run.\n"
          description: "Event data payload.\n"
        id:
          type: string
          description: "The unique ID of the event.\n"
        object:
          enum:
            - event
          type: string
          description: "The object of the event. Always `event`.\n"
          x-stainless-const: true
        type:
          enum:
            - eval.run.failed
          type: string
          description: "The type of the event. Always `eval.run.failed`.\n"
          x-stainless-const: true
      description: "Sent when an eval run has failed.\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"eval.run.failed\",\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"evalrun_abc123\"\n  }\n} \n"
        group: webhook-events
        name: eval.run.failed
    WebhookEvalRunSucceeded:
      title: eval.run.succeeded
      required:
        - created_at
        - id
        - data
        - type
      type: object
      properties:
        created_at:
          type: integer
          description: "The Unix timestamp (in seconds) of when the eval run succeeded.\n"
        data:
          required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "The unique ID of the eval run.\n"
          description: "Event data payload.\n"
        id:
          type: string
          description: "The unique ID of the event.\n"
        object:
          enum:
            - event
          type: string
          description: "The object of the event. Always `event`.\n"
          x-stainless-const: true
        type:
          enum:
            - eval.run.succeeded
          type: string
          description: "The type of the event. Always `eval.run.succeeded`.\n"
          x-stainless-const: true
      description: "Sent when an eval run has succeeded.\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"eval.run.succeeded\",\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"evalrun_abc123\"\n  }\n} \n"
        group: webhook-events
        name: eval.run.succeeded
    WebhookFineTuningJobCancelled:
      title: fine_tuning.job.cancelled
      required:
        - created_at
        - id
        - data
        - type
      type: object
      properties:
        created_at:
          type: integer
          description: "The Unix timestamp (in seconds) of when the fine-tuning job was cancelled.\n"
        data:
          required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "The unique ID of the fine-tuning job.\n"
          description: "Event data payload.\n"
        id:
          type: string
          description: "The unique ID of the event.\n"
        object:
          enum:
            - event
          type: string
          description: "The object of the event. Always `event`.\n"
          x-stainless-const: true
        type:
          enum:
            - fine_tuning.job.cancelled
          type: string
          description: "The type of the event. Always `fine_tuning.job.cancelled`.\n"
          x-stainless-const: true
      description: "Sent when a fine-tuning job has been cancelled.\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"fine_tuning.job.cancelled\",\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"ftjob_abc123\"\n  }\n} \n"
        group: webhook-events
        name: fine_tuning.job.cancelled
    WebhookFineTuningJobFailed:
      title: fine_tuning.job.failed
      required:
        - created_at
        - id
        - data
        - type
      type: object
      properties:
        created_at:
          type: integer
          description: "The Unix timestamp (in seconds) of when the fine-tuning job failed.\n"
        data:
          required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "The unique ID of the fine-tuning job.\n"
          description: "Event data payload.\n"
        id:
          type: string
          description: "The unique ID of the event.\n"
        object:
          enum:
            - event
          type: string
          description: "The object of the event. Always `event`.\n"
          x-stainless-const: true
        type:
          enum:
            - fine_tuning.job.failed
          type: string
          description: "The type of the event. Always `fine_tuning.job.failed`.\n"
          x-stainless-const: true
      description: "Sent when a fine-tuning job has failed.\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"fine_tuning.job.failed\",\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"ftjob_abc123\"\n  }\n} \n"
        group: webhook-events
        name: fine_tuning.job.failed
    WebhookFineTuningJobSucceeded:
      title: fine_tuning.job.succeeded
      required:
        - created_at
        - id
        - data
        - type
      type: object
      properties:
        created_at:
          type: integer
          description: "The Unix timestamp (in seconds) of when the fine-tuning job succeeded.\n"
        data:
          required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "The unique ID of the fine-tuning job.\n"
          description: "Event data payload.\n"
        id:
          type: string
          description: "The unique ID of the event.\n"
        object:
          enum:
            - event
          type: string
          description: "The object of the event. Always `event`.\n"
          x-stainless-const: true
        type:
          enum:
            - fine_tuning.job.succeeded
          type: string
          description: "The type of the event. Always `fine_tuning.job.succeeded`.\n"
          x-stainless-const: true
      description: "Sent when a fine-tuning job has succeeded.\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"fine_tuning.job.succeeded\",\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"ftjob_abc123\"\n  }\n} \n"
        group: webhook-events
        name: fine_tuning.job.succeeded
    WebhookRealtimeCallIncoming:
      title: realtime.call.incoming
      required:
        - created_at
        - id
        - data
        - type
      type: object
      properties:
        created_at:
          type: integer
          description: "The Unix timestamp (in seconds) of when the model response was completed.\n"
        data:
          required:
            - call_id
            - sip_headers
          type: object
          properties:
            call_id:
              type: string
              description: "The unique ID of this call.\n"
            sip_headers:
              type: array
              items:
                required:
                  - name
                  - value
                type: object
                properties:
                  name:
                    type: string
                    description: "Name of the SIP Header.\n"
                  value:
                    type: string
                    description: "Value of the SIP Header.\n"
                description: "A header from the SIP Invite.\n"
              description: "Headers from the SIP Invite.\n"
          description: "Event data payload.\n"
        id:
          type: string
          description: "The unique ID of the event.\n"
        object:
          enum:
            - event
          type: string
          description: "The object of the event. Always `event`.\n"
          x-stainless-const: true
        type:
          enum:
            - realtime.call.incoming
          type: string
          description: "The type of the event. Always `realtime.call.incoming`.\n"
          x-stainless-const: true
      description: "Sent when Realtime API Receives a incoming SIP call.\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"realtime.call.incoming\",\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"call_id\": \"rtc_479a275623b54bdb9b6fbae2f7cbd408\",\n    \"sip_headers\": [\n      {\"name\": \"Max-Forwards\", \"value\": \"63\"},\n      {\"name\": \"CSeq\", \"value\": \"851287 INVITE\"},\n      {\"name\": \"Content-Type\", \"value\": \"application/sdp\"},\n    ]\n  }\n}\n"
        group: webhook-events
        name: realtime.call.incoming
    WebhookResponseCancelled:
      title: response.cancelled
      required:
        - created_at
        - id
        - data
        - type
      type: object
      properties:
        created_at:
          type: integer
          description: "The Unix timestamp (in seconds) of when the model response was cancelled.\n"
        data:
          required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "The unique ID of the model response.\n"
          description: "Event data payload.\n"
        id:
          type: string
          description: "The unique ID of the event.\n"
        object:
          enum:
            - event
          type: string
          description: "The object of the event. Always `event`.\n"
          x-stainless-const: true
        type:
          enum:
            - response.cancelled
          type: string
          description: "The type of the event. Always `response.cancelled`.\n"
          x-stainless-const: true
      description: "Sent when a background response has been cancelled.\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"response.cancelled\",\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"resp_abc123\"\n  }\n}\n"
        group: webhook-events
        name: response.cancelled
    WebhookResponseCompleted:
      title: response.completed
      required:
        - created_at
        - id
        - data
        - type
      type: object
      properties:
        created_at:
          type: integer
          description: "The Unix timestamp (in seconds) of when the model response was completed.\n"
        data:
          required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "The unique ID of the model response.\n"
          description: "Event data payload.\n"
        id:
          type: string
          description: "The unique ID of the event.\n"
        object:
          enum:
            - event
          type: string
          description: "The object of the event. Always `event`.\n"
          x-stainless-const: true
        type:
          enum:
            - response.completed
          type: string
          description: "The type of the event. Always `response.completed`.\n"
          x-stainless-const: true
      description: "Sent when a background response has been completed.\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"response.completed\",\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"resp_abc123\"\n  }\n}\n"
        group: webhook-events
        name: response.completed
    WebhookResponseFailed:
      title: response.failed
      required:
        - created_at
        - id
        - data
        - type
      type: object
      properties:
        created_at:
          type: integer
          description: "The Unix timestamp (in seconds) of when the model response failed.\n"
        data:
          required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "The unique ID of the model response.\n"
          description: "Event data payload.\n"
        id:
          type: string
          description: "The unique ID of the event.\n"
        object:
          enum:
            - event
          type: string
          description: "The object of the event. Always `event`.\n"
          x-stainless-const: true
        type:
          enum:
            - response.failed
          type: string
          description: "The type of the event. Always `response.failed`.\n"
          x-stainless-const: true
      description: "Sent when a background response has failed.\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"response.failed\",\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"resp_abc123\"\n  }\n}\n"
        group: webhook-events
        name: response.failed
    WebhookResponseIncomplete:
      title: response.incomplete
      required:
        - created_at
        - id
        - data
        - type
      type: object
      properties:
        created_at:
          type: integer
          description: "The Unix timestamp (in seconds) of when the model response was interrupted.\n"
        data:
          required:
            - id
          type: object
          properties:
            id:
              type: string
              description: "The unique ID of the model response.\n"
          description: "Event data payload.\n"
        id:
          type: string
          description: "The unique ID of the event.\n"
        object:
          enum:
            - event
          type: string
          description: "The object of the event. Always `event`.\n"
          x-stainless-const: true
        type:
          enum:
            - response.incomplete
          type: string
          description: "The type of the event. Always `response.incomplete`.\n"
          x-stainless-const: true
      description: "Sent when a background response has been interrupted.\n"
      x-oaiMeta:
        example: "{\n  \"id\": \"evt_abc123\",\n  \"type\": \"response.incomplete\",\n  \"created_at\": 1719168000,\n  \"data\": {\n    \"id\": \"resp_abc123\"\n  }\n}\n"
        group: webhook-events
        name: response.incomplete
    RealtimeServerEventType:
      enum:
        - error
        - session.created
        - session.updated
        - conversation.created
        - input_audio_buffer.committed
        - input_audio_buffer.cleared
        - input_audio_buffer.speech_started
        - input_audio_buffer.speech_stopped
        - conversation.item.created
        - conversation.item.input_audio_transcription.completed
        - conversation.item.input_audio_transcription.failed
        - conversation.item.truncated
        - conversation.item.deleted
        - response.created
        - response.done
        - response.output_item.added
        - response.output_item.done
        - response.content_part.added
        - response.content_part.done
        - response.text.delta
        - response.text.done
        - response.audio_transcript.delta
        - response.audio_transcript.done
        - response.audio.delta
        - response.audio.done
        - response.function_call_arguments.delta
        - response.function_call_arguments.done
        - rate_limits.updated
      type: string
    RealtimeServerEventBase:
      required:
        - type
        - event_id
      type: object
      properties:
        event_id:
          type: string
        type:
          $ref: '#/components/schemas/RealtimeServerEventType'
    RealtimeAudioFormat:
      enum:
        - pcm16
        - g711_ulaw
        - g711_alaw
      type: string
      description: The format of input/output audio.
    RealtimeConversation:
      type: object
      properties:
        id:
          type: string
          description: The unique ID of the conversation.
          example: conv_001
        object:
          enum:
            - realtime.conversation
          type: string
          description: 'The object type, must be "realtime.conversation".'
          example: realtime.conversation
      description: "A realtime Conversation consists of a list of Items.\nBy default, there is only one Conversation, and it gets created at the beginning of the Session.\nIn the future, we may add support for additional conversations.\n"
      example:
        id: conv_001
        object: realtime.conversation
    RealtimeContentPart:
      type: object
      properties:
        type:
          enum:
            - text
            - audio
          type: string
          description: The content type.
          example: text
        text:
          type: string
          description: The text content (if type is "text").
          example: 'Sure, I can help with that.'
        audio:
          type: string
          description: Base64-encoded audio data (if type is "audio").
        transcript:
          type: string
          description: The transcript of the audio (if type is "audio").
      description: The content part that was added.
    RealtimeErrorDetails:
      type: object
      properties:
        type:
          type: string
          description: 'The type of error (e.g., "invalid_request_error", "server_error").'
          example: invalid_request_error
        code:
          type: string
          description: 'Error code, if any.'
          example: invalid_event
        message:
          type: string
          description: A human-readable error message.
          example: The 'type' field is missing.
        param:
          type: string
          description: 'Parameter related to the error, if any.'
          example: 
        event_id:
          type: string
          description: 'The event_id of the client event that caused the error, if applicable.'
          example: event_567
      description: Details of the error.
      example:
        type: invalid_request_error
        code: invalid_event
        message: The 'type' field is missing.
        param: 
        event_id: event_567
    RealtimeSessionUpdate:
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
          example: event_123
        type:
          enum:
            - session.update
          type: string
          description: 'The event type, must be "session.update".'
          example: session.update
        session:
          $ref: '#/components/schemas/RealtimeSession'
      description: Send this event to update the session’s default configuration.
      example:
        event_id: event_123
        type: session.update
        session:
          modalities:
            - text
            - audio
          instructions: Your knowledge cutoff is 2023-10. You are a helpful assistant.
          voice: alloy
          input_audio_format: pcm16
          output_audio_format: pcm16
          input_audio_transcription:
            enabled: true
            model: whisper-1
          turn_detection:
            type: server_vad
            threshold: 0.5
            prefix_padding_ms: 300
            silence_duration_ms: 200
          tools:
            - type: function
              name: get_weather
              description: Get the current weather for a location.
              parameters:
                type: object
                properties:
                  location:
                    type: string
                required:
                  - location
          tool_choice: auto
          temperature: 0.8
          max_output_tokens: 
    RealtimeInputAudioBufferAppend:
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
          example: event_456
        type:
          enum:
            - input_audio_buffer.append
          type: string
          description: 'The event type, must be "input_audio_buffer.append".'
          example: input_audio_buffer.append
        audio:
          type: string
          description: Base64-encoded audio bytes.
          example: Base64EncodedAudioData
      description: Send this event to append audio bytes to the input audio buffer.
      example:
        event_id: event_456
        type: input_audio_buffer.append
        audio: Base64EncodedAudioData
    RealtimeInputAudioBufferCommit:
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
          example: event_789
        type:
          enum:
            - input_audio_buffer.commit
          type: string
          description: 'The event type, must be "input_audio_buffer.commit".'
          example: input_audio_buffer.commit
      description: Send this event to commit audio bytes to a user message.
      example:
        event_id: event_789
        type: input_audio_buffer.commit
    RealtimeInputAudioBufferClear:
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
          example: event_012
        type:
          enum:
            - input_audio_buffer.clear
          type: string
          description: 'The event type, must be "input_audio_buffer.clear".'
          example: input_audio_buffer.clear
      description: Send this event to clear the audio bytes in the buffer.
      example:
        event_id: event_012
        type: input_audio_buffer.clear
    RealtimeConversationItemCreate:
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
          example: event_345
        type:
          enum:
            - conversation.item.create
          type: string
          description: 'The event type, must be "conversation.item.create".'
          example: conversation.item.create
        previous_item_id:
          type: string
          description: The ID of the preceding item after which the new item will be inserted.
          example: 
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
      description: Send this event when adding an item to the conversation.
      example:
        event_id: event_345
        type: conversation.item.create
        previous_item_id: 
        item:
          id: msg_001
          type: message
          status: completed
          role: user
          content:
            - type: input_text
              text: 'Hello, how are you?'
    RealtimeConversationItemTruncate:
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
          example: event_678
        type:
          enum:
            - conversation.item.truncate
          type: string
          description: 'The event type, must be "conversation.item.truncate".'
          example: conversation.item.truncate
        item_id:
          type: string
          description: The ID of the assistant message item to truncate.
          example: msg_002
        content_index:
          type: integer
          description: The index of the content part to truncate.
          example: 0
        audio_end_ms:
          type: integer
          description: 'Inclusive duration up to which audio is truncated, in milliseconds.'
          example: 1500
      description: Send this event when you want to truncate a previous assistant message’s audio.
      example:
        event_id: event_678
        type: conversation.item.truncate
        item_id: msg_002
        content_index: 0
        audio_end_ms: 1500
    RealtimeConversationItemDelete:
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
          example: event_901
        type:
          enum:
            - conversation.item.delete
          type: string
          description: 'The event type, must be "conversation.item.delete".'
          example: conversation.item.delete
        item_id:
          type: string
          description: The ID of the item to delete.
          example: msg_003
      description: Send this event when you want to remove any item from the conversation history.
      example:
        event_id: event_901
        type: conversation.item.delete
        item_id: msg_003
    RealtimeResponseCreate:
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
        type:
          enum:
            - response.create
          type: string
          description: 'The event type, must be ''response.create''.'
        response:
          type: object
          properties:
            modalities:
              type: array
              items:
                enum:
                  - text
                  - audio
                type: string
              description: The modalities for the response.
            instructions:
              type: string
              description: Instructions for the model.
            voice:
              enum:
                - alloy
                - echo
                - shimmer
              type: string
              description: The voice the model uses to respond.
            output_audio_format:
              $ref: '#/components/schemas/RealtimeAudioFormat'
            tools:
              type: array
              items:
                type: object
                properties:
                  type:
                    type: string
                    description: The type of the tool.
                  name:
                    type: string
                    description: The name of the function.
                  description:
                    type: string
                    description: The description of the function.
                  parameters:
                    type: object
                    description: Parameters of the function in JSON Schema.
              description: Tools (functions) available to the model.
            tool_choice:
              oneOf:
                - enum:
                    - auto
                    - none
                    - required
                  type: string
                - type: string
              description: "How the model chooses tools. \nOptions are \"auto\", \"none\", \"required\", or specify a function.\n"
            temperature:
              type: number
              description: Sampling temperature.
            max_output_tokens:
              oneOf:
                - type: integer
                - enum:
                    - inf
                  type: string
              description: 'Maximum number of output tokens for a single assistant response, inclusive of tool calls. Provide an integer between 1 and 4096 to limit output tokens, or "inf" for the maximum available tokens for a given model. Defaults to "inf".'
              default: inf
          description: Configuration for the response.
      description: Send this event to trigger a response generation.
    RealtimeResponseCancel:
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event.
          example: event_567
        type:
          enum:
            - response.cancel
          type: string
          description: 'The event type, must be "response.cancel".'
          example: response.cancel
      description: Send this event to cancel an in-progress response.
      example:
        event_id: event_567
        type: response.cancel
    RealtimeError:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_890
        type:
          enum:
            - error
          type: string
          description: 'The event type, must be "error".'
          example: error
        error:
          $ref: '#/components/schemas/RealtimeErrorDetails'
      description: Returned when an error occurs.
      example:
        event_id: event_890
        type: error
        error:
          type: invalid_request_error
          code: invalid_event
          message: The 'type' field is missing.
          param: 
          event_id: event_567
    RealtimeSessionCreated:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_1234
        type:
          enum:
            - session.created
          type: string
          description: 'The event type, must be "session.created".'
          example: session.created
        session:
          $ref: '#/components/schemas/RealtimeSession'
      description: Returned when a session is created. Emitted automatically when a new connection is established.
    RealtimeSessionUpdated:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_5678
        type:
          enum:
            - session.updated
          type: string
          description: 'The event type, must be "session.updated".'
          example: session.updated
        session:
          $ref: '#/components/schemas/RealtimeSession'
      description: Returned when a session is updated.
    RealtimeConversationCreated:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_9101
        type:
          enum:
            - conversation.created
          type: string
          description: 'The event type, must be "conversation.created".'
          example: conversation.created
        conversation:
          $ref: '#/components/schemas/RealtimeConversation'
      description: Returned when a conversation is created. Emitted right after session creation.
      example:
        event_id: event_9101
        type: conversation.created
        conversation:
          id: conv_001
          object: realtime.conversation
    RealtimeConversationItemCreated:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_1920
        type:
          enum:
            - conversation.item.created
          type: string
          description: 'The event type, must be "conversation.item.created".'
          example: conversation.item.created
        previous_item_id:
          type: string
          description: The ID of the preceding item.
          example: msg_002
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
      description: Returned when a conversation item is created.
      example:
        event_id: event_1920
        type: conversation.item.created
        previous_item_id: msg_002
        item:
          id: msg_003
          object: realtime.item
          type: message
          status: completed
          role: user
          content:
            - type: input_audio
              transcript: 
    RealtimeConversationItemInputAudioTranscriptionCompleted:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_2122
        type:
          enum:
            - conversation.item.input_audio_transcription.completed
          type: string
          description: 'The event type, must be "conversation.item.input_audio_transcription.completed".'
          example: conversation.item.input_audio_transcription.completed
        item_id:
          type: string
          description: The ID of the user message item.
          example: msg_003
        content_index:
          type: integer
          description: The index of the content part containing the audio.
          example: 0
        transcript:
          type: string
          description: The transcribed text.
          example: 'Hello, how are you?'
      description: Returned when input audio transcription is enabled and a transcription succeeds.
      example:
        event_id: event_2122
        type: conversation.item.input_audio_transcription.completed
        item_id: msg_003
        content_index: 0
        transcript: 'Hello, how are you?'
    RealtimeConversationItemInputAudioTranscriptionFailed:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_2324
        type:
          enum:
            - conversation.item.input_audio_transcription.failed
          type: string
          description: 'The event type, must be "conversation.item.input_audio_transcription.failed".'
          example: conversation.item.input_audio_transcription.failed
        item_id:
          type: string
          description: The ID of the user message item.
          example: msg_003
        content_index:
          type: integer
          description: The index of the content part containing the audio.
          example: 0
        error:
          $ref: '#/components/schemas/RealtimeErrorDetails'
      description: 'Returned when input audio transcription is configured, and a transcription request for a user message failed.'
      example:
        event_id: event_2324
        type: conversation.item.input_audio_transcription.failed
        item_id: msg_003
        content_index: 0
        error:
          type: transcription_error
          code: audio_unintelligible
          message: The audio could not be transcribed.
          param: 
    RealtimeConversationItemTruncated:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_2526
        type:
          enum:
            - conversation.item.truncated
          type: string
          description: 'The event type, must be "conversation.item.truncated".'
          example: conversation.item.truncated
        item_id:
          type: string
          description: The ID of the assistant message item that was truncated.
          example: msg_004
        content_index:
          type: integer
          description: The index of the content part that was truncated.
          example: 0
        audio_end_ms:
          type: integer
          description: 'The duration up to which the audio was truncated, in milliseconds.'
          example: 1500
      description: Returned when an earlier assistant audio message item is truncated by the client.
      example:
        event_id: event_2526
        type: conversation.item.truncated
        item_id: msg_004
        content_index: 0
        audio_end_ms: 1500
    RealtimeConversationItemDeleted:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_2728
        type:
          enum:
            - conversation.item.deleted
          type: string
          description: 'The event type, must be "conversation.item.deleted".'
          example: conversation.item.deleted
        item_id:
          type: string
          description: The ID of the item that was deleted.
          example: msg_005
      description: Returned when an item in the conversation is deleted.
      example:
        event_id: event_2728
        type: conversation.item.deleted
        item_id: msg_005
    RealtimeInputAudioBufferCommitted:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_1121
        type:
          enum:
            - input_audio_buffer.committed
          type: string
          description: 'The event type, must be "input_audio_buffer.committed".'
          example: input_audio_buffer.committed
        previous_item_id:
          type: string
          description: The ID of the preceding item after which the new item will be inserted.
          example: msg_001
        item_id:
          type: string
          description: The ID of the user message item that will be created.
          example: msg_002
      description: 'Returned when an input audio buffer is committed, either by the client or automatically in server VAD mode.'
      example:
        event_id: event_1121
        type: input_audio_buffer.committed
        previous_item_id: msg_001
        item_id: msg_002
    RealtimeInputAudioBufferCleared:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_1314
        type:
          enum:
            - input_audio_buffer.cleared
          type: string
          description: 'The event type, must be "input_audio_buffer.cleared".'
          example: input_audio_buffer.cleared
      description: Returned when the input audio buffer is cleared by the client.
      example:
        event_id: event_1314
        type: input_audio_buffer.cleared
    RealtimeInputAudioBufferSpeechStarted:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_1516
        type:
          enum:
            - input_audio_buffer.speech_started
          type: string
          description: 'The event type, must be "input_audio_buffer.speech_started".'
          example: input_audio_buffer.speech_started
        audio_start_ms:
          type: integer
          description: Milliseconds since the session started when speech was detected.
          example: 1000
        item_id:
          type: string
          description: The ID of the user message item that will be created when speech stops.
          example: msg_003
      description: Returned in server turn detection mode when speech is detected.
      example:
        event_id: event_1516
        type: input_audio_buffer.speech_started
        audio_start_ms: 1000
        item_id: msg_003
    RealtimeInputAudioBufferSpeechStopped:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_1718
        type:
          enum:
            - input_audio_buffer.speech_stopped
          type: string
          description: 'The event type, must be "input_audio_buffer.speech_stopped".'
          example: input_audio_buffer.speech_stopped
        audio_end_ms:
          type: integer
          description: Milliseconds since the session started when speech stopped.
          example: 2000
        item_id:
          type: string
          description: The ID of the user message item that will be created.
          example: msg_003
      description: Returned in server turn detection mode when speech stops.
      example:
        event_id: event_1718
        type: input_audio_buffer.speech_stopped
        audio_end_ms: 2000
        item_id: msg_003
    RealtimeResponseCreated:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_2930
        type:
          enum:
            - response.created
          type: string
          description: 'The event type, must be "response.created".'
          example: response.created
        response:
          $ref: '#/components/schemas/RealtimeResponse'
      description: 'Returned when a new Response is created. The first event of response creation, where the response is in an initial state of "in_progress".'
      example:
        event_id: event_2930
        type: response.created
        response:
          id: resp_001
          object: realtime.response
          status: in_progress
          status_details: 
          output: [ ]
          usage: 
    RealtimeResponseDone:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_3132
        type:
          enum:
            - response.done
          type: string
          description: 'The event type, must be "response.done".'
          example: response.done
        response:
          $ref: '#/components/schemas/RealtimeResponse'
      description: 'Returned when a Response is done streaming. Always emitted, no matter the final state.'
      example:
        event_id: event_3132
        type: response.done
        response:
          id: resp_001
          object: realtime.response
          status: completed
          status_details: 
          output:
            - id: msg_006
              object: realtime.item
              type: message
              status: completed
              role: assistant
              content:
                - type: text
                  text: 'Sure, how can I assist you today?'
          usage:
            total_tokens: 50
            input_tokens: 20
            output_tokens: 30
    RealtimeResponseOutputItemAdded:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_3334
        type:
          enum:
            - response.output_item.added
          type: string
          description: 'The event type, must be "response.output_item.added".'
          example: response.output_item.added
        response_id:
          type: string
          description: The ID of the response to which the item belongs.
          example: resp_001
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
      description: Returned when a new Item is created during response generation.
      example:
        event_id: event_3334
        type: response.output_item.added
        response_id: resp_001
        output_index: 0
        item:
          id: msg_007
          object: realtime.item
          type: message
          status: in_progress
          role: assistant
          content: [ ]
    RealtimeResponseOutputItemDone:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_3536
        type:
          enum:
            - response.output_item.done
          type: string
          description: 'The event type, must be "response.output_item.done".'
          example: response.output_item.done
        response_id:
          type: string
          description: The ID of the response to which the item belongs.
          example: resp_001
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
      description: 'Returned when an Item is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.'
      example:
        event_id: event_3536
        type: response.output_item.done
        response_id: resp_001
        output_index: 0
        item:
          id: msg_007
          object: realtime.item
          type: message
          status: completed
          role: assistant
          content:
            - type: text
              text: 'Sure, I can help with that.'
    RealtimeResponseContentPartAdded:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_3738
        type:
          enum:
            - response.content_part.added
          type: string
          description: 'The event type, must be "response.content_part.added".'
          example: response.content_part.added
        response_id:
          type: string
          description: The ID of the response.
          example: resp_001
        item_id:
          type: string
          description: The ID of the item to which the content part was added.
          example: msg_007
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
          example: 0
        part:
          $ref: '#/components/schemas/RealtimeContentPart'
      description: Returned when a new content part is added to an assistant message item during response generation.
      example:
        event_id: event_3738
        type: response.content_part.added
        response_id: resp_001
        item_id: msg_007
        output_index: 0
        content_index: 0
        part:
          type: text
          text: ''
    RealtimeResponseContentPartDone:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_3940
        type:
          enum:
            - response.content_part.done
          type: string
          description: 'The event type, must be "response.content_part.done".'
          example: response.content_part.done
        response_id:
          type: string
          description: The ID of the response.
          example: resp_001
        item_id:
          type: string
          description: The ID of the item.
          example: msg_007
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
          example: 0
        part:
          $ref: '#/components/schemas/RealtimeContentPart'
      description: 'Returned when a content part is done streaming in an assistant message item. Also emitted when a Response is interrupted, incomplete, or cancelled.'
      example:
        event_id: event_3940
        type: response.content_part.done
        response_id: resp_001
        item_id: msg_007
        output_index: 0
        content_index: 0
        part:
          type: text
          text: 'Sure, I can help with that.'
    RealtimeResponseTextDelta:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_4142
        type:
          enum:
            - response.text.delta
          type: string
          description: 'The event type, must be "response.text.delta".'
          example: response.text.delta
        response_id:
          type: string
          description: The ID of the response.
          example: resp_001
        item_id:
          type: string
          description: The ID of the item.
          example: msg_007
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
          example: 0
        delta:
          type: string
          description: The text delta.
          example: 'Sure, I can h'
      description: Returned when the text value of a "text" content part is updated.
      example:
        event_id: event_4142
        type: response.text.delta
        response_id: resp_001
        item_id: msg_007
        output_index: 0
        content_index: 0
        delta: 'Sure, I can h'
    RealtimeResponseTextDone:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_4344
        type:
          enum:
            - response.text.done
          type: string
          description: 'The event type, must be "response.text.done".'
          example: response.text.done
        response_id:
          type: string
          description: The ID of the response.
          example: resp_001
        item_id:
          type: string
          description: The ID of the item.
          example: msg_007
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
          example: 0
        text:
          type: string
          description: The final text content.
          example: 'Sure, I can help with that.'
      description: 'Returned when the text value of a "text" content part is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.'
      example:
        event_id: event_4344
        type: response.text.done
        response_id: resp_001
        item_id: msg_007
        output_index: 0
        content_index: 0
        text: 'Sure, I can help with that.'
    RealtimeResponseAudioTranscriptDelta:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_4546
        type:
          enum:
            - response.audio_transcript.delta
          type: string
          description: 'The event type, must be "response.audio_transcript.delta".'
          example: response.audio_transcript.delta
        response_id:
          type: string
          description: The ID of the response.
          example: resp_001
        item_id:
          type: string
          description: The ID of the item.
          example: msg_008
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
          example: 0
        delta:
          type: string
          description: The transcript delta.
          example: 'Hello, how can I a'
      description: Returned when the model-generated transcription of audio output is updated.
      example:
        event_id: event_4546
        type: response.audio_transcript.delta
        response_id: resp_001
        item_id: msg_008
        output_index: 0
        content_index: 0
        delta: 'Hello, how can I a'
    RealtimeResponseAudioTranscriptDone:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_4748
        type:
          enum:
            - response.audio_transcript.done
          type: string
          description: 'The event type, must be "response.audio_transcript.done".'
          example: response.audio_transcript.done
        response_id:
          type: string
          description: The ID of the response.
          example: resp_001
        item_id:
          type: string
          description: The ID of the item.
          example: msg_008
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
          example: 0
        transcript:
          type: string
          description: The final transcript of the audio.
          example: 'Hello, how can I assist you today?'
      description: 'Returned when the model-generated transcription of audio output is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.'
      example:
        event_id: event_4748
        type: response.audio_transcript.done
        response_id: resp_001
        item_id: msg_008
        output_index: 0
        content_index: 0
        transcript: 'Hello, how can I assist you today?'
    RealtimeResponseAudioDelta:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_4950
        type:
          enum:
            - response.audio.delta
          type: string
          description: 'The event type, must be "response.audio.delta".'
          example: response.audio.delta
        response_id:
          type: string
          description: The ID of the response.
          example: resp_001
        item_id:
          type: string
          description: The ID of the item.
          example: msg_008
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
          example: 0
        delta:
          type: string
          description: Base64-encoded audio data delta.
          example: Base64EncodedAudioDelta
      description: Returned when the model-generated audio is updated.
      example:
        event_id: event_4950
        type: response.audio.delta
        response_id: resp_001
        item_id: msg_008
        output_index: 0
        content_index: 0
        delta: Base64EncodedAudioDelta
    RealtimeResponseAudioDone:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_5152
        type:
          enum:
            - response.audio.done
          type: string
          description: 'The event type, must be "response.audio.done".'
          example: response.audio.done
        response_id:
          type: string
          description: The ID of the response.
          example: resp_001
        item_id:
          type: string
          description: The ID of the item.
          example: msg_008
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        content_index:
          type: integer
          description: The index of the content part in the item's content array.
          example: 0
      description: 'Returned when the model-generated audio is done. Also emitted when a Response is interrupted, incomplete, or cancelled.'
      example:
        event_id: event_5152
        type: response.audio.done
        response_id: resp_001
        item_id: msg_008
        output_index: 0
        content_index: 0
    RealtimeResponseFunctionCallArgumentsDelta:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_5354
        type:
          enum:
            - response.function_call_arguments.delta
          type: string
          description: 'The event type, must be "response.function_call_arguments.delta".'
          example: response.function_call_arguments.delta
        response_id:
          type: string
          description: The ID of the response.
          example: resp_002
        item_id:
          type: string
          description: The ID of the function call item.
          example: fc_001
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        call_id:
          type: string
          description: The ID of the function call.
          example: call_001
        delta:
          type: string
          description: The arguments delta as a JSON string.
          example: '{"location": "San"'
      description: Returned when the model-generated function call arguments are updated.
      example:
        event_id: event_5354
        type: response.function_call_arguments.delta
        response_id: resp_002
        item_id: fc_001
        output_index: 0
        call_id: call_001
        delta: '{"location": "San"'
    RealtimeResponseFunctionCallArgumentsDone:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_5556
        type:
          enum:
            - response.function_call_arguments.done
          type: string
          description: 'The event type, must be "response.function_call_arguments.done".'
          example: response.function_call_arguments.done
        response_id:
          type: string
          description: The ID of the response.
          example: resp_002
        item_id:
          type: string
          description: The ID of the function call item.
          example: fc_001
        output_index:
          type: integer
          description: The index of the output item in the response.
          example: 0
        call_id:
          type: string
          description: The ID of the function call.
          example: call_001
        arguments:
          type: string
          description: The final arguments as a JSON string.
          example: '{"location": "San Francisco"}'
      description: 'Returned when the model-generated function call arguments are done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.'
      example:
        event_id: event_5556
        type: response.function_call_arguments.done
        response_id: resp_002
        item_id: fc_001
        output_index: 0
        call_id: call_001
        arguments: '{"location": "San Francisco"}'
    RealtimeRateLimitsUpdated:
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event.
          example: event_5758
        type:
          enum:
            - rate_limits.updated
          type: string
          description: 'The event type, must be "rate_limits.updated".'
          example: rate_limits.updated
        rate_limits:
          type: array
          items:
            type: object
            properties:
              name:
                enum:
                  - requests
                  - tokens
                  - input_tokens
                  - output_tokens
                type: string
                description: The name of the rate limit.
                example: requests
              limit:
                type: integer
                description: The maximum allowed value for the rate limit.
                example: 1000
              remaining:
                type: integer
                description: The remaining value before the limit is reached.
                example: 999
              reset_seconds:
                type: number
                description: Seconds until the rate limit resets.
                example: 60
          description: List of rate limit information.
      description: Emitted after every "response.done" event to indicate the updated rate limits.
      example:
        event_id: event_5758
        type: rate_limits.updated
        rate_limits:
          - name: requests
            limit: 1000
            remaining: 999
            reset_seconds: 60
          - name: tokens
            limit: 50000
            remaining: 49950
            reset_seconds: 60
  securitySchemes:
    ApiKeyAuth:
      type: http
      scheme: bearer
security:
  - ApiKeyAuth: [ ]
tags:
  - name: Assistants
    description: Build Assistants that can call models and use tools.
  - name: Audio
    description: Turn audio into text or text into audio.
  - name: Chat
    description: 'Given a list of messages comprising a conversation, the model will return a response.'
  - name: Conversations
    description: Manage conversations and conversation items.
  - name: Completions
    description: 'Given a prompt, the model will return one or more predicted completions, and can also return the probabilities of alternative tokens at each position.'
  - name: Embeddings
    description: Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
  - name: Evals
    description: Manage and run evals in the OpenAI platform.
  - name: Fine-tuning
    description: Manage fine-tuning jobs to tailor a model to your specific training data.
  - name: Graders
    description: Manage and run graders in the OpenAI platform.
  - name: Batch
    description: Create large batches of API requests to run asynchronously.
  - name: Files
    description: Files are used to upload documents that can be used with features like Assistants and Fine-tuning.
  - name: Uploads
    description: Use Uploads to upload large files in multiple parts.
  - name: Images
    description: 'Given a prompt and/or an input image, the model will generate a new image.'
  - name: Models
    description: List and describe the various models available in the API.
  - name: Moderations
    description: 'Given text and/or image inputs, classifies if those inputs are potentially harmful.'
  - name: Audit Logs
    description: List user actions and configuration changes within this organization.
x-oaiMeta:
  groups:
    - description: "OpenAI's most advanced interface for generating model responses. Supports\ntext and image inputs, and text outputs. Create stateful interactions\nwith the model, using the output of previous responses as input. Extend\nthe model's capabilities with built-in tools for file search, web search,\ncomputer use, and more. Allow the model access to external systems and data\nusing function calling.\n\nRelated guides:\n- [Quickstart](https://platform.openai.com/docs/quickstart?api-mode=responses)\n- [Text inputs and outputs](https://platform.openai.com/docs/guides/text?api-mode=responses)\n- [Image inputs](https://platform.openai.com/docs/guides/images?api-mode=responses)\n- [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses)\n- [Function calling](https://platform.openai.com/docs/guides/function-calling?api-mode=responses)\n- [Conversation state](https://platform.openai.com/docs/guides/conversation-state?api-mode=responses)\n- [Extend the models with tools](https://platform.openai.com/docs/guides/tools?api-mode=responses)\n"
      id: responses
      navigationGroup: responses
      sections:
        - key: createResponse
          path: create
          type: endpoint
        - key: getResponse
          path: get
          type: endpoint
        - key: deleteResponse
          path: delete
          type: endpoint
        - key: cancelResponse
          path: cancel
          type: endpoint
        - key: listInputItems
          path: input-items
          type: endpoint
        - key: Response
          path: object
          type: object
        - key: ResponseItemList
          path: list
          type: object
      title: Responses
    - description: "Create and manage conversations to store and retrieve conversation state across Response API calls.\n"
      id: conversations
      navigationGroup: responses
      sections:
        - key: createConversation
          path: create
          type: endpoint
        - key: getConversation
          path: retrieve
          type: endpoint
        - key: updateConversation
          path: update
          type: endpoint
        - key: deleteConversation
          path: delete
          type: endpoint
        - key: listConversationItems
          path: list-items
          type: endpoint
        - key: createConversationItems
          path: create-items
          type: endpoint
        - key: getConversationItem
          path: get-item
          type: endpoint
        - key: deleteConversationItem
          path: delete-item
          type: endpoint
        - key: Conversation
          path: object
          type: object
        - key: ConversationItemList
          path: list-items-object
          type: object
      title: Conversations
    - description: "When you [create a Response](https://platform.openai.com/docs/api-reference/responses/create) with\n`stream` set to `true`, the server will emit server-sent events to the\nclient as the Response is generated. This section contains the events that\nare emitted by the server.\n\n[Learn more about streaming responses](https://platform.openai.com/docs/guides/streaming-responses?api-mode=responses).\n"
      id: responses-streaming
      navigationGroup: responses
      sections:
        - key: ResponseCreatedEvent
          path: <auto>
          type: object
        - key: ResponseInProgressEvent
          path: <auto>
          type: object
        - key: ResponseCompletedEvent
          path: <auto>
          type: object
        - key: ResponseFailedEvent
          path: <auto>
          type: object
        - key: ResponseIncompleteEvent
          path: <auto>
          type: object
        - key: ResponseOutputItemAddedEvent
          path: <auto>
          type: object
        - key: ResponseOutputItemDoneEvent
          path: <auto>
          type: object
        - key: ResponseContentPartAddedEvent
          path: <auto>
          type: object
        - key: ResponseContentPartDoneEvent
          path: <auto>
          type: object
        - key: ResponseTextDeltaEvent
          path: response/output_text/delta
          type: object
        - key: ResponseTextDoneEvent
          path: response/output_text/done
          type: object
        - key: ResponseRefusalDeltaEvent
          path: <auto>
          type: object
        - key: ResponseRefusalDoneEvent
          path: <auto>
          type: object
        - key: ResponseFunctionCallArgumentsDeltaEvent
          path: <auto>
          type: object
        - key: ResponseFunctionCallArgumentsDoneEvent
          path: <auto>
          type: object
        - key: ResponseFileSearchCallInProgressEvent
          path: <auto>
          type: object
        - key: ResponseFileSearchCallSearchingEvent
          path: <auto>
          type: object
        - key: ResponseFileSearchCallCompletedEvent
          path: <auto>
          type: object
        - key: ResponseWebSearchCallInProgressEvent
          path: <auto>
          type: object
        - key: ResponseWebSearchCallSearchingEvent
          path: <auto>
          type: object
        - key: ResponseWebSearchCallCompletedEvent
          path: <auto>
          type: object
        - key: ResponseReasoningSummaryPartAddedEvent
          path: <auto>
          type: object
        - key: ResponseReasoningSummaryPartDoneEvent
          path: <auto>
          type: object
        - key: ResponseReasoningSummaryTextDeltaEvent
          path: <auto>
          type: object
        - key: ResponseReasoningSummaryTextDoneEvent
          path: <auto>
          type: object
        - key: ResponseReasoningTextDeltaEvent
          path: <auto>
          type: object
        - key: ResponseReasoningTextDoneEvent
          path: <auto>
          type: object
        - key: ResponseImageGenCallCompletedEvent
          path: <auto>
          type: object
        - key: ResponseImageGenCallGeneratingEvent
          path: <auto>
          type: object
        - key: ResponseImageGenCallInProgressEvent
          path: <auto>
          type: object
        - key: ResponseImageGenCallPartialImageEvent
          path: <auto>
          type: object
        - key: ResponseMCPCallArgumentsDeltaEvent
          path: <auto>
          type: object
        - key: ResponseMCPCallArgumentsDoneEvent
          path: <auto>
          type: object
        - key: ResponseMCPCallCompletedEvent
          path: <auto>
          type: object
        - key: ResponseMCPCallFailedEvent
          path: <auto>
          type: object
        - key: ResponseMCPCallInProgressEvent
          path: <auto>
          type: object
        - key: ResponseMCPListToolsCompletedEvent
          path: <auto>
          type: object
        - key: ResponseMCPListToolsFailedEvent
          path: <auto>
          type: object
        - key: ResponseMCPListToolsInProgressEvent
          path: <auto>
          type: object
        - key: ResponseCodeInterpreterCallInProgressEvent
          path: <auto>
          type: object
        - key: ResponseCodeInterpreterCallInterpretingEvent
          path: <auto>
          type: object
        - key: ResponseCodeInterpreterCallCompletedEvent
          path: <auto>
          type: object
        - key: ResponseCodeInterpreterCallCodeDeltaEvent
          path: <auto>
          type: object
        - key: ResponseCodeInterpreterCallCodeDoneEvent
          path: <auto>
          type: object
        - key: ResponseOutputTextAnnotationAddedEvent
          path: <auto>
          type: object
        - key: ResponseQueuedEvent
          path: <auto>
          type: object
        - key: ResponseCustomToolCallInputDeltaEvent
          path: <auto>
          type: object
        - key: ResponseCustomToolCallInputDoneEvent
          path: <auto>
          type: object
        - key: ResponseErrorEvent
          path: <auto>
          type: object
      title: Streaming events
    - description: "Webhooks are HTTP requests sent by OpenAI to a URL you specify when certain\nevents happen during the course of API usage.\n\n[Learn more about webhooks](https://platform.openai.com/docs/guides/webhooks).\n"
      id: webhook-events
      navigationGroup: webhooks
      sections:
        - key: WebhookResponseCompleted
          path: <auto>
          type: object
        - key: WebhookResponseCancelled
          path: <auto>
          type: object
        - key: WebhookResponseFailed
          path: <auto>
          type: object
        - key: WebhookResponseIncomplete
          path: <auto>
          type: object
        - key: WebhookBatchCompleted
          path: <auto>
          type: object
        - key: WebhookBatchCancelled
          path: <auto>
          type: object
        - key: WebhookBatchExpired
          path: <auto>
          type: object
        - key: WebhookBatchFailed
          path: <auto>
          type: object
        - key: WebhookFineTuningJobSucceeded
          path: <auto>
          type: object
        - key: WebhookFineTuningJobFailed
          path: <auto>
          type: object
        - key: WebhookFineTuningJobCancelled
          path: <auto>
          type: object
        - key: WebhookEvalRunSucceeded
          path: <auto>
          type: object
        - key: WebhookEvalRunFailed
          path: <auto>
          type: object
        - key: WebhookEvalRunCanceled
          path: <auto>
          type: object
        - key: WebhookRealtimeCallIncoming
          path: <auto>
          type: object
      title: Webhook Events
    - description: "Learn how to turn audio into text or text into audio.\n\nRelated guide: [Speech to text](https://platform.openai.com/docs/guides/speech-to-text)\n"
      id: audio
      navigationGroup: endpoints
      sections:
        - key: createSpeech
          path: createSpeech
          type: endpoint
        - key: createTranscription
          path: createTranscription
          type: endpoint
        - key: createTranslation
          path: createTranslation
          type: endpoint
        - key: CreateTranscriptionResponseJson
          path: json-object
          type: object
        - key: CreateTranscriptionResponseVerboseJson
          path: verbose-json-object
          type: object
        - key: SpeechAudioDeltaEvent
          path: speech-audio-delta-event
          type: object
        - key: SpeechAudioDoneEvent
          path: speech-audio-done-event
          type: object
        - key: TranscriptTextDeltaEvent
          path: transcript-text-delta-event
          type: object
        - key: TranscriptTextDoneEvent
          path: transcript-text-done-event
          type: object
      title: Audio
    - description: "Given a prompt and/or an input image, the model will generate a new image.\nRelated guide: [Image generation](https://platform.openai.com/docs/guides/images)\n"
      id: images
      navigationGroup: endpoints
      sections:
        - key: createImage
          path: create
          type: endpoint
        - key: createImageEdit
          path: createEdit
          type: endpoint
        - key: createImageVariation
          path: createVariation
          type: endpoint
        - key: ImagesResponse
          path: object
          type: object
      title: Images
    - description: "Stream image generation and editing in real time with server-sent events.\n[Learn more about image streaming](https://platform.openai.com/docs/guides/image-generation).\n"
      id: images-streaming
      navigationGroup: endpoints
      sections:
        - key: ImageGenPartialImageEvent
          path: <auto>
          type: object
        - key: ImageGenCompletedEvent
          path: <auto>
          type: object
        - key: ImageEditPartialImageEvent
          path: <auto>
          type: object
        - key: ImageEditCompletedEvent
          path: <auto>
          type: object
      title: Image Streaming
    - description: "Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.\nRelated guide: [Embeddings](https://platform.openai.com/docs/guides/embeddings)\n"
      id: embeddings
      navigationGroup: endpoints
      sections:
        - key: createEmbedding
          path: create
          type: endpoint
        - key: Embedding
          path: object
          type: object
      title: Embeddings
    - description: "Create, manage, and run evals in the OpenAI platform.\nRelated guide: [Evals](https://platform.openai.com/docs/guides/evals)\n"
      id: evals
      navigationGroup: endpoints
      sections:
        - key: createEval
          path: create
          type: endpoint
        - key: getEval
          path: get
          type: endpoint
        - key: updateEval
          path: update
          type: endpoint
        - key: deleteEval
          path: delete
          type: endpoint
        - key: listEvals
          path: list
          type: endpoint
        - key: getEvalRuns
          path: getRuns
          type: endpoint
        - key: getEvalRun
          path: getRun
          type: endpoint
        - key: createEvalRun
          path: createRun
          type: endpoint
        - key: cancelEvalRun
          path: cancelRun
          type: endpoint
        - key: deleteEvalRun
          path: deleteRun
          type: endpoint
        - key: getEvalRunOutputItem
          path: getRunOutputItem
          type: endpoint
        - key: getEvalRunOutputItems
          path: getRunOutputItems
          type: endpoint
        - key: Eval
          path: object
          type: object
        - key: EvalRun
          path: run-object
          type: object
        - key: EvalRunOutputItem
          path: run-output-item-object
          type: object
      title: Evals
    - description: "Manage fine-tuning jobs to tailor a model to your specific training data.\nRelated guide: [Fine-tune models](https://platform.openai.com/docs/guides/fine-tuning)\n"
      id: fine-tuning
      navigationGroup: endpoints
      sections:
        - key: createFineTuningJob
          path: create
          type: endpoint
        - key: listPaginatedFineTuningJobs
          path: list
          type: endpoint
        - key: listFineTuningEvents
          path: list-events
          type: endpoint
        - key: listFineTuningJobCheckpoints
          path: list-checkpoints
          type: endpoint
        - key: listFineTuningCheckpointPermissions
          path: list-permissions
          type: endpoint
        - key: createFineTuningCheckpointPermission
          path: create-permission
          type: endpoint
        - key: deleteFineTuningCheckpointPermission
          path: delete-permission
          type: endpoint
        - key: retrieveFineTuningJob
          path: retrieve
          type: endpoint
        - key: cancelFineTuningJob
          path: cancel
          type: endpoint
        - key: resumeFineTuningJob
          path: resume
          type: endpoint
        - key: pauseFineTuningJob
          path: pause
          type: endpoint
        - key: FineTuneChatRequestInput
          path: chat-input
          type: object
        - key: FineTunePreferenceRequestInput
          path: preference-input
          type: object
        - key: FineTuneReinforcementRequestInput
          path: reinforcement-input
          type: object
        - key: FineTuningJob
          path: object
          type: object
        - key: FineTuningJobEvent
          path: event-object
          type: object
        - key: FineTuningJobCheckpoint
          path: checkpoint-object
          type: object
        - key: FineTuningCheckpointPermission
          path: permission-object
          type: object
      title: Fine-tuning
    - description: "Manage and run graders in the OpenAI platform.\nRelated guide: [Graders](https://platform.openai.com/docs/guides/graders)\n"
      id: graders
      navigationGroup: endpoints
      sections:
        - key: GraderStringCheck
          path: string-check
          type: object
        - key: GraderTextSimilarity
          path: text-similarity
          type: object
        - key: GraderScoreModel
          path: score-model
          type: object
        - key: GraderLabelModel
          path: label-model
          type: object
        - key: GraderPython
          path: python
          type: object
        - key: GraderMulti
          path: multi
          type: object
        - key: runGrader
          path: run
          type: endpoint
        - beta: true
          key: validateGrader
          path: validate
          type: endpoint
      title: Graders
    - description: "Create large batches of API requests for asynchronous processing. The Batch API returns completions within 24 hours for a 50% discount.\nRelated guide: [Batch](https://platform.openai.com/docs/guides/batch)\n"
      id: batch
      navigationGroup: endpoints
      sections:
        - key: createBatch
          path: create
          type: endpoint
        - key: retrieveBatch
          path: retrieve
          type: endpoint
        - key: cancelBatch
          path: cancel
          type: endpoint
        - key: listBatches
          path: list
          type: endpoint
        - key: Batch
          path: object
          type: object
        - key: BatchRequestInput
          path: request-input
          type: object
        - key: BatchRequestOutput
          path: request-output
          type: object
      title: Batch
    - description: "Files are used to upload documents that can be used with features like [Assistants](https://platform.openai.com/docs/api-reference/assistants), [Fine-tuning](https://platform.openai.com/docs/api-reference/fine-tuning), and [Batch API](https://platform.openai.com/docs/guides/batch).\n"
      id: files
      navigationGroup: endpoints
      sections:
        - key: createFile
          path: create
          type: endpoint
        - key: listFiles
          path: list
          type: endpoint
        - key: retrieveFile
          path: retrieve
          type: endpoint
        - key: deleteFile
          path: delete
          type: endpoint
        - key: downloadFile
          path: retrieve-contents
          type: endpoint
        - key: OpenAIFile
          path: object
          type: object
      title: Files
    - description: "Allows you to upload large files in multiple parts.\n"
      id: uploads
      navigationGroup: endpoints
      sections:
        - key: createUpload
          path: create
          type: endpoint
        - key: addUploadPart
          path: add-part
          type: endpoint
        - key: completeUpload
          path: complete
          type: endpoint
        - key: cancelUpload
          path: cancel
          type: endpoint
        - key: Upload
          path: object
          type: object
        - key: UploadPart
          path: part-object
          type: object
      title: Uploads
    - description: "List and describe the various models available in the API. You can refer to the [Models](https://platform.openai.com/docs/models) documentation to understand what models are available and the differences between them.\n"
      id: models
      navigationGroup: endpoints
      sections:
        - key: listModels
          path: list
          type: endpoint
        - key: retrieveModel
          path: retrieve
          type: endpoint
        - key: deleteModel
          path: delete
          type: endpoint
        - key: Model
          path: object
          type: object
      title: Models
    - description: "Given text and/or image inputs, classifies if those inputs are potentially harmful across several categories.\nRelated guide: [Moderations](https://platform.openai.com/docs/guides/moderation)\n"
      id: moderations
      navigationGroup: endpoints
      sections:
        - key: createModeration
          path: create
          type: endpoint
        - key: CreateModerationResponse
          path: object
          type: object
      title: Moderations
    - description: "Vector stores power semantic search for the Retrieval API and the `file_search` tool in the Responses and Assistants APIs.\n\nRelated guide: [File Search](https://platform.openai.com/docs/assistants/tools/file-search)\n"
      id: vector-stores
      navigationGroup: vector_stores
      sections:
        - key: createVectorStore
          path: create
          type: endpoint
        - key: listVectorStores
          path: list
          type: endpoint
        - key: getVectorStore
          path: retrieve
          type: endpoint
        - key: modifyVectorStore
          path: modify
          type: endpoint
        - key: deleteVectorStore
          path: delete
          type: endpoint
        - key: searchVectorStore
          path: search
          type: endpoint
        - key: VectorStoreObject
          path: object
          type: object
      title: Vector stores
    - description: "Vector store files represent files inside a vector store.\n\nRelated guide: [File Search](https://platform.openai.com/docs/assistants/tools/file-search)\n"
      id: vector-stores-files
      navigationGroup: vector_stores
      sections:
        - key: createVectorStoreFile
          path: createFile
          type: endpoint
        - key: listVectorStoreFiles
          path: listFiles
          type: endpoint
        - key: getVectorStoreFile
          path: getFile
          type: endpoint
        - key: retrieveVectorStoreFileContent
          path: getContent
          type: endpoint
        - key: updateVectorStoreFileAttributes
          path: updateAttributes
          type: endpoint
        - key: deleteVectorStoreFile
          path: deleteFile
          type: endpoint
        - key: VectorStoreFileObject
          path: file-object
          type: object
      title: Vector store files
    - description: "Vector store file batches represent operations to add multiple files to a vector store.\nRelated guide: [File Search](https://platform.openai.com/docs/assistants/tools/file-search)\n"
      id: vector-stores-file-batches
      navigationGroup: vector_stores
      sections:
        - key: createVectorStoreFileBatch
          path: createBatch
          type: endpoint
        - key: getVectorStoreFileBatch
          path: getBatch
          type: endpoint
        - key: cancelVectorStoreFileBatch
          path: cancelBatch
          type: endpoint
        - key: listFilesInVectorStoreBatch
          path: listBatchFiles
          type: endpoint
        - key: VectorStoreFileBatchObject
          path: batch-object
          type: object
      title: Vector store file batches
    - description: "Create and manage containers for use with the Code Interpreter tool.\n"
      id: containers
      navigationGroup: containers
      sections:
        - key: CreateContainer
          path: createContainers
          type: endpoint
        - key: ListContainers
          path: listContainers
          type: endpoint
        - key: RetrieveContainer
          path: retrieveContainer
          type: endpoint
        - key: DeleteContainer
          path: deleteContainer
          type: endpoint
        - key: ContainerResource
          path: object
          type: object
      title: Containers
    - description: "Create and manage container files for use with the Code Interpreter tool.\n"
      id: container-files
      navigationGroup: containers
      sections:
        - key: CreateContainerFile
          path: createContainerFile
          type: endpoint
        - key: ListContainerFiles
          path: listContainerFiles
          type: endpoint
        - key: RetrieveContainerFile
          path: retrieveContainerFile
          type: endpoint
        - key: RetrieveContainerFileContent
          path: retrieveContainerFileContent
          type: endpoint
        - key: DeleteContainerFile
          path: deleteContainerFile
          type: endpoint
        - key: ContainerFileResource
          path: object
          type: object
      title: Container Files
    - description: "Communicate with a multimodal model in real time over low latency interfaces\nlike WebRTC, WebSocket, and SIP. Natively supports speech-to-speech\nas well as text, image, and audio inputs and outputs.\n\n[Learn more about the Realtime API](https://platform.openai.com/docs/guides/realtime).\n"
      id: realtime
      navigationGroup: realtime
      title: Realtime
    - description: "REST API endpoint to generate ephemeral session tokens for use in client-side\napplications.\n"
      id: realtime-sessions
      navigationGroup: realtime
      sections:
        - key: create-realtime-client-secret
          path: create-realtime-client-secret
          type: endpoint
        - key: RealtimeCreateClientSecretResponse
          path: create-secret-response
          type: object
      title: Session tokens
    - description: "These are events that the OpenAI Realtime WebSocket server will accept from the client.\n"
      id: realtime-client-events
      navigationGroup: realtime
      sections:
        - key: RealtimeClientEventSessionUpdate
          path: <auto>
          type: object
        - key: RealtimeClientEventInputAudioBufferAppend
          path: <auto>
          type: object
        - key: RealtimeClientEventInputAudioBufferCommit
          path: <auto>
          type: object
        - key: RealtimeClientEventInputAudioBufferClear
          path: <auto>
          type: object
        - key: RealtimeClientEventConversationItemCreate
          path: <auto>
          type: object
        - key: RealtimeClientEventConversationItemRetrieve
          path: <auto>
          type: object
        - key: RealtimeClientEventConversationItemTruncate
          path: <auto>
          type: object
        - key: RealtimeClientEventConversationItemDelete
          path: <auto>
          type: object
        - key: RealtimeClientEventResponseCreate
          path: <auto>
          type: object
        - key: RealtimeClientEventResponseCancel
          path: <auto>
          type: object
        - key: RealtimeClientEventTranscriptionSessionUpdate
          path: <auto>
          type: object
        - key: RealtimeClientEventOutputAudioBufferClear
          path: <auto>
          type: object
      title: Client events
    - description: "These are events emitted from the OpenAI Realtime WebSocket server to the client.\n"
      id: realtime-server-events
      navigationGroup: realtime
      sections:
        - key: RealtimeServerEventError
          path: <auto>
          type: object
        - key: RealtimeServerEventSessionCreated
          path: <auto>
          type: object
        - key: RealtimeServerEventSessionUpdated
          path: <auto>
          type: object
        - key: RealtimeServerEventTranscriptionSessionCreated
          path: <auto>
          type: object
        - key: RealtimeServerEventConversationItemCreated
          path: <auto>
          type: object
        - key: RealtimeServerEventConversationItemAdded
          path: <auto>
          type: object
        - key: RealtimeServerEventConversationItemDone
          path: <auto>
          type: object
        - key: RealtimeServerEventConversationItemRetrieved
          path: <auto>
          type: object
        - key: RealtimeServerEventConversationItemInputAudioTranscriptionCompleted
          path: <auto>
          type: object
        - key: RealtimeServerEventConversationItemInputAudioTranscriptionDelta
          path: <auto>
          type: object
        - key: RealtimeServerEventConversationItemInputAudioTranscriptionSegment
          path: <auto>
          type: object
        - key: RealtimeServerEventConversationItemInputAudioTranscriptionFailed
          path: <auto>
          type: object
        - key: RealtimeServerEventConversationItemTruncated
          path: <auto>
          type: object
        - key: RealtimeServerEventConversationItemDeleted
          path: <auto>
          type: object
        - key: RealtimeServerEventInputAudioBufferCommitted
          path: <auto>
          type: object
        - key: RealtimeServerEventInputAudioBufferCleared
          path: <auto>
          type: object
        - key: RealtimeServerEventInputAudioBufferSpeechStarted
          path: <auto>
          type: object
        - key: RealtimeServerEventInputAudioBufferSpeechStopped
          path: <auto>
          type: object
        - key: RealtimeServerEventInputAudioBufferTimeoutTriggered
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseCreated
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseDone
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseOutputItemAdded
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseOutputItemDone
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseContentPartAdded
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseContentPartDone
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseTextDelta
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseTextDone
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseAudioTranscriptDelta
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseAudioTranscriptDone
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseAudioDelta
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseAudioDone
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseFunctionCallArgumentsDelta
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseFunctionCallArgumentsDone
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseMCPCallArgumentsDelta
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseMCPCallArgumentsDone
          path: <auto>
          type: object
        - key: RealtimeServerEventMCPListToolsInProgress
          path: <auto>
          type: object
        - key: RealtimeServerEventMCPListToolsCompleted
          path: <auto>
          type: object
        - key: RealtimeServerEventMCPListToolsFailed
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseMCPCallInProgress
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseMCPCallCompleted
          path: <auto>
          type: object
        - key: RealtimeServerEventResponseMCPCallFailed
          path: <auto>
          type: object
        - key: RealtimeServerEventTranscriptionSessionUpdated
          path: <auto>
          type: object
        - key: RealtimeServerEventRateLimitsUpdated
          path: <auto>
          type: object
      title: Server events
    - description: "The Chat Completions API endpoint will generate a model response from a\nlist of messages comprising a conversation.\n\nRelated guides:\n- [Quickstart](https://platform.openai.com/docs/quickstart?api-mode=chat)\n- [Text inputs and outputs](https://platform.openai.com/docs/guides/text?api-mode=chat)\n- [Image inputs](https://platform.openai.com/docs/guides/images?api-mode=chat)\n- [Audio inputs and outputs](https://platform.openai.com/docs/guides/audio?api-mode=chat)\n- [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs?api-mode=chat)\n- [Function calling](https://platform.openai.com/docs/guides/function-calling?api-mode=chat)\n- [Conversation state](https://platform.openai.com/docs/guides/conversation-state?api-mode=chat)\n\n**Starting a new project?** We recommend trying [Responses](https://platform.openai.com/docs/api-reference/responses)\nto take advantage of the latest OpenAI platform features. Compare\n[Chat Completions with Responses](https://platform.openai.com/docs/guides/responses-vs-chat-completions?api-mode=responses).\n"
      id: chat
      navigationGroup: chat
      sections:
        - key: createChatCompletion
          path: create
          type: endpoint
        - key: getChatCompletion
          path: get
          type: endpoint
        - key: getChatCompletionMessages
          path: getMessages
          type: endpoint
        - key: listChatCompletions
          path: list
          type: endpoint
        - key: updateChatCompletion
          path: update
          type: endpoint
        - key: deleteChatCompletion
          path: delete
          type: endpoint
        - key: CreateChatCompletionResponse
          path: object
          type: object
        - key: ChatCompletionList
          path: list-object
          type: object
        - key: ChatCompletionMessageList
          path: message-list
          type: object
      title: Chat Completions
    - description: "Stream Chat Completions in real time. Receive chunks of completions\nreturned from the model using server-sent events.\n[Learn more](https://platform.openai.com/docs/guides/streaming-responses?api-mode=chat).\n"
      id: chat-streaming
      navigationGroup: chat
      sections:
        - key: CreateChatCompletionStreamResponse
          path: streaming
          type: object
      title: Streaming
    - beta: true
      description: "Build assistants that can call models and use tools to perform tasks.\n\n[Get started with the Assistants API](https://platform.openai.com/docs/assistants)\n"
      id: assistants
      navigationGroup: assistants
      sections:
        - key: createAssistant
          path: createAssistant
          type: endpoint
        - key: listAssistants
          path: listAssistants
          type: endpoint
        - key: getAssistant
          path: getAssistant
          type: endpoint
        - key: modifyAssistant
          path: modifyAssistant
          type: endpoint
        - key: deleteAssistant
          path: deleteAssistant
          type: endpoint
        - key: AssistantObject
          path: object
          type: object
      title: Assistants
    - beta: true
      description: "Create threads that assistants can interact with.\n\nRelated guide: [Assistants](https://platform.openai.com/docs/assistants/overview)\n"
      id: threads
      navigationGroup: assistants
      sections:
        - key: createThread
          path: createThread
          type: endpoint
        - key: getThread
          path: getThread
          type: endpoint
        - key: modifyThread
          path: modifyThread
          type: endpoint
        - key: deleteThread
          path: deleteThread
          type: endpoint
        - key: ThreadObject
          path: object
          type: object
      title: Threads
    - beta: true
      description: "Create messages within threads\n\nRelated guide: [Assistants](https://platform.openai.com/docs/assistants/overview)\n"
      id: messages
      navigationGroup: assistants
      sections:
        - key: createMessage
          path: createMessage
          type: endpoint
        - key: listMessages
          path: listMessages
          type: endpoint
        - key: getMessage
          path: getMessage
          type: endpoint
        - key: modifyMessage
          path: modifyMessage
          type: endpoint
        - key: deleteMessage
          path: deleteMessage
          type: endpoint
        - key: MessageObject
          path: object
          type: object
      title: Messages
    - beta: true
      description: "Represents an execution run on a thread.\n\nRelated guide: [Assistants](https://platform.openai.com/docs/assistants/overview)\n"
      id: runs
      navigationGroup: assistants
      sections:
        - key: createRun
          path: createRun
          type: endpoint
        - key: createThreadAndRun
          path: createThreadAndRun
          type: endpoint
        - key: listRuns
          path: listRuns
          type: endpoint
        - key: getRun
          path: getRun
          type: endpoint
        - key: modifyRun
          path: modifyRun
          type: endpoint
        - key: submitToolOuputsToRun
          path: submitToolOutputs
          type: endpoint
        - key: cancelRun
          path: cancelRun
          type: endpoint
        - key: RunObject
          path: object
          type: object
      title: Runs
    - beta: true
      description: "Represents the steps (model and tool calls) taken during the run.\n\nRelated guide: [Assistants](https://platform.openai.com/docs/assistants/overview)\n"
      id: run-steps
      navigationGroup: assistants
      sections:
        - key: listRunSteps
          path: listRunSteps
          type: endpoint
        - key: getRunStep
          path: getRunStep
          type: endpoint
        - key: RunStepObject
          path: step-object
          type: object
      title: Run steps
    - beta: true
      description: "Stream the result of executing a Run or resuming a Run after submitting tool outputs.\nYou can stream events from the [Create Thread and Run](https://platform.openai.com/docs/api-reference/runs/createThreadAndRun),\n[Create Run](https://platform.openai.com/docs/api-reference/runs/createRun), and [Submit Tool Outputs](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\nendpoints by passing `\"stream\": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.\nOur Node and Python SDKs provide helpful utilities to make streaming easy. Reference the\n[Assistants API quickstart](https://platform.openai.com/docs/assistants/overview) to learn more.\n"
      id: assistants-streaming
      navigationGroup: assistants
      sections:
        - key: MessageDeltaObject
          path: message-delta-object
          type: object
        - key: RunStepDeltaObject
          path: run-step-delta-object
          type: object
        - key: AssistantStreamEvent
          path: events
          type: object
      title: Streaming
    - description: "Programmatically manage your organization.\nThe Audit Logs endpoint provides a log of all actions taken in the organization for security and monitoring purposes.\nTo access these endpoints please generate an Admin API Key through the [API Platform Organization overview](/organization/admin-keys). Admin API keys cannot be used for non-administration endpoints.\nFor best practices on setting up your organization, please refer to this [guide](https://platform.openai.com/docs/guides/production-best-practices#setting-up-your-organization)\n"
      id: administration
      navigationGroup: administration
      title: Administration
    - description: "Admin API keys enable Organization Owners to programmatically manage various aspects of their organization, including users, projects, and API keys. These keys provide administrative capabilities, such as creating, updating, and deleting users; managing projects; and overseeing API key lifecycles.\n\nKey Features of Admin API Keys:\n\n- User Management: Invite new users, update roles, and remove users from the organization.\n\n- Project Management: Create, update, archive projects, and manage user assignments within projects.\n\n- API Key Oversight: List, retrieve, and delete API keys associated with projects.\n\nOnly Organization Owners have the authority to create and utilize Admin API keys. To manage these keys, Organization Owners can navigate to the Admin Keys section of their API Platform dashboard.\n\nFor direct access to the Admin Keys management page, Organization Owners can use the following link:\n\n[https://platform.openai.com/settings/organization/admin-keys](https://platform.openai.com/settings/organization/admin-keys)\n\nIt's crucial to handle Admin API keys with care due to their elevated permissions. Adhering to best practices, such as regular key rotation and assigning appropriate permissions, enhances security and ensures proper governance within the organization.\n"
      id: admin-api-keys
      navigationGroup: administration
      sections:
        - key: admin-api-keys-list
          path: list
          type: endpoint
        - key: admin-api-keys-create
          path: create
          type: endpoint
        - key: admin-api-keys-get
          path: listget
          type: endpoint
        - key: admin-api-keys-delete
          path: delete
          type: endpoint
        - key: AdminApiKey
          path: object
          type: object
      title: Admin API Keys
    - description: Invite and manage invitations for an organization.
      id: invite
      navigationGroup: administration
      sections:
        - key: list-invites
          path: list
          type: endpoint
        - key: inviteUser
          path: create
          type: endpoint
        - key: retrieve-invite
          path: retrieve
          type: endpoint
        - key: delete-invite
          path: delete
          type: endpoint
        - key: Invite
          path: object
          type: object
      title: Invites
    - description: "Manage users and their role in an organization.\n"
      id: users
      navigationGroup: administration
      sections:
        - key: list-users
          path: list
          type: endpoint
        - key: modify-user
          path: modify
          type: endpoint
        - key: retrieve-user
          path: retrieve
          type: endpoint
        - key: delete-user
          path: delete
          type: endpoint
        - key: User
          path: object
          type: object
      title: Users
    - description: "Manage the projects within an orgnanization includes creation, updating, and archiving or projects.\nThe Default project cannot be archived.\n"
      id: projects
      navigationGroup: administration
      sections:
        - key: list-projects
          path: list
          type: endpoint
        - key: create-project
          path: create
          type: endpoint
        - key: retrieve-project
          path: retrieve
          type: endpoint
        - key: modify-project
          path: modify
          type: endpoint
        - key: archive-project
          path: archive
          type: endpoint
        - key: Project
          path: object
          type: object
      title: Projects
    - description: "Manage users within a project, including adding, updating roles, and removing users.\n"
      id: project-users
      navigationGroup: administration
      sections:
        - key: list-project-users
          path: list
          type: endpoint
        - key: create-project-user
          path: create
          type: endpoint
        - key: retrieve-project-user
          path: retrieve
          type: endpoint
        - key: modify-project-user
          path: modify
          type: endpoint
        - key: delete-project-user
          path: delete
          type: endpoint
        - key: ProjectUser
          path: object
          type: object
      title: Project users
    - description: "Manage service accounts within a project. A service account is a bot user that is not associated with a user.\nIf a user leaves an organization, their keys and membership in projects will no longer work. Service accounts\ndo not have this limitation. However, service accounts can also be deleted from a project.\n"
      id: project-service-accounts
      navigationGroup: administration
      sections:
        - key: list-project-service-accounts
          path: list
          type: endpoint
        - key: create-project-service-account
          path: create
          type: endpoint
        - key: retrieve-project-service-account
          path: retrieve
          type: endpoint
        - key: delete-project-service-account
          path: delete
          type: endpoint
        - key: ProjectServiceAccount
          path: object
          type: object
      title: Project service accounts
    - description: "Manage API keys for a given project. Supports listing and deleting keys for users.\nThis API does not allow issuing keys for users, as users need to authorize themselves to generate keys.\n"
      id: project-api-keys
      navigationGroup: administration
      sections:
        - key: list-project-api-keys
          path: list
          type: endpoint
        - key: retrieve-project-api-key
          path: retrieve
          type: endpoint
        - key: delete-project-api-key
          path: delete
          type: endpoint
        - key: ProjectApiKey
          path: object
          type: object
      title: Project API keys
    - description: "Manage rate limits per model for projects. Rate limits may be configured to be equal to or lower than the organization's rate limits.\n"
      id: project-rate-limits
      navigationGroup: administration
      sections:
        - key: list-project-rate-limits
          path: list
          type: endpoint
        - key: update-project-rate-limits
          path: update
          type: endpoint
        - key: ProjectRateLimit
          path: object
          type: object
      title: Project rate limits
    - description: "Logs of user actions and configuration changes within this organization.\nTo log events, an Organization Owner must activate logging in the [Data Controls Settings](/settings/organization/data-controls/data-retention).\nOnce activated, for security reasons, logging cannot be deactivated.\n"
      id: audit-logs
      navigationGroup: administration
      sections:
        - key: list-audit-logs
          path: list
          type: endpoint
        - key: AuditLog
          path: object
          type: object
      title: Audit logs
    - description: "The **Usage API** provides detailed insights into your activity across the OpenAI API. It also includes a separate [Costs endpoint](https://platform.openai.com/docs/api-reference/usage/costs), which offers visibility into your spend, breaking down consumption by invoice line items and project IDs.\n\nWhile the Usage API delivers granular usage data, it may not always reconcile perfectly with the Costs due to minor differences in how usage and spend are recorded. For financial purposes, we recommend using the [Costs endpoint](https://platform.openai.com/docs/api-reference/usage/costs) or the [Costs tab](/settings/organization/usage) in the Usage Dashboard, which will reconcile back to your billing invoice.\n"
      id: usage
      navigationGroup: administration
      sections:
        - key: usage-completions
          path: completions
          type: endpoint
        - key: UsageCompletionsResult
          path: completions_object
          type: object
        - key: usage-embeddings
          path: embeddings
          type: endpoint
        - key: UsageEmbeddingsResult
          path: embeddings_object
          type: object
        - key: usage-moderations
          path: moderations
          type: endpoint
        - key: UsageModerationsResult
          path: moderations_object
          type: object
        - key: usage-images
          path: images
          type: endpoint
        - key: UsageImagesResult
          path: images_object
          type: object
        - key: usage-audio-speeches
          path: audio_speeches
          type: endpoint
        - key: UsageAudioSpeechesResult
          path: audio_speeches_object
          type: object
        - key: usage-audio-transcriptions
          path: audio_transcriptions
          type: endpoint
        - key: UsageAudioTranscriptionsResult
          path: audio_transcriptions_object
          type: object
        - key: usage-vector-stores
          path: vector_stores
          type: endpoint
        - key: UsageVectorStoresResult
          path: vector_stores_object
          type: object
        - key: usage-code-interpreter-sessions
          path: code_interpreter_sessions
          type: endpoint
        - key: UsageCodeInterpreterSessionsResult
          path: code_interpreter_sessions_object
          type: object
        - key: usage-costs
          path: costs
          type: endpoint
        - key: CostsResult
          path: costs_object
          type: object
      title: Usage
    - beta: true
      description: "Manage Mutual TLS certificates across your organization and projects.\n\n[Learn more about Mutual TLS.](https://help.openai.com/en/articles/10876024-openai-mutual-tls-beta-program)\n"
      id: certificates
      navigationGroup: administration
      sections:
        - key: uploadCertificate
          path: uploadCertificate
          type: endpoint
        - key: getCertificate
          path: getCertificate
          type: endpoint
        - key: modifyCertificate
          path: modifyCertificate
          type: endpoint
        - key: deleteCertificate
          path: deleteCertificate
          type: endpoint
        - key: listOrganizationCertificates
          path: listOrganizationCertificates
          type: endpoint
        - key: listProjectCertificates
          path: listProjectCertificates
          type: endpoint
        - key: activateOrganizationCertificates
          path: activateOrganizationCertificates
          type: endpoint
        - key: deactivateOrganizationCertificates
          path: deactivateOrganizationCertificates
          type: endpoint
        - key: activateProjectCertificates
          path: activateProjectCertificates
          type: endpoint
        - key: deactivateProjectCertificates
          path: deactivateProjectCertificates
          type: endpoint
        - key: Certificate
          path: object
          type: object
      title: Certificates
    - description: "Given a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our [Chat Completions API](https://platform.openai.com/docs/guides/text-generation#text-generation-models) to leverage our best and newest models.\n"
      id: completions
      legacy: true
      navigationGroup: legacy
      sections:
        - key: createCompletion
          path: create
          type: endpoint
        - key: CreateCompletionResponse
          path: object
          type: object
      title: Completions
  navigationGroups:
    - id: responses
      title: Responses API
    - id: webhooks
      title: Webhooks
    - id: endpoints
      title: Platform APIs
    - id: vector_stores
      title: Vector stores
    - id: containers
      title: Containers
    - id: realtime
      title: Realtime
    - id: chat
      title: Chat Completions
    - beta: true
      id: assistants
      title: Assistants
    - id: administration
      title: Administration
    - id: legacy
      title: Legacy