
#pragma warning disable CS0618 // Type or member is obsolete

#nullable enable

namespace tryAGI.OpenAI
{
    /// <summary>
    /// 
    /// </summary>
    public sealed partial class ResponseVariant3
    {
        /// <summary>
        /// Unix timestamp (in seconds) of when this Response was created.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("created_at")]
        [global::System.Text.Json.Serialization.JsonRequired]
        public required double CreatedAt { get; set; }

        /// <summary>
        /// An error object returned when the model fails to generate a Response.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("error")]
        [global::System.Text.Json.Serialization.JsonRequired]
        public required global::tryAGI.OpenAI.ResponseError? Error { get; set; }

        /// <summary>
        /// Unique identifier for this Response.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("id")]
        [global::System.Text.Json.Serialization.JsonRequired]
        public required string Id { get; set; }

        /// <summary>
        /// Details about why the response is incomplete.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("incomplete_details")]
        [global::System.Text.Json.Serialization.JsonRequired]
        public required global::tryAGI.OpenAI.ResponseVariant3IncompleteDetails? IncompleteDetails { get; set; }

        /// <summary>
        /// A system (or developer) message inserted into the model's context.<br/>
        /// When using along with `previous_response_id`, the instructions from a previous<br/>
        /// response will not be carried over to the next response. This makes it simple<br/>
        /// to swap out system (or developer) messages in new responses.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("instructions")]
        [global::System.Text.Json.Serialization.JsonConverter(typeof(global::tryAGI.OpenAI.JsonConverters.OneOfJsonConverter<string, global::System.Collections.Generic.IList<global::tryAGI.OpenAI.InputItem>>))]
        [global::System.Text.Json.Serialization.JsonRequired]
        public required global::tryAGI.OpenAI.OneOf<string, global::System.Collections.Generic.IList<global::tryAGI.OpenAI.InputItem>>? Instructions { get; set; }

        /// <summary>
        /// The object type of this resource - always set to `response`.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("object")]
        [global::System.Text.Json.Serialization.JsonConverter(typeof(global::tryAGI.OpenAI.JsonConverters.ResponseVariant3ObjectJsonConverter))]
        public global::tryAGI.OpenAI.ResponseVariant3Object Object { get; set; }

        /// <summary>
        /// An array of content items generated by the model.<br/>
        /// - The length and order of items in the `output` array is dependent<br/>
        ///   on the model's response.<br/>
        /// - Rather than accessing the first item in the `output` array and <br/>
        ///   assuming it's an `assistant` message with the content generated by<br/>
        ///   the model, you might consider using the `output_text` property where<br/>
        ///   supported in SDKs.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("output")]
        [global::System.Text.Json.Serialization.JsonRequired]
        public required global::System.Collections.Generic.IList<global::tryAGI.OpenAI.OutputItem> Output { get; set; }

        /// <summary>
        /// SDK-only convenience property that contains the aggregated text output <br/>
        /// from all `output_text` items in the `output` array, if any are present. <br/>
        /// Supported in the Python and JavaScript SDKs.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("output_text")]
        public string? OutputText { get; set; }

        /// <summary>
        /// Whether to allow the model to run tool calls in parallel.<br/>
        /// Default Value: true
        /// </summary>
        /// <default>true</default>
        [global::System.Text.Json.Serialization.JsonPropertyName("parallel_tool_calls")]
        [global::System.Text.Json.Serialization.JsonRequired]
        public required bool ParallelToolCalls { get; set; } = true;

        /// <summary>
        /// The status of the response generation. One of `completed`, `failed`, <br/>
        /// `in_progress`, `cancelled`, `queued`, or `incomplete`.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("status")]
        [global::System.Text.Json.Serialization.JsonConverter(typeof(global::tryAGI.OpenAI.JsonConverters.ResponseVariant3StatusJsonConverter))]
        public global::tryAGI.OpenAI.ResponseVariant3Status? Status { get; set; }

        /// <summary>
        /// Represents token usage details including input tokens, output tokens,<br/>
        /// a breakdown of output tokens, and the total tokens used.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("usage")]
        public global::tryAGI.OpenAI.ResponseUsage? Usage { get; set; }

        /// <summary>
        /// Additional properties that are not explicitly defined in the schema
        /// </summary>
        [global::System.Text.Json.Serialization.JsonExtensionData]
        public global::System.Collections.Generic.IDictionary<string, object> AdditionalProperties { get; set; } = new global::System.Collections.Generic.Dictionary<string, object>();

        /// <summary>
        /// Initializes a new instance of the <see cref="ResponseVariant3" /> class.
        /// </summary>
        /// <param name="createdAt">
        /// Unix timestamp (in seconds) of when this Response was created.
        /// </param>
        /// <param name="error">
        /// An error object returned when the model fails to generate a Response.
        /// </param>
        /// <param name="id">
        /// Unique identifier for this Response.
        /// </param>
        /// <param name="incompleteDetails">
        /// Details about why the response is incomplete.
        /// </param>
        /// <param name="instructions">
        /// A system (or developer) message inserted into the model's context.<br/>
        /// When using along with `previous_response_id`, the instructions from a previous<br/>
        /// response will not be carried over to the next response. This makes it simple<br/>
        /// to swap out system (or developer) messages in new responses.
        /// </param>
        /// <param name="object">
        /// The object type of this resource - always set to `response`.
        /// </param>
        /// <param name="output">
        /// An array of content items generated by the model.<br/>
        /// - The length and order of items in the `output` array is dependent<br/>
        ///   on the model's response.<br/>
        /// - Rather than accessing the first item in the `output` array and <br/>
        ///   assuming it's an `assistant` message with the content generated by<br/>
        ///   the model, you might consider using the `output_text` property where<br/>
        ///   supported in SDKs.
        /// </param>
        /// <param name="outputText">
        /// SDK-only convenience property that contains the aggregated text output <br/>
        /// from all `output_text` items in the `output` array, if any are present. <br/>
        /// Supported in the Python and JavaScript SDKs.
        /// </param>
        /// <param name="parallelToolCalls">
        /// Whether to allow the model to run tool calls in parallel.<br/>
        /// Default Value: true
        /// </param>
        /// <param name="status">
        /// The status of the response generation. One of `completed`, `failed`, <br/>
        /// `in_progress`, `cancelled`, `queued`, or `incomplete`.
        /// </param>
        /// <param name="usage">
        /// Represents token usage details including input tokens, output tokens,<br/>
        /// a breakdown of output tokens, and the total tokens used.
        /// </param>
#if NET7_0_OR_GREATER
        [global::System.Diagnostics.CodeAnalysis.SetsRequiredMembers]
#endif
        public ResponseVariant3(
            double createdAt,
            global::tryAGI.OpenAI.ResponseError? error,
            string id,
            global::tryAGI.OpenAI.ResponseVariant3IncompleteDetails? incompleteDetails,
            global::tryAGI.OpenAI.OneOf<string, global::System.Collections.Generic.IList<global::tryAGI.OpenAI.InputItem>>? instructions,
            global::System.Collections.Generic.IList<global::tryAGI.OpenAI.OutputItem> output,
            bool parallelToolCalls,
            global::tryAGI.OpenAI.ResponseVariant3Object @object,
            string? outputText,
            global::tryAGI.OpenAI.ResponseVariant3Status? status,
            global::tryAGI.OpenAI.ResponseUsage? usage)
        {
            this.CreatedAt = createdAt;
            this.Error = error ?? throw new global::System.ArgumentNullException(nameof(error));
            this.Id = id ?? throw new global::System.ArgumentNullException(nameof(id));
            this.IncompleteDetails = incompleteDetails ?? throw new global::System.ArgumentNullException(nameof(incompleteDetails));
            this.Instructions = instructions;
            this.Output = output ?? throw new global::System.ArgumentNullException(nameof(output));
            this.ParallelToolCalls = parallelToolCalls;
            this.Object = @object;
            this.OutputText = outputText;
            this.Status = status;
            this.Usage = usage;
        }

        /// <summary>
        /// Initializes a new instance of the <see cref="ResponseVariant3" /> class.
        /// </summary>
        public ResponseVariant3()
        {
        }
    }
}