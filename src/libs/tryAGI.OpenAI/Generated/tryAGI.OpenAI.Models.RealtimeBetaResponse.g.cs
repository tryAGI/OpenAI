
#pragma warning disable CS0618 // Type or member is obsolete

#nullable enable

namespace tryAGI.OpenAI
{
    /// <summary>
    /// The response resource.
    /// </summary>
    public sealed partial class RealtimeBetaResponse
    {
        /// <summary>
        /// Which conversation the response is added to, determined by the `conversation`<br/>
        /// field in the `response.create` event. If `auto`, the response will be added to<br/>
        /// the default conversation and the value of `conversation_id` will be an id like<br/>
        /// `conv_1234`. If `none`, the response will not be added to any conversation and<br/>
        /// the value of `conversation_id` will be `null`. If responses are being triggered<br/>
        /// by server VAD, the response will be added to the default conversation, thus<br/>
        /// the `conversation_id` will be an id like `conv_1234`.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("conversation_id")]
        public string? ConversationId { get; set; }

        /// <summary>
        /// The unique ID of the response.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("id")]
        public string? Id { get; set; }

        /// <summary>
        /// Maximum number of output tokens for a single assistant response,<br/>
        /// inclusive of tool calls, that was used in this response.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("max_output_tokens")]
        [global::System.Text.Json.Serialization.JsonConverter(typeof(global::tryAGI.OpenAI.JsonConverters.AnyOfJsonConverter<int?, global::tryAGI.OpenAI.RealtimeBetaResponseMaxOutputTokens?>))]
        public global::tryAGI.OpenAI.AnyOf<int?, global::tryAGI.OpenAI.RealtimeBetaResponseMaxOutputTokens?>? MaxOutputTokens { get; set; }

        /// <summary>
        /// Set of 16 key-value pairs that can be attached to an object. This can be<br/>
        /// useful for storing additional information about the object in a structured<br/>
        /// format, and querying for objects via API or the dashboard. <br/>
        /// Keys are strings with a maximum length of 64 characters. Values are strings<br/>
        /// with a maximum length of 512 characters.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("metadata")]
        public global::System.Collections.Generic.Dictionary<string, string>? Metadata { get; set; }

        /// <summary>
        /// The set of modalities the model used to respond. If there are multiple modalities,<br/>
        /// the model will pick one, for example if `modalities` is `["text", "audio"]`, the model<br/>
        /// could be responding in either text or audio.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("modalities")]
        public global::System.Collections.Generic.IList<global::tryAGI.OpenAI.RealtimeBetaResponseModalitie>? Modalities { get; set; }

        /// <summary>
        /// The object type, must be `realtime.response`.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("object")]
        [global::System.Text.Json.Serialization.JsonConverter(typeof(global::tryAGI.OpenAI.JsonConverters.RealtimeBetaResponseObjectJsonConverter))]
        public global::tryAGI.OpenAI.RealtimeBetaResponseObject? Object { get; set; }

        /// <summary>
        /// The list of output items generated by the response.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("output")]
        public global::System.Collections.Generic.IList<global::tryAGI.OpenAI.RealtimeConversationItem>? Output { get; set; }

        /// <summary>
        /// The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("output_audio_format")]
        [global::System.Text.Json.Serialization.JsonConverter(typeof(global::tryAGI.OpenAI.JsonConverters.RealtimeBetaResponseOutputAudioFormatJsonConverter))]
        public global::tryAGI.OpenAI.RealtimeBetaResponseOutputAudioFormat? OutputAudioFormat { get; set; }

        /// <summary>
        /// The final status of the response (`completed`, `cancelled`, `failed`, or <br/>
        /// `incomplete`, `in_progress`).
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("status")]
        [global::System.Text.Json.Serialization.JsonConverter(typeof(global::tryAGI.OpenAI.JsonConverters.RealtimeBetaResponseStatusJsonConverter))]
        public global::tryAGI.OpenAI.RealtimeBetaResponseStatus? Status { get; set; }

        /// <summary>
        /// Additional details about the status.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("status_details")]
        public global::tryAGI.OpenAI.RealtimeBetaResponseStatusDetails? StatusDetails { get; set; }

        /// <summary>
        /// Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("temperature")]
        public double? Temperature { get; set; }

        /// <summary>
        /// Usage statistics for the Response, this will correspond to billing. A <br/>
        /// Realtime API session will maintain a conversation context and append new <br/>
        /// Items to the Conversation, thus output from previous turns (text and <br/>
        /// audio tokens) will become the input for later turns.
        /// </summary>
        [global::System.Text.Json.Serialization.JsonPropertyName("usage")]
        public global::tryAGI.OpenAI.RealtimeBetaResponseUsage? Usage { get; set; }

        /// <summary>
        /// Example: ash
        /// </summary>
        /// <example>ash</example>
        [global::System.Text.Json.Serialization.JsonPropertyName("voice")]
        [global::System.Text.Json.Serialization.JsonConverter(typeof(global::tryAGI.OpenAI.JsonConverters.VoiceIdsSharedJsonConverter))]
        public global::tryAGI.OpenAI.VoiceIdsShared? Voice { get; set; }

        /// <summary>
        /// Additional properties that are not explicitly defined in the schema
        /// </summary>
        [global::System.Text.Json.Serialization.JsonExtensionData]
        public global::System.Collections.Generic.IDictionary<string, object> AdditionalProperties { get; set; } = new global::System.Collections.Generic.Dictionary<string, object>();

        /// <summary>
        /// Initializes a new instance of the <see cref="RealtimeBetaResponse" /> class.
        /// </summary>
        /// <param name="conversationId">
        /// Which conversation the response is added to, determined by the `conversation`<br/>
        /// field in the `response.create` event. If `auto`, the response will be added to<br/>
        /// the default conversation and the value of `conversation_id` will be an id like<br/>
        /// `conv_1234`. If `none`, the response will not be added to any conversation and<br/>
        /// the value of `conversation_id` will be `null`. If responses are being triggered<br/>
        /// by server VAD, the response will be added to the default conversation, thus<br/>
        /// the `conversation_id` will be an id like `conv_1234`.
        /// </param>
        /// <param name="id">
        /// The unique ID of the response.
        /// </param>
        /// <param name="maxOutputTokens">
        /// Maximum number of output tokens for a single assistant response,<br/>
        /// inclusive of tool calls, that was used in this response.
        /// </param>
        /// <param name="metadata">
        /// Set of 16 key-value pairs that can be attached to an object. This can be<br/>
        /// useful for storing additional information about the object in a structured<br/>
        /// format, and querying for objects via API or the dashboard. <br/>
        /// Keys are strings with a maximum length of 64 characters. Values are strings<br/>
        /// with a maximum length of 512 characters.
        /// </param>
        /// <param name="modalities">
        /// The set of modalities the model used to respond. If there are multiple modalities,<br/>
        /// the model will pick one, for example if `modalities` is `["text", "audio"]`, the model<br/>
        /// could be responding in either text or audio.
        /// </param>
        /// <param name="object">
        /// The object type, must be `realtime.response`.
        /// </param>
        /// <param name="output">
        /// The list of output items generated by the response.
        /// </param>
        /// <param name="outputAudioFormat">
        /// The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
        /// </param>
        /// <param name="status">
        /// The final status of the response (`completed`, `cancelled`, `failed`, or <br/>
        /// `incomplete`, `in_progress`).
        /// </param>
        /// <param name="statusDetails">
        /// Additional details about the status.
        /// </param>
        /// <param name="temperature">
        /// Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.
        /// </param>
        /// <param name="usage">
        /// Usage statistics for the Response, this will correspond to billing. A <br/>
        /// Realtime API session will maintain a conversation context and append new <br/>
        /// Items to the Conversation, thus output from previous turns (text and <br/>
        /// audio tokens) will become the input for later turns.
        /// </param>
        /// <param name="voice">
        /// Example: ash
        /// </param>
#if NET7_0_OR_GREATER
        [global::System.Diagnostics.CodeAnalysis.SetsRequiredMembers]
#endif
        public RealtimeBetaResponse(
            string? conversationId,
            string? id,
            global::tryAGI.OpenAI.AnyOf<int?, global::tryAGI.OpenAI.RealtimeBetaResponseMaxOutputTokens?>? maxOutputTokens,
            global::System.Collections.Generic.Dictionary<string, string>? metadata,
            global::System.Collections.Generic.IList<global::tryAGI.OpenAI.RealtimeBetaResponseModalitie>? modalities,
            global::tryAGI.OpenAI.RealtimeBetaResponseObject? @object,
            global::System.Collections.Generic.IList<global::tryAGI.OpenAI.RealtimeConversationItem>? output,
            global::tryAGI.OpenAI.RealtimeBetaResponseOutputAudioFormat? outputAudioFormat,
            global::tryAGI.OpenAI.RealtimeBetaResponseStatus? status,
            global::tryAGI.OpenAI.RealtimeBetaResponseStatusDetails? statusDetails,
            double? temperature,
            global::tryAGI.OpenAI.RealtimeBetaResponseUsage? usage,
            global::tryAGI.OpenAI.VoiceIdsShared? voice)
        {
            this.ConversationId = conversationId;
            this.Id = id;
            this.MaxOutputTokens = maxOutputTokens;
            this.Metadata = metadata;
            this.Modalities = modalities;
            this.Object = @object;
            this.Output = output;
            this.OutputAudioFormat = outputAudioFormat;
            this.Status = status;
            this.StatusDetails = statusDetails;
            this.Temperature = temperature;
            this.Usage = usage;
            this.Voice = voice;
        }

        /// <summary>
        /// Initializes a new instance of the <see cref="RealtimeBetaResponse" /> class.
        /// </summary>
        public RealtimeBetaResponse()
        {
        }
    }
}